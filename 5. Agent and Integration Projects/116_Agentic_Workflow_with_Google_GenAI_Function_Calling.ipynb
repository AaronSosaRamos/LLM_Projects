{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Agentic Workflow with Google GenAI Function Calling\n",
        "Made by: Wilfredo Aaron Sosa Ramos (AI Lab Manager at RealityAI Labs)"
      ],
      "metadata": {
        "id": "GdrMF8R77Q78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HVmMlt6o0gnF"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai google-ai-generativelanguage langchain langchain-community langchain-core langgraph langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "KUIUEMpM0twS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_google_genai = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0)"
      ],
      "metadata": {
        "id": "WpAKz4K41Ox2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class QuestionChoice(BaseModel):\n",
        "    key: str = Field(description=\"A unique identifier for the choice using letters A, B, C, or D.\")\n",
        "    value: str = Field(description=\"The text content of the choice\")\n",
        "class MultipleChoiceQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The question text\")\n",
        "    choices: List[QuestionChoice] = Field(description=\"A list of choices for the question, each with a key and a value\")\n",
        "    answer: str = Field(description=\"The key of the correct answer from the choices list\")\n",
        "    explanation: str = Field(description=\"An explanation of why the answer is correct\")\n",
        "\n",
        "class OpenEndedQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The open-ended question text\")\n",
        "    answer: str = Field(description=\"The expected correct answer\")\n",
        "    feedback: List[str] = Field(description=\"A list of possible answers for the provided question\")\n",
        "\n",
        "class QuestionList(BaseModel):\n",
        "    multiple_choice_questions: List[MultipleChoiceQuestion]\n",
        "    open_ended_questions: List[OpenEndedQuestion]"
      ],
      "metadata": {
        "id": "JOqi8bBX1b5i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_questions_for_json(output, parser):\n",
        "    return {\n",
        "        \"questions\": output,\n",
        "        \"format_instructions\": parser.get_format_instructions()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "l885DeE_5wIP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Translation tool:"
      ],
      "metadata": {
        "id": "Yt-FEqSk9AbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translation_tool(user_query: str, source_lang: str, target_lang: str):\n",
        "    \"\"\" Used for translating content from a source language to a target language. \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"You are a professional translator specializing in converting text into multiple languages with exceptional accuracy, cultural sensitivity, and tone preservation.\n",
        "                  Follow these precise instructions to ensure high-quality translations:\n",
        "\n",
        "                1. **Accuracy:** Reflect the exact meaning of the original text while adapting grammar and syntax to the target language.\n",
        "                2. **Cultural Context:** Incorporate cultural nuances, idiomatic expressions, and regional variations relevant to the target audience.\n",
        "                3. **Tone Consistency:** Maintain the tone and style of the original text, whether formal, technical, persuasive, or conversational.\n",
        "                4. **Language Expertise:** Leverage advanced linguistic knowledge to handle complex terms, technical jargon, or ambiguous phrases appropriately.\n",
        "                5. **Output Clarity:** Present translations cleanly and clearly, ensuring each language is distinct and readable.\"\"\"\n",
        "            ),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"\"\"\n",
        "                Here you have the content to translate: {user_query}\n",
        "                You have to translate it from {source_lang} to {target_lang}\n",
        "\n",
        "                Don't return the analysis, just return the final output\n",
        "\n",
        "                \"\"\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat_google_genai\n",
        "    result = chain.invoke({\n",
        "        \"user_query\": user_query,\n",
        "        \"source_lang\": source_lang,\n",
        "        \"target_lang\": target_lang\n",
        "    })\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "x7bZEqcO9DHj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Summarization tool:"
      ],
      "metadata": {
        "id": "ct6hBy5qITYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarization_tool(user_query: str, summarization_type: str):\n",
        "    \"\"\" Used for summarize content\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"\n",
        "                You are a professional summarization specialist, responsible for condensing information into concise and coherent formats while preserving key details and maintaining contextual accuracy.\n",
        "                Follow these guidelines for effective summarization:\n",
        "\n",
        "                1. **Clarity and Brevity:** Eliminate unnecessary details while ensuring the summary is clear and directly conveys the main points.\n",
        "                2. **Preserve Context:** Maintain the original meaning, emphasizing critical ideas, facts, or insights.\n",
        "                3. **Flexible Formats:** Decide whether to present the summary as a single sentence, a paragraph, or bullet points, based on the content and what best conveys the information.\n",
        "                If the user specifies a format, follow their instructions.\n",
        "                4. **Audience Awareness:** Tailor the language, tone, and level of detail to suit the target audience.\n",
        "                5. **Logical Flow:** Organize information logically, ensuring seamless understanding and flow.\n",
        "\n",
        "                Below are examples demonstrating different summarization formats:\n",
        "\n",
        "                ---\n",
        "\n",
        "                Original text:\n",
        "                \"The recent advancements in artificial intelligence have led to significant breakthroughs in natural language processing. These include improved machine translation, more accurate\n",
        "                speech recognition, and the ability to generate human-like text, transforming industries like healthcare, education, and customer service.\"\n",
        "\n",
        "                **If single sentence format is best:**\n",
        "                \"Advancements in AI have revolutionized natural language processing, enabling better translation, speech recognition, and text generation across various industries.\"\n",
        "\n",
        "                **If paragraph format is best:**\n",
        "                \"Recent progress in artificial intelligence has transformed natural language processing, with breakthroughs in machine translation, speech recognition, and text generation.\n",
        "                These advancements are driving innovation in industries such as healthcare, education, and customer service.\"\n",
        "\n",
        "                **If bullet points format is best:**\n",
        "                - AI advancements revolutionize natural language processing.\n",
        "                - Key breakthroughs:\n",
        "                  - Enhanced machine translation.\n",
        "                  - Improved speech recognition.\n",
        "                  - Human-like text generation.\n",
        "                - Impact on industries: healthcare, education, customer service.\n",
        "\n",
        "\n",
        "                \"\"\"\n",
        "            ),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"\"\"\n",
        "                Here is the content that you must summarize: {user_query}\n",
        "                And here is the summarization type: {summarization_type}\n",
        "                You must summarize in the language of the given user query.\n",
        "                \"\"\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat_google_genai\n",
        "    result = chain.invoke({\n",
        "        \"user_query\": user_query,\n",
        "        \"summarization_type\": summarization_type\n",
        "    })\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "sSyF2GSvInWc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Rewrite tool:"
      ],
      "metadata": {
        "id": "_5T0CSD8ITUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite_tool(user_query: str, focus: str, tone: str):\n",
        "    \"\"\" Used for rewriting content\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"\n",
        "                You are a professional rewriter specializing in modifying text to improve clarity, adjust tone, or provide alternative phrasing.\n",
        "                Use your expertise to decide whether to focus on clarity, tone adjustment, or alternative phrasing based on the content's context unless the user specifies their preference.\n",
        "                Follow these guidelines:\n",
        "\n",
        "                1. **Clarity and Precision:** Ensure the rewritten text is clear, concise, and easy to understand, eliminating ambiguities or overly complex language.\n",
        "                2. **Tone Adaptation:** Adjust the tone to suit the context and audience, whether formal, professional, conversational, or creative.\n",
        "                3. **Preserve Meaning:** Retain the original intent and key details while enhancing readability or style.\n",
        "                4. **Alternative Phrasing:** Provide multiple phrasings for variety or emphasis if it improves the content's impact.\n",
        "                5. **Audience-Centric:** Tailor the rewrite to meet the expectations and preferences of the target audience.\n",
        "\n",
        "                Below are examples demonstrating how to rewrite content effectively:\n",
        "\n",
        "                ---\n",
        "\n",
        "                Original text:\n",
        "                \"The new policy aims to improve employee satisfaction by offering flexible work hours and remote work opportunities.\"\n",
        "\n",
        "                **If clarity is the focus:**\n",
        "                \"The updated policy is designed to enhance employee satisfaction by introducing flexible work schedules and options for remote work.\"\n",
        "\n",
        "                **If tone adjustment is required (formal):**\n",
        "                \"The revised policy seeks to promote greater employee satisfaction by implementing flexible working hours and opportunities for remote employment.\"\n",
        "\n",
        "                **If tone adjustment is required (conversational):**\n",
        "                \"We’ve updated our policy to make employees happier, giving them more flexibility with work hours and the option to work remotely.\"\n",
        "\n",
        "                **If alternative phrasing is appropriate:**\n",
        "                1. \"To boost employee satisfaction, the new policy includes flexible scheduling and remote work possibilities.\"\n",
        "                2. \"Flexible hours and remote work are key elements of the new policy aimed at enhancing employee happiness.\"\n",
        "                \"\"\"\n",
        "            ),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"\"\"\n",
        "                Here is the content that you must rewrite: {user_query}\n",
        "                Here is the focus for the rewriting task: {focus}\n",
        "                And here is the tone for the rewriting task: {tone}\n",
        "                You must rewrite in the language of the given user query.\n",
        "                \"\"\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat_google_genai\n",
        "    result = chain.invoke({\n",
        "        \"user_query\": user_query,\n",
        "        \"focus\": focus,\n",
        "        \"tone\": tone\n",
        "    })\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "IFQQSBGhJNPU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Custom prompt tool:"
      ],
      "metadata": {
        "id": "4rA4f1RmIcWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_prompt_tool(user_query: str, action: str):\n",
        "    \"\"\" Used for managing custom prompts\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"\n",
        "                You are a professional assistant specializing in creating, managing, and reusing user-defined custom prompts. Your role is to facilitate the creation, saving,\n",
        "                and application of custom prompts to ensure users can easily define and reuse specific instructions for consistent and efficient results. Follow these guidelines:\n",
        "\n",
        "                1. **Define Custom Prompts:**\n",
        "                  - Assist users in crafting clear, detailed, and purpose-driven custom prompts tailored to their needs.\n",
        "                  - Ensure the prompts are actionable and cover all necessary instructions.\n",
        "\n",
        "                2. **Save Prompts:**\n",
        "                  - Label prompts descriptively for easy identification.\n",
        "                  - Organize prompts into categories or tags if necessary for efficient retrieval.\n",
        "\n",
        "                3. **Reuse Prompts:**\n",
        "                  - Allow users to apply saved prompts directly to new tasks or content.\n",
        "                  - Offer customization options to adapt previously saved prompts to new contexts.\n",
        "\n",
        "                4. **User Preferences:**\n",
        "                  - Default to user-defined preferences when saved prompts exist.\n",
        "                  - Suggest improvements to prompts if they can be optimized for better performance.\n",
        "\n",
        "                5. **Prompt History Management:**\n",
        "                  - Maintain a record of frequently used prompts for quick access.\n",
        "                  - Enable users to update, rename, or delete prompts as needed.\n",
        "                \"\"\"\n",
        "            ),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"\"\"\n",
        "                Here is the custom prompt: {user_query}\n",
        "                And here is the action that must be taken: {action}\n",
        "                \"\"\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat_google_genai\n",
        "    result = chain.invoke({\n",
        "        \"user_query\": user_query,\n",
        "        \"action\": action\n",
        "    })\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "5yGT8TUaMJZB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Question Generation tool:"
      ],
      "metadata": {
        "id": "1i38t0VM89WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.base import RunnableMap, RunnableLambda\n",
        "\n",
        "def generate_questions_to_json_tool(user_query: str):\n",
        "    \"\"\" Used for generating questions. The results are returned in a JSON format \"\"\"\n",
        "    prompt_generate_questions = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\n",
        "              \"system\",\n",
        "              \"You are a specialized creator of multiple choice and open-ended questions.\"\n",
        "          ),\n",
        "          (\"human\",\n",
        "          \"\"\"\n",
        "            You are a professional in creating high-quality questions for assessments, discussions, or educational purposes. Based on the provided content, generate multiple-choice and/or free-response questions. Unless the user specifies otherwise, you should independently decide the type, number, and format of the questions. If the user provides specific instructions, prioritize their preferences over your decision-making. Follow these guidelines:\n",
        "\n",
        "            1. **Clarity and Relevance:** Ensure each question is concise, focused, and directly aligned with the content.\n",
        "            2. **Dynamic Formats:** Choose the type (multiple-choice or free-response) and number of questions based on the complexity and depth of the content. Use a combination of both formats when appropriate.\n",
        "            3. **Multiple-Choice Questions:**\n",
        "              - Include one correct answer and 2–4 plausible distractors.\n",
        "              - Distractors should be logical, relevant, and neither overly obvious nor misleading.\n",
        "            4. **Free-Response Questions:**\n",
        "              - Use open-ended prompts that encourage thoughtful and detailed responses.\n",
        "              - Focus on analytical, reflective, or application-based phrasing to elicit deeper understanding.\n",
        "            5. **Challenge Level:** Adjust the difficulty of questions to match the intended audience’s knowledge level, ranging from basic recall to advanced critical thinking.\n",
        "\n",
        "            Generate a question for the following query: {user_query}. Generate questions in the language of the given user query.\n",
        "          \"\"\"\n",
        "          )\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    chain_generate_questions = prompt_generate_questions | chat_google_genai\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=QuestionList)\n",
        "    prompt_questions_to_json = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a specialized creator of multiple choice and open-ended questions in JSON.\"\n",
        "        ),\n",
        "        (\"human\",\n",
        "         \"\"\"\n",
        "         Please convert the following questions into JSON format:\n",
        "          **Tasks:**\n",
        "          1. For Multiple Choice Questions:\n",
        "            - Include the question text.\n",
        "            - Provide all choices, each with a unique key (e.g., A, B, C, D) and its corresponding value (text content).\n",
        "            - Specify the correct answer using the key of the appropriate choice.\n",
        "            - Add a brief explanation of why the answer is correct.\n",
        "\n",
        "          2. For Open-Ended Questions:\n",
        "            - Include the question text.\n",
        "            - Provide the expected correct answer.\n",
        "            - Add a list of possible feedback answers, reflecting different valid responses to the question.\n",
        "\n",
        "          3. Ensure all questions are formatted as JSON objects and grouped in a list.\n",
        "\n",
        "          **Input Questions:**\n",
        "          {questions}\n",
        "\n",
        "          **Output:**\n",
        "          You must respond as a JSON object:\n",
        "          {format_instructions}\n",
        "         \"\"\"\n",
        "        )\n",
        "    ]\n",
        "    )\n",
        "\n",
        "    chain_questions_to_json = prompt_questions_to_json | chat_google_genai\n",
        "    combined_chain = (\n",
        "        chain_generate_questions\n",
        "        | RunnableLambda(lambda x: adapt_questions_for_json(x.content, parser))\n",
        "        | chain_questions_to_json\n",
        "        | parser\n",
        "    )\n",
        "\n",
        "    result = combined_chain.invoke(user_query)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "L0_AVdHJ0-BO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_questions_to_json_tool(\"Large Language Models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_63E3Wxz5dyK",
        "outputId": "4a2a86c5-72e8-4177-a4b8-3fe021893cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'multiple_choice_questions': [{'question': 'Which of the following best describes a Large Language Model (LLM)?',\n",
              "   'choices': [{'key': 'A',\n",
              "     'value': 'A type of computer program that only understands numerical data.'},\n",
              "    {'key': 'B',\n",
              "     'value': 'A machine learning model trained on a massive dataset of text and code.'},\n",
              "    {'key': 'C',\n",
              "     'value': 'A simple algorithm that translates languages word-for-word.'},\n",
              "    {'key': 'D',\n",
              "     'value': 'A database that stores information about different languages.'}],\n",
              "   'answer': 'B',\n",
              "   'explanation': 'LLMs are machine learning models trained on vast amounts of text and code data, enabling them to understand and generate human-like text.'},\n",
              "  {'question': 'What is a key characteristic of LLMs that allows them to generate human-like text?',\n",
              "   'choices': [{'key': 'A',\n",
              "     'value': 'Their ability to perform complex mathematical calculations.'},\n",
              "    {'key': 'B',\n",
              "     'value': 'Their use of pre-programmed rules for grammar and syntax.'},\n",
              "    {'key': 'C',\n",
              "     'value': 'Their ability to learn patterns and relationships in vast amounts of text data.'},\n",
              "    {'key': 'D',\n",
              "     'value': 'Their reliance on a limited set of vocabulary and sentence structures.'}],\n",
              "   'answer': 'C',\n",
              "   'explanation': 'LLMs learn from the patterns and relationships in the text data they are trained on, which allows them to generate coherent and contextually relevant text.'},\n",
              "  {'question': 'Which of the following is a common application of Large Language Models?',\n",
              "   'choices': [{'key': 'A',\n",
              "     'value': 'Controlling robotic arms in manufacturing.'},\n",
              "    {'key': 'B', 'value': 'Predicting stock market fluctuations.'},\n",
              "    {'key': 'C',\n",
              "     'value': 'Generating creative content, such as poems and articles.'},\n",
              "    {'key': 'D', 'value': 'Analyzing geological data for oil exploration.'}],\n",
              "   'answer': 'C',\n",
              "   'explanation': 'LLMs are frequently used for generating creative content due to their ability to understand and produce human-like text.'}],\n",
              " 'open_ended_questions': [{'question': 'Explain the concept of \"training\" in the context of Large Language Models. What does it mean for an LLM to be \"trained\" on a large dataset, and how does this process affect its capabilities?',\n",
              "   'answer': 'Training an LLM involves exposing it to a massive dataset of text and code, allowing it to learn patterns, relationships, and statistical probabilities within the data. This process enables the LLM to generate text, translate languages, and perform other language-related tasks.',\n",
              "   'feedback': ['Training involves exposing the LLM to a large dataset to learn patterns.',\n",
              "    'Training allows the LLM to understand language and generate text.',\n",
              "    'The training process enables the LLM to perform various language-related tasks.']},\n",
              "  {'question': 'Discuss the potential ethical concerns associated with the use of Large Language Models. Consider issues such as bias, misinformation, and the impact on human jobs.',\n",
              "   'answer': 'Ethical concerns include the potential for bias in LLMs due to biased training data, the spread of misinformation through generated text, and the displacement of human jobs due to automation. These issues require careful consideration and mitigation strategies.',\n",
              "   'feedback': ['LLMs can exhibit bias due to biased training data.',\n",
              "    'LLMs can be used to spread misinformation.',\n",
              "    'LLMs may lead to job displacement due to automation.']},\n",
              "  {'question': 'Beyond text generation, what are some other potential applications of Large Language Models? Provide examples and explain how LLMs could be used in these contexts.',\n",
              "   'answer': 'Beyond text generation, LLMs can be used for tasks such as code generation, question answering, summarization, and even creative tasks like music composition. For example, LLMs can assist developers by generating code snippets or help researchers by summarizing large volumes of text.',\n",
              "   'feedback': ['LLMs can be used for code generation.',\n",
              "    'LLMs can be used for question answering and summarization.',\n",
              "    'LLMs can be used for creative tasks like music composition.']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Default prompt:"
      ],
      "metadata": {
        "id": "IMUAg0rTIjXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def default_prompt_tool(user_query: str):\n",
        "    \"\"\"Used for answering any kind of prompt that is not about Translation, Summarization,\n",
        "    Rewriting, Question Generation, or Custom Prompts\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"\n",
        "                You are an expert in responding to any type of query by leveraging the SYSTEM_INSTRUCTION\n",
        "                provided by the model. Your responses should be precise, informative, and tailored to the\n",
        "                user's needs, ensuring clarity and effectiveness in communication.\n",
        "                \"\"\"\n",
        "            ),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"\"\"\n",
        "                Here is the user's query: {user_query}\n",
        "                \"\"\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat_google_genai\n",
        "    result = chain.invoke({\n",
        "        \"user_query\": user_query\n",
        "    })\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "c9AUvN_VIlQj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.ai.generativelanguage_v1beta.types import content\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "krnxmAaD7pif"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    translation_tool,\n",
        "    summarization_tool,\n",
        "    rewrite_tool,\n",
        "    generate_questions_to_json_tool,\n",
        "    custom_prompt_tool,\n",
        "    default_prompt_tool\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-2.0-flash-exp',\n",
        "                              system_instruction=\"\"\"\n",
        "                                You are the **CoTeacher Assistant**, a personalized and adaptive virtual assistant dedicated to empowering educators by enhancing the teaching experience.\n",
        "                                Your role is to provide context-aware, role-specific, and actionable guidance tailored to teachers' needs. You are equipped with the following advanced tools,\n",
        "                                which allow you to address a variety of educational tasks while maintaining the user's preferred language if it differs from English:\n",
        "\n",
        "                                ### **Tool Capabilities**\n",
        "\n",
        "                                1. **Translation Tool**\n",
        "                                  - Translate text or educational materials between multiple languages.\n",
        "                                  - Ensure translations are accurate, context-appropriate, and maintain the tone and intent of the original content.\n",
        "\n",
        "                                2. **Summarization Tool**\n",
        "                                  - Condense lengthy texts, lesson materials, or research papers into concise summaries.\n",
        "                                  - Highlight key points, themes, or actionable insights for quick understanding and application.\n",
        "\n",
        "                                3. **Rewrite Tool**\n",
        "                                  - Rephrase or rewrite text to suit different reading levels, contexts, or stylistic preferences.\n",
        "                                  - Ensure clarity, engagement, and alignment with the intended audience, such as students, parents, or other educators.\n",
        "\n",
        "                                4. **Generate Questions to JSON Tool**\n",
        "                                  - Create structured questions in JSON format based on input text or materials.\n",
        "                                  - Support diverse question types (e.g., multiple choice, short answer, discussion prompts) to assist in assessments, quizzes, or learning activities.\n",
        "\n",
        "                                5. **Custom Prompt Tool**\n",
        "                                  - Create, manage, and reuse user-defined custom prompts.\n",
        "                                  - Facilitate prompt saving, organization, and application for consistent and efficient results.\n",
        "                                  - Allow users to adapt and improve prompts based on context or preferences.\n",
        "\n",
        "                                6. **Default Prompt Tool**\n",
        "                                  - Handle general prompts not covered by Translation, Summarization, Rewriting, Question Generation, or Custom Prompts.\n",
        "                                  - Leverage the SYSTEM_INSTRUCTION of the model to respond precisely and effectively to any user query.\n",
        "                                  - Provide expert-level insights, ensuring clarity and relevance in all responses.\n",
        "\n",
        "                                ### **General Assistance**\n",
        "                                Beyond these tools, you can also handle broader educational queries and tasks, providing versatile support to address any unique challenges or requirements.\n",
        "\n",
        "                                ---\n",
        "\n",
        "                                ### Professional Guidelines for Interaction:\n",
        "\n",
        "                                1. **Dynamic Adaptation**\n",
        "                                  - Analyze the teaching context provided in the interface, whether it involves lesson planning, classroom management, or student engagement.\n",
        "                                  - Customize your responses to be highly relevant and actionable for the specific situation.\n",
        "\n",
        "                                2. **Role-Specific Support**\n",
        "                                  - Collaborate as a professional partner in education by offering solutions that are practical, evidence-based, and aligned with best practices.\n",
        "\n",
        "                                3. **Clarity and Precision**\n",
        "                                  - Communicate responses clearly and concisely, ensuring they directly address the user’s inquiry or task.\n",
        "\n",
        "                                4. **Empathetic and Encouraging Tone**\n",
        "                                  - Use a supportive and positive tone to empower educators, building their confidence and enthusiasm in achieving their teaching goals.\n",
        "\n",
        "                                5. **Proactive Engagement**\n",
        "                                  - Anticipate potential needs based on the user’s input and context. Examples include:\n",
        "                                    - Suggesting tailored strategies for differentiated instruction.\n",
        "                                    - Recommending effective classroom management techniques.\n",
        "                                    - Providing constructive feedback on lesson plans.\n",
        "                                    - Offering actionable suggestions for fostering student engagement or addressing challenges.\n",
        "                              \"\"\",\n",
        "                              tools=tools)"
      ],
      "metadata": {
        "id": "C31xi75d7tYr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model._tools.to_proto()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzusUAbP7xK7",
        "outputId": "2f8e4dc5-d6c9-47c1-fb95-985ddb0371c5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[function_declarations {\n",
              "   name: \"translation_tool\"\n",
              "   description: \" Used for translating content from a source language to a target language. \"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"target_lang\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"source_lang\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "     required: \"source_lang\"\n",
              "     required: \"target_lang\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"summarization_tool\"\n",
              "   description: \" Used for summarize content\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"summarization_type\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "     required: \"summarization_type\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"rewrite_tool\"\n",
              "   description: \" Used for rewriting content\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"tone\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"focus\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "     required: \"focus\"\n",
              "     required: \"tone\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"generate_questions_to_json_tool\"\n",
              "   description: \" Used for generating questions. The results are returned in a JSON format \"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"custom_prompt_tool\"\n",
              "   description: \" Used for managing custom prompts\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     properties {\n",
              "       key: \"action\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "     required: \"action\"\n",
              "   }\n",
              " }\n",
              " function_declarations {\n",
              "   name: \"default_prompt_tool\"\n",
              "   description: \"Used for answering any kind of prompt that is not about Translation, Summarization, \\n    Rewriting, Question Generation, or Custom Prompts\"\n",
              "   parameters {\n",
              "     type_: OBJECT\n",
              "     properties {\n",
              "       key: \"user_query\"\n",
              "       value {\n",
              "         type_: STRING\n",
              "       }\n",
              "     }\n",
              "     required: \"user_query\"\n",
              "   }\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examples (Without automating agentic workflow):"
      ],
      "metadata": {
        "id": "ZNDrQ4dUBc7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Complex task: Translation + Question Generation"
      ],
      "metadata": {
        "id": "TClSSHxBB09a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"\"\"Could you convert 'Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\n",
        "These models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\n",
        "of performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\n",
        "for specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development.' into Spanish and after that creating questions from it?\"\"\")"
      ],
      "metadata": {
        "id": "7xeeNaPj74qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvCw4Q7n8WwR",
        "outputId": "2f1f16ac-8eb0-4283-f616-fd1eaa5c2073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"function_call\": {\n",
              "                  \"name\": \"translation_tool\",\n",
              "                  \"args\": {\n",
              "                    \"user_query\": \"Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\\\\nThese models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\\\\nof performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\\\\nfor specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development.\",\n",
              "                    \"target_lang\": \"Spanish\",\n",
              "                    \"source_lang\": \"English\"\n",
              "                  }\n",
              "                }\n",
              "              },\n",
              "              {\n",
              "                \"text\": \"\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            }\n",
              "          ],\n",
              "          \"citation_metadata\": {\n",
              "            \"citation_sources\": [\n",
              "              {\n",
              "                \"start_index\": 135,\n",
              "                \"end_index\": 259,\n",
              "                \"uri\": \"https://eng.unimelb.edu.au/ingenium/technology-and-society/student-programmed-office-robot-assistant-wins-top-prize-at-hri24\"\n",
              "              }\n",
              "            ]\n",
              "          },\n",
              "          \"avg_logprobs\": -0.007890262387015602\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 267,\n",
              "        \"candidates_token_count\": 132,\n",
              "        \"total_token_count\": 399\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s74xM0KH_Ze4",
        "outputId": "f6c8b1a0-b4be-412a-ed7a-dba35dcaaa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "translation_tool(user_query=Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\\nThese models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\\nof performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\\nfor specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development., target_lang=Spanish, source_lang=English)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc = response.candidates[0].content.parts[0].function_call"
      ],
      "metadata": {
        "id": "laGeDWtn_bOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmK4bsOC_hHE",
        "outputId": "3aa7bf06-8651-4a18-e194-590690f51051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name: \"translation_tool\"\n",
              "args {\n",
              "  fields {\n",
              "    key: \"user_query\"\n",
              "    value {\n",
              "      string_value: \"Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\\\\nThese models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\\\\nof performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\\\\nfor specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development.\"\n",
              "    }\n",
              "  }\n",
              "  fields {\n",
              "    key: \"target_lang\"\n",
              "    value {\n",
              "      string_value: \"Spanish\"\n",
              "    }\n",
              "  }\n",
              "  fields {\n",
              "    key: \"source_lang\"\n",
              "    value {\n",
              "      string_value: \"English\"\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = translation_tool(user_query = fc.args['user_query'], source_lang = fc.args['source_lang'], target_lang = fc.args['target_lang'])"
      ],
      "metadata": {
        "id": "HddZfXkL_n9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "B1yMHCZX_ucU",
        "outputId": "307cbc1a-f59b-44a7-ad83-65bd22c32954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    genai.protos.Content(\n",
        "    parts=[genai.protos.Part(\n",
        "        function_response = genai.protos.FunctionResponse(\n",
        "          name='translation_tool',\n",
        "          response={'result': result}))]))"
      ],
      "metadata": {
        "id": "vnsn4bIYAz9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-4pGBPtA55G",
        "outputId": "a03eb6d2-9159-488d-c4f1-c6ce1f46f155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"function_call\": {\n",
              "                  \"name\": \"generate_questions_to_json_tool\",\n",
              "                  \"args\": {\n",
              "                    \"user_query\": \"Los Modelos de Lenguaje Grandes (LLM, por sus siglas en ingl\\u00e9s) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan t\\u00e9cnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducci\\u00f3n de idiomas, el resumen, la creaci\\u00f3n de contenido e incluso la resoluci\\u00f3n de problemas complejos. Sus capacidades contin\\u00faan expandi\\u00e9ndose a medida que se ajustan para aplicaciones espec\\u00edficas, lo que los convierte en herramientas invaluables en industrias como la atenci\\u00f3n m\\u00e9dica, la educaci\\u00f3n, la atenci\\u00f3n al cliente y el desarrollo de software.\"\n",
              "                  }\n",
              "                }\n",
              "              },\n",
              "              {\n",
              "                \"text\": \"\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            }\n",
              "          ],\n",
              "          \"avg_logprobs\": -0.002819884338496644\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 581,\n",
              "        \"candidates_token_count\": 162,\n",
              "        \"total_token_count\": 743\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2UURaK9A91E",
        "outputId": "deb8f145-ee43-47c4-9fe6-0c143697055d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate_questions_to_json_tool(user_query=Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc = response.candidates[0].content.parts[0].function_call"
      ],
      "metadata": {
        "id": "MrN5dB_vA-za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCGkB9dCBB9k",
        "outputId": "f2eb0b8d-a49f-4c1c-eab1-e1f7313739e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name: \"generate_questions_to_json_tool\"\n",
              "args {\n",
              "  fields {\n",
              "    key: \"user_query\"\n",
              "    value {\n",
              "      string_value: \"Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.\"\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = generate_questions_to_json_tool(user_query = fc.args['user_query'])"
      ],
      "metadata": {
        "id": "-8ksvxPKBC9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-AK3b29Bq-h",
        "outputId": "0fff136c-d86d-4af1-e06f-2e23e8b2d3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'multiple_choice_questions': [{'question': '¿Qué son los Modelos de Lenguaje Grandes (LLM)?',\n",
              "   'choices': [{'key': 'A', 'value': 'Sistemas de almacenamiento de datos.'},\n",
              "    {'key': 'B',\n",
              "     'value': 'Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.'},\n",
              "    {'key': 'C', 'value': 'Programas de edición de texto.'},\n",
              "    {'key': 'D', 'value': 'Herramientas de diseño gráfico.'}],\n",
              "   'answer': 'B',\n",
              "   'explanation': 'Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.'},\n",
              "  {'question': '¿Qué técnica de aprendizaje profundo utilizan principalmente los LLM?',\n",
              "   'choices': [{'key': 'A', 'value': 'Redes neuronales convolucionales.'},\n",
              "    {'key': 'B', 'value': 'Máquinas de vectores de soporte.'},\n",
              "    {'key': 'C', 'value': 'Arquitecturas de transformadores.'},\n",
              "    {'key': 'D', 'value': 'Algoritmos genéticos.'}],\n",
              "   'answer': 'C',\n",
              "   'explanation': 'Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.'},\n",
              "  {'question': '¿Cuál de las siguientes NO es una función típica de los LLM?',\n",
              "   'choices': [{'key': 'A', 'value': 'Traducción de idiomas.'},\n",
              "    {'key': 'B', 'value': 'Resumen de textos.'},\n",
              "    {'key': 'C', 'value': 'Creación de contenido.'},\n",
              "    {'key': 'D', 'value': 'Control de hardware físico.'}],\n",
              "   'answer': 'D',\n",
              "   'explanation': 'Los LLM se centran en el procesamiento de texto y no están diseñados para controlar hardware físico.'}],\n",
              " 'open_ended_questions': [{'question': 'Describe brevemente cómo los LLM procesan y generan texto, mencionando las técnicas clave que utilizan.',\n",
              "   'answer': 'Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan técnicas como el auto-atención para enfocarse en las partes relevantes del texto.',\n",
              "   'feedback': ['Los LLM usan redes neuronales y transformadores para entender y generar texto.',\n",
              "    'Procesan texto mediante auto-atención para entender las relaciones entre palabras.',\n",
              "    'Utilizan técnicas de aprendizaje profundo para generar texto coherente.']},\n",
              "  {'question': 'Explica por qué los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones específicas.',\n",
              "   'answer': 'Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atención al cliente automatizada (chatbots), generación de contenido de marketing, y traducción de documentos.',\n",
              "   'feedback': ['Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.',\n",
              "    'Ejemplos de aplicaciones son chatbots, generación de contenido y traducción.',\n",
              "    'Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.']},\n",
              "  {'question': '¿Cómo crees que la continua expansión de las capacidades de los LLM podría impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desafíos.',\n",
              "   'answer': 'La expansión de los LLM podría traer beneficios como la automatización de tareas, la mejora de la comunicación y el acceso a la información. Sin embargo, también existen desafíos como la desinformación, el desplazamiento laboral y la necesidad de regular su uso ético.',\n",
              "   'feedback': ['Podrían automatizar tareas y mejorar la comunicación, pero también generar desinformación.',\n",
              "    'Los beneficios incluyen mayor acceso a la información, pero hay desafíos como el desplazamiento laboral.',\n",
              "    'Es importante considerar tanto los beneficios como los desafíos éticos y sociales de los LLM.']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    genai.protos.Content(\n",
        "    parts=[genai.protos.Part(\n",
        "        function_response = genai.protos.FunctionResponse(\n",
        "          name='generate_questions_to_json_tool',\n",
        "          response={'result': result}))]))"
      ],
      "metadata": {
        "id": "hdIhGVIkB9OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWL6nDgFCT5Q",
        "outputId": "c109ca6d-04a3-4234-d8b4-2a44b1117c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Okay, I've translated the text to Spanish and generated some questions based on it. Here are the results:\\n\\n**Spanish Translation:**\\n\\nLos Modelos de Lenguaje Grandes (LLM, por sus siglas en ingl\\u00e9s) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan t\\u00e9cnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducci\\u00f3n de idiomas, el resumen, la creaci\\u00f3n de contenido e incluso la resoluci\\u00f3n de problemas complejos. Sus capacidades contin\\u00faan expandi\\u00e9ndose a medida que se ajustan para aplicaciones espec\\u00edficas, lo que los convierte en herramientas invaluables en industrias como la atenci\\u00f3n m\\u00e9dica, la educaci\\u00f3n, la atenci\\u00f3n al cliente y el desarrollo de software.\\n\\n**Generated Questions:**\\n\\nHere are some multiple-choice and open-ended questions based on the translated text:\\n\\n**Multiple Choice Questions:**\\n\\n1.  **Question:** \\u00bfQu\\u00e9 son los Modelos de Lenguaje Grandes (LLM)?\\n    *   A) Sistemas de almacenamiento de datos.\\n    *   B) Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.\\n    *   C) Programas de edici\\u00f3n de texto.\\n    *   D) Herramientas de dise\\u00f1o gr\\u00e1fico.\\n    *   **Answer:** B\\n    *   **Explanation:** Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.\\n\\n2.  **Question:** \\u00bfQu\\u00e9 t\\u00e9cnica de aprendizaje profundo utilizan principalmente los LLM?\\n    *   A) Redes neuronales convolucionales.\\n    *   B) M\\u00e1quinas de vectores de soporte.\\n    *   C) Arquitecturas de transformadores.\\n    *   D) Algoritmos gen\\u00e9ticos.\\n    *   **Answer:** C\\n    *   **Explanation:** Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.\\n\\n3.  **Question:** \\u00bfCu\\u00e1l de las siguientes NO es una funci\\u00f3n t\\u00edpica de los LLM?\\n    *   A) Traducci\\u00f3n de idiomas.\\n    *   B) Resumen de textos.\\n    *   C) Creaci\\u00f3n de contenido.\\n    *   D) Control de hardware f\\u00edsico.\\n    *   **Answer:** D\\n    *    **Explanation:** Los LLM se centran en el procesamiento de texto y no est\\u00e1n dise\\u00f1ados para controlar hardware f\\u00edsico.\\n\\n**Open-Ended Questions:**\\n\\n1.  **Question:** Describe brevemente c\\u00f3mo los LLM procesan y generan texto, mencionando las t\\u00e9cnicas clave que utilizan.\\n    *   **Answer:** Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan t\\u00e9cnicas como el auto-atenci\\u00f3n para enfocarse en las partes relevantes del texto.\\n    *   **Feedback:**\\n        *   Los LLM usan redes neuronales y transformadores para entender y generar texto.\\n        *   Procesan texto mediante auto-atenci\\u00f3n para entender las relaciones entre palabras.\\n        *   Utilizan t\\u00e9cnicas de aprendizaje profundo para generar texto coherente.\\n\\n2.  **Question:** Explica por qu\\u00e9 los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones espec\\u00edficas.\\n    *   **Answer:** Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atenci\\u00f3n al cliente automatizada (chatbots), generaci\\u00f3n de contenido de marketing, y traducci\\u00f3n de documentos.\\n    *    **Feedback:**\\n        *   Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.\\n        *   Ejemplos de aplicaciones son chatbots, generaci\\u00f3n de contenido y traducci\\u00f3n.\\n         *  Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.\\n\\n3.  **Question:** \\u00bfC\\u00f3mo crees que la continua expansi\\u00f3n de las capacidades de los LLM podr\\u00eda impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desaf\\u00edos.\\n    *   **Answer:** La expansi\\u00f3n de los LLM podr\\u00eda traer beneficios como la automatizaci\\u00f3n de tareas, la mejora de la comunicaci\\u00f3n y el acceso a la informaci\\u00f3n. Sin embargo, tambi\\u00e9n existen desaf\\u00edos como la desinformaci\\u00f3n, el desplazamiento laboral y la necesidad de regular su uso \\u00e9tico.\\n    *   **Feedback:**\\n        *   Podr\\u00edan automatizar tareas y mejorar la comunicaci\\u00f3n, pero tambi\\u00e9n generar desinformaci\\u00f3n.\\n        *   Los beneficios incluyen mayor acceso a la informaci\\u00f3n, pero hay desaf\\u00edos como el desplazamiento laboral.\\n        *   Es importante considerar tanto los beneficios como los desaf\\u00edos \\u00e9ticos y sociales de los LLM.\\n\\nI hope this is helpful! Let me know if you have other questions.\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            }\n",
              "          ],\n",
              "          \"avg_logprobs\": -0.015742318672046327\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 1582,\n",
              "        \"candidates_token_count\": 1026,\n",
              "        \"total_token_count\": 2608\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "8gqy-JwsCalO",
        "outputId": "c12b1ef3-c965-49d5-dabe-04163f891133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, I've translated the text to Spanish and generated some questions based on it. Here are the results:\\n\\n**Spanish Translation:**\\n\\nLos Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.\\n\\n**Generated Questions:**\\n\\nHere are some multiple-choice and open-ended questions based on the translated text:\\n\\n**Multiple Choice Questions:**\\n\\n1.  **Question:** ¿Qué son los Modelos de Lenguaje Grandes (LLM)?\\n    *   A) Sistemas de almacenamiento de datos.\\n    *   B) Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.\\n    *   C) Programas de edición de texto.\\n    *   D) Herramientas de diseño gráfico.\\n    *   **Answer:** B\\n    *   **Explanation:** Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.\\n\\n2.  **Question:** ¿Qué técnica de aprendizaje profundo utilizan principalmente los LLM?\\n    *   A) Redes neuronales convolucionales.\\n    *   B) Máquinas de vectores de soporte.\\n    *   C) Arquitecturas de transformadores.\\n    *   D) Algoritmos genéticos.\\n    *   **Answer:** C\\n    *   **Explanation:** Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.\\n\\n3.  **Question:** ¿Cuál de las siguientes NO es una función típica de los LLM?\\n    *   A) Traducción de idiomas.\\n    *   B) Resumen de textos.\\n    *   C) Creación de contenido.\\n    *   D) Control de hardware físico.\\n    *   **Answer:** D\\n    *    **Explanation:** Los LLM se centran en el procesamiento de texto y no están diseñados para controlar hardware físico.\\n\\n**Open-Ended Questions:**\\n\\n1.  **Question:** Describe brevemente cómo los LLM procesan y generan texto, mencionando las técnicas clave que utilizan.\\n    *   **Answer:** Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan técnicas como el auto-atención para enfocarse en las partes relevantes del texto.\\n    *   **Feedback:**\\n        *   Los LLM usan redes neuronales y transformadores para entender y generar texto.\\n        *   Procesan texto mediante auto-atención para entender las relaciones entre palabras.\\n        *   Utilizan técnicas de aprendizaje profundo para generar texto coherente.\\n\\n2.  **Question:** Explica por qué los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones específicas.\\n    *   **Answer:** Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atención al cliente automatizada (chatbots), generación de contenido de marketing, y traducción de documentos.\\n    *    **Feedback:**\\n        *   Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.\\n        *   Ejemplos de aplicaciones son chatbots, generación de contenido y traducción.\\n         *  Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.\\n\\n3.  **Question:** ¿Cómo crees que la continua expansión de las capacidades de los LLM podría impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desafíos.\\n    *   **Answer:** La expansión de los LLM podría traer beneficios como la automatización de tareas, la mejora de la comunicación y el acceso a la información. Sin embargo, también existen desafíos como la desinformación, el desplazamiento laboral y la necesidad de regular su uso ético.\\n    *   **Feedback:**\\n        *   Podrían automatizar tareas y mejorar la comunicación, pero también generar desinformación.\\n        *   Los beneficios incluyen mayor acceso a la información, pero hay desafíos como el desplazamiento laboral.\\n        *   Es importante considerar tanto los beneficios como los desafíos éticos y sociales de los LLM.\\n\\nI hope this is helpful! Let me know if you have other questions.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "id": "3rXNny_bC9Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AUTOMATED AGENTIC WORKFLOW:"
      ],
      "metadata": {
        "id": "8EhPq9m2EPVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function_map = {\n",
        "    \"translation_tool\": translation_tool,\n",
        "    \"summarization_tool\": summarization_tool,\n",
        "    \"rewrite_tool\": rewrite_tool,\n",
        "    \"generate_questions_to_json_tool\": generate_questions_to_json_tool,\n",
        "    \"custom_prompt_tool\": custom_prompt_tool,\n",
        "    \"default_prompt_tool\": default_prompt_tool\n",
        "}"
      ],
      "metadata": {
        "id": "ZkwEqfVSEO34"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_generic_assistant(user_query: str):\n",
        "  chat = model.start_chat()\n",
        "\n",
        "  response = chat.send_message(user_query)\n",
        "\n",
        "  result = None\n",
        "\n",
        "  while True:\n",
        "      for part in response.parts:\n",
        "          if fn := part.function_call:\n",
        "              args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "              print(f\"USING THE FUNCTION: {fn.name}({args})\")\n",
        "              break\n",
        "      else:\n",
        "          print(f\"FINAL RESPONSE: {response.text}\")\n",
        "          break\n",
        "\n",
        "      fc = response.candidates[0].content.parts[0].function_call\n",
        "      result = function_map[fc.name](**fc.args)\n",
        "      print(f\"GENERATED RESULT: {result}\")\n",
        "\n",
        "      response = chat.send_message(\n",
        "          genai.protos.Content(\n",
        "              parts=[genai.protos.Part(\n",
        "                  function_response=genai.protos.FunctionResponse(\n",
        "                      name=fc.name,\n",
        "                      response={'result': result}))]))\n",
        "\n",
        "  return result, response.text"
      ],
      "metadata": {
        "id": "KYvyJlPAEU9N"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_generic_assistant(\"\"\"\n",
        "Could you convert 'Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\n",
        "These models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\n",
        "of performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\n",
        "for specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development.' into Spanish and after that creating questions from it?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xzuETK4WH2Y2",
        "outputId": "51556ade-c2d7-4318-d8d4-ddb821a45e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: translation_tool(user_query=Large Language Models (LLMs) are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\\nThese models leverage deep learning techniques, particularly transformer architectures, to process and generate text across a wide range of contexts and tasks. LLMs are capable\\nof performing diverse functions, including language translation, summarization, content creation, and even complex problem-solving. Their capabilities continue to expand as they are fine-tuned\\nfor specific applications, making them invaluable tools in industries such as healthcare, education, customer support, and software development., source_lang=English, target_lang=Spanish)\n",
            "GENERATED RESULT: Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.\n",
            "\n",
            "USING THE FUNCTION: generate_questions_to_json_tool(user_query=Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.)\n",
            "GENERATED RESULT: {'multiple_choice_questions': [{'question': '¿Qué son los Modelos de Lenguaje Grandes (LLM)?', 'choices': [{'key': 'A', 'value': 'Sistemas de almacenamiento de datos.'}, {'key': 'B', 'value': 'Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.'}, {'key': 'C', 'value': 'Programas de edición de texto.'}, {'key': 'D', 'value': 'Herramientas de diseño gráfico.'}], 'answer': 'B', 'explanation': 'Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.'}, {'question': '¿Qué técnica de aprendizaje profundo utilizan principalmente los LLM?', 'choices': [{'key': 'A', 'value': 'Redes neuronales convolucionales.'}, {'key': 'B', 'value': 'Máquinas de vectores de soporte.'}, {'key': 'C', 'value': 'Arquitecturas de transformadores.'}, {'key': 'D', 'value': 'Algoritmos genéticos.'}], 'answer': 'C', 'explanation': 'Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.'}, {'question': '¿Cuál de las siguientes NO es una función típica de los LLM?', 'choices': [{'key': 'A', 'value': 'Traducción de idiomas.'}, {'key': 'B', 'value': 'Resumen de textos.'}, {'key': 'C', 'value': 'Creación de contenido.'}, {'key': 'D', 'value': 'Control de hardware físico.'}], 'answer': 'D', 'explanation': 'Los LLM se centran en el procesamiento de texto y no están diseñados para controlar hardware físico.'}], 'open_ended_questions': [{'question': 'Describe brevemente cómo los LLM procesan y generan texto, mencionando las técnicas clave que utilizan.', 'answer': 'Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan técnicas como el auto-atención para enfocarse en las partes relevantes del texto.', 'feedback': ['Los LLM usan redes neuronales y transformadores para entender y generar texto.', 'Procesan texto mediante auto-atención para entender las relaciones entre palabras.', 'Utilizan técnicas de aprendizaje profundo para generar texto coherente.']}, {'question': 'Explica por qué los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones específicas.', 'answer': 'Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atención al cliente automatizada (chatbots), generación de contenido de marketing, y traducción de documentos.', 'feedback': ['Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.', 'Ejemplos de aplicaciones son chatbots, generación de contenido y traducción.', 'Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.']}, {'question': '¿Cómo crees que la continua expansión de las capacidades de los LLM podría impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desafíos.', 'answer': 'La expansión de los LLM podría traer beneficios como la automatización de tareas, la mejora de la comunicación y el acceso a la información. Sin embargo, también existen desafíos como la desinformación, el desplazamiento laboral y la necesidad de regular su uso ético.', 'feedback': ['Podrían automatizar tareas y mejorar la comunicación, pero también generar desinformación.', 'Los beneficios incluyen mayor acceso a la información, pero hay desafíos como el desplazamiento laboral.', 'Es importante considerar tanto los beneficios como los desafíos éticos y sociales de los LLM.']}]}\n",
            "FINAL RESPONSE: Okay, I've translated the text to Spanish and generated some questions about it. Here they are:\n",
            "\n",
            "**Spanish Translation:**\n",
            "\n",
            "Los Modelos de Lenguaje Grandes (LLM, por sus siglas en inglés) son sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto para comprender y generar lenguaje similar al humano. Estos modelos aprovechan técnicas de aprendizaje profundo, particularmente arquitecturas de transformadores, para procesar y generar texto en una amplia gama de contextos y tareas. Los LLM son capaces de realizar diversas funciones, incluyendo la traducción de idiomas, el resumen, la creación de contenido e incluso la resolución de problemas complejos. Sus capacidades continúan expandiéndose a medida que se ajustan para aplicaciones específicas, lo que los convierte en herramientas invaluables en industrias como la atención médica, la educación, la atención al cliente y el desarrollo de software.\n",
            "\n",
            "**Questions:**\n",
            "\n",
            "**Multiple Choice Questions:**\n",
            "\n",
            "1.  **Question:** ¿Qué son los Modelos de Lenguaje Grandes (LLM)?\n",
            "    *   A) Sistemas de almacenamiento de datos.\n",
            "    *   B) Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.\n",
            "    *   C) Programas de edición de texto.\n",
            "    *   D) Herramientas de diseño gráfico.\n",
            "    *   **Answer:** B\n",
            "    *   **Explanation:** Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.\n",
            "\n",
            "2.  **Question:** ¿Qué técnica de aprendizaje profundo utilizan principalmente los LLM?\n",
            "    *   A) Redes neuronales convolucionales.\n",
            "    *   B) Máquinas de vectores de soporte.\n",
            "    *   C) Arquitecturas de transformadores.\n",
            "    *   D) Algoritmos genéticos.\n",
            "    *   **Answer:** C\n",
            "    *   **Explanation:** Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.\n",
            "\n",
            "3.  **Question:** ¿Cuál de las siguientes NO es una función típica de los LLM?\n",
            "    *   A) Traducción de idiomas.\n",
            "    *   B) Resumen de textos.\n",
            "    *   C) Creación de contenido.\n",
            "    *   D) Control de hardware físico.\n",
            "    *   **Answer:** D\n",
            "    *   **Explanation:** Los LLM se centran en el procesamiento de texto y no están diseñados para controlar hardware físico.\n",
            "\n",
            "**Open-Ended Questions:**\n",
            "\n",
            "1.  **Question:** Describe brevemente cómo los LLM procesan y generan texto, mencionando las técnicas clave que utilizan.\n",
            "    *   **Answer:** Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan técnicas como el auto-atención para enfocarse en las partes relevantes del texto.\n",
            "    *   **Feedback:**\n",
            "        *   Los LLM usan redes neuronales y transformadores para entender y generar texto.\n",
            "        *   Procesan texto mediante auto-atención para entender las relaciones entre palabras.\n",
            "        *   Utilizan técnicas de aprendizaje profundo para generar texto coherente.\n",
            "\n",
            "2.  **Question:** Explica por qué los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones específicas.\n",
            "    *   **Answer:** Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atención al cliente automatizada (chatbots), generación de contenido de marketing, y traducción de documentos.\n",
            "    *   **Feedback:**\n",
            "        *   Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.\n",
            "        *   Ejemplos de aplicaciones son chatbots, generación de contenido y traducción.\n",
            "        *   Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.\n",
            "\n",
            "3.  **Question:** ¿Cómo crees que la continua expansión de las capacidades de los LLM podría impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desafíos.\n",
            "    *   **Answer:** La expansión de los LLM podría traer beneficios como la automatización de tareas, la mejora de la comunicación y el acceso a la información. Sin embargo, también existen desafíos como la desinformación, el desplazamiento laboral y la necesidad de regular su uso ético.\n",
            "    *   **Feedback:**\n",
            "        *   Podrían automatizar tareas y mejorar la comunicación, pero también generar desinformación.\n",
            "        *   Los beneficios incluyen mayor acceso a la información, pero hay desafíos como el desplazamiento laboral.\n",
            "        *   Es importante considerar tanto los beneficios como los desafíos éticos y sociales de los LLM.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'multiple_choice_questions': [{'question': '¿Qué son los Modelos de Lenguaje Grandes (LLM)?',\n",
              "   'choices': [{'key': 'A', 'value': 'Sistemas de almacenamiento de datos.'},\n",
              "    {'key': 'B',\n",
              "     'value': 'Sistemas avanzados de inteligencia artificial entrenados con grandes cantidades de datos de texto.'},\n",
              "    {'key': 'C', 'value': 'Programas de edición de texto.'},\n",
              "    {'key': 'D', 'value': 'Herramientas de diseño gráfico.'}],\n",
              "   'answer': 'B',\n",
              "   'explanation': 'Los LLM son sistemas de IA entrenados con grandes cantidades de texto para entender y generar lenguaje.'},\n",
              "  {'question': '¿Qué técnica de aprendizaje profundo utilizan principalmente los LLM?',\n",
              "   'choices': [{'key': 'A', 'value': 'Redes neuronales convolucionales.'},\n",
              "    {'key': 'B', 'value': 'Máquinas de vectores de soporte.'},\n",
              "    {'key': 'C', 'value': 'Arquitecturas de transformadores.'},\n",
              "    {'key': 'D', 'value': 'Algoritmos genéticos.'}],\n",
              "   'answer': 'C',\n",
              "   'explanation': 'Los LLM se basan principalmente en arquitecturas de transformadores debido a su capacidad para procesar secuencias de datos de manera eficiente.'},\n",
              "  {'question': '¿Cuál de las siguientes NO es una función típica de los LLM?',\n",
              "   'choices': [{'key': 'A', 'value': 'Traducción de idiomas.'},\n",
              "    {'key': 'B', 'value': 'Resumen de textos.'},\n",
              "    {'key': 'C', 'value': 'Creación de contenido.'},\n",
              "    {'key': 'D', 'value': 'Control de hardware físico.'}],\n",
              "   'answer': 'D',\n",
              "   'explanation': 'Los LLM se centran en el procesamiento de texto y no están diseñados para controlar hardware físico.'}],\n",
              " 'open_ended_questions': [{'question': 'Describe brevemente cómo los LLM procesan y generan texto, mencionando las técnicas clave que utilizan.',\n",
              "   'answer': 'Los LLM procesan texto utilizando redes neuronales, especialmente arquitecturas de transformadores, que les permiten entender las relaciones entre palabras y generar texto coherente. Utilizan técnicas como el auto-atención para enfocarse en las partes relevantes del texto.',\n",
              "   'feedback': ['Los LLM usan redes neuronales y transformadores para entender y generar texto.',\n",
              "    'Procesan texto mediante auto-atención para entender las relaciones entre palabras.',\n",
              "    'Utilizan técnicas de aprendizaje profundo para generar texto coherente.']},\n",
              "  {'question': 'Explica por qué los LLM se consideran herramientas valiosas en diversas industrias. Proporciona al menos tres ejemplos de aplicaciones específicas.',\n",
              "   'answer': 'Los LLM son valiosos por su capacidad para automatizar tareas de procesamiento de lenguaje, mejorar la eficiencia y generar contenido. Ejemplos incluyen: atención al cliente automatizada (chatbots), generación de contenido de marketing, y traducción de documentos.',\n",
              "   'feedback': ['Son valiosos por su capacidad para automatizar tareas de lenguaje y mejorar la eficiencia.',\n",
              "    'Ejemplos de aplicaciones son chatbots, generación de contenido y traducción.',\n",
              "    'Los LLM ayudan a automatizar tareas y generar contenido en diversas industrias.']},\n",
              "  {'question': '¿Cómo crees que la continua expansión de las capacidades de los LLM podría impactar la sociedad en el futuro? Considera tanto los beneficios como los posibles desafíos.',\n",
              "   'answer': 'La expansión de los LLM podría traer beneficios como la automatización de tareas, la mejora de la comunicación y el acceso a la información. Sin embargo, también existen desafíos como la desinformación, el desplazamiento laboral y la necesidad de regular su uso ético.',\n",
              "   'feedback': ['Podrían automatizar tareas y mejorar la comunicación, pero también generar desinformación.',\n",
              "    'Los beneficios incluyen mayor acceso a la información, pero hay desafíos como el desplazamiento laboral.',\n",
              "    'Es importante considerar tanto los beneficios como los desafíos éticos y sociales de los LLM.']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_generic_assistant(\"\"\"\n",
        "Could you summarize 'LLM (Large Language Model) Engineering is a specialized field within artificial intelligence that focuses on designing, fine-tuning, and optimizing large-scale\n",
        "language models to perform a wide range of natural language processing tasks. These models, such as OpenAI’s GPT, Google’s Gemini, or Meta’s LLaMA, are built on deep learning architectures,\n",
        "trained on vast datasets, and capable of understanding and generating human-like text.'\n",
        "then translate that summarization from English to Spanish and after that creating questions from it?\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cYif9C7JNz3B",
        "outputId": "4cd2b162-b66d-438e-c95a-45d790d40099"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: summarization_tool(user_query=LLM (Large Language Model) Engineering is a specialized field within artificial intelligence that focuses on designing, fine-tuning, and optimizing large-scale \\nlanguage models to perform a wide range of natural language processing tasks. These models, such as OpenAI’s GPT, Google’s Gemini, or Meta’s LLaMA, are built on deep learning architectures, \\ntrained on vast datasets, and capable of understanding and generating human-like text., summarization_type=executive)\n",
            "GENERATED RESULT: LLM Engineering is a specialized AI field focused on developing and optimizing large language models like GPT, Gemini, and LLaMA. These models, built on deep learning and trained on extensive data, are designed to understand and generate human-like text for various natural language processing tasks.\n",
            "\n",
            "USING THE FUNCTION: translation_tool(user_query=LLM Engineering is a specialized AI field focused on developing and optimizing large language models like GPT, Gemini, and LLaMA. These models, built on deep learning and trained on extensive data, are designed to understand and generate human-like text for various natural language processing tasks., source_lang=en, target_lang=es)\n",
            "GENERATED RESULT: La ingeniería de LLM es un campo especializado de la IA que se centra en el desarrollo y la optimización de modelos de lenguaje grandes como GPT, Gemini y LLaMA. Estos modelos, construidos sobre aprendizaje profundo y entrenados con datos extensos, están diseñados para comprender y generar texto similar al humano para diversas tareas de procesamiento del lenguaje natural.\n",
            "\n",
            "USING THE FUNCTION: generate_questions_to_json_tool(user_query=La ingeniería de LLM es un campo especializado de la IA que se centra en el desarrollo y la optimización de modelos de lenguaje grandes como GPT, Gemini y LLaMA. Estos modelos, construidos sobre aprendizaje profundo y entrenados con datos extensos, están diseñados para comprender y generar texto similar al humano para diversas tareas de procesamiento del lenguaje natural.)\n",
            "GENERATED RESULT: {'multiple_choice_questions': [{'question': '¿Cuál es el enfoque principal de la ingeniería de LLM?', 'choices': [{'key': 'A', 'value': 'El desarrollo de hardware para inteligencia artificial.'}, {'key': 'B', 'value': 'La creación y optimización de modelos de lenguaje grandes.'}, {'key': 'C', 'value': 'El análisis de datos para aplicaciones de negocios.'}, {'key': 'D', 'value': 'La investigación en robótica avanzada.'}], 'answer': 'B', 'explanation': 'La ingeniería de LLM se centra en la creación y optimización de modelos de lenguaje grandes, no en hardware, análisis de datos o robótica.'}, {'question': '¿Qué tipo de aprendizaje es fundamental para la construcción de modelos de lenguaje grandes (LLM)?', 'choices': [{'key': 'A', 'value': 'Aprendizaje por refuerzo.'}, {'key': 'B', 'value': 'Aprendizaje supervisado.'}, {'key': 'C', 'value': 'Aprendizaje profundo.'}, {'key': 'D', 'value': 'Aprendizaje no supervisado.'}], 'answer': 'C', 'explanation': 'El aprendizaje profundo es fundamental para la construcción de LLMs debido a su capacidad para manejar grandes cantidades de datos y aprender patrones complejos.'}, {'question': '¿Cuál de los siguientes NO es un ejemplo de un modelo de lenguaje grande (LLM) mencionado en el texto?', 'choices': [{'key': 'A', 'value': 'GPT'}, {'key': 'B', 'value': 'Gemini'}, {'key': 'C', 'value': 'LLaMA'}, {'key': 'D', 'value': 'TensorFlow'}], 'answer': 'D', 'explanation': 'TensorFlow es una biblioteca de software para aprendizaje automático, no un modelo de lenguaje grande en sí mismo. GPT, Gemini y LLaMA son ejemplos de LLMs.'}], 'open_ended_questions': [{'question': 'Describe brevemente el propósito de los modelos de lenguaje grandes (LLM) y cómo se utilizan en el procesamiento del lenguaje natural.', 'answer': 'Los LLMs están diseñados para entender y generar texto similar al humano, y se utilizan en diversas tareas de procesamiento del lenguaje natural como traducción, resumen y generación de contenido.', 'feedback': ['Los LLMs son modelos que entienden y generan texto.', 'Se usan para tareas de NLP como traducción y resumen.', 'Su propósito es procesar y generar lenguaje humano.']}, {'question': 'Explica por qué el entrenamiento con \"datos extensos\" es crucial para el desarrollo de modelos de lenguaje grandes efectivos.', 'answer': 'El entrenamiento con datos extensos permite a los LLMs aprender patrones complejos y matices del lenguaje, lo que mejora su capacidad para entender y generar texto de manera precisa y coherente.', 'feedback': ['Los datos extensos permiten aprender patrones complejos.', 'Ayuda a los modelos a entender mejor el lenguaje.', 'Mejora la precisión y coherencia en la generación de texto.']}, {'question': '¿Cómo crees que la ingeniería de LLM podría impactar diferentes industrias en el futuro? Proporciona al menos dos ejemplos específicos.', 'answer': 'La ingeniería de LLM podría impactar la industria de la salud al mejorar el diagnóstico y la atención al paciente mediante el análisis de datos médicos y la generación de informes. En la industria del servicio al cliente, podría automatizar la atención al cliente y proporcionar respuestas personalizadas a las consultas.', 'feedback': ['En salud, podría mejorar el diagnóstico y la atención.', 'En servicio al cliente, podría automatizar la atención.', 'Podría mejorar la eficiencia en diversas industrias.']}]}\n",
            "FINAL RESPONSE: Okay, I've summarized the text, translated the summary to Spanish, and generated questions based on the translated summary. Here's the breakdown:\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "LLM Engineering is a specialized AI field focused on developing and optimizing large language models like GPT, Gemini, and LLaMA. These models, built on deep learning and trained on extensive data, are designed to understand and generate human-like text for various natural language processing tasks.\n",
            "\n",
            "**Spanish Translation of the Summary:**\n",
            "\n",
            "La ingeniería de LLM es un campo especializado de la IA que se centra en el desarrollo y la optimización de modelos de lenguaje grandes como GPT, Gemini y LLaMA. Estos modelos, construidos sobre aprendizaje profundo y entrenados con datos extensos, están diseñados para comprender y generar texto similar al humano para diversas tareas de procesamiento del lenguaje natural.\n",
            "\n",
            "**Generated Questions:**\n",
            "\n",
            "I've created a mix of multiple-choice and open-ended questions in JSON format. The multiple-choice questions test comprehension of specific details, while the open-ended questions encourage deeper thinking and application of the concepts.\n",
            "\n",
            "I hope these are helpful for your needs! Let me know if you have more questions or tasks.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'multiple_choice_questions': [{'question': '¿Cuál es el enfoque principal de la ingeniería de LLM?',\n",
              "    'choices': [{'key': 'A',\n",
              "      'value': 'El desarrollo de hardware para inteligencia artificial.'},\n",
              "     {'key': 'B',\n",
              "      'value': 'La creación y optimización de modelos de lenguaje grandes.'},\n",
              "     {'key': 'C',\n",
              "      'value': 'El análisis de datos para aplicaciones de negocios.'},\n",
              "     {'key': 'D', 'value': 'La investigación en robótica avanzada.'}],\n",
              "    'answer': 'B',\n",
              "    'explanation': 'La ingeniería de LLM se centra en la creación y optimización de modelos de lenguaje grandes, no en hardware, análisis de datos o robótica.'},\n",
              "   {'question': '¿Qué tipo de aprendizaje es fundamental para la construcción de modelos de lenguaje grandes (LLM)?',\n",
              "    'choices': [{'key': 'A', 'value': 'Aprendizaje por refuerzo.'},\n",
              "     {'key': 'B', 'value': 'Aprendizaje supervisado.'},\n",
              "     {'key': 'C', 'value': 'Aprendizaje profundo.'},\n",
              "     {'key': 'D', 'value': 'Aprendizaje no supervisado.'}],\n",
              "    'answer': 'C',\n",
              "    'explanation': 'El aprendizaje profundo es fundamental para la construcción de LLMs debido a su capacidad para manejar grandes cantidades de datos y aprender patrones complejos.'},\n",
              "   {'question': '¿Cuál de los siguientes NO es un ejemplo de un modelo de lenguaje grande (LLM) mencionado en el texto?',\n",
              "    'choices': [{'key': 'A', 'value': 'GPT'},\n",
              "     {'key': 'B', 'value': 'Gemini'},\n",
              "     {'key': 'C', 'value': 'LLaMA'},\n",
              "     {'key': 'D', 'value': 'TensorFlow'}],\n",
              "    'answer': 'D',\n",
              "    'explanation': 'TensorFlow es una biblioteca de software para aprendizaje automático, no un modelo de lenguaje grande en sí mismo. GPT, Gemini y LLaMA son ejemplos de LLMs.'}],\n",
              "  'open_ended_questions': [{'question': 'Describe brevemente el propósito de los modelos de lenguaje grandes (LLM) y cómo se utilizan en el procesamiento del lenguaje natural.',\n",
              "    'answer': 'Los LLMs están diseñados para entender y generar texto similar al humano, y se utilizan en diversas tareas de procesamiento del lenguaje natural como traducción, resumen y generación de contenido.',\n",
              "    'feedback': ['Los LLMs son modelos que entienden y generan texto.',\n",
              "     'Se usan para tareas de NLP como traducción y resumen.',\n",
              "     'Su propósito es procesar y generar lenguaje humano.']},\n",
              "   {'question': 'Explica por qué el entrenamiento con \"datos extensos\" es crucial para el desarrollo de modelos de lenguaje grandes efectivos.',\n",
              "    'answer': 'El entrenamiento con datos extensos permite a los LLMs aprender patrones complejos y matices del lenguaje, lo que mejora su capacidad para entender y generar texto de manera precisa y coherente.',\n",
              "    'feedback': ['Los datos extensos permiten aprender patrones complejos.',\n",
              "     'Ayuda a los modelos a entender mejor el lenguaje.',\n",
              "     'Mejora la precisión y coherencia en la generación de texto.']},\n",
              "   {'question': '¿Cómo crees que la ingeniería de LLM podría impactar diferentes industrias en el futuro? Proporciona al menos dos ejemplos específicos.',\n",
              "    'answer': 'La ingeniería de LLM podría impactar la industria de la salud al mejorar el diagnóstico y la atención al paciente mediante el análisis de datos médicos y la generación de informes. En la industria del servicio al cliente, podría automatizar la atención al cliente y proporcionar respuestas personalizadas a las consultas.',\n",
              "    'feedback': ['En salud, podría mejorar el diagnóstico y la atención.',\n",
              "     'En servicio al cliente, podría automatizar la atención.',\n",
              "     'Podría mejorar la eficiencia en diversas industrias.']}]},\n",
              " \"Okay, I've summarized the text, translated the summary to Spanish, and generated questions based on the translated summary. Here's the breakdown:\\n\\n**Summary:**\\n\\nLLM Engineering is a specialized AI field focused on developing and optimizing large language models like GPT, Gemini, and LLaMA. These models, built on deep learning and trained on extensive data, are designed to understand and generate human-like text for various natural language processing tasks.\\n\\n**Spanish Translation of the Summary:**\\n\\nLa ingeniería de LLM es un campo especializado de la IA que se centra en el desarrollo y la optimización de modelos de lenguaje grandes como GPT, Gemini y LLaMA. Estos modelos, construidos sobre aprendizaje profundo y entrenados con datos extensos, están diseñados para comprender y generar texto similar al humano para diversas tareas de procesamiento del lenguaje natural.\\n\\n**Generated Questions:**\\n\\nI've created a mix of multiple-choice and open-ended questions in JSON format. The multiple-choice questions test comprehension of specific details, while the open-ended questions encourage deeper thinking and application of the concepts.\\n\\nI hope these are helpful for your needs! Let me know if you have more questions or tasks.\\n\")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_generic_assistant(\"\"\"\n",
        "Please, rewrite this: Retrieval-Augmented Generation (RAG) is a cutting-edge framework in artificial intelligence that combines information retrieval with generative AI models to\n",
        "enhance response quality and relevance. In RAG, an AI system retrieves relevant documents or data from an external knowledge base in real-time and uses this retrieved information\n",
        "to inform the generation of responses. This approach addresses a key limitation of generative models, which often rely solely on their pre-trained knowledge, potentially leading to\n",
        "outdated or inaccurate outputs. By integrating retrieval, RAG ensures that responses are both contextually rich and factually accurate, making it particularly valuable for applications\n",
        "like customer support, research assistance, and content generation. After that, translate it from English to German and finally summarize that content with bullet points.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "MDBIt5v4OkBW",
        "outputId": "371f8abf-a9db-495d-e344-fb995fafab08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: rewrite_tool(tone=formal, focus=RAG, user_query=Retrieval-Augmented Generation (RAG) is a cutting-edge framework in artificial intelligence that combines information retrieval with generative AI models to \\nenhance response quality and relevance. In RAG, an AI system retrieves relevant documents or data from an external knowledge base in real-time and uses this retrieved information \\nto inform the generation of responses. This approach addresses a key limitation of generative models, which often rely solely on their pre-trained knowledge, potentially leading to \\noutdated or inaccurate outputs. By integrating retrieval, RAG ensures that responses are both contextually rich and factually accurate, making it particularly valuable for applications \\nlike customer support, research assistance, and content generation.)\n",
            "GENERATED RESULT: Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG methodology, an AI system accesses and retrieves pertinent documents or data from an external knowledge repository in real-time. This retrieved information is then utilized to guide the generation of responses. This approach effectively mitigates a significant limitation inherent in generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of real-time retrieval, RAG ensures that generated responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation.\n",
            "\n",
            "USING THE FUNCTION: translation_tool(user_query=Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG methodology, an AI system accesses and retrieves pertinent documents or data from an external knowledge repository in real-time. This retrieved information is then utilized to guide the generation of responses. This approach effectively mitigates a significant limitation inherent in generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of real-time retrieval, RAG ensures that generated responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation., target_lang=German, source_lang=English)\n",
            "GENERATED RESULT: Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. In der RAG-Methodik greift ein KI-System in Echtzeit auf relevante Dokumente oder Daten aus einem externen Wissensspeicher zu und ruft diese ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Dieser Ansatz mildert effektiv eine erhebliche Einschränkung, die generativen Modellen innewohnt, welche typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten basieren, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung des Echtzeit-Abrufs stellt RAG sicher, dass generierte Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "USING THE FUNCTION: summarization_tool(user_query=Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. In der RAG-Methodik greift ein KI-System in Echtzeit auf relevante Dokumente oder Daten aus einem externen Wissensspeicher zu und ruft diese ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Dieser Ansatz mildert effektiv eine erhebliche Einschränkung, die generativen Modellen innewohnt, welche typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten basieren, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung des Echtzeit-Abrufs stellt RAG sicher, dass generierte Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung., summarization_type=bullet points)\n",
            "GENERATED RESULT: *   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\n",
            "*   RAG integriert Informationsabruf mit generativen KI-Modellen.\n",
            "*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\n",
            "*   Ein KI-System greift in Echtzeit auf externe Wissensspeicher zu.\n",
            "*   Abgerufene Informationen steuern die Antwortgenerierung.\n",
            "*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten basieren.\n",
            "*   Echtzeit-Abruf sorgt für kontextuelle und faktische Genauigkeit.\n",
            "*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "FINAL RESPONSE: Okay, here's the rewritten text, the German translation, and a summary with bullet points:\n",
            "\n",
            "**Rewritten Text (Formal Tone):**\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG methodology, an AI system accesses and retrieves pertinent documents or data from an external knowledge repository in real-time. This retrieved information is then utilized to guide the generation of responses. This approach effectively mitigates a significant limitation inherent in generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of real-time retrieval, RAG ensures that generated responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation.\n",
            "\n",
            "**German Translation:**\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. In der RAG-Methodik greift ein KI-System in Echtzeit auf relevante Dokumente oder Daten aus einem externen Wissensspeicher zu und ruft diese ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Dieser Ansatz mildert effektiv eine erhebliche Einschränkung, die generativen Modellen innewohnt, welche typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten basieren, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung des Echtzeit-Abrufs stellt RAG sicher, dass generierte Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "**Summary (Bullet Points):**\n",
            "\n",
            "*   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\n",
            "*   RAG integriert Informationsabruf mit generativen KI-Modellen.\n",
            "*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\n",
            "*   Ein KI-System greift in Echtzeit auf externe Wissensspeicher zu.\n",
            "*   Abgerufene Informationen steuern die Antwortgenerierung.\n",
            "*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten basieren.\n",
            "*   Echtzeit-Abruf sorgt für kontextuelle und faktische Genauigkeit.\n",
            "*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\\n*   RAG integriert Informationsabruf mit generativen KI-Modellen.\\n*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\\n*   Ein KI-System greift in Echtzeit auf externe Wissensspeicher zu.\\n*   Abgerufene Informationen steuern die Antwortgenerierung.\\n*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten basieren.\\n*   Echtzeit-Abruf sorgt für kontextuelle und faktische Genauigkeit.\\n*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result, response = run_generic_assistant(\"\"\"\n",
        "Please, rewrite this: Retrieval-Augmented Generation (RAG) is a cutting-edge framework in artificial intelligence that combines information retrieval with generative AI models to\n",
        "enhance response quality and relevance. In RAG, an AI system retrieves relevant documents or data from an external knowledge base in real-time and uses this retrieved information\n",
        "to inform the generation of responses. This approach addresses a key limitation of generative models, which often rely solely on their pre-trained knowledge, potentially leading to\n",
        "outdated or inaccurate outputs. By integrating retrieval, RAG ensures that responses are both contextually rich and factually accurate, making it particularly valuable for applications\n",
        "like customer support, research assistance, and content generation. After that, translate it from English to German and finally summarize that content with bullet points.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "GZu5Eng1Wda-",
        "outputId": "59c63b1f-033b-4930-bdcc-7a8554512af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: rewrite_tool(tone=formal, focus=AI, user_query=Retrieval-Augmented Generation (RAG) is a cutting-edge framework in artificial intelligence that combines information retrieval with generative AI models to enhance response quality and relevance. In RAG, an AI system retrieves relevant documents or data from an external knowledge base in real-time and uses this retrieved information to inform the generation of responses. This approach addresses a key limitation of generative models, which often rely solely on their pre-trained knowledge, potentially leading to outdated or inaccurate outputs. By integrating retrieval, RAG ensures that responses are both contextually rich and factually accurate, making it particularly valuable for applications like customer support, research assistance, and content generation.)\n",
            "GENERATED RESULT: Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG framework, an AI system dynamically retrieves pertinent documents or data from an external knowledge repository. This retrieved information is then utilized to guide the generation of responses. This methodology effectively mitigates a significant constraint of generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of retrieval processes, RAG ensures that responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation.\n",
            "\n",
            "USING THE FUNCTION: translation_tool(user_query=Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG framework, an AI system dynamically retrieves pertinent documents or data from an external knowledge repository. This retrieved information is then utilized to guide the generation of responses. This methodology effectively mitigates a significant constraint of generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of retrieval processes, RAG ensures that responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation., target_lang=German, source_lang=English)\n",
            "GENERATED RESULT: Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. Im RAG-Framework ruft ein KI-System dynamisch relevante Dokumente oder Daten aus einem externen Wissensspeicher ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Diese Methodik mildert effektiv eine wesentliche Einschränkung generativer Modelle, die typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten beruhen, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung von Abrufprozessen stellt RAG sicher, dass Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "USING THE FUNCTION: summarization_tool(user_query=Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. Im RAG-Framework ruft ein KI-System dynamisch relevante Dokumente oder Daten aus einem externen Wissensspeicher ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Diese Methodik mildert effektiv eine wesentliche Einschränkung generativer Modelle, die typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten beruhen, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung von Abrufprozessen stellt RAG sicher, dass Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung., summarization_type=bullet points)\n",
            "GENERATED RESULT: *   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\n",
            "*   RAG integriert Informationsabruf mit generativen KI-Modellen.\n",
            "*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\n",
            "*   Das System ruft dynamisch relevante Informationen aus einem externen Wissensspeicher ab.\n",
            "*   Diese Informationen steuern die Generierung von Antworten.\n",
            "*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten beruhen.\n",
            "*   Es stellt sicher, dass Antworten kontextuell und faktisch präzise sind.\n",
            "*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "FINAL RESPONSE: Okay, here's the rewritten text, its translation to German, and a summary with bullet points:\n",
            "\n",
            "**Rewritten Text (Formal Tone):**\n",
            "Retrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG framework, an AI system dynamically retrieves pertinent documents or data from an external knowledge repository. This retrieved information is then utilized to guide the generation of responses. This methodology effectively mitigates a significant constraint of generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of retrieval processes, RAG ensures that responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation.\n",
            "\n",
            "**German Translation:**\n",
            "Retrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. Im RAG-Framework ruft ein KI-System dynamisch relevante Dokumente oder Daten aus einem externen Wissensspeicher ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Diese Methodik mildert effektiv eine wesentliche Einschränkung generativer Modelle, die typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten beruhen, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung von Abrufprozessen stellt RAG sicher, dass Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n",
            "**Summary (Bullet Points):**\n",
            "*   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\n",
            "*   RAG integriert Informationsabruf mit generativen KI-Modellen.\n",
            "*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\n",
            "*   Das System ruft dynamisch relevante Informationen aus einem externen Wissensspeicher ab.\n",
            "*   Diese Informationen steuern die Generierung von Antworten.\n",
            "*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten beruhen.\n",
            "*   Es stellt sicher, dass Antworten kontextuell und faktisch präzise sind.\n",
            "*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "xd1I0BXJWlon",
        "outputId": "d1bde40a-b44c-4c82-d5cf-a0647a805a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\\n*   RAG integriert Informationsabruf mit generativen KI-Modellen.\\n*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\\n*   Das System ruft dynamisch relevante Informationen aus einem externen Wissensspeicher ab.\\n*   Diese Informationen steuern die Generierung von Antworten.\\n*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten beruhen.\\n*   Es stellt sicher, dass Antworten kontextuell und faktisch präzise sind.\\n*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "wsmfnhwIWnHK",
        "outputId": "54622bce-7364-463b-9c77-5c0ed4fdf59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, here's the rewritten text, its translation to German, and a summary with bullet points:\\n\\n**Rewritten Text (Formal Tone):**\\nRetrieval-Augmented Generation (RAG) represents an advanced framework within the field of artificial intelligence. It integrates information retrieval mechanisms with generative AI models to improve the quality and relevance of generated responses. In the RAG framework, an AI system dynamically retrieves pertinent documents or data from an external knowledge repository. This retrieved information is then utilized to guide the generation of responses. This methodology effectively mitigates a significant constraint of generative models, which typically depend exclusively on their pre-existing training data, potentially resulting in responses that are either outdated or factually incorrect. Through the incorporation of retrieval processes, RAG ensures that responses are both contextually comprehensive and factually precise. This makes it particularly advantageous for applications such as customer support, research assistance, and content creation.\\n\\n**German Translation:**\\nRetrieval-Augmented Generation (RAG) stellt einen fortschrittlichen Rahmen im Bereich der künstlichen Intelligenz dar. Es integriert Informationsabrufmechanismen mit generativen KI-Modellen, um die Qualität und Relevanz der generierten Antworten zu verbessern. Im RAG-Framework ruft ein KI-System dynamisch relevante Dokumente oder Daten aus einem externen Wissensspeicher ab. Diese abgerufenen Informationen werden dann verwendet, um die Generierung von Antworten zu steuern. Diese Methodik mildert effektiv eine wesentliche Einschränkung generativer Modelle, die typischerweise ausschließlich auf ihren vorhandenen Trainingsdaten beruhen, was potenziell zu Antworten führt, die entweder veraltet oder sachlich falsch sind. Durch die Einbeziehung von Abrufprozessen stellt RAG sicher, dass Antworten sowohl kontextuell umfassend als auch faktisch präzise sind. Dies macht es besonders vorteilhaft für Anwendungen wie Kundensupport, Forschungshilfe und Inhaltserstellung.\\n\\n**Summary (Bullet Points):**\\n*   Retrieval-Augmented Generation (RAG) ist ein fortschrittlicher KI-Rahmen.\\n*   RAG integriert Informationsabruf mit generativen KI-Modellen.\\n*   Ziel ist die Verbesserung der Qualität und Relevanz generierter Antworten.\\n*   Das System ruft dynamisch relevante Informationen aus einem externen Wissensspeicher ab.\\n*   Diese Informationen steuern die Generierung von Antworten.\\n*   RAG mildert Einschränkungen generativer Modelle, die auf Trainingsdaten beruhen.\\n*   Es stellt sicher, dass Antworten kontextuell und faktisch präzise sind.\\n*   Vorteilhaft für Kundensupport, Forschungshilfe und Inhaltserstellung.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result, response = run_generic_assistant(\"\"\"\n",
        "Generate tips for differentiated instruction\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QRH6IRRxW16H",
        "outputId": "ca1f03bd-4655-4fbf-d383-ed02095042ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: default_prompt_tool(user_query=Generate tips for differentiated instruction)\n",
            "GENERATED RESULT: Okay, I can help with that! Here are some tips for differentiated instruction, tailored to help you meet the diverse needs of your students:\n",
            "\n",
            "**Understanding Your Students**\n",
            "\n",
            "1.  **Know Your Learners:**\n",
            "    *   **Assess Regularly:** Use pre-assessments, formative assessments, and observations to understand students' prior knowledge, learning styles, and interests.\n",
            "    *   **Individual Profiles:** Create student profiles that include learning preferences, strengths, and areas for growth.\n",
            "\n",
            "**Strategies for Differentiation**\n",
            "\n",
            "2.  **Content Differentiation:**\n",
            "    *   **Vary Resources:** Provide a range of materials (e.g., texts at different reading levels, videos, audio recordings).\n",
            "    *   **Tiered Content:** Offer different levels of complexity within the same topic.\n",
            "    *   **Choice Boards:** Allow students to select from a variety of content options.\n",
            "\n",
            "3.  **Process Differentiation:**\n",
            "    *   **Flexible Grouping:** Use whole-class, small-group, and individual work based on learning needs.\n",
            "    *   **Learning Centers:** Set up stations with different activities that cater to various learning styles.\n",
            "    *   **Varied Activities:** Offer a range of activities (e.g., hands-on projects, discussions, research, presentations).\n",
            "\n",
            "4.  **Product Differentiation:**\n",
            "    *   **Choice in Output:** Allow students to demonstrate their learning through various formats (e.g., written reports, presentations, models, performances).\n",
            "    *   **Rubrics:** Provide clear rubrics that allow for different levels of complexity and creativity.\n",
            "    *   **Student-Led Projects:** Encourage students to design their own projects based on their interests.\n",
            "\n",
            "**Classroom Environment**\n",
            "\n",
            "5.  **Create a Supportive Environment:**\n",
            "    *   **Positive Culture:** Foster a classroom where students feel safe to take risks and learn from mistakes.\n",
            "    *   **Growth Mindset:** Encourage students to believe in their ability to learn and improve.\n",
            "    *   **Accessibility:** Ensure all materials and activities are accessible to all students.\n",
            "\n",
            "**Implementation Tips**\n",
            "\n",
            "6.  **Start Small:**\n",
            "    *   **Focus on One Area:** Begin by differentiating one aspect of your lesson (e.g., content, process, or product).\n",
            "    *   **Gradual Implementation:** Gradually introduce more differentiation strategies as you become comfortable.\n",
            "\n",
            "7.  **Reflect and Adjust:**\n",
            "    *   **Monitor Progress:** Regularly assess the effectiveness of your differentiation strategies.\n",
            "    *   **Seek Feedback:** Ask students for feedback on what works best for them.\n",
            "    *   **Be Flexible:** Be prepared to adjust your approach based on student needs and feedback.\n",
            "\n",
            "**Additional Tips**\n",
            "\n",
            "8.  **Use Technology:**\n",
            "    *   **Adaptive Software:** Utilize programs that adjust to students' skill levels.\n",
            "    *   **Digital Tools:** Incorporate digital tools for research, collaboration, and presentation.\n",
            "\n",
            "9.  **Collaborate:**\n",
            "    *   **Team Teaching:** Work with other teachers to share ideas and resources.\n",
            "    *   **Professional Development:** Seek out opportunities to learn more about differentiated instruction.\n",
            "\n",
            "**Example**\n",
            "\n",
            "*   **Topic:** The Water Cycle\n",
            "    *   **Content:** Provide reading materials at different levels, videos, and interactive diagrams.\n",
            "    *   **Process:** Offer options for group work, individual research, or hands-on experiments.\n",
            "    *   **Product:** Allow students to choose between creating a poster, giving a presentation, or writing a report.\n",
            "\n",
            "By implementing these tips, you can create a more inclusive and effective learning environment that meets the diverse needs of all your students. Let me know if you have any other questions or need more specific advice!\n",
            "\n",
            "FINAL RESPONSE: Okay, here are some tips for differentiated instruction:\n",
            "\n",
            "**Understanding Your Students**\n",
            "\n",
            "1.  **Know Your Learners:**\n",
            "    *   **Assess Regularly:** Use pre-assessments, formative assessments, and observations to understand students' prior knowledge, learning styles, and interests.\n",
            "    *   **Individual Profiles:** Create student profiles that include learning preferences, strengths, and areas for growth.\n",
            "\n",
            "**Strategies for Differentiation**\n",
            "\n",
            "2.  **Content Differentiation:**\n",
            "    *   **Vary Resources:** Provide a range of materials (e.g., texts at different reading levels, videos, audio recordings).\n",
            "    *   **Tiered Content:** Offer different levels of complexity within the same topic.\n",
            "    *   **Choice Boards:** Allow students to select from a variety of content options.\n",
            "\n",
            "3.  **Process Differentiation:**\n",
            "    *   **Flexible Grouping:** Use whole-class, small-group, and individual work based on learning needs.\n",
            "    *   **Learning Centers:** Set up stations with different activities that cater to various learning styles.\n",
            "    *   **Varied Activities:** Offer a range of activities (e.g., hands-on projects, discussions, research, presentations).\n",
            "\n",
            "4.  **Product Differentiation:**\n",
            "    *   **Choice in Output:** Allow students to demonstrate their learning through various formats (e.g., written reports, presentations, models, performances).\n",
            "    *   **Rubrics:** Provide clear rubrics that allow for different levels of complexity and creativity.\n",
            "    *   **Student-Led Projects:** Encourage students to design their own projects based on their interests.\n",
            "\n",
            "**Classroom Environment**\n",
            "\n",
            "5.  **Create a Supportive Environment:**\n",
            "    *   **Positive Culture:** Foster a classroom where students feel safe to take risks and learn from mistakes.\n",
            "    *   **Growth Mindset:** Encourage students to believe in their ability to learn and improve.\n",
            "    *   **Accessibility:** Ensure all materials and activities are accessible to all students.\n",
            "\n",
            "**Implementation Tips**\n",
            "\n",
            "6.  **Start Small:**\n",
            "    *   **Focus on One Area:** Begin by differentiating one aspect of your lesson (e.g., content, process, or product).\n",
            "    *   **Gradual Implementation:** Gradually introduce more differentiation strategies as you become comfortable.\n",
            "\n",
            "7.  **Reflect and Adjust:**\n",
            "    *   **Monitor Progress:** Regularly assess the effectiveness of your differentiation strategies.\n",
            "    *   **Seek Feedback:** Ask students for feedback on what works best for them.\n",
            "    *   **Be Flexible:** Be prepared to adjust your approach based on student needs and feedback.\n",
            "\n",
            "**Additional Tips**\n",
            "\n",
            "8.  **Use Technology:**\n",
            "    *   **Adaptive Software:** Utilize programs that adjust to students' skill levels.\n",
            "    *   **Digital Tools:** Incorporate digital tools for research, collaboration, and presentation.\n",
            "\n",
            "9.  **Collaborate:**\n",
            "    *   **Team Teaching:** Work with other teachers to share ideas and resources.\n",
            "    *   **Professional Development:** Seek out opportunities to learn more about differentiated instruction.\n",
            "\n",
            "**Example**\n",
            "\n",
            "*   **Topic:** The Water Cycle\n",
            "    *   **Content:** Provide reading materials at different levels, videos, and interactive diagrams.\n",
            "    *   **Process:** Offer options for group work, individual research, or hands-on experiments.\n",
            "    *   **Product:** Allow students to choose between creating a poster, giving a presentation, or writing a report.\n",
            "\n",
            "By implementing these tips, you can create a more inclusive and effective learning environment that meets the diverse needs of all your students. Let me know if you have any other questions or need more specific advice!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "U4hJRjMjXI1a",
        "outputId": "62c54802-fbdb-45e3-b5d2-a5b40238f663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, I can help with that! Here are some tips for differentiated instruction, tailored to help you meet the diverse needs of your students:\\n\\n**Understanding Your Students**\\n\\n1.  **Know Your Learners:**\\n    *   **Assess Regularly:** Use pre-assessments, formative assessments, and observations to understand students' prior knowledge, learning styles, and interests.\\n    *   **Individual Profiles:** Create student profiles that include learning preferences, strengths, and areas for growth.\\n\\n**Strategies for Differentiation**\\n\\n2.  **Content Differentiation:**\\n    *   **Vary Resources:** Provide a range of materials (e.g., texts at different reading levels, videos, audio recordings).\\n    *   **Tiered Content:** Offer different levels of complexity within the same topic.\\n    *   **Choice Boards:** Allow students to select from a variety of content options.\\n\\n3.  **Process Differentiation:**\\n    *   **Flexible Grouping:** Use whole-class, small-group, and individual work based on learning needs.\\n    *   **Learning Centers:** Set up stations with different activities that cater to various learning styles.\\n    *   **Varied Activities:** Offer a range of activities (e.g., hands-on projects, discussions, research, presentations).\\n\\n4.  **Product Differentiation:**\\n    *   **Choice in Output:** Allow students to demonstrate their learning through various formats (e.g., written reports, presentations, models, performances).\\n    *   **Rubrics:** Provide clear rubrics that allow for different levels of complexity and creativity.\\n    *   **Student-Led Projects:** Encourage students to design their own projects based on their interests.\\n\\n**Classroom Environment**\\n\\n5.  **Create a Supportive Environment:**\\n    *   **Positive Culture:** Foster a classroom where students feel safe to take risks and learn from mistakes.\\n    *   **Growth Mindset:** Encourage students to believe in their ability to learn and improve.\\n    *   **Accessibility:** Ensure all materials and activities are accessible to all students.\\n\\n**Implementation Tips**\\n\\n6.  **Start Small:**\\n    *   **Focus on One Area:** Begin by differentiating one aspect of your lesson (e.g., content, process, or product).\\n    *   **Gradual Implementation:** Gradually introduce more differentiation strategies as you become comfortable.\\n\\n7.  **Reflect and Adjust:**\\n    *   **Monitor Progress:** Regularly assess the effectiveness of your differentiation strategies.\\n    *   **Seek Feedback:** Ask students for feedback on what works best for them.\\n    *   **Be Flexible:** Be prepared to adjust your approach based on student needs and feedback.\\n\\n**Additional Tips**\\n\\n8.  **Use Technology:**\\n    *   **Adaptive Software:** Utilize programs that adjust to students' skill levels.\\n    *   **Digital Tools:** Incorporate digital tools for research, collaboration, and presentation.\\n\\n9.  **Collaborate:**\\n    *   **Team Teaching:** Work with other teachers to share ideas and resources.\\n    *   **Professional Development:** Seek out opportunities to learn more about differentiated instruction.\\n\\n**Example**\\n\\n*   **Topic:** The Water Cycle\\n    *   **Content:** Provide reading materials at different levels, videos, and interactive diagrams.\\n    *   **Process:** Offer options for group work, individual research, or hands-on experiments.\\n    *   **Product:** Allow students to choose between creating a poster, giving a presentation, or writing a report.\\n\\nBy implementing these tips, you can create a more inclusive and effective learning environment that meets the diverse needs of all your students. Let me know if you have any other questions or need more specific advice!\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "7awZSRLlXNP3",
        "outputId": "bbb04075-5ca2-4544-d89d-b9bf8c9c2f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, here are some tips for differentiated instruction:\\n\\n**Understanding Your Students**\\n\\n1.  **Know Your Learners:**\\n    *   **Assess Regularly:** Use pre-assessments, formative assessments, and observations to understand students' prior knowledge, learning styles, and interests.\\n    *   **Individual Profiles:** Create student profiles that include learning preferences, strengths, and areas for growth.\\n\\n**Strategies for Differentiation**\\n\\n2.  **Content Differentiation:**\\n    *   **Vary Resources:** Provide a range of materials (e.g., texts at different reading levels, videos, audio recordings).\\n    *   **Tiered Content:** Offer different levels of complexity within the same topic.\\n    *   **Choice Boards:** Allow students to select from a variety of content options.\\n\\n3.  **Process Differentiation:**\\n    *   **Flexible Grouping:** Use whole-class, small-group, and individual work based on learning needs.\\n    *   **Learning Centers:** Set up stations with different activities that cater to various learning styles.\\n    *   **Varied Activities:** Offer a range of activities (e.g., hands-on projects, discussions, research, presentations).\\n\\n4.  **Product Differentiation:**\\n    *   **Choice in Output:** Allow students to demonstrate their learning through various formats (e.g., written reports, presentations, models, performances).\\n    *   **Rubrics:** Provide clear rubrics that allow for different levels of complexity and creativity.\\n    *   **Student-Led Projects:** Encourage students to design their own projects based on their interests.\\n\\n**Classroom Environment**\\n\\n5.  **Create a Supportive Environment:**\\n    *   **Positive Culture:** Foster a classroom where students feel safe to take risks and learn from mistakes.\\n    *   **Growth Mindset:** Encourage students to believe in their ability to learn and improve.\\n    *   **Accessibility:** Ensure all materials and activities are accessible to all students.\\n\\n**Implementation Tips**\\n\\n6.  **Start Small:**\\n    *   **Focus on One Area:** Begin by differentiating one aspect of your lesson (e.g., content, process, or product).\\n    *   **Gradual Implementation:** Gradually introduce more differentiation strategies as you become comfortable.\\n\\n7.  **Reflect and Adjust:**\\n    *   **Monitor Progress:** Regularly assess the effectiveness of your differentiation strategies.\\n    *   **Seek Feedback:** Ask students for feedback on what works best for them.\\n    *   **Be Flexible:** Be prepared to adjust your approach based on student needs and feedback.\\n\\n**Additional Tips**\\n\\n8.  **Use Technology:**\\n    *   **Adaptive Software:** Utilize programs that adjust to students' skill levels.\\n    *   **Digital Tools:** Incorporate digital tools for research, collaboration, and presentation.\\n\\n9.  **Collaborate:**\\n    *   **Team Teaching:** Work with other teachers to share ideas and resources.\\n    *   **Professional Development:** Seek out opportunities to learn more about differentiated instruction.\\n\\n**Example**\\n\\n*   **Topic:** The Water Cycle\\n    *   **Content:** Provide reading materials at different levels, videos, and interactive diagrams.\\n    *   **Process:** Offer options for group work, individual research, or hands-on experiments.\\n    *   **Product:** Allow students to choose between creating a poster, giving a presentation, or writing a report.\\n\\nBy implementing these tips, you can create a more inclusive and effective learning environment that meets the diverse needs of all your students. Let me know if you have any other questions or need more specific advice!\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result, response = run_generic_assistant(\"\"\"\n",
        "Generate tips for differentiated instruction, and then translate that from English to Spanish\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "NOq1XeSCGl4r",
        "outputId": "060e650d-1049-46e3-d261-661d1ec5fb85"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING THE FUNCTION: default_prompt_tool(user_query=Generate a list of 5 tips for differentiated instruction)\n",
            "GENERATED RESULT: Okay, here are 5 tips for differentiated instruction:\n",
            "\n",
            "1.  **Know Your Students:** Understand their individual learning styles, strengths, weaknesses, interests, and prior knowledge. This foundational knowledge allows you to tailor instruction effectively. Use pre-assessments, surveys, and observations to gather this information.\n",
            "\n",
            "2.  **Offer Choice:** Provide students with options in how they learn and demonstrate their understanding. This could include choices in the types of activities, resources, or assessment methods. For example, allow students to choose between writing a paper, creating a presentation, or building a model to show what they've learned.\n",
            "\n",
            "3.  **Vary Content, Process, and Product:** Differentiate instruction by adjusting the content (what students learn), the process (how they learn it), and the product (how they demonstrate their learning). For example, you might provide different reading materials based on reading levels (content), offer various learning activities like group work or independent study (process), and allow students to choose how they present their final project (product).\n",
            "\n",
            "4.  **Use Flexible Grouping:** Group students in different ways based on the learning activity. Sometimes, group students by ability, interest, or learning style. Other times, use random groupings to encourage collaboration with different peers. Be sure to change groupings regularly to provide diverse learning experiences.\n",
            "\n",
            "5.  **Provide Ongoing Feedback:** Regularly check in with students to monitor their progress and provide specific, actionable feedback. This helps students understand their strengths and areas for improvement, and allows you to adjust your instruction as needed. Use a variety of feedback methods, such as written comments, verbal feedback, and peer reviews.\n",
            "\n",
            "USING THE FUNCTION: translation_tool(user_query=Okay, here are 5 tips for differentiated instruction:\\n\\n1.  **Know Your Students:** Understand their individual learning styles, strengths, weaknesses, interests, and prior knowledge. This foundational knowledge allows you to tailor instruction effectively. Use pre-assessments, surveys, and observations to gather this information.\\n\\n2.  **Offer Choice:** Provide students with options in how they learn and demonstrate their understanding. This could include choices in the types of activities, resources, or assessment methods. For example, allow students to choose between writing a paper, creating a presentation, or building a model to show what they've learned.\\n\\n3.  **Vary Content, Process, and Product:** Differentiate instruction by adjusting the content (what students learn), the process (how they learn it), and the product (how they demonstrate their learning). For example, you might provide different reading materials based on reading levels (content), offer various learning activities like group work or independent study (process), and allow students to choose how they present their final project (product).\\n\\n4.  **Use Flexible Grouping:** Group students in different ways based on the learning activity. Sometimes, group students by ability, interest, or learning style. Other times, use random groupings to encourage collaboration with different peers. Be sure to change groupings regularly to provide diverse learning experiences.\\n\\n5.  **Provide Ongoing Feedback:** Regularly check in with students to monitor their progress and provide specific, actionable feedback. This helps students understand their strengths and areas for improvement, and allows you to adjust your instruction as needed. Use a variety of feedback methods, such as written comments, verbal feedback, and peer reviews., target_lang=es, source_lang=en)\n",
            "GENERATED RESULT: Claro, aquí tienes 5 consejos para la instrucción diferenciada:\n",
            "\n",
            "1.  **Conoce a tus estudiantes:** Comprende sus estilos de aprendizaje individuales, fortalezas, debilidades, intereses y conocimientos previos. Este conocimiento fundamental te permite adaptar la instrucción de manera efectiva. Utiliza evaluaciones previas, encuestas y observaciones para recopilar esta información.\n",
            "\n",
            "2.  **Ofrece opciones:** Proporciona a los estudiantes opciones sobre cómo aprenden y demuestran su comprensión. Esto podría incluir opciones en los tipos de actividades, recursos o métodos de evaluación. Por ejemplo, permite a los estudiantes elegir entre escribir un ensayo, crear una presentación o construir un modelo para mostrar lo que han aprendido.\n",
            "\n",
            "3.  **Varía el contenido, el proceso y el producto:** Diferencia la instrucción ajustando el contenido (lo que los estudiantes aprenden), el proceso (cómo lo aprenden) y el producto (cómo demuestran su aprendizaje). Por ejemplo, podrías proporcionar diferentes materiales de lectura según los niveles de lectura (contenido), ofrecer diversas actividades de aprendizaje como trabajo en grupo o estudio independiente (proceso), y permitir que los estudiantes elijan cómo presentar su proyecto final (producto).\n",
            "\n",
            "4.  **Utiliza agrupaciones flexibles:** Agrupa a los estudiantes de diferentes maneras según la actividad de aprendizaje. A veces, agrupa a los estudiantes por habilidad, interés o estilo de aprendizaje. Otras veces, utiliza agrupaciones aleatorias para fomentar la colaboración con diferentes compañeros. Asegúrate de cambiar las agrupaciones regularmente para proporcionar diversas experiencias de aprendizaje.\n",
            "\n",
            "5.  **Proporciona retroalimentación continua:** Revisa regularmente a los estudiantes para monitorear su progreso y proporcionar retroalimentación específica y práctica. Esto ayuda a los estudiantes a comprender sus fortalezas y áreas de mejora, y te permite ajustar tu instrucción según sea necesario. Utiliza una variedad de métodos de retroalimentación, como comentarios escritos, retroalimentación verbal y revisiones por pares.\n",
            "\n",
            "FINAL RESPONSE: Here are 5 tips for differentiated instruction:\n",
            "\n",
            "1.  **Know Your Students:** Understand their individual learning styles, strengths, weaknesses, interests, and prior knowledge. This foundational knowledge allows you to tailor instruction effectively. Use pre-assessments, surveys, and observations to gather this information.\n",
            "\n",
            "2.  **Offer Choice:** Provide students with options in how they learn and demonstrate their understanding. This could include choices in the types of activities, resources, or assessment methods. For example, allow students to choose between writing a paper, creating a presentation, or building a model to show what they've learned.\n",
            "\n",
            "3.  **Vary Content, Process, and Product:** Differentiate instruction by adjusting the content (what students learn), the process (how they learn it), and the product (how they demonstrate their learning). For example, you might provide different reading materials based on reading levels (content), offer various learning activities like group work or independent study (process), and allow students to choose how they present their final project (product).\n",
            "\n",
            "4.  **Use Flexible Grouping:** Group students in different ways based on the learning activity. Sometimes, group students by ability, interest, or learning style. Other times, use random groupings to encourage collaboration with different peers. Be sure to change groupings regularly to provide diverse learning experiences.\n",
            "\n",
            "5.  **Provide Ongoing Feedback:** Regularly check in with students to monitor their progress and provide specific, actionable feedback. This helps students understand their strengths and areas for improvement, and allows you to adjust your instruction as needed. Use a variety of feedback methods, such as written comments, verbal feedback, and peer reviews.\n",
            "\n",
            "Here are the same tips translated to Spanish:\n",
            "\n",
            "Claro, aquí tienes 5 consejos para la instrucción diferenciada:\n",
            "\n",
            "1.  **Conoce a tus estudiantes:** Comprende sus estilos de aprendizaje individuales, fortalezas, debilidades, intereses y conocimientos previos. Este conocimiento fundamental te permite adaptar la instrucción de manera efectiva. Utiliza evaluaciones previas, encuestas y observaciones para recopilar esta información.\n",
            "\n",
            "2.  **Ofrece opciones:** Proporciona a los estudiantes opciones sobre cómo aprenden y demuestran su comprensión. Esto podría incluir opciones en los tipos de actividades, recursos o métodos de evaluación. Por ejemplo, permite a los estudiantes elegir entre escribir un ensayo, crear una presentación o construir un modelo para mostrar lo que han aprendido.\n",
            "\n",
            "3.  **Varía el contenido, el proceso y el producto:** Diferencia la instrucción ajustando el contenido (lo que los estudiantes aprenden), el proceso (cómo lo aprenden) y el producto (cómo demuestran su aprendizaje). Por ejemplo, podrías proporcionar diferentes materiales de lectura según los niveles de lectura (contenido), ofrecer diversas actividades de aprendizaje como trabajo en grupo o estudio independiente (proceso), y permitir que los estudiantes elijan cómo presentar su proyecto final (producto).\n",
            "\n",
            "4.  **Utiliza agrupaciones flexibles:** Agrupa a los estudiantes de diferentes maneras según la actividad de aprendizaje. A veces, agrupa a los estudiantes por habilidad, interés o estilo de aprendizaje. Otras veces, utiliza agrupaciones aleatorias para fomentar la colaboración con diferentes compañeros. Asegúrate de cambiar las agrupaciones regularmente para proporcionar diversas experiencias de aprendizaje.\n",
            "\n",
            "5.  **Proporciona retroalimentación continua:** Revisa regularmente a los estudiantes para monitorear su progreso y proporcionar retroalimentación específica y práctica. Esto ayuda a los estudiantes a comprender sus fortalezas y áreas de mejora, y te permite ajustar tu instrucción según sea necesario. Utiliza una variedad de métodos de retroalimentación, como comentarios escritos, retroalimentación verbal y revisiones por pares.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "NZVwYC0II6GM",
        "outputId": "42901402-f033-43b8-adb9-ccad12ec241f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Claro, aquí tienes 5 consejos para la instrucción diferenciada:\\n\\n1.  **Conoce a tus estudiantes:** Comprende sus estilos de aprendizaje individuales, fortalezas, debilidades, intereses y conocimientos previos. Este conocimiento fundamental te permite adaptar la instrucción de manera efectiva. Utiliza evaluaciones previas, encuestas y observaciones para recopilar esta información.\\n\\n2.  **Ofrece opciones:** Proporciona a los estudiantes opciones sobre cómo aprenden y demuestran su comprensión. Esto podría incluir opciones en los tipos de actividades, recursos o métodos de evaluación. Por ejemplo, permite a los estudiantes elegir entre escribir un ensayo, crear una presentación o construir un modelo para mostrar lo que han aprendido.\\n\\n3.  **Varía el contenido, el proceso y el producto:** Diferencia la instrucción ajustando el contenido (lo que los estudiantes aprenden), el proceso (cómo lo aprenden) y el producto (cómo demuestran su aprendizaje). Por ejemplo, podrías proporcionar diferentes materiales de lectura según los niveles de lectura (contenido), ofrecer diversas actividades de aprendizaje como trabajo en grupo o estudio independiente (proceso), y permitir que los estudiantes elijan cómo presentar su proyecto final (producto).\\n\\n4.  **Utiliza agrupaciones flexibles:** Agrupa a los estudiantes de diferentes maneras según la actividad de aprendizaje. A veces, agrupa a los estudiantes por habilidad, interés o estilo de aprendizaje. Otras veces, utiliza agrupaciones aleatorias para fomentar la colaboración con diferentes compañeros. Asegúrate de cambiar las agrupaciones regularmente para proporcionar diversas experiencias de aprendizaje.\\n\\n5.  **Proporciona retroalimentación continua:** Revisa regularmente a los estudiantes para monitorear su progreso y proporcionar retroalimentación específica y práctica. Esto ayuda a los estudiantes a comprender sus fortalezas y áreas de mejora, y te permite ajustar tu instrucción según sea necesario. Utiliza una variedad de métodos de retroalimentación, como comentarios escritos, retroalimentación verbal y revisiones por pares.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "ybSSp3gwJCDD",
        "outputId": "56ec13af-81ad-468c-a271-7c96b7a5cb39"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here are 5 tips for differentiated instruction:\\n\\n1.  **Know Your Students:** Understand their individual learning styles, strengths, weaknesses, interests, and prior knowledge. This foundational knowledge allows you to tailor instruction effectively. Use pre-assessments, surveys, and observations to gather this information.\\n\\n2.  **Offer Choice:** Provide students with options in how they learn and demonstrate their understanding. This could include choices in the types of activities, resources, or assessment methods. For example, allow students to choose between writing a paper, creating a presentation, or building a model to show what they've learned.\\n\\n3.  **Vary Content, Process, and Product:** Differentiate instruction by adjusting the content (what students learn), the process (how they learn it), and the product (how they demonstrate their learning). For example, you might provide different reading materials based on reading levels (content), offer various learning activities like group work or independent study (process), and allow students to choose how they present their final project (product).\\n\\n4.  **Use Flexible Grouping:** Group students in different ways based on the learning activity. Sometimes, group students by ability, interest, or learning style. Other times, use random groupings to encourage collaboration with different peers. Be sure to change groupings regularly to provide diverse learning experiences.\\n\\n5.  **Provide Ongoing Feedback:** Regularly check in with students to monitor their progress and provide specific, actionable feedback. This helps students understand their strengths and areas for improvement, and allows you to adjust your instruction as needed. Use a variety of feedback methods, such as written comments, verbal feedback, and peer reviews.\\n\\nHere are the same tips translated to Spanish:\\n\\nClaro, aquí tienes 5 consejos para la instrucción diferenciada:\\n\\n1.  **Conoce a tus estudiantes:** Comprende sus estilos de aprendizaje individuales, fortalezas, debilidades, intereses y conocimientos previos. Este conocimiento fundamental te permite adaptar la instrucción de manera efectiva. Utiliza evaluaciones previas, encuestas y observaciones para recopilar esta información.\\n\\n2.  **Ofrece opciones:** Proporciona a los estudiantes opciones sobre cómo aprenden y demuestran su comprensión. Esto podría incluir opciones en los tipos de actividades, recursos o métodos de evaluación. Por ejemplo, permite a los estudiantes elegir entre escribir un ensayo, crear una presentación o construir un modelo para mostrar lo que han aprendido.\\n\\n3.  **Varía el contenido, el proceso y el producto:** Diferencia la instrucción ajustando el contenido (lo que los estudiantes aprenden), el proceso (cómo lo aprenden) y el producto (cómo demuestran su aprendizaje). Por ejemplo, podrías proporcionar diferentes materiales de lectura según los niveles de lectura (contenido), ofrecer diversas actividades de aprendizaje como trabajo en grupo o estudio independiente (proceso), y permitir que los estudiantes elijan cómo presentar su proyecto final (producto).\\n\\n4.  **Utiliza agrupaciones flexibles:** Agrupa a los estudiantes de diferentes maneras según la actividad de aprendizaje. A veces, agrupa a los estudiantes por habilidad, interés o estilo de aprendizaje. Otras veces, utiliza agrupaciones aleatorias para fomentar la colaboración con diferentes compañeros. Asegúrate de cambiar las agrupaciones regularmente para proporcionar diversas experiencias de aprendizaje.\\n\\n5.  **Proporciona retroalimentación continua:** Revisa regularmente a los estudiantes para monitorear su progreso y proporcionar retroalimentación específica y práctica. Esto ayuda a los estudiantes a comprender sus fortalezas y áreas de mejora, y te permite ajustar tu instrucción según sea necesario. Utiliza una variedad de métodos de retroalimentación, como comentarios escritos, retroalimentación verbal y revisiones por pares.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}