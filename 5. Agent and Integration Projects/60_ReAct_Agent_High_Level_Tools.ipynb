{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8bcd1a3d-7c50-4f58-be4e-1ed654aa33be",
      "metadata": {
        "id": "8bcd1a3d-7c50-4f58-be4e-1ed654aa33be"
      },
      "source": [
        "# ReAct agent with tool calling\n",
        "\n",
        "This notebook walks through an example creating a ReAct Agent that uses tool calling.\n",
        "This is useful for getting started quickly.\n",
        "However, it is highly likely you will want to customize the logic - for information on that, check out the other examples in this folder."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e130cf70-a30e-47d7-8fd5-464f1a92e374",
      "metadata": {
        "id": "e130cf70-a30e-47d7-8fd5-464f1a92e374"
      },
      "source": [
        "## Set up the chat model and tools\n",
        "\n",
        "Here we will define the chat model and tools that we want to use.\n",
        "Importantly, this model MUST support OpenAI function calling."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet -U langgraph langchain langchain_openai tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cV2hADHY2bA",
        "outputId": "56209596-f7fd-4c91-d885-e9131410fce0"
      },
      "id": "5cV2hADHY2bA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.9/378.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR0FgJlEY9ln",
        "outputId": "e757eb1b-c453-43c9-af29-f5e281840946"
      },
      "id": "pR0FgJlEY9ln",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "NEW4fs8IY5FQ"
      },
      "id": "NEW4fs8IY5FQ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "efb7e3c0-c63f-40f6-93ce-19681d650fc2",
      "metadata": {
        "id": "efb7e3c0-c63f-40f6-93ce-19681d650fc2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a7025f33-3160-41cf-868b-17ebc916fb1d",
      "metadata": {
        "id": "a7025f33-3160-41cf-868b-17ebc916fb1d"
      },
      "outputs": [],
      "source": [
        "tools = [TavilySearchResults(max_results=1)]\n",
        "model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43064805-2ac9-4b5a-850c-a68dd7282350",
      "metadata": {
        "id": "43064805-2ac9-4b5a-850c-a68dd7282350"
      },
      "source": [
        "## Create executor\n",
        "\n",
        "We can now use the high level interface to create the executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "32b4ae66-f667-4a8b-a602-503fd0effcd9",
      "metadata": {
        "id": "32b4ae66-f667-4a8b-a602-503fd0effcd9"
      },
      "outputs": [],
      "source": [
        "app = create_react_agent(model, tools=tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63dbfc7-a5c1-4a03-991c-f0789ba52c52",
      "metadata": {
        "id": "d63dbfc7-a5c1-4a03-991c-f0789ba52c52"
      },
      "source": [
        "We can now invoke this executor. The input to this must be a dictionary with a single `messages` key that contains a list of messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0abc5655-d772-450c-832f-1fee1111a5f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0abc5655-d772-450c-832f-1fee1111a5f6",
        "outputId": "7c891be9-e5c8-41b6-ce82-07dd6a1ab38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_e8AdRqfb2twdUOBsEFhafIq8', 'function': {'arguments': '{\"query\": \"weather in San Jerónimo de Tunán, Junin, Peru\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_IgOJN1PsIn3u1EISW0zuSrVo', 'function': {'arguments': '{\"query\": \"weather in Tarma, Junin, Peru\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 103, 'total_tokens': 175}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f3c5e2d6-65b7-40d3-943b-13f1ceeb7de7-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Jerónimo de Tunán, Junin, Peru'}, 'id': 'call_e8AdRqfb2twdUOBsEFhafIq8', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Tarma, Junin, Peru'}, 'id': 'call_IgOJN1PsIn3u1EISW0zuSrVo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 72, 'total_tokens': 175})]}\n",
            "----\n",
            "{'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Pedro De Cajas\\', \\'region\\': \\'Junin\\', \\'country\\': \\'Peru\\', \\'lat\\': -11.25, \\'lon\\': -75.86, \\'tz_id\\': \\'America/Lima\\', \\'localtime_epoch\\': 1722523307, \\'localtime\\': \\'2024-08-01 9:41\\'}, \\'current\\': {\\'last_updated_epoch\\': 1722522600, \\'last_updated\\': \\'2024-08-01 09:30\\', \\'temp_c\\': 7.1, \\'temp_f\\': 44.8, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 2.7, \\'wind_kph\\': 4.3, \\'wind_degree\\': 55, \\'wind_dir\\': \\'NE\\', \\'pressure_mb\\': 1024.0, \\'pressure_in\\': 30.23, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 64, \\'cloud\\': 7, \\'feelslike_c\\': 6.7, \\'feelslike_f\\': 44.1, \\'windchill_c\\': 6.7, \\'windchill_f\\': 44.1, \\'heatindex_c\\': 7.1, \\'heatindex_f\\': 44.8, \\'dewpoint_c\\': 0.7, \\'dewpoint_f\\': 33.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 4.0, \\'gust_mph\\': 3.1, \\'gust_kph\\': 5.0}}\"}]', name='tavily_search_results_json', tool_call_id='call_e8AdRqfb2twdUOBsEFhafIq8'), ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Tarma\\', \\'region\\': \\'Junin\\', \\'country\\': \\'Peru\\', \\'lat\\': -11.42, \\'lon\\': -75.69, \\'tz_id\\': \\'America/Lima\\', \\'localtime_epoch\\': 1722523307, \\'localtime\\': \\'2024-08-01 9:41\\'}, \\'current\\': {\\'last_updated_epoch\\': 1722522600, \\'last_updated\\': \\'2024-08-01 09:30\\', \\'temp_c\\': 7.1, \\'temp_f\\': 44.8, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 2.7, \\'wind_kph\\': 4.3, \\'wind_degree\\': 55, \\'wind_dir\\': \\'NE\\', \\'pressure_mb\\': 1024.0, \\'pressure_in\\': 30.23, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 64, \\'cloud\\': 7, \\'feelslike_c\\': 6.7, \\'feelslike_f\\': 44.1, \\'windchill_c\\': 6.7, \\'windchill_f\\': 44.1, \\'heatindex_c\\': 7.1, \\'heatindex_f\\': 44.8, \\'dewpoint_c\\': 0.7, \\'dewpoint_f\\': 33.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 4.0, \\'gust_mph\\': 3.1, \\'gust_kph\\': 5.0}}\"}]', name='tavily_search_results_json', tool_call_id='call_IgOJN1PsIn3u1EISW0zuSrVo')]}\n",
            "----\n",
            "{'messages': [AIMessage(content='The current weather in **San Jerónimo de Tunán, Junin, Peru** is **Sunny** with a temperature of **7.1°C** (44.8°F). The wind is coming from the northeast at **4.3 km/h**.\\n\\nThe current weather in **Tarma, Junin, Peru** is also **Sunny** with a temperature of **7.1°C** (44.8°F). The wind is coming from the northeast at **4.3 km/h**.', response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 995, 'total_tokens': 1102}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a73ae42a-9e10-4e82-8136-1ff723b5797e-0', usage_metadata={'input_tokens': 995, 'output_tokens': 107, 'total_tokens': 1102})]}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in San Jerónimo de Tunán and Tarma, Junin, Perú?\")]}\n",
        "for s in app.stream(inputs):\n",
        "    print(list(s.values())[0])\n",
        "    print(\"----\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}