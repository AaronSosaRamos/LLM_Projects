{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chonkie SentenceChunker\n",
        "Made by: Wilfredo Aaron Sosa Ramos"
      ],
      "metadata": {
        "id": "GO3slet5cq_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCZuwl_Wcpcg",
        "outputId": "6ecd295f-1400-4e08-8587-bfe02236493d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q chonkie[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single Text Chunking"
      ],
      "metadata": {
        "id": "1pRkOBTJdeh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import SentenceChunker\n",
        "\n",
        "# Basic initialization with default parameters\n",
        "chunker = SentenceChunker(\n",
        "    tokenizer=\"gpt2\",                # Supports string identifiers\n",
        "    chunk_size=128,                  # Maximum tokens per chunk\n",
        "    chunk_overlap=32,               # Overlap between chunks\n",
        "    min_sentences_per_chunk=1        # Minimum sentences in each chunk\n",
        ")\n"
      ],
      "metadata": {
        "id": "s4cMLGmDc1s9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "1. The Evolution of LLM Engineering\n",
        "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
        "\n",
        "2. The Science of Prompt Design\n",
        "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
        "\n",
        "3. Advanced Prompting Techniques and Applications\n",
        "Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
        "\n",
        "4. Integration with External Systems\n",
        "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
        "\n",
        "5. Ethical Considerations in LLM Engineering\n",
        "As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
        "\n",
        "6. The Future of LLM Engineering and Prompting\n",
        "The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
        "\"\"\"\n",
        "chunks = chunker.chunk(text)\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(f\"Chunk text: {chunk.text}\")\n",
        "    print(f\"Token count: {chunk.token_count}\")\n",
        "    print(f\"Number of sentences: {len(chunk.sentences)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG-rzkPQc5pD",
        "outputId": "b47037a5-904d-4524-c37c-a38c221ff1ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk text: \n",
            "1. The Evolution of LLM Engineering\n",
            "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\n",
            "Token count: 109\n",
            "Number of sentences: 6\n",
            "Chunk text:  LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "\n",
            "2. The Science of Prompt Design\n",
            "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\n",
            "Token count: 102\n",
            "Number of sentences: 4\n",
            "Chunk text:  The Science of Prompt Design\n",
            "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\n",
            "Token count: 117\n",
            "Number of sentences: 5\n",
            "Chunk text:  Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "\n",
            "3. Advanced Prompting Techniques and Applications\n",
            "Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\n",
            "Token count: 107\n",
            "Number of sentences: 5\n",
            "Chunk text:  For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "\n",
            "4. Integration with External Systems\n",
            "\n",
            "Token count: 108\n",
            "Number of sentences: 5\n",
            "Chunk text:  By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "\n",
            "4. Integration with External Systems\n",
            "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\n",
            "Token count: 112\n",
            "Number of sentences: 5\n",
            "Chunk text:  For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "\n",
            "5. Ethical Considerations in LLM Engineering\n",
            "As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\n",
            "Token count: 111\n",
            "Number of sentences: 5\n",
            "Chunk text:  Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "\n",
            "6. The Future of LLM Engineering and Prompting\n",
            "\n",
            "Token count: 102\n",
            "Number of sentences: 5\n",
            "Chunk text:  The Future of LLM Engineering and Prompting\n",
            "The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\n",
            "Token count: 103\n",
            "Number of sentences: 4\n",
            "Chunk text:  Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
            "\n",
            "Token count: 60\n",
            "Number of sentences: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batch Chunking"
      ],
      "metadata": {
        "id": "clu5vu5bdXJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The Evolution of LLM Engineering\n",
        "evolution_of_llm_engineering = [\n",
        "    \"LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\",\n",
        "    \"These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\",\n",
        "    \"However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\",\n",
        "    \"LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\",\n",
        "    \"It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\"\n",
        "]\n",
        "\n",
        "# 2. The Science of Prompt Design\n",
        "science_of_prompt_design = [\n",
        "    \"Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\",\n",
        "    \"Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\",\n",
        "    \"Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\",\n",
        "    \"Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\",\n",
        "    \"By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\"\n",
        "]\n",
        "\n",
        "# 3. Advanced Prompting Techniques and Applications\n",
        "advanced_prompting_techniques = [\n",
        "    \"Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\",\n",
        "    \"For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\",\n",
        "    \"Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\",\n",
        "    \"These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\",\n",
        "    \"By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\"\n",
        "]\n",
        "\n",
        "# 4. Integration with External Systems\n",
        "integration_with_external_systems = [\n",
        "    \"Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\",\n",
        "    \"Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\",\n",
        "    \"For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\",\n",
        "    \"This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\",\n",
        "    \"It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\"\n",
        "]\n",
        "\n",
        "# 5. Ethical Considerations in LLM Engineering\n",
        "ethical_considerations = [\n",
        "    \"As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\",\n",
        "    \"Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\",\n",
        "    \"Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\",\n",
        "    \"Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\",\n",
        "    \"Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\"\n",
        "]\n",
        "\n",
        "# 6. The Future of LLM Engineering and Prompting\n",
        "future_of_llm_engineering = [\n",
        "    \"The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\",\n",
        "    \"Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\",\n",
        "    \"Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\",\n",
        "    \"As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\",\n",
        "    \"They will drive innovation while upholding ethical and technical standards.\"\n",
        "]\n",
        "texts = evolution_of_llm_engineering + science_of_prompt_design + advanced_prompting_techniques + integration_with_external_systems + ethical_considerations + future_of_llm_engineering"
      ],
      "metadata": {
        "id": "rkbTWAQfdT6W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_chunks = chunker.chunk_batch(texts)\n",
        "\n",
        "for doc_chunks in batch_chunks:\n",
        "    for chunk in doc_chunks:\n",
        "        print(f\"Chunk: {chunk.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YCM1XnadRqT",
        "outputId": "80101ea4-a767-41f1-fe09-0c314df9da8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk: LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\n",
            "Chunk: These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\n",
            "Chunk: However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\n",
            "Chunk: LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\n",
            "Chunk: It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "Chunk: Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\n",
            "Chunk: Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\n",
            "Chunk: Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\n",
            "Chunk: Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\n",
            "Chunk: By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "Chunk: Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\n",
            "Chunk: For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\n",
            "Chunk: Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\n",
            "Chunk: These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\n",
            "Chunk: By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "Chunk: Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\n",
            "Chunk: Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\n",
            "Chunk: For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\n",
            "Chunk: This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\n",
            "Chunk: It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "Chunk: As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\n",
            "Chunk: Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\n",
            "Chunk: Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\n",
            "Chunk: Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\n",
            "Chunk: Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "Chunk: The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\n",
            "Chunk: Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\n",
            "Chunk: Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\n",
            "Chunk: As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\n",
            "Chunk: They will drive innovation while upholding ethical and technical standards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using as a Callable"
      ],
      "metadata": {
        "id": "bUh9bqqgdiaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single text\n",
        "chunks = chunker(text)\n",
        "\n",
        "# Multiple texts\n",
        "batch_chunks = chunker(texts)"
      ],
      "metadata": {
        "id": "fDxG5ogodjUe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc3OayKqdkhy",
        "outputId": "70e7b0db-88c3-4789-80e3-c8fccca2a7d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SentenceChunk(text='\\n1. The Evolution of LLM Engineering\\nLLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=0, end_index=629, token_count=109, context=None, sentences=[Sentence(text='\\n1.', start_index=0, end_index=3, token_count=1), Sentence(text=' The Evolution of LLM Engineering\\n', start_index=3, end_index=37, token_count=5.0), Sentence(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.', start_index=37, end_index=197, token_count=26.0), Sentence(text=' These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.', start_index=197, end_index=354, token_count=26.0), Sentence(text=' However, their true utility lies in how they are engineered to interact with specific tasks and contexts.', start_index=354, end_index=460, token_count=17.0), Sentence(text=' LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=460, end_index=629, token_count=28.0)]),\n",
              " SentenceChunk(text=' LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2. The Science of Prompt Design\\nCentral to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=460, end_index=1008, token_count=102, context=None, sentences=[Sentence(text=' LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=460, end_index=629, token_count=28.0), Sentence(text=' It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2.', start_index=629, end_index=835, token_count=34.0), Sentence(text=' The Science of Prompt Design\\n', start_index=835, end_index=865, token_count=5.0), Sentence(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=865, end_index=1008, token_count=23.0)]),\n",
              " SentenceChunk(text=' The Science of Prompt Design\\nCentral to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=835, end_index=1470, token_count=117, context=None, sentences=[Sentence(text=' The Science of Prompt Design\\n', start_index=835, end_index=865, token_count=5.0), Sentence(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=865, end_index=1008, token_count=23.0), Sentence(text=' Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.', start_index=1008, end_index=1185, token_count=29.0), Sentence(text=' Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.', start_index=1185, end_index=1334, token_count=24.0), Sentence(text=' Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=1334, end_index=1470, token_count=22.0)]),\n",
              " SentenceChunk(text=\" Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3. Advanced Prompting Techniques and Applications\\nBeyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\", start_index=1334, end_index=1937, token_count=107, context=None, sentences=[Sentence(text=' Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=1334, end_index=1470, token_count=22.0), Sentence(text=\" By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3.\", start_index=1470, end_index=1629, token_count=26.0), Sentence(text=' Advanced Prompting Techniques and Applications\\n', start_index=1629, end_index=1677, token_count=8.0), Sentence(text='Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.', start_index=1677, end_index=1781, token_count=17.0), Sentence(text=' For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=1781, end_index=1937, token_count=26.0)]),\n",
              " SentenceChunk(text=' For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4. Integration with External Systems\\n', start_index=1781, end_index=2406, token_count=108, context=None, sentences=[Sentence(text=' For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=1781, end_index=1937, token_count=26.0), Sentence(text=' Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.', start_index=1937, end_index=2051, token_count=19.0), Sentence(text=' These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.', start_index=2051, end_index=2218, token_count=27.0), Sentence(text=' By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.', start_index=2218, end_index=2371, token_count=25.0), Sentence(text=' Integration with External Systems\\n', start_index=2371, end_index=2406, token_count=5.0)]),\n",
              " SentenceChunk(text=' By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4. Integration with External Systems\\nAnother critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=2218, end_index=2857, token_count=112, context=None, sentences=[Sentence(text=' By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.', start_index=2218, end_index=2371, token_count=25.0), Sentence(text=' Integration with External Systems\\n', start_index=2371, end_index=2406, token_count=5.0), Sentence(text='Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.', start_index=2406, end_index=2530, token_count=20.0), Sentence(text=' Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.', start_index=2530, end_index=2741, token_count=35.0), Sentence(text=' For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=2741, end_index=2857, token_count=19.0)]),\n",
              " SentenceChunk(text=' For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5. Ethical Considerations in LLM Engineering\\nAs LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=2741, end_index=3326, token_count=111, context=None, sentences=[Sentence(text=' For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=2741, end_index=2857, token_count=19.0), Sentence(text=' This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5.', start_index=2857, end_index=3063, token_count=34.0), Sentence(text=' Ethical Considerations in LLM Engineering\\n', start_index=3063, end_index=3106, token_count=7.0), Sentence(text='As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.', start_index=3106, end_index=3223, token_count=19.0), Sentence(text=' Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=3223, end_index=3326, token_count=17.0)]),\n",
              " SentenceChunk(text=' Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6. The Future of LLM Engineering and Prompting\\n', start_index=3223, end_index=3809, token_count=102, context=None, sentences=[Sentence(text=' Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=3223, end_index=3326, token_count=17.0), Sentence(text=' Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=3326, end_index=3445, token_count=19.0), Sentence(text=' Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=3445, end_index=3611, token_count=27.0), Sentence(text=' Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6.', start_index=3611, end_index=3764, token_count=25.0), Sentence(text=' The Future of LLM Engineering and Prompting\\n', start_index=3764, end_index=3809, token_count=7.0)]),\n",
              " SentenceChunk(text=' The Future of LLM Engineering and Prompting\\nThe future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=3764, end_index=4354, token_count=103, context=None, sentences=[Sentence(text=' The Future of LLM Engineering and Prompting\\n', start_index=3764, end_index=3809, token_count=7.0), Sentence(text='The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.', start_index=3809, end_index=3970, token_count=26.0), Sentence(text=' Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.', start_index=3970, end_index=4200, token_count=38.0), Sentence(text=' Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=4200, end_index=4354, token_count=25.0)]),\n",
              " SentenceChunk(text=\" Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=4200, end_index=4535, token_count=60, context=None, sentences=[Sentence(text=' Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=4200, end_index=4354, token_count=25.0), Sentence(text=\" As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=4354, end_index=4535, token_count=30.0)])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK12bPGFdk84",
        "outputId": "8c02e963-f2c1-4b29-a643-4a53538c1b4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[SentenceChunk(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.', start_index=0, end_index=160, token_count=24, context=None, sentences=[Sentence(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.', start_index=0, end_index=160, token_count=26.0)])],\n",
              " [SentenceChunk(text='These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.', start_index=0, end_index=156, token_count=27, context=None, sentences=[Sentence(text='These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.', start_index=0, end_index=156, token_count=26.0)])],\n",
              " [SentenceChunk(text='However, their true utility lies in how they are engineered to interact with specific tasks and contexts.', start_index=0, end_index=105, token_count=19, context=None, sentences=[Sentence(text='However, their true utility lies in how they are engineered to interact with specific tasks and contexts.', start_index=0, end_index=105, token_count=17.0)])],\n",
              " [SentenceChunk(text='LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=0, end_index=168, token_count=29, context=None, sentences=[Sentence(text='LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=0, end_index=168, token_count=28.0)])],\n",
              " [SentenceChunk(text='It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.', start_index=0, end_index=201, token_count=32, context=None, sentences=[Sentence(text='It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.', start_index=0, end_index=201, token_count=33.0)])],\n",
              " [SentenceChunk(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=0, end_index=143, token_count=31, context=None, sentences=[Sentence(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=0, end_index=143, token_count=23.0)])],\n",
              " [SentenceChunk(text='Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.', start_index=0, end_index=176, token_count=33, context=None, sentences=[Sentence(text='Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.', start_index=0, end_index=176, token_count=29.0)])],\n",
              " [SentenceChunk(text='Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.', start_index=0, end_index=148, token_count=26, context=None, sentences=[Sentence(text='Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.', start_index=0, end_index=148, token_count=24.0)])],\n",
              " [SentenceChunk(text='Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=0, end_index=135, token_count=22, context=None, sentences=[Sentence(text='Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=0, end_index=135, token_count=22.0)])],\n",
              " [SentenceChunk(text=\"By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\", start_index=0, end_index=154, token_count=28, context=None, sentences=[Sentence(text=\"By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\", start_index=0, end_index=154, token_count=25.0)])],\n",
              " [SentenceChunk(text='Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.', start_index=0, end_index=104, token_count=19, context=None, sentences=[Sentence(text='Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.', start_index=0, end_index=104, token_count=17.0)])],\n",
              " [SentenceChunk(text='For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=0, end_index=155, token_count=27, context=None, sentences=[Sentence(text='For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=0, end_index=155, token_count=25.0)])],\n",
              " [SentenceChunk(text='Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.', start_index=0, end_index=113, token_count=21, context=None, sentences=[Sentence(text='Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.', start_index=0, end_index=113, token_count=18.0)])],\n",
              " [SentenceChunk(text='These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.', start_index=0, end_index=166, token_count=25, context=None, sentences=[Sentence(text='These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.', start_index=0, end_index=166, token_count=27.0)])],\n",
              " [SentenceChunk(text='By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.', start_index=0, end_index=148, token_count=26, context=None, sentences=[Sentence(text='By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.', start_index=0, end_index=148, token_count=24.0)])],\n",
              " [SentenceChunk(text='Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.', start_index=0, end_index=124, token_count=20, context=None, sentences=[Sentence(text='Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.', start_index=0, end_index=124, token_count=20.0)])],\n",
              " [SentenceChunk(text='Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.', start_index=0, end_index=210, token_count=36, context=None, sentences=[Sentence(text='Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.', start_index=0, end_index=210, token_count=35.0)])],\n",
              " [SentenceChunk(text='For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=0, end_index=115, token_count=21, context=None, sentences=[Sentence(text='For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=0, end_index=115, token_count=19.0)])],\n",
              " [SentenceChunk(text='This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.', start_index=0, end_index=106, token_count=20, context=None, sentences=[Sentence(text='This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.', start_index=0, end_index=106, token_count=17.0)])],\n",
              " [SentenceChunk(text='It enhances their value in industries like finance, e-commerce, and AI-powered customer support.', start_index=0, end_index=96, token_count=20, context=None, sentences=[Sentence(text='It enhances their value in industries like finance, e-commerce, and AI-powered customer support.', start_index=0, end_index=96, token_count=16.0)])],\n",
              " [SentenceChunk(text='As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.', start_index=0, end_index=117, token_count=20, context=None, sentences=[Sentence(text='As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.', start_index=0, end_index=117, token_count=19.0)])],\n",
              " [SentenceChunk(text='Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=0, end_index=102, token_count=18, context=None, sentences=[Sentence(text='Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=0, end_index=102, token_count=17.0)])],\n",
              " [SentenceChunk(text='Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=0, end_index=118, token_count=20, context=None, sentences=[Sentence(text='Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=0, end_index=118, token_count=19.0)])],\n",
              " [SentenceChunk(text='Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=0, end_index=165, token_count=24, context=None, sentences=[Sentence(text='Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=0, end_index=165, token_count=27.0)])],\n",
              " [SentenceChunk(text='Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.', start_index=0, end_index=148, token_count=27, context=None, sentences=[Sentence(text='Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.', start_index=0, end_index=148, token_count=24.0)])],\n",
              " [SentenceChunk(text='The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.', start_index=0, end_index=161, token_count=25, context=None, sentences=[Sentence(text='The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.', start_index=0, end_index=161, token_count=26.0)])],\n",
              " [SentenceChunk(text='Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.', start_index=0, end_index=229, token_count=42, context=None, sentences=[Sentence(text='Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.', start_index=0, end_index=229, token_count=38.0)])],\n",
              " [SentenceChunk(text='Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=0, end_index=153, token_count=27, context=None, sentences=[Sentence(text='Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=0, end_index=153, token_count=25.0)])],\n",
              " [SentenceChunk(text=\"As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\", start_index=0, end_index=111, token_count=23, context=None, sentences=[Sentence(text=\"As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\", start_index=0, end_index=111, token_count=18.0)])],\n",
              " [SentenceChunk(text='They will drive innovation while upholding ethical and technical standards.', start_index=0, end_index=75, token_count=11, context=None, sentences=[Sentence(text='They will drive innovation while upholding ethical and technical standards.', start_index=0, end_index=75, token_count=12.0)])]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}