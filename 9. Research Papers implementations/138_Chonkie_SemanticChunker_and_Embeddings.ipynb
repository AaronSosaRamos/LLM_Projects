{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a223c54ff702471abe91d977f6afe9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a40283c5eedf42c18c64a33801908024",
              "IPY_MODEL_c2d78a0a46a0419ea7d7522e947b7f17",
              "IPY_MODEL_7e33e3f0171946beba6bba0484d11073"
            ],
            "layout": "IPY_MODEL_94b0f48855df428b9296e0ba7d398a7d"
          }
        },
        "a40283c5eedf42c18c64a33801908024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9c701a580e4d0aba9079e04d9d4355",
            "placeholder": "​",
            "style": "IPY_MODEL_e3b054e978104f2b95fca318e809f897",
            "value": "config.json: 100%"
          }
        },
        "c2d78a0a46a0419ea7d7522e947b7f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16dcd5faa924b1b8705d06e726831e6",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ceb77ee5c9b045d7a54b012f5d8dfcf5",
            "value": 616
          }
        },
        "7e33e3f0171946beba6bba0484d11073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a8280bef25744a4b0ff9f7223808925",
            "placeholder": "​",
            "style": "IPY_MODEL_bcff783498314b68acb3d07fd2d552d3",
            "value": " 616/616 [00:00&lt;00:00, 38.7kB/s]"
          }
        },
        "94b0f48855df428b9296e0ba7d398a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9c701a580e4d0aba9079e04d9d4355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b054e978104f2b95fca318e809f897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b16dcd5faa924b1b8705d06e726831e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb77ee5c9b045d7a54b012f5d8dfcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a8280bef25744a4b0ff9f7223808925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcff783498314b68acb3d07fd2d552d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bfa126c9ad344e8a2a43fdee52167f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bc8388a12c34bb595a8d49f133be2aa",
              "IPY_MODEL_44974e8c1bff444b9e13992e1b5b1e1e",
              "IPY_MODEL_9443e15948774f6285cd91441e90fc67"
            ],
            "layout": "IPY_MODEL_ffa4de2f5edb47d8bb18ee171c6ee8cc"
          }
        },
        "0bc8388a12c34bb595a8d49f133be2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ba3b52ec954d1ab88f9bb01b4c2108",
            "placeholder": "​",
            "style": "IPY_MODEL_34d1a3cf071842e58c27aa4dfb208c1f",
            "value": "model.safetensors: 100%"
          }
        },
        "44974e8c1bff444b9e13992e1b5b1e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4466f390f3f04c6fb3552f4998d628f9",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bcc2a31bb594fd78d7f44cfd4a52ada",
            "value": 1340616616
          }
        },
        "9443e15948774f6285cd91441e90fc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf7d94722d14fb4906876bae99c4508",
            "placeholder": "​",
            "style": "IPY_MODEL_7e65dad092164afeb66eb70dd210f5ef",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 99.4MB/s]"
          }
        },
        "ffa4de2f5edb47d8bb18ee171c6ee8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ba3b52ec954d1ab88f9bb01b4c2108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d1a3cf071842e58c27aa4dfb208c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4466f390f3f04c6fb3552f4998d628f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bcc2a31bb594fd78d7f44cfd4a52ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccf7d94722d14fb4906876bae99c4508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e65dad092164afeb66eb70dd210f5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d7c1d254a849b3b12fef8363d468a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6212bbe8cc394a739cb3484be9c460b2",
              "IPY_MODEL_dcf8258e26954f46b4fe6440a532a008",
              "IPY_MODEL_bba934f1cab944c88dce0069dcc43f1e"
            ],
            "layout": "IPY_MODEL_f262f2dd28bb419c83c63df87a795e9f"
          }
        },
        "6212bbe8cc394a739cb3484be9c460b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4839de9339da4a9ab3b7ad8250cc4df9",
            "placeholder": "​",
            "style": "IPY_MODEL_dfb8b0f394864a81ba7c293ee4e0f7d1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "dcf8258e26954f46b4fe6440a532a008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f6dbad87be4540b3c5981d2fea5c99",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a367dd51df5414ea64654a506bde8c0",
            "value": 314
          }
        },
        "bba934f1cab944c88dce0069dcc43f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9efa088458dc44f989f86cfc98159ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_84ecc8706bd94942ab12235daaff3e89",
            "value": " 314/314 [00:00&lt;00:00, 9.97kB/s]"
          }
        },
        "f262f2dd28bb419c83c63df87a795e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4839de9339da4a9ab3b7ad8250cc4df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb8b0f394864a81ba7c293ee4e0f7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9f6dbad87be4540b3c5981d2fea5c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a367dd51df5414ea64654a506bde8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9efa088458dc44f989f86cfc98159ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ecc8706bd94942ab12235daaff3e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bf86bdd479b49f7b14c41ef31e69524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9d87ee16bd74946b68bcfb316309cb3",
              "IPY_MODEL_c57b55ff41364ffe8eff49443af83da5",
              "IPY_MODEL_71bfcb2c416f49bea6d429066901b793"
            ],
            "layout": "IPY_MODEL_9cb97cb10e764539bbccf3445a21104a"
          }
        },
        "f9d87ee16bd74946b68bcfb316309cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d289616e36fe45b09faa2ea66ead65b8",
            "placeholder": "​",
            "style": "IPY_MODEL_e781973a050445cb9735af18e43358e9",
            "value": "vocab.txt: 100%"
          }
        },
        "c57b55ff41364ffe8eff49443af83da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a095c08105744b8b5c5da0efdac8f2a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b350da049d6d4737b870685c21770e05",
            "value": 231508
          }
        },
        "71bfcb2c416f49bea6d429066901b793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60881203646e4391981bb09264d4be7f",
            "placeholder": "​",
            "style": "IPY_MODEL_033ef9b5a2f041db9bfa496eb266a1d4",
            "value": " 232k/232k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "9cb97cb10e764539bbccf3445a21104a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d289616e36fe45b09faa2ea66ead65b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e781973a050445cb9735af18e43358e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a095c08105744b8b5c5da0efdac8f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b350da049d6d4737b870685c21770e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60881203646e4391981bb09264d4be7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033ef9b5a2f041db9bfa496eb266a1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2c22f82b5f404e982fb6ebc043b3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf2f7e6cb8404704937905349f5a673f",
              "IPY_MODEL_04bb2a18f77a4d20b0f0b1b75ff03206",
              "IPY_MODEL_7631346bca744f28be0307abb0083e77"
            ],
            "layout": "IPY_MODEL_ab081b7262444357968bad559c781eaa"
          }
        },
        "cf2f7e6cb8404704937905349f5a673f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db12236845654e7caf1dbc0272c658dd",
            "placeholder": "​",
            "style": "IPY_MODEL_1edc2754640841d095e14eda778eae6d",
            "value": "tokenizer.json: 100%"
          }
        },
        "04bb2a18f77a4d20b0f0b1b75ff03206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4468ba2ebcfa476eb7dd3a04578fabda",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_944bd7cf84e544cbb555eb7bfba00150",
            "value": 711396
          }
        },
        "7631346bca744f28be0307abb0083e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_958a3660c1744b06b0e2b658f4627974",
            "placeholder": "​",
            "style": "IPY_MODEL_2151c9fa47e244e89cdc33b927123c6f",
            "value": " 711k/711k [00:00&lt;00:00, 2.88MB/s]"
          }
        },
        "ab081b7262444357968bad559c781eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db12236845654e7caf1dbc0272c658dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edc2754640841d095e14eda778eae6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4468ba2ebcfa476eb7dd3a04578fabda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944bd7cf84e544cbb555eb7bfba00150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "958a3660c1744b06b0e2b658f4627974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2151c9fa47e244e89cdc33b927123c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3217044de4b04b479740cd459a558f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a483110331e7452488fef9f89ee22da9",
              "IPY_MODEL_a4201ed5e97d438c8db0e8d5f417292e",
              "IPY_MODEL_4b47005a872048629f2ab47858fb0b37"
            ],
            "layout": "IPY_MODEL_77a382932a5e458280fa77016900ea13"
          }
        },
        "a483110331e7452488fef9f89ee22da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04923440086f469384eb15e2e3e3a6f7",
            "placeholder": "​",
            "style": "IPY_MODEL_6cfd0f46b4e3463dabe81d5415de4699",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a4201ed5e97d438c8db0e8d5f417292e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981d20a157744a878afe87b4e768cfc9",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1475c085c85d4932b06458a1eb9ed9b5",
            "value": 125
          }
        },
        "4b47005a872048629f2ab47858fb0b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534a8b429ca24163b6aa9f78f1f31c29",
            "placeholder": "​",
            "style": "IPY_MODEL_ba129454fc0a423eb8b2df688c5519b2",
            "value": " 125/125 [00:00&lt;00:00, 4.49kB/s]"
          }
        },
        "77a382932a5e458280fa77016900ea13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04923440086f469384eb15e2e3e3a6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfd0f46b4e3463dabe81d5415de4699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981d20a157744a878afe87b4e768cfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1475c085c85d4932b06458a1eb9ed9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "534a8b429ca24163b6aa9f78f1f31c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba129454fc0a423eb8b2df688c5519b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chonkie SemanticChunker\n",
        "Made by: Wilfredo Aaron Sosa Ramos"
      ],
      "metadata": {
        "id": "xYyrBFB2RMtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsYUy-AMQi9-",
        "outputId": "a670b53e-8714-4058-c01d-c844eade45e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q chonkie[all] \"chonkie[semantic]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single Text Chunking"
      ],
      "metadata": {
        "id": "a2soQMAvRU5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import SemanticChunker\n",
        "\n",
        "# Basic initialization with default parameters\n",
        "chunker = SemanticChunker(\n",
        "    embedding_model=\"minishlab/potion-base-8M\",  # Default model\n",
        "    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or \"auto\"\n",
        "    chunk_size=256,                              # Maximum tokens per chunk\n",
        "    min_sentences=1                              # Initial sentences per chunk\n",
        ")"
      ],
      "metadata": {
        "id": "W1sWhhHORVMp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "1. The Evolution of LLM Engineering\n",
        "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
        "\n",
        "2. The Science of Prompt Design\n",
        "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
        "\n",
        "3. Advanced Prompting Techniques and Applications\n",
        "Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
        "\n",
        "4. Integration with External Systems\n",
        "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
        "\n",
        "5. Ethical Considerations in LLM Engineering\n",
        "As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
        "\n",
        "6. The Future of LLM Engineering and Prompting\n",
        "The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
        "\"\"\"\n",
        "\n",
        "chunks = chunker.chunk(text)\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(f\"Chunk text: {chunk.text}\")\n",
        "    print(f\"Token count: {chunk.token_count}\")\n",
        "    print(f\"Number of sentences: {len(chunk.sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovqizj9SRfAb",
        "outputId": "08648c0b-6a92-4630-f12b-82f6aa49828c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk text: \n",
            "1. The Evolution of LLM Engineering\n",
            "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "\n",
            "2. The Science of Prompt Design\n",
            "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\n",
            "Token count: 238\n",
            "Number of sentences: 11\n",
            "Chunk text:  Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "\n",
            "3. Advanced Prompting Techniques and Applications\n",
            "Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "\n",
            "4. Integration with External Systems\n",
            "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\n",
            "Token count: 211\n",
            "Number of sentences: 10\n",
            "Chunk text:  Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "\n",
            "5. Ethical Considerations in LLM Engineering\n",
            "As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "\n",
            "6. The Future of LLM Engineering and Prompting\n",
            "\n",
            "Token count: 234\n",
            "Number of sentences: 10\n",
            "Chunk text: The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
            "\n",
            "Token count: 133\n",
            "Number of sentences: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The Evolution of LLM Engineering\n",
        "evolution_of_llm_engineering = [\n",
        "    \"LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\",\n",
        "    \"These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\",\n",
        "    \"However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\",\n",
        "    \"LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\",\n",
        "    \"It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\"\n",
        "]\n",
        "\n",
        "# 2. The Science of Prompt Design\n",
        "science_of_prompt_design = [\n",
        "    \"Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\",\n",
        "    \"Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\",\n",
        "    \"Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\",\n",
        "    \"Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\",\n",
        "    \"By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\"\n",
        "]\n",
        "\n",
        "# 3. Advanced Prompting Techniques and Applications\n",
        "advanced_prompting_techniques = [\n",
        "    \"Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\",\n",
        "    \"For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\",\n",
        "    \"Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\",\n",
        "    \"These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\",\n",
        "    \"By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\"\n",
        "]\n",
        "\n",
        "# 4. Integration with External Systems\n",
        "integration_with_external_systems = [\n",
        "    \"Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\",\n",
        "    \"Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\",\n",
        "    \"For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\",\n",
        "    \"This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\",\n",
        "    \"It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\"\n",
        "]\n",
        "\n",
        "# 5. Ethical Considerations in LLM Engineering\n",
        "ethical_considerations = [\n",
        "    \"As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\",\n",
        "    \"Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\",\n",
        "    \"Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\",\n",
        "    \"Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\",\n",
        "    \"Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\"\n",
        "]\n",
        "\n",
        "# 6. The Future of LLM Engineering and Prompting\n",
        "future_of_llm_engineering = [\n",
        "    \"The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\",\n",
        "    \"Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\",\n",
        "    \"Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\",\n",
        "    \"As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\",\n",
        "    \"They will drive innovation while upholding ethical and technical standards.\"\n",
        "]\n",
        "texts = evolution_of_llm_engineering + science_of_prompt_design + advanced_prompting_techniques + integration_with_external_systems + ethical_considerations + future_of_llm_engineering"
      ],
      "metadata": {
        "id": "aubP-ideRpM1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_chunks = chunker.chunk_batch(texts)\n",
        "\n",
        "for doc_chunks in batch_chunks:\n",
        "    for chunk in doc_chunks:\n",
        "        print(f\"Chunk: {chunk.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ukT_8pRo7m",
        "outputId": "5f1e92d0-4c71-435a-ab69-f457d218bef3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🦛 choooooooooooooooooooonk 100% • 30/30 docs chunked [00:00<00:00, 1681.33doc/s] 🌱"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk: LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\n",
            "Chunk: These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\n",
            "Chunk: However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\n",
            "Chunk: LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\n",
            "Chunk: It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "Chunk: Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\n",
            "Chunk: Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\n",
            "Chunk: Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\n",
            "Chunk: Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\n",
            "Chunk: By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "Chunk: Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\n",
            "Chunk: For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\n",
            "Chunk: Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\n",
            "Chunk: These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\n",
            "Chunk: By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "Chunk: Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\n",
            "Chunk: Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\n",
            "Chunk: For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\n",
            "Chunk: This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\n",
            "Chunk: It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "Chunk: As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\n",
            "Chunk: Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\n",
            "Chunk: Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\n",
            "Chunk: Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\n",
            "Chunk: Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "Chunk: The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\n",
            "Chunk: Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\n",
            "Chunk: Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\n",
            "Chunk: As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\n",
            "Chunk: They will drive innovation while upholding ethical and technical standards.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings"
      ],
      "metadata": {
        "id": "aB2Qvm-LR0pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. AutoEmbeddings"
      ],
      "metadata": {
        "id": "_O-c6n4xR7S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "AfJLK-U9R1nP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import AutoEmbeddings\n",
        "\n",
        "# Get the embeddings handler for SentenceTransformer\n",
        "embeddings_sentence_transformer = AutoEmbeddings.get_embeddings(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Get the embeddings handler for OpenAI\n",
        "embeddings_openai = AutoEmbeddings.get_embeddings(\"text-embedding-3-large\")\n",
        "\n",
        "# Get the embeddings handler for Model2Vec\n",
        "embeddings_model2vec = AutoEmbeddings.get_embeddings(\"minishlab/potion-base-8M\")"
      ],
      "metadata": {
        "id": "PQOecx9nSANo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single text embedding\n",
        "emb_single_text = embeddings_sentence_transformer.embed(text)\n",
        "\n",
        "# Batch processing\n",
        "emb_batch_processing = embeddings_sentence_transformer.embed_batch(texts)\n",
        "\n",
        "# Direct calling\n",
        "emb_direct_calling = embeddings_sentence_transformer(text)  # or embeddings([text1, text2])"
      ],
      "metadata": {
        "id": "0hFp8mIlSbFT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_single_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA-bq-pRS0za",
        "outputId": "96e38c60-1c0b-405d-c934-beab4d69ec7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.48870794e-02,  1.83277112e-02,  4.77530658e-02, -1.38475662e-02,\n",
              "        3.02790962e-02, -4.32046838e-02,  6.23071427e-03,  5.95367439e-02,\n",
              "       -1.12173532e-03, -4.43947613e-02, -1.33559808e-01, -4.43594046e-02,\n",
              "        1.11916095e-01, -3.71096767e-02,  2.33589225e-02,  7.19019724e-03,\n",
              "        9.25967693e-02, -3.25391367e-02, -2.97154281e-02, -4.53184731e-02,\n",
              "        4.93117049e-02,  4.15870920e-02,  7.90585428e-02,  1.44620230e-02,\n",
              "       -7.66994208e-02, -1.83139148e-03,  4.59219553e-02, -3.48730391e-04,\n",
              "        6.43289238e-02, -1.70797128e-02,  3.42165120e-02,  5.80768213e-02,\n",
              "        1.24822510e-02,  6.57148957e-02, -4.90070283e-02,  4.40610908e-02,\n",
              "       -2.78278813e-02,  4.24919464e-02, -6.80714706e-03, -5.28121889e-02,\n",
              "       -8.37868154e-02, -6.89068213e-02,  2.37371586e-02, -2.66803242e-03,\n",
              "        8.42702463e-02, -4.52312268e-02, -4.15657312e-02, -5.34140877e-02,\n",
              "       -8.22660550e-02,  2.05986574e-03, -1.16063096e-01, -9.54612568e-02,\n",
              "       -3.18644568e-03, -3.96194756e-02, -5.14685139e-02,  8.09957758e-02,\n",
              "        6.94901943e-02,  1.98143218e-02, -2.28920598e-02, -5.87589964e-02,\n",
              "       -7.67315403e-02, -1.10257231e-01, -7.75132030e-02,  5.42019084e-02,\n",
              "        4.13192660e-02,  3.13723274e-02, -2.10317299e-02,  9.17202383e-02,\n",
              "        3.21280994e-02, -1.93982869e-02,  3.07106152e-02,  2.00873204e-02,\n",
              "       -1.88127588e-02,  4.19171415e-02, -1.67080872e-02,  2.02019997e-02,\n",
              "       -1.54888267e-02,  3.66312787e-02,  6.15088046e-02, -5.25325872e-02,\n",
              "       -3.21979262e-02, -1.77728012e-02, -2.13775393e-02,  3.25539410e-02,\n",
              "        8.88254028e-03,  1.66691598e-02,  3.74831595e-02,  6.14355877e-02,\n",
              "        4.39639091e-02,  5.66582493e-02, -1.33352224e-02, -9.17474404e-02,\n",
              "       -3.21154781e-02,  3.73941101e-02,  5.61851598e-02,  7.18871206e-02,\n",
              "       -3.20164999e-03, -1.74684465e-01, -2.54545752e-02,  4.35702801e-02,\n",
              "        1.29178469e-03,  7.78867230e-02,  2.87020784e-02, -7.05215633e-02,\n",
              "       -4.25284244e-02, -2.44255420e-02, -6.26195734e-03,  2.50623561e-02,\n",
              "        3.85525338e-02, -7.23432451e-02,  1.92780197e-02,  5.86134717e-02,\n",
              "        4.87779900e-02, -1.22703193e-02, -2.12868839e-03, -6.43077791e-02,\n",
              "        1.44941323e-02, -5.77803217e-02,  3.89426537e-02,  4.04001400e-02,\n",
              "        2.45272461e-02,  1.88328046e-02, -2.94915345e-02, -2.86009703e-02,\n",
              "        2.91788615e-02, -4.98619303e-02, -4.22131158e-02,  2.02969248e-33,\n",
              "        7.76850507e-02,  2.64068395e-02, -1.80368754e-03,  1.05993658e-01,\n",
              "        9.20901597e-02,  2.47061439e-03,  5.12261130e-02,  9.21554640e-02,\n",
              "       -1.06349420e-02, -1.02618942e-02, -9.22648050e-03, -9.25427862e-03,\n",
              "       -2.55302787e-02,  7.92400986e-02,  4.00636680e-02, -2.13604253e-02,\n",
              "       -2.59864945e-02,  4.20279019e-02, -5.02316654e-02, -8.13769642e-03,\n",
              "       -3.51704992e-02, -4.19549607e-02,  5.76691441e-02, -1.71737671e-02,\n",
              "        1.09411404e-01,  9.42744166e-02,  7.64561594e-02,  2.08311714e-02,\n",
              "       -2.96917949e-02,  3.58374454e-02, -1.12079389e-01,  3.21546569e-04,\n",
              "       -3.30672935e-02,  1.78010967e-02, -5.59901912e-03,  1.35404160e-02,\n",
              "       -5.27254604e-02, -5.18525690e-02,  7.92639032e-02,  9.81211383e-03,\n",
              "       -1.25547601e-02, -2.05506943e-02,  3.12673189e-02,  2.47717593e-02,\n",
              "       -7.12418631e-02, -2.16427278e-02,  4.53656502e-02, -1.69746100e-03,\n",
              "       -8.50560293e-02,  3.85359228e-02,  2.83243284e-02,  3.01191546e-02,\n",
              "        1.97224692e-02, -3.36379670e-02,  2.79556345e-02, -3.15870941e-02,\n",
              "       -1.69485919e-02, -3.74900363e-02, -1.20733995e-02, -1.20864436e-02,\n",
              "       -2.30995379e-02,  1.06091805e-01,  1.13461744e-02,  9.97850075e-02,\n",
              "        7.61661008e-02,  2.35029627e-02, -5.29101081e-02,  4.84693907e-02,\n",
              "        8.45006257e-02, -1.66086126e-02, -5.31793945e-02, -4.23438288e-03,\n",
              "       -7.23469704e-02, -6.56636283e-02, -1.15332054e-02, -2.69925930e-02,\n",
              "        5.38898855e-02, -5.32719716e-02,  9.01216641e-02,  3.26233953e-02,\n",
              "        4.57552411e-02,  2.73768175e-02, -1.88673567e-02, -2.20392141e-02,\n",
              "        5.88941723e-02,  2.60334257e-02,  4.56783138e-02, -4.88054752e-02,\n",
              "       -4.94651198e-02, -1.53964208e-02, -3.53565589e-02, -6.76074401e-02,\n",
              "       -1.57882879e-03,  1.25892982e-01,  2.48549823e-02, -1.62096630e-33,\n",
              "       -1.64328404e-02,  1.10110259e-02, -6.69180676e-02,  5.93228973e-02,\n",
              "        1.86499432e-02, -6.71345592e-02, -3.93867167e-03, -2.06982605e-02,\n",
              "        2.16866489e-02, -3.06048635e-02, -3.10601983e-02, -9.86958761e-03,\n",
              "        3.17619741e-02,  7.45128142e-03,  1.35387247e-02, -3.67018543e-02,\n",
              "       -1.60974506e-02, -4.21458259e-02,  1.74938198e-02,  2.50474606e-02,\n",
              "        2.96605863e-02,  1.28847808e-01, -1.79152235e-01, -1.51741831e-02,\n",
              "       -4.83203195e-02,  1.55643551e-02, -5.11970818e-02,  3.80877070e-02,\n",
              "        2.19239369e-02,  2.82900929e-02,  1.03906300e-02, -1.21116650e-03,\n",
              "        1.38780866e-02,  2.65924037e-02, -8.07887912e-02,  7.23429546e-02,\n",
              "        9.85098854e-02,  1.34039987e-02,  1.69586111e-02,  5.97970150e-02,\n",
              "        7.40031973e-02, -2.39408407e-02, -1.51398256e-02,  2.65815714e-03,\n",
              "       -5.07098287e-02,  1.04766823e-02, -1.13817593e-02, -4.89022620e-02,\n",
              "        1.54028796e-02,  2.63837334e-02, -1.50891328e-02, -7.88543373e-03,\n",
              "        1.20720845e-02, -4.02161479e-02, -7.64116645e-02, -1.20463394e-01,\n",
              "        1.86624806e-02, -9.11929905e-02,  2.70262156e-02, -2.24028397e-02,\n",
              "       -1.47756776e-02,  2.93939520e-04,  1.17846332e-01, -6.99004531e-02,\n",
              "       -2.76134536e-02, -6.72657415e-02, -2.50621792e-02,  3.85103859e-02,\n",
              "       -6.65751472e-02, -2.65287682e-02,  5.12572415e-02, -2.12714374e-02,\n",
              "       -2.49237996e-02,  5.02666272e-03,  3.79749201e-02,  2.65580770e-02,\n",
              "       -5.39074391e-02, -1.05500877e-01, -6.39346167e-02, -4.19796295e-02,\n",
              "        5.87090850e-02,  1.25263641e-02, -1.69832930e-02,  1.10987268e-01,\n",
              "       -6.61689090e-03,  2.29967088e-02,  2.14551650e-02,  1.28418475e-01,\n",
              "        6.91830087e-03,  1.18080843e-02, -4.90973741e-02,  6.79631084e-02,\n",
              "       -1.04325581e-02,  9.20584127e-02, -8.32480490e-02, -5.26486339e-08,\n",
              "       -4.68293764e-02, -4.19685468e-02,  5.51246747e-04,  4.77200337e-02,\n",
              "        1.11046003e-03, -2.74978690e-02, -5.53049631e-02,  3.46902236e-02,\n",
              "        3.98948789e-03, -1.08734712e-01,  6.19709902e-02,  3.89195941e-02,\n",
              "       -4.78265285e-02,  1.34916035e-02,  4.21451032e-02,  2.38941908e-02,\n",
              "       -4.39210422e-02,  1.59524344e-02, -7.48034641e-02, -8.30237493e-02,\n",
              "        8.08734745e-02,  5.14369924e-04, -5.23462519e-03,  1.59144513e-02,\n",
              "        8.22757855e-02, -5.96026257e-02, -7.14911008e-03,  4.89728525e-02,\n",
              "        1.00147417e-02, -2.92924978e-02, -3.36866267e-02, -1.24961110e-02,\n",
              "       -2.73629110e-02,  6.58885613e-02,  1.72348134e-02,  4.51147035e-02,\n",
              "        5.67270517e-02, -3.73149998e-02,  5.78687862e-02, -5.82166575e-02,\n",
              "        1.35547677e-02,  2.05453783e-02, -6.37760386e-02,  6.29791543e-02,\n",
              "       -6.49371147e-02, -2.05118079e-02, -1.16643934e-02, -1.43351480e-01,\n",
              "       -3.37647907e-02,  1.57074928e-02, -4.00160179e-02, -2.37769037e-02,\n",
              "       -1.52152395e-02,  1.74216814e-02,  1.99326780e-02,  9.37183425e-02,\n",
              "        2.53971722e-02, -3.15961316e-02,  4.79599969e-08,  4.05513942e-02,\n",
              "        2.19822470e-02,  9.54961479e-02, -2.86719645e-03, -2.32769083e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_batch_processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY42tHz3S2Ct",
        "outputId": "f8a6d1dc-0f5d-4d6d-936e-c77abeac014a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.3526954e-02, -8.2325451e-02,  5.8019586e-02, ...,\n",
              "         5.4756008e-02,  6.4687811e-05, -3.1627618e-02],\n",
              "       [-2.2949705e-02, -1.0813794e-01,  2.7377063e-02, ...,\n",
              "         2.1301134e-02,  1.2248737e-02, -4.2163379e-02],\n",
              "       [-4.1390467e-02, -1.1339505e-02, -6.6433256e-03, ...,\n",
              "         9.4248198e-02,  6.4004302e-02, -2.2237033e-02],\n",
              "       ...,\n",
              "       [ 2.4521290e-03, -4.8830509e-02,  5.4585803e-02, ...,\n",
              "         4.3447401e-02, -7.2111823e-02,  4.1129217e-02],\n",
              "       [-1.7496713e-02, -7.7107700e-04,  5.4657206e-02, ...,\n",
              "         3.9128628e-02, -2.5253374e-02, -6.5227404e-02],\n",
              "       [-7.4132636e-02, -2.8664522e-02, -1.9233793e-02, ...,\n",
              "        -7.2487772e-02,  1.6280073e-01, -1.9565623e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_direct_calling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8cMCNMRS30w",
        "outputId": "31333bf6-bb55-4fdc-fb99-9747213f3179"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.48870794e-02,  1.83277112e-02,  4.77530658e-02, -1.38475662e-02,\n",
              "        3.02790962e-02, -4.32046838e-02,  6.23071427e-03,  5.95367439e-02,\n",
              "       -1.12173532e-03, -4.43947613e-02, -1.33559808e-01, -4.43594046e-02,\n",
              "        1.11916095e-01, -3.71096767e-02,  2.33589225e-02,  7.19019724e-03,\n",
              "        9.25967693e-02, -3.25391367e-02, -2.97154281e-02, -4.53184731e-02,\n",
              "        4.93117049e-02,  4.15870920e-02,  7.90585428e-02,  1.44620230e-02,\n",
              "       -7.66994208e-02, -1.83139148e-03,  4.59219553e-02, -3.48730391e-04,\n",
              "        6.43289238e-02, -1.70797128e-02,  3.42165120e-02,  5.80768213e-02,\n",
              "        1.24822510e-02,  6.57148957e-02, -4.90070283e-02,  4.40610908e-02,\n",
              "       -2.78278813e-02,  4.24919464e-02, -6.80714706e-03, -5.28121889e-02,\n",
              "       -8.37868154e-02, -6.89068213e-02,  2.37371586e-02, -2.66803242e-03,\n",
              "        8.42702463e-02, -4.52312268e-02, -4.15657312e-02, -5.34140877e-02,\n",
              "       -8.22660550e-02,  2.05986574e-03, -1.16063096e-01, -9.54612568e-02,\n",
              "       -3.18644568e-03, -3.96194756e-02, -5.14685139e-02,  8.09957758e-02,\n",
              "        6.94901943e-02,  1.98143218e-02, -2.28920598e-02, -5.87589964e-02,\n",
              "       -7.67315403e-02, -1.10257231e-01, -7.75132030e-02,  5.42019084e-02,\n",
              "        4.13192660e-02,  3.13723274e-02, -2.10317299e-02,  9.17202383e-02,\n",
              "        3.21280994e-02, -1.93982869e-02,  3.07106152e-02,  2.00873204e-02,\n",
              "       -1.88127588e-02,  4.19171415e-02, -1.67080872e-02,  2.02019997e-02,\n",
              "       -1.54888267e-02,  3.66312787e-02,  6.15088046e-02, -5.25325872e-02,\n",
              "       -3.21979262e-02, -1.77728012e-02, -2.13775393e-02,  3.25539410e-02,\n",
              "        8.88254028e-03,  1.66691598e-02,  3.74831595e-02,  6.14355877e-02,\n",
              "        4.39639091e-02,  5.66582493e-02, -1.33352224e-02, -9.17474404e-02,\n",
              "       -3.21154781e-02,  3.73941101e-02,  5.61851598e-02,  7.18871206e-02,\n",
              "       -3.20164999e-03, -1.74684465e-01, -2.54545752e-02,  4.35702801e-02,\n",
              "        1.29178469e-03,  7.78867230e-02,  2.87020784e-02, -7.05215633e-02,\n",
              "       -4.25284244e-02, -2.44255420e-02, -6.26195734e-03,  2.50623561e-02,\n",
              "        3.85525338e-02, -7.23432451e-02,  1.92780197e-02,  5.86134717e-02,\n",
              "        4.87779900e-02, -1.22703193e-02, -2.12868839e-03, -6.43077791e-02,\n",
              "        1.44941323e-02, -5.77803217e-02,  3.89426537e-02,  4.04001400e-02,\n",
              "        2.45272461e-02,  1.88328046e-02, -2.94915345e-02, -2.86009703e-02,\n",
              "        2.91788615e-02, -4.98619303e-02, -4.22131158e-02,  2.02969248e-33,\n",
              "        7.76850507e-02,  2.64068395e-02, -1.80368754e-03,  1.05993658e-01,\n",
              "        9.20901597e-02,  2.47061439e-03,  5.12261130e-02,  9.21554640e-02,\n",
              "       -1.06349420e-02, -1.02618942e-02, -9.22648050e-03, -9.25427862e-03,\n",
              "       -2.55302787e-02,  7.92400986e-02,  4.00636680e-02, -2.13604253e-02,\n",
              "       -2.59864945e-02,  4.20279019e-02, -5.02316654e-02, -8.13769642e-03,\n",
              "       -3.51704992e-02, -4.19549607e-02,  5.76691441e-02, -1.71737671e-02,\n",
              "        1.09411404e-01,  9.42744166e-02,  7.64561594e-02,  2.08311714e-02,\n",
              "       -2.96917949e-02,  3.58374454e-02, -1.12079389e-01,  3.21546569e-04,\n",
              "       -3.30672935e-02,  1.78010967e-02, -5.59901912e-03,  1.35404160e-02,\n",
              "       -5.27254604e-02, -5.18525690e-02,  7.92639032e-02,  9.81211383e-03,\n",
              "       -1.25547601e-02, -2.05506943e-02,  3.12673189e-02,  2.47717593e-02,\n",
              "       -7.12418631e-02, -2.16427278e-02,  4.53656502e-02, -1.69746100e-03,\n",
              "       -8.50560293e-02,  3.85359228e-02,  2.83243284e-02,  3.01191546e-02,\n",
              "        1.97224692e-02, -3.36379670e-02,  2.79556345e-02, -3.15870941e-02,\n",
              "       -1.69485919e-02, -3.74900363e-02, -1.20733995e-02, -1.20864436e-02,\n",
              "       -2.30995379e-02,  1.06091805e-01,  1.13461744e-02,  9.97850075e-02,\n",
              "        7.61661008e-02,  2.35029627e-02, -5.29101081e-02,  4.84693907e-02,\n",
              "        8.45006257e-02, -1.66086126e-02, -5.31793945e-02, -4.23438288e-03,\n",
              "       -7.23469704e-02, -6.56636283e-02, -1.15332054e-02, -2.69925930e-02,\n",
              "        5.38898855e-02, -5.32719716e-02,  9.01216641e-02,  3.26233953e-02,\n",
              "        4.57552411e-02,  2.73768175e-02, -1.88673567e-02, -2.20392141e-02,\n",
              "        5.88941723e-02,  2.60334257e-02,  4.56783138e-02, -4.88054752e-02,\n",
              "       -4.94651198e-02, -1.53964208e-02, -3.53565589e-02, -6.76074401e-02,\n",
              "       -1.57882879e-03,  1.25892982e-01,  2.48549823e-02, -1.62096630e-33,\n",
              "       -1.64328404e-02,  1.10110259e-02, -6.69180676e-02,  5.93228973e-02,\n",
              "        1.86499432e-02, -6.71345592e-02, -3.93867167e-03, -2.06982605e-02,\n",
              "        2.16866489e-02, -3.06048635e-02, -3.10601983e-02, -9.86958761e-03,\n",
              "        3.17619741e-02,  7.45128142e-03,  1.35387247e-02, -3.67018543e-02,\n",
              "       -1.60974506e-02, -4.21458259e-02,  1.74938198e-02,  2.50474606e-02,\n",
              "        2.96605863e-02,  1.28847808e-01, -1.79152235e-01, -1.51741831e-02,\n",
              "       -4.83203195e-02,  1.55643551e-02, -5.11970818e-02,  3.80877070e-02,\n",
              "        2.19239369e-02,  2.82900929e-02,  1.03906300e-02, -1.21116650e-03,\n",
              "        1.38780866e-02,  2.65924037e-02, -8.07887912e-02,  7.23429546e-02,\n",
              "        9.85098854e-02,  1.34039987e-02,  1.69586111e-02,  5.97970150e-02,\n",
              "        7.40031973e-02, -2.39408407e-02, -1.51398256e-02,  2.65815714e-03,\n",
              "       -5.07098287e-02,  1.04766823e-02, -1.13817593e-02, -4.89022620e-02,\n",
              "        1.54028796e-02,  2.63837334e-02, -1.50891328e-02, -7.88543373e-03,\n",
              "        1.20720845e-02, -4.02161479e-02, -7.64116645e-02, -1.20463394e-01,\n",
              "        1.86624806e-02, -9.11929905e-02,  2.70262156e-02, -2.24028397e-02,\n",
              "       -1.47756776e-02,  2.93939520e-04,  1.17846332e-01, -6.99004531e-02,\n",
              "       -2.76134536e-02, -6.72657415e-02, -2.50621792e-02,  3.85103859e-02,\n",
              "       -6.65751472e-02, -2.65287682e-02,  5.12572415e-02, -2.12714374e-02,\n",
              "       -2.49237996e-02,  5.02666272e-03,  3.79749201e-02,  2.65580770e-02,\n",
              "       -5.39074391e-02, -1.05500877e-01, -6.39346167e-02, -4.19796295e-02,\n",
              "        5.87090850e-02,  1.25263641e-02, -1.69832930e-02,  1.10987268e-01,\n",
              "       -6.61689090e-03,  2.29967088e-02,  2.14551650e-02,  1.28418475e-01,\n",
              "        6.91830087e-03,  1.18080843e-02, -4.90973741e-02,  6.79631084e-02,\n",
              "       -1.04325581e-02,  9.20584127e-02, -8.32480490e-02, -5.26486339e-08,\n",
              "       -4.68293764e-02, -4.19685468e-02,  5.51246747e-04,  4.77200337e-02,\n",
              "        1.11046003e-03, -2.74978690e-02, -5.53049631e-02,  3.46902236e-02,\n",
              "        3.98948789e-03, -1.08734712e-01,  6.19709902e-02,  3.89195941e-02,\n",
              "       -4.78265285e-02,  1.34916035e-02,  4.21451032e-02,  2.38941908e-02,\n",
              "       -4.39210422e-02,  1.59524344e-02, -7.48034641e-02, -8.30237493e-02,\n",
              "        8.08734745e-02,  5.14369924e-04, -5.23462519e-03,  1.59144513e-02,\n",
              "        8.22757855e-02, -5.96026257e-02, -7.14911008e-03,  4.89728525e-02,\n",
              "        1.00147417e-02, -2.92924978e-02, -3.36866267e-02, -1.24961110e-02,\n",
              "       -2.73629110e-02,  6.58885613e-02,  1.72348134e-02,  4.51147035e-02,\n",
              "        5.67270517e-02, -3.73149998e-02,  5.78687862e-02, -5.82166575e-02,\n",
              "        1.35547677e-02,  2.05453783e-02, -6.37760386e-02,  6.29791543e-02,\n",
              "       -6.49371147e-02, -2.05118079e-02, -1.16643934e-02, -1.43351480e-01,\n",
              "       -3.37647907e-02,  1.57074928e-02, -4.00160179e-02, -2.37769037e-02,\n",
              "       -1.52152395e-02,  1.74216814e-02,  1.99326780e-02,  9.37183425e-02,\n",
              "        2.53971722e-02, -3.15961316e-02,  4.79599969e-08,  4.05513942e-02,\n",
              "        2.19822470e-02,  9.54961479e-02, -2.86719645e-03, -2.32769083e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import SemanticChunker\n",
        "chunker = SemanticChunker(embeddings_openai, similarity_threshold=0.7)\n",
        "\n",
        "# Chunk the text\n",
        "chunks = chunker(text)"
      ],
      "metadata": {
        "id": "N7cYWC5CS61e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4pXbOXXTry8",
        "outputId": "316edea3-83a6-4684-f2da-52126a27fdd0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SemanticChunk(text='\\n1. The Evolution of LLM Engineering\\n', start_index=0, end_index=37, token_count=10, context=None, sentences=[SemanticSentence(text='\\n1.', start_index=0, end_index=3, token_count=3, embedding=array([-0.00796941, -0.00584776, -0.02342363, ..., -0.00952094,\n",
              "         0.00309695,  0.00754182], dtype=float32)), SemanticSentence(text=' The Evolution of LLM Engineering\\n', start_index=3, end_index=37, token_count=7, embedding=array([-0.01866442, -0.00540902, -0.03082924, ...,  0.00124795,\n",
              "        -0.00084813,  0.01044476], dtype=float32))]),\n",
              " SemanticChunk(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=37, end_index=629, token_count=98, context=None, sentences=[SemanticSentence(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.', start_index=37, end_index=197, token_count=24, embedding=array([-0.03429084, -0.00015153, -0.03341468, ...,  0.00741709,\n",
              "        -0.00495102,  0.01061959], dtype=float32)), SemanticSentence(text=' These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.', start_index=197, end_index=354, token_count=27, embedding=array([-0.02687627,  0.00344229, -0.03581402, ...,  0.00896139,\n",
              "        -0.00609248, -0.00015492], dtype=float32)), SemanticSentence(text=' However, their true utility lies in how they are engineered to interact with specific tasks and contexts.', start_index=354, end_index=460, token_count=19, embedding=array([-0.02315936,  0.00180956, -0.02662343, ...,  0.01480928,\n",
              "        -0.0229022 , -0.0002321 ], dtype=float32)), SemanticSentence(text=' LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=460, end_index=629, token_count=28, embedding=array([-1.47102745e-02,  3.30176663e-05, -2.87218690e-02, ...,\n",
              "        -3.73072922e-03, -1.24851270e-02, -1.10573880e-02], dtype=float32))]),\n",
              " SemanticChunk(text=\" It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2. The Science of Prompt Design\\nCentral to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3. Advanced Prompting Techniques and Applications\\nBeyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.\", start_index=629, end_index=2371, token_count=296, context=None, sentences=[SemanticSentence(text=' It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2.', start_index=629, end_index=835, token_count=35, embedding=array([-0.00166905, -0.01893404, -0.02969349, ..., -0.00821094,\n",
              "        -0.00493141, -0.01122795], dtype=float32)), SemanticSentence(text=' The Science of Prompt Design\\n', start_index=835, end_index=865, token_count=6, embedding=array([ 0.0110578 , -0.02589183, -0.02848898, ..., -0.0029437 ,\n",
              "        -0.00649686, -0.0074449 ], dtype=float32)), SemanticSentence(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=865, end_index=1008, token_count=29, embedding=array([-0.00516732, -0.00604565, -0.02562746, ..., -0.00321674,\n",
              "        -0.002481  ,  0.00150476], dtype=float32)), SemanticSentence(text=' Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.', start_index=1008, end_index=1185, token_count=30, embedding=array([-0.00632873, -0.00011191, -0.02531492, ...,  0.00155487,\n",
              "        -0.00183307,  0.00131916], dtype=float32)), SemanticSentence(text=' Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.', start_index=1185, end_index=1334, token_count=24, embedding=array([-0.01010758,  0.00209844, -0.02104417, ...,  0.01368668,\n",
              "        -0.00913508, -0.00441609], dtype=float32)), SemanticSentence(text=' Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=1334, end_index=1470, token_count=19, embedding=array([ 0.00113336,  0.00199254, -0.02076275, ...,  0.01786452,\n",
              "        -0.00684569, -0.00269037], dtype=float32)), SemanticSentence(text=\" By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3.\", start_index=1470, end_index=1629, token_count=29, embedding=array([-0.00745713, -0.01340246, -0.02812089, ...,  0.00198961,\n",
              "        -0.00435521, -0.00454321], dtype=float32)), SemanticSentence(text=' Advanced Prompting Techniques and Applications\\n', start_index=1629, end_index=1677, token_count=7, embedding=array([-0.0069789 , -0.00031967, -0.02367562, ...,  0.0042029 ,\n",
              "        -0.00029002, -0.00826497], dtype=float32)), SemanticSentence(text='Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.', start_index=1677, end_index=1781, token_count=19, embedding=array([-0.02076134,  0.01097339, -0.03447408, ...,  0.00964377,\n",
              "         0.00348826, -0.00837022], dtype=float32)), SemanticSentence(text=' For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=1781, end_index=1937, token_count=26, embedding=array([-0.01651498,  0.01009932, -0.02830435, ...,  0.00746168,\n",
              "        -0.00264994,  0.00085426], dtype=float32)), SemanticSentence(text=' Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.', start_index=1937, end_index=2051, token_count=19, embedding=array([-0.02484463,  0.00139956, -0.02440739, ...,  0.0039742 ,\n",
              "         0.00066269, -0.01079047], dtype=float32)), SemanticSentence(text=' These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.', start_index=2051, end_index=2218, token_count=25, embedding=array([-0.0243088 , -0.00527746, -0.03216363, ..., -0.00219136,\n",
              "        -0.0208248 , -0.0056615 ], dtype=float32)), SemanticSentence(text=' By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.', start_index=2218, end_index=2371, token_count=28, embedding=array([-0.00866709, -0.00758963, -0.0262223 , ...,  0.00803561,\n",
              "        -0.00873814, -0.00567939], dtype=float32))]),\n",
              " SemanticChunk(text=' Integration with External Systems\\nAnother critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5.', start_index=2371, end_index=3063, token_count=119, context=None, sentences=[SemanticSentence(text=' Integration with External Systems\\n', start_index=2371, end_index=2406, token_count=5, embedding=array([-0.01453674,  0.00348566, -0.02628641, ...,  0.01370062,\n",
              "         0.00064772,  0.00063809], dtype=float32)), SemanticSentence(text='Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.', start_index=2406, end_index=2530, token_count=20, embedding=array([-0.02161065,  0.00917405, -0.02897384, ...,  0.00432887,\n",
              "         0.00109625,  0.00370591], dtype=float32)), SemanticSentence(text=' Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.', start_index=2530, end_index=2741, token_count=36, embedding=array([-0.02714993,  0.00819245, -0.03007471, ...,  0.00556627,\n",
              "        -0.01215086,  0.01286291], dtype=float32)), SemanticSentence(text=' For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=2741, end_index=2857, token_count=21, embedding=array([-0.01319363, -0.00733193, -0.02654121, ...,  0.00032642,\n",
              "        -0.01735032, -0.0055461 ], dtype=float32)), SemanticSentence(text=' This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5.', start_index=2857, end_index=3063, token_count=37, embedding=array([-0.02318815, -0.00112129, -0.02739855, ..., -0.00494954,\n",
              "        -0.00873039, -0.01515434], dtype=float32))]),\n",
              " SemanticChunk(text=' Ethical Considerations in LLM Engineering\\nAs LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=3063, end_index=3445, token_count=68, context=None, sentences=[SemanticSentence(text=' Ethical Considerations in LLM Engineering\\n', start_index=3063, end_index=3106, token_count=9, embedding=array([-0.02226101, -0.00982194, -0.02783396, ..., -0.00462617,\n",
              "        -0.00771284, -0.0207831 ], dtype=float32)), SemanticSentence(text='As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.', start_index=3106, end_index=3223, token_count=21, embedding=array([-0.02650898, -0.00607287, -0.03015198, ..., -0.00721761,\n",
              "        -0.00457535,  0.00055752], dtype=float32)), SemanticSentence(text=' Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=3223, end_index=3326, token_count=18, embedding=array([-0.0211827 , -0.00470972, -0.02645995, ..., -0.01289831,\n",
              "        -0.00414588,  0.00561261], dtype=float32)), SemanticSentence(text=' Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=3326, end_index=3445, token_count=20, embedding=array([-0.01838695, -0.0139828 , -0.02316901, ..., -0.01995675,\n",
              "        -0.01095223,  0.00111103], dtype=float32))]),\n",
              " SemanticChunk(text=' Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=3445, end_index=3611, token_count=24, context=None, sentences=[SemanticSentence(text=' Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=3445, end_index=3611, token_count=24, embedding=array([-0.01053375, -0.00867624, -0.027463  , ..., -0.0138569 ,\n",
              "        -0.02868567, -0.01145076], dtype=float32))]),\n",
              " SemanticChunk(text=\" Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6. The Future of LLM Engineering and Prompting\\nThe future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=3611, end_index=4535, token_count=162, context=None, sentences=[SemanticSentence(text=' Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6.', start_index=3611, end_index=3764, token_count=29, embedding=array([-0.03562276, -0.00496785, -0.03013989, ..., -0.01598112,\n",
              "        -0.01879386, -0.02329424], dtype=float32)), SemanticSentence(text=' The Future of LLM Engineering and Prompting\\n', start_index=3764, end_index=3809, token_count=10, embedding=array([-0.03687552, -0.00426488, -0.02940241, ..., -0.01023724,\n",
              "        -0.01721266, -0.02016822], dtype=float32)), SemanticSentence(text='The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.', start_index=3809, end_index=3970, token_count=25, embedding=array([-0.03246934,  0.00086757, -0.02941128, ..., -0.0088069 ,\n",
              "        -0.00978877, -0.00352276], dtype=float32)), SemanticSentence(text=' Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.', start_index=3970, end_index=4200, token_count=38, embedding=array([-0.02529262,  0.00918398, -0.03022205, ..., -0.00939671,\n",
              "        -0.01303509, -0.00068678], dtype=float32)), SemanticSentence(text=' Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=4200, end_index=4354, token_count=27, embedding=array([-0.01493106,  0.00497937, -0.02815772, ..., -0.00787402,\n",
              "        -0.01365628, -0.00537377], dtype=float32)), SemanticSentence(text=\" As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=4354, end_index=4535, token_count=33, embedding=array([-0.02161575,  0.01378863, -0.02341122, ..., -0.017085  ,\n",
              "        -0.01404112, -0.00475518], dtype=float32))])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Custom Embeddings:"
      ],
      "metadata": {
        "id": "iGJQSGDLU-aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie.embeddings import BaseEmbeddings\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "class CustomEmbeddings(BaseEmbeddings):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Use a state-of-the-art embedding model\n",
        "        self.model_name = \"intfloat/e5-large-v2\"\n",
        "        self.model = AutoModel.from_pretrained(self.model_name)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "    @property\n",
        "    def dimension(self) -> int:\n",
        "        \"\"\"Return the dimensionality of the embeddings.\"\"\"\n",
        "        return self.model.config.hidden_size\n",
        "\n",
        "    def embed(self, text: str) -> \"np.ndarray\":\n",
        "        \"\"\"Generate an embedding for a single text input.\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "        outputs = self.model(**inputs)\n",
        "        embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        return embedding[0]  # Return a 1D numpy array\n",
        "\n",
        "    def embed_batch(self, texts: List[str]) -> List[\"np.ndarray\"]:\n",
        "        \"\"\"Generate embeddings for a batch of text inputs.\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "        outputs = self.model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        return [embedding for embedding in embeddings]\n",
        "\n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"Count the number of tokens in a single text input.\"\"\"\n",
        "        return len(self.tokenizer.tokenize(text))\n",
        "\n",
        "    def count_tokens_batch(self, texts: List[str]) -> List[int]:\n",
        "        \"\"\"Count the number of tokens for a batch of text inputs.\"\"\"\n",
        "        return [len(self.tokenizer.tokenize(text)) for text in texts]\n",
        "\n",
        "    def get_tokenizer_or_token_counter(self):\n",
        "        \"\"\"Return the tokenizer instance.\"\"\"\n",
        "        return self.tokenizer\n",
        "\n",
        "    @classmethod\n",
        "    def is_available(cls) -> bool:\n",
        "        \"\"\"Check if the required dependencies are available.\"\"\"\n",
        "        try:\n",
        "            import transformers\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"String representation of the embedding model.\"\"\"\n",
        "        return f\"CustomEmbeddings(model_name='{self.model_name}')\""
      ],
      "metadata": {
        "id": "npb6TYJVVAcI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = CustomEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "a223c54ff702471abe91d977f6afe9af",
            "a40283c5eedf42c18c64a33801908024",
            "c2d78a0a46a0419ea7d7522e947b7f17",
            "7e33e3f0171946beba6bba0484d11073",
            "94b0f48855df428b9296e0ba7d398a7d",
            "8d9c701a580e4d0aba9079e04d9d4355",
            "e3b054e978104f2b95fca318e809f897",
            "b16dcd5faa924b1b8705d06e726831e6",
            "ceb77ee5c9b045d7a54b012f5d8dfcf5",
            "0a8280bef25744a4b0ff9f7223808925",
            "bcff783498314b68acb3d07fd2d552d3",
            "4bfa126c9ad344e8a2a43fdee52167f1",
            "0bc8388a12c34bb595a8d49f133be2aa",
            "44974e8c1bff444b9e13992e1b5b1e1e",
            "9443e15948774f6285cd91441e90fc67",
            "ffa4de2f5edb47d8bb18ee171c6ee8cc",
            "59ba3b52ec954d1ab88f9bb01b4c2108",
            "34d1a3cf071842e58c27aa4dfb208c1f",
            "4466f390f3f04c6fb3552f4998d628f9",
            "1bcc2a31bb594fd78d7f44cfd4a52ada",
            "ccf7d94722d14fb4906876bae99c4508",
            "7e65dad092164afeb66eb70dd210f5ef",
            "62d7c1d254a849b3b12fef8363d468a8",
            "6212bbe8cc394a739cb3484be9c460b2",
            "dcf8258e26954f46b4fe6440a532a008",
            "bba934f1cab944c88dce0069dcc43f1e",
            "f262f2dd28bb419c83c63df87a795e9f",
            "4839de9339da4a9ab3b7ad8250cc4df9",
            "dfb8b0f394864a81ba7c293ee4e0f7d1",
            "d9f6dbad87be4540b3c5981d2fea5c99",
            "2a367dd51df5414ea64654a506bde8c0",
            "9efa088458dc44f989f86cfc98159ef6",
            "84ecc8706bd94942ab12235daaff3e89",
            "4bf86bdd479b49f7b14c41ef31e69524",
            "f9d87ee16bd74946b68bcfb316309cb3",
            "c57b55ff41364ffe8eff49443af83da5",
            "71bfcb2c416f49bea6d429066901b793",
            "9cb97cb10e764539bbccf3445a21104a",
            "d289616e36fe45b09faa2ea66ead65b8",
            "e781973a050445cb9735af18e43358e9",
            "5a095c08105744b8b5c5da0efdac8f2a",
            "b350da049d6d4737b870685c21770e05",
            "60881203646e4391981bb09264d4be7f",
            "033ef9b5a2f041db9bfa496eb266a1d4",
            "dd2c22f82b5f404e982fb6ebc043b3a4",
            "cf2f7e6cb8404704937905349f5a673f",
            "04bb2a18f77a4d20b0f0b1b75ff03206",
            "7631346bca744f28be0307abb0083e77",
            "ab081b7262444357968bad559c781eaa",
            "db12236845654e7caf1dbc0272c658dd",
            "1edc2754640841d095e14eda778eae6d",
            "4468ba2ebcfa476eb7dd3a04578fabda",
            "944bd7cf84e544cbb555eb7bfba00150",
            "958a3660c1744b06b0e2b658f4627974",
            "2151c9fa47e244e89cdc33b927123c6f",
            "3217044de4b04b479740cd459a558f55",
            "a483110331e7452488fef9f89ee22da9",
            "a4201ed5e97d438c8db0e8d5f417292e",
            "4b47005a872048629f2ab47858fb0b37",
            "77a382932a5e458280fa77016900ea13",
            "04923440086f469384eb15e2e3e3a6f7",
            "6cfd0f46b4e3463dabe81d5415de4699",
            "981d20a157744a878afe87b4e768cfc9",
            "1475c085c85d4932b06458a1eb9ed9b5",
            "534a8b429ca24163b6aa9f78f1f31c29",
            "ba129454fc0a423eb8b2df688c5519b2"
          ]
        },
        "id": "EU8qNE-YVsGq",
        "outputId": "c2d3521c-f438-473a-8e8a-c6f8a567a739"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a223c54ff702471abe91d977f6afe9af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bfa126c9ad344e8a2a43fdee52167f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d7c1d254a849b3b12fef8363d468a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bf86bdd479b49f7b14c41ef31e69524"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd2c22f82b5f404e982fb6ebc043b3a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3217044de4b04b479740cd459a558f55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH607rFdVvy3",
        "outputId": "0ce27306-146c-4928-b44b-5385a9799ae3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.4359811 , -0.58790463, -0.11468964, ..., -0.7736882 ,\n",
              "         0.60339296,  0.6033563 ], dtype=float32),\n",
              " array([ 0.36218122, -1.1659063 ,  0.56538236, ..., -0.80528873,\n",
              "         0.8631767 ,  0.66225153], dtype=float32),\n",
              " array([ 0.7624157 , -0.9271328 ,  0.8223067 , ..., -0.10036118,\n",
              "         0.8112479 ,  1.3361131 ], dtype=float32),\n",
              " array([ 0.560898  , -0.55373585,  0.05681695, ..., -0.84703386,\n",
              "         1.0089536 ,  0.93075854], dtype=float32),\n",
              " array([-0.2610247 , -1.0300088 , -0.04631982, ..., -0.17331098,\n",
              "         0.84630984,  0.66522604], dtype=float32),\n",
              " array([ 0.18299493, -0.9590812 ,  0.41047063, ..., -0.5811159 ,\n",
              "         0.83544344,  0.55094576], dtype=float32),\n",
              " array([ 0.725686  , -0.63923055,  1.2876815 , ..., -0.7500254 ,\n",
              "         0.9145995 ,  0.6906319 ], dtype=float32),\n",
              " array([ 0.7129024 , -0.2591378 ,  1.2687846 , ..., -0.24357282,\n",
              "         1.0471714 ,  0.73569274], dtype=float32),\n",
              " array([ 0.38317734, -1.1104361 ,  0.51858056, ..., -1.084575  ,\n",
              "         1.0646209 ,  0.7831806 ], dtype=float32),\n",
              " array([-0.25327337, -0.9085072 ,  0.47756842, ..., -0.7889462 ,\n",
              "         0.870697  ,  0.7978704 ], dtype=float32),\n",
              " array([ 0.8890334 , -0.86968607,  0.76259255, ..., -0.3833329 ,\n",
              "         0.88080084,  0.24118863], dtype=float32),\n",
              " array([ 0.24401076, -0.89753455,  0.66343063, ..., -0.7627144 ,\n",
              "         0.71240723, -0.16900492], dtype=float32),\n",
              " array([ 0.08955975, -0.60147935,  0.3899071 , ..., -0.6244658 ,\n",
              "         1.2423958 ,  0.0034354 ], dtype=float32),\n",
              " array([ 0.47994596, -0.8237424 ,  0.46325713, ..., -0.65721047,\n",
              "         0.61291444,  0.7419635 ], dtype=float32),\n",
              " array([ 0.2143969 , -0.24341333, -0.12670052, ..., -0.49782276,\n",
              "         0.6365684 ,  0.3126565 ], dtype=float32),\n",
              " array([ 0.7141877 , -0.3444245 ,  0.2323185 , ..., -0.37751678,\n",
              "         0.94630384,  0.763435  ], dtype=float32),\n",
              " array([ 0.7483044 , -0.7682396 ,  0.20974976, ..., -0.8210115 ,\n",
              "         0.6998073 , -0.04909665], dtype=float32),\n",
              " array([ 0.29632097, -0.79067355,  0.13871443, ..., -0.32595927,\n",
              "         0.8765594 ,  0.64798087], dtype=float32),\n",
              " array([ 0.51108307, -0.69663805,  0.21791637, ..., -0.40795144,\n",
              "         0.5466775 ,  0.60426   ], dtype=float32),\n",
              " array([ 0.41712907, -0.9457059 ,  0.49346375, ..., -0.9177767 ,\n",
              "         1.1079335 ,  0.1183597 ], dtype=float32),\n",
              " array([ 0.68267244, -1.0815424 ,  0.4982892 , ..., -0.47545812,\n",
              "         0.5972664 ,  0.7024831 ], dtype=float32),\n",
              " array([-0.09520273, -1.3625174 ,  0.2804672 , ..., -0.3489631 ,\n",
              "         1.2320598 ,  0.89331144], dtype=float32),\n",
              " array([-0.05347   , -1.1191423 ,  0.4246787 , ..., -0.69889486,\n",
              "         0.47016698,  0.73322886], dtype=float32),\n",
              " array([ 0.08372702, -0.7146503 ,  0.40935886, ..., -0.78020567,\n",
              "         0.8872647 ,  0.83938575], dtype=float32),\n",
              " array([ 0.19730294, -0.91190994,  0.33847088, ..., -0.8402494 ,\n",
              "         0.81939656,  0.84539926], dtype=float32),\n",
              " array([ 0.07234255, -0.6816154 ,  0.7063637 , ..., -0.7352966 ,\n",
              "         1.3471144 ,  0.40204197], dtype=float32),\n",
              " array([ 0.22026968, -1.7032733 ,  0.66192037, ..., -0.7690669 ,\n",
              "         1.2239836 ,  0.33590156], dtype=float32),\n",
              " array([ 0.14227194, -1.053454  ,  0.33747396, ..., -0.41103417,\n",
              "         0.94854146,  0.68861365], dtype=float32),\n",
              " array([ 0.27940652, -0.63281405,  0.6556578 , ..., -0.42103824,\n",
              "         1.0433509 ,  0.54320204], dtype=float32),\n",
              " array([ 0.51636  , -2.0204463,  0.2588959, ..., -1.4181602,  0.8765713,\n",
              "         0.9199873], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import SemanticChunker\n",
        "custom_chunker = SemanticChunker(embeddings, similarity_threshold=0.7)\n",
        "\n",
        "# Chunk the text\n",
        "custom_chunks = chunker(text)"
      ],
      "metadata": {
        "id": "o8xxO0eNWQf5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHo2QdqaWbte",
        "outputId": "c357f534-98c0-40fc-abb7-7256a60c5417"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SemanticChunk(text='\\n1. The Evolution of LLM Engineering\\n', start_index=0, end_index=37, token_count=10, context=None, sentences=[SemanticSentence(text='\\n1.', start_index=0, end_index=3, token_count=3, embedding=array([-0.0079946 , -0.00584424, -0.02344213, ..., -0.00952184,\n",
              "         0.00310335,  0.00753846], dtype=float32)), SemanticSentence(text=' The Evolution of LLM Engineering\\n', start_index=3, end_index=37, token_count=7, embedding=array([-0.01877389, -0.00547267, -0.03072889, ...,  0.00133158,\n",
              "        -0.00083864,  0.01038929], dtype=float32))]),\n",
              " SemanticChunk(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=37, end_index=629, token_count=98, context=None, sentences=[SemanticSentence(text='LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.', start_index=37, end_index=197, token_count=24, embedding=array([-0.03443007, -0.00026048, -0.03343253, ...,  0.0074475 ,\n",
              "        -0.00497634,  0.01073861], dtype=float32)), SemanticSentence(text=' These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.', start_index=197, end_index=354, token_count=27, embedding=array([-0.02676347,  0.00334937, -0.03572663, ...,  0.00886077,\n",
              "        -0.00605683, -0.00022177], dtype=float32)), SemanticSentence(text=' However, their true utility lies in how they are engineered to interact with specific tasks and contexts.', start_index=354, end_index=460, token_count=19, embedding=array([-0.02312879,  0.0018067 , -0.02666845, ...,  0.01481664,\n",
              "        -0.02288676, -0.0002373 ], dtype=float32)), SemanticSentence(text=' LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.', start_index=460, end_index=629, token_count=28, embedding=array([-0.0148082 ,  0.00011955, -0.028765  , ..., -0.00373246,\n",
              "        -0.01231482, -0.01101493], dtype=float32))]),\n",
              " SemanticChunk(text=\" It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2. The Science of Prompt Design\\nCentral to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3. Advanced Prompting Techniques and Applications\\nBeyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.\", start_index=629, end_index=2371, token_count=296, context=None, sentences=[SemanticSentence(text=' It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\\n\\n2.', start_index=629, end_index=835, token_count=35, embedding=array([-0.00172072, -0.01891986, -0.02985816, ..., -0.00826027,\n",
              "        -0.00489557, -0.01133414], dtype=float32)), SemanticSentence(text=' The Science of Prompt Design\\n', start_index=835, end_index=865, token_count=6, embedding=array([ 0.01105896, -0.02586268, -0.02852384, ..., -0.00291812,\n",
              "        -0.00650551, -0.00749348], dtype=float32)), SemanticSentence(text='Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.', start_index=865, end_index=1008, token_count=29, embedding=array([-0.00512177, -0.00606095, -0.02561265, ..., -0.00325101,\n",
              "        -0.00247153,  0.00150953], dtype=float32)), SemanticSentence(text=' Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.', start_index=1008, end_index=1185, token_count=30, embedding=array([-6.6398699e-03, -7.7462617e-05, -2.5165027e-02, ...,\n",
              "         1.8646766e-03, -2.0501309e-03,  1.3741856e-03], dtype=float32)), SemanticSentence(text=' Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.', start_index=1185, end_index=1334, token_count=24, embedding=array([-0.00993003,  0.00230519, -0.02100768, ...,  0.01366774,\n",
              "        -0.00927653, -0.00425971], dtype=float32)), SemanticSentence(text=' Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.', start_index=1334, end_index=1470, token_count=19, embedding=array([ 0.00131051,  0.00185928, -0.02082554, ...,  0.01778254,\n",
              "        -0.00727468, -0.0028964 ], dtype=float32)), SemanticSentence(text=\" By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\\n\\n3.\", start_index=1470, end_index=1629, token_count=29, embedding=array([-0.00753181, -0.01324628, -0.0280749 , ...,  0.00206018,\n",
              "        -0.00431229, -0.00446895], dtype=float32)), SemanticSentence(text=' Advanced Prompting Techniques and Applications\\n', start_index=1629, end_index=1677, token_count=7, embedding=array([-0.00690098, -0.00023465, -0.02366051, ...,  0.00408055,\n",
              "        -0.00039425, -0.00842795], dtype=float32)), SemanticSentence(text='Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.', start_index=1677, end_index=1781, token_count=19, embedding=array([-0.02075936,  0.01094031, -0.03437468, ...,  0.00964285,\n",
              "         0.00348392, -0.00836141], dtype=float32)), SemanticSentence(text=' For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.', start_index=1781, end_index=1937, token_count=26, embedding=array([-0.01644921,  0.01013205, -0.02836975, ...,  0.00749444,\n",
              "        -0.0025966 ,  0.00090091], dtype=float32)), SemanticSentence(text=' Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.', start_index=1937, end_index=2051, token_count=19, embedding=array([-0.02480173,  0.00127599, -0.02441152, ...,  0.00385527,\n",
              "         0.00072823, -0.01081661], dtype=float32)), SemanticSentence(text=' These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.', start_index=2051, end_index=2218, token_count=25, embedding=array([-0.02429505, -0.00530959, -0.03211888, ..., -0.00218758,\n",
              "        -0.02082659, -0.00568574], dtype=float32)), SemanticSentence(text=' By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\\n\\n4.', start_index=2218, end_index=2371, token_count=28, embedding=array([-0.0087226 , -0.00766879, -0.02615992, ...,  0.00801217,\n",
              "        -0.00875418, -0.00567956], dtype=float32))]),\n",
              " SemanticChunk(text=' Integration with External Systems\\nAnother critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5.', start_index=2371, end_index=3063, token_count=119, context=None, sentences=[SemanticSentence(text=' Integration with External Systems\\n', start_index=2371, end_index=2406, token_count=5, embedding=array([-0.01455129,  0.00344887, -0.02631414, ...,  0.01368541,\n",
              "         0.00065721,  0.0006219 ], dtype=float32)), SemanticSentence(text='Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.', start_index=2406, end_index=2530, token_count=20, embedding=array([-0.02160832,  0.00918054, -0.02898567, ...,  0.00433588,\n",
              "         0.00107929,  0.00370925], dtype=float32)), SemanticSentence(text=' Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.', start_index=2530, end_index=2741, token_count=36, embedding=array([-0.02716751,  0.00825439, -0.03003128, ...,  0.00557439,\n",
              "        -0.0121289 ,  0.01285633], dtype=float32)), SemanticSentence(text=' For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.', start_index=2741, end_index=2857, token_count=21, embedding=array([-0.01319363, -0.00733193, -0.02654121, ...,  0.00032642,\n",
              "        -0.01735032, -0.0055461 ], dtype=float32)), SemanticSentence(text=' This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\\n\\n5.', start_index=2857, end_index=3063, token_count=37, embedding=array([-0.02319075, -0.00112529, -0.02740162, ..., -0.00493848,\n",
              "        -0.00872362, -0.01510959], dtype=float32))]),\n",
              " SemanticChunk(text=' Ethical Considerations in LLM Engineering\\nAs LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=3063, end_index=3445, token_count=68, context=None, sentences=[SemanticSentence(text=' Ethical Considerations in LLM Engineering\\n', start_index=3063, end_index=3106, token_count=9, embedding=array([-0.02222099, -0.00978617, -0.02781089, ..., -0.004639  ,\n",
              "        -0.00769958, -0.02075807], dtype=float32)), SemanticSentence(text='As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.', start_index=3106, end_index=3223, token_count=21, embedding=array([-0.02653594, -0.00600406, -0.03017869, ..., -0.00726391,\n",
              "        -0.00464343,  0.00060338], dtype=float32)), SemanticSentence(text=' Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.', start_index=3223, end_index=3326, token_count=18, embedding=array([-0.02118306, -0.00473929, -0.02648988, ..., -0.01289115,\n",
              "        -0.00415332,  0.00561639], dtype=float32)), SemanticSentence(text=' Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.', start_index=3326, end_index=3445, token_count=20, embedding=array([-0.01840859, -0.01412972, -0.02315966, ..., -0.01986151,\n",
              "        -0.01097686,  0.00112511], dtype=float32))]),\n",
              " SemanticChunk(text=' Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=3445, end_index=3611, token_count=24, context=None, sentences=[SemanticSentence(text=' Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.', start_index=3445, end_index=3611, token_count=24, embedding=array([-0.010541  , -0.00862089, -0.02746146, ..., -0.01387964,\n",
              "        -0.02871541, -0.01145011], dtype=float32))]),\n",
              " SemanticChunk(text=\" Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6. The Future of LLM Engineering and Prompting\\nThe future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=3611, end_index=4535, token_count=162, context=None, sentences=[SemanticSentence(text=' Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\\n\\n6.', start_index=3611, end_index=3764, token_count=29, embedding=array([-0.0355697 , -0.00497326, -0.0301328 , ..., -0.01597783,\n",
              "        -0.01876761, -0.0232693 ], dtype=float32)), SemanticSentence(text=' The Future of LLM Engineering and Prompting\\n', start_index=3764, end_index=3809, token_count=10, embedding=array([-0.03687552, -0.00426488, -0.02940241, ..., -0.01023724,\n",
              "        -0.01721266, -0.02016822], dtype=float32)), SemanticSentence(text='The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.', start_index=3809, end_index=3970, token_count=25, embedding=array([-0.0325003 ,  0.00087569, -0.02937009, ..., -0.00882151,\n",
              "        -0.00977255, -0.00354021], dtype=float32)), SemanticSentence(text=' Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.', start_index=3970, end_index=4200, token_count=38, embedding=array([-0.02526757,  0.00918021, -0.03023896, ..., -0.00939285,\n",
              "        -0.0130224 , -0.00063746], dtype=float32)), SemanticSentence(text=' Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.', start_index=4200, end_index=4354, token_count=27, embedding=array([-0.01489976,  0.0049748 , -0.02815181, ..., -0.00791462,\n",
              "        -0.0136675 , -0.00537616], dtype=float32)), SemanticSentence(text=\" As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\\n\", start_index=4354, end_index=4535, token_count=33, embedding=array([-0.02164714,  0.01378374, -0.02337274, ..., -0.0170736 ,\n",
              "        -0.0140503 , -0.00475942], dtype=float32))])]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}