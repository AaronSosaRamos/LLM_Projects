{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chonkie RecursiveChunker\n",
        "Made by: Wilfredo Aaron Sosa Ramos"
      ],
      "metadata": {
        "id": "jHgIZNacPKLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdUg7ecXPGRB",
        "outputId": "ce6f64fb-2de0-4d60-f91d-b1ef9e763e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q chonkie[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single Text Chunking"
      ],
      "metadata": {
        "id": "vqidLRgvPPFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chonkie import RecursiveChunker, RecursiveRules\n",
        "\n",
        "chunker = RecursiveChunker(\n",
        "    tokenizer=\"gpt2\",\n",
        "    chunk_size=256,\n",
        "    rules=RecursiveRules(), # Default rules\n",
        "    min_characters_per_chunk=12,\n",
        ")"
      ],
      "metadata": {
        "id": "6DZWOg0-PPXT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "1. The Evolution of LLM Engineering\n",
        "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
        "\n",
        "2. The Science of Prompt Design\n",
        "Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
        "\n",
        "3. Advanced Prompting Techniques and Applications\n",
        "Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
        "\n",
        "4. Integration with External Systems\n",
        "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
        "\n",
        "5. Ethical Considerations in LLM Engineering\n",
        "As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
        "\n",
        "6. The Future of LLM Engineering and Prompting\n",
        "The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
        "\"\"\"\n",
        "\n",
        "chunks = chunker.chunk(text)\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(f\"Chunk text: {chunk.text}\")\n",
        "    print(f\"Token count: {chunk.token_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hQ21pDBPScb",
        "outputId": "87a6d13c-d74f-48df-9b78-a1f51cd23fa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk text: \n",
            "1. The Evolution of LLM Engineering\n",
            "LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "\n",
            "2. The Science of Prompt Design\n",
            "\n",
            "Token count: 150\n",
            "Chunk text: Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "\n",
            "3. Advanced Prompting Techniques and Applications\n",
            "\n",
            "Token count: 149\n",
            "Chunk text: Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "\n",
            "4. Integration with External Systems\n",
            "Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "\n",
            "5. Ethical Considerations in LLM Engineering\n",
            "\n",
            "Token count: 254\n",
            "Chunk text: As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "\n",
            "6. The Future of LLM Engineering and Prompting\n",
            "The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
            "\n",
            "Token count: 247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batch Chunking\n",
        "\n"
      ],
      "metadata": {
        "id": "Kj8rSLfCPdWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The Evolution of LLM Engineering\n",
        "evolution_of_llm_engineering = [\n",
        "    \"LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\",\n",
        "    \"These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\",\n",
        "    \"However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\",\n",
        "    \"LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\",\n",
        "    \"It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\"\n",
        "]\n",
        "\n",
        "# 2. The Science of Prompt Design\n",
        "science_of_prompt_design = [\n",
        "    \"Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\",\n",
        "    \"Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\",\n",
        "    \"Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\",\n",
        "    \"Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\",\n",
        "    \"By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\"\n",
        "]\n",
        "\n",
        "# 3. Advanced Prompting Techniques and Applications\n",
        "advanced_prompting_techniques = [\n",
        "    \"Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\",\n",
        "    \"For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\",\n",
        "    \"Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\",\n",
        "    \"These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\",\n",
        "    \"By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\"\n",
        "]\n",
        "\n",
        "# 4. Integration with External Systems\n",
        "integration_with_external_systems = [\n",
        "    \"Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\",\n",
        "    \"Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\",\n",
        "    \"For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\",\n",
        "    \"This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\",\n",
        "    \"It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\"\n",
        "]\n",
        "\n",
        "# 5. Ethical Considerations in LLM Engineering\n",
        "ethical_considerations = [\n",
        "    \"As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\",\n",
        "    \"Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\",\n",
        "    \"Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\",\n",
        "    \"Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\",\n",
        "    \"Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\"\n",
        "]\n",
        "\n",
        "# 6. The Future of LLM Engineering and Prompting\n",
        "future_of_llm_engineering = [\n",
        "    \"The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\",\n",
        "    \"Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\",\n",
        "    \"Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\",\n",
        "    \"As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\",\n",
        "    \"They will drive innovation while upholding ethical and technical standards.\"\n",
        "]\n",
        "texts = evolution_of_llm_engineering + science_of_prompt_design + advanced_prompting_techniques + integration_with_external_systems + ethical_considerations + future_of_llm_engineering"
      ],
      "metadata": {
        "id": "YbVXAnX1PgIF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunker.chunk_batch(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEMYR0ZbPd5H",
        "outputId": "86034e4f-0d8d-4cd8-d07d-912b9672299d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🦛 choooooooooooooooooooonk 100% • 30/30 docs chunked [00:00<00:00, 453.47doc/s] 🌱\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrumXxLMPmTe",
        "outputId": "5b6ab9dd-a0e8-4cdd-9952-0ba3235c69ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[RecursiveChunk(text=LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications., start_index=0, end_index=160, token_count=24, level=0)],\n",
              " [RecursiveChunk(text=These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation., start_index=0, end_index=156, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=However, their true utility lies in how they are engineered to interact with specific tasks and contexts., start_index=0, end_index=105, token_count=19, level=0)],\n",
              " [RecursiveChunk(text=LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable., start_index=0, end_index=168, token_count=29, level=0)],\n",
              " [RecursiveChunk(text=It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business., start_index=0, end_index=201, token_count=32, level=0)],\n",
              " [RecursiveChunk(text=Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior., start_index=0, end_index=143, token_count=31, level=0)],\n",
              " [RecursiveChunk(text=Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering., start_index=0, end_index=176, token_count=33, level=0)],\n",
              " [RecursiveChunk(text=Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance., start_index=0, end_index=148, token_count=26, level=0)],\n",
              " [RecursiveChunk(text=Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process., start_index=0, end_index=135, token_count=22, level=0)],\n",
              " [RecursiveChunk(text=By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs., start_index=0, end_index=154, token_count=28, level=0)],\n",
              " [RecursiveChunk(text=Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively., start_index=0, end_index=104, token_count=19, level=0)],\n",
              " [RecursiveChunk(text=For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction., start_index=0, end_index=155, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements., start_index=0, end_index=113, token_count=21, level=0)],\n",
              " [RecursiveChunk(text=These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount., start_index=0, end_index=166, token_count=25, level=0)],\n",
              " [RecursiveChunk(text=By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments., start_index=0, end_index=148, token_count=26, level=0)],\n",
              " [RecursiveChunk(text=Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality., start_index=0, end_index=124, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems., start_index=0, end_index=210, token_count=36, level=0)],\n",
              " [RecursiveChunk(text=For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries., start_index=0, end_index=115, token_count=21, level=0)],\n",
              " [RecursiveChunk(text=This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows., start_index=0, end_index=106, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=It enhances their value in industries like finance, e-commerce, and AI-powered customer support., start_index=0, end_index=96, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering., start_index=0, end_index=117, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment., start_index=0, end_index=102, token_count=18, level=0)],\n",
              " [RecursiveChunk(text=Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets., start_index=0, end_index=118, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations., start_index=0, end_index=165, token_count=24, level=0)],\n",
              " [RecursiveChunk(text=Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration., start_index=0, end_index=148, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries., start_index=0, end_index=161, token_count=25, level=0)],\n",
              " [RecursiveChunk(text=Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly., start_index=0, end_index=229, token_count=42, level=0)],\n",
              " [RecursiveChunk(text=Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time., start_index=0, end_index=153, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society., start_index=0, end_index=111, token_count=23, level=0)],\n",
              " [RecursiveChunk(text=They will drive innovation while upholding ethical and technical standards., start_index=0, end_index=75, token_count=11, level=0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk_array in chunks:\n",
        "    for chunk in chunk_array:\n",
        "      print(f\"Chunk text: {chunk.text}\")\n",
        "      print(f\"Token count: {chunk.token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3-okGfrPop1",
        "outputId": "f831ea39-dc64-42c7-b758-2d3e4f9bc66b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk text: LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications.\n",
            "Token count: 24\n",
            "Chunk text: These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation.\n",
            "Token count: 27\n",
            "Chunk text: However, their true utility lies in how they are engineered to interact with specific tasks and contexts.\n",
            "Token count: 19\n",
            "Chunk text: LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable.\n",
            "Token count: 29\n",
            "Chunk text: It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
            "Token count: 32\n",
            "Chunk text: Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior.\n",
            "Token count: 31\n",
            "Chunk text: Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering.\n",
            "Token count: 33\n",
            "Chunk text: Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance.\n",
            "Token count: 26\n",
            "Chunk text: Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process.\n",
            "Token count: 22\n",
            "Chunk text: By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
            "Token count: 28\n",
            "Chunk text: Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively.\n",
            "Token count: 19\n",
            "Chunk text: For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction.\n",
            "Token count: 27\n",
            "Chunk text: Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements.\n",
            "Token count: 21\n",
            "Chunk text: These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount.\n",
            "Token count: 25\n",
            "Chunk text: By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
            "Token count: 26\n",
            "Chunk text: Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality.\n",
            "Token count: 20\n",
            "Chunk text: Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems.\n",
            "Token count: 36\n",
            "Chunk text: For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries.\n",
            "Token count: 21\n",
            "Chunk text: This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows.\n",
            "Token count: 20\n",
            "Chunk text: It enhances their value in industries like finance, e-commerce, and AI-powered customer support.\n",
            "Token count: 20\n",
            "Chunk text: As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering.\n",
            "Token count: 20\n",
            "Chunk text: Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment.\n",
            "Token count: 18\n",
            "Chunk text: Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets.\n",
            "Token count: 20\n",
            "Chunk text: Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations.\n",
            "Token count: 24\n",
            "Chunk text: Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
            "Token count: 27\n",
            "Chunk text: The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries.\n",
            "Token count: 25\n",
            "Chunk text: Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly.\n",
            "Token count: 42\n",
            "Chunk text: Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time.\n",
            "Token count: 27\n",
            "Chunk text: As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society.\n",
            "Token count: 23\n",
            "Chunk text: They will drive innovation while upholding ethical and technical standards.\n",
            "Token count: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using as a Callable\n",
        "\n"
      ],
      "metadata": {
        "id": "c_FmCaCzPysA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single text\n",
        "chunks = chunker(text)\n",
        "\n",
        "# Multiple texts\n",
        "batch_chunks = chunker(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4ZCV8vNPzSY",
        "outputId": "d36b69b6-4296-49c1-8c82-fde908bcc920"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🦛 choooooooooooooooooooonk 100% • 30/30 docs chunked [00:00<00:00, 1120.32doc/s] 🌱\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ-Bq3CqQVpu",
        "outputId": "5e7c0b28-527a-4be2-95fa-b77335e2d32e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RecursiveChunk(text=\n",
              " 1. The Evolution of LLM Engineering\n",
              " LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications. These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation. However, their true utility lies in how they are engineered to interact with specific tasks and contexts. LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable. It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business.\n",
              " \n",
              " 2. The Science of Prompt Design\n",
              " , start_index=0, end_index=865, token_count=150, level=0),\n",
              " RecursiveChunk(text=Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior. Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering. Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance. Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process. By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs.\n",
              " \n",
              " 3. Advanced Prompting Techniques and Applications\n",
              " , start_index=865, end_index=1677, token_count=149, level=0),\n",
              " RecursiveChunk(text=Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively. For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction. Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements. These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount. By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments.\n",
              " \n",
              " 4. Integration with External Systems\n",
              " Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality. Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems. For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries. This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows, enhancing their value in industries like finance, e-commerce, and AI-powered customer support.\n",
              " \n",
              " 5. Ethical Considerations in LLM Engineering\n",
              " , start_index=1677, end_index=3106, token_count=254, level=0),\n",
              " RecursiveChunk(text=As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering. Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment. Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets. Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations. Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration.\n",
              " \n",
              " 6. The Future of LLM Engineering and Prompting\n",
              " The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries. Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly. Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time. As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society, driving innovation while upholding ethical and technical standards.\n",
              " , start_index=3106, end_index=4535, token_count=247, level=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9z9FTR_QWGi",
        "outputId": "eb646779-e394-4993-8c0f-c107a913abef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[RecursiveChunk(text=LLM engineering is a cornerstone of modern artificial intelligence, enabling the development and optimization of large language models for diverse applications., start_index=0, end_index=160, token_count=24, level=0)],\n",
              " [RecursiveChunk(text=These models, like GPT-4 or Gemini, are trained on massive datasets and possess extraordinary capabilities in natural language understanding and generation., start_index=0, end_index=156, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=However, their true utility lies in how they are engineered to interact with specific tasks and contexts., start_index=0, end_index=105, token_count=19, level=0)],\n",
              " [RecursiveChunk(text=LLM engineering focuses on creating robust pipelines, integrating external tools, and refining user interactions to make models more effective, reliable, and adaptable., start_index=0, end_index=168, token_count=29, level=0)],\n",
              " [RecursiveChunk(text=It also addresses challenges like hallucinations, bias, and efficiency, ensuring that these models deliver meaningful and accurate results across industries such as education, healthcare, and business., start_index=0, end_index=201, token_count=32, level=0)],\n",
              " [RecursiveChunk(text=Central to LLM engineering is the art and science of prompt design—crafting the textual or programmatic inputs that guide the model’s behavior., start_index=0, end_index=143, token_count=31, level=0)],\n",
              " [RecursiveChunk(text=Prompting techniques range from basic approaches, like zero-shot and few-shot prompting, to more advanced strategies, such as instruction tuning and dynamic prompt engineering., start_index=0, end_index=176, token_count=33, level=0)],\n",
              " [RecursiveChunk(text=Zero-shot prompting involves giving the model a direct task with minimal context, while few-shot prompting provides examples to improve performance., start_index=0, end_index=148, token_count=26, level=0)],\n",
              " [RecursiveChunk(text=Engineers often employ techniques like chaining prompts or incorporating contextual constraints to guide the model’s reasoning process., start_index=0, end_index=135, token_count=22, level=0)],\n",
              " [RecursiveChunk(text=By mastering prompt design, LLM engineers can unlock the model's latent potential, ensuring it understands tasks deeply and produces high-quality outputs., start_index=0, end_index=154, token_count=28, level=0)],\n",
              " [RecursiveChunk(text=Beyond basic prompting, advanced techniques enable LLMs to tackle complex, multi-step tasks effectively., start_index=0, end_index=104, token_count=19, level=0)],\n",
              " [RecursiveChunk(text=For example, chain-of-thought prompting encourages models to explain their reasoning step by step, improving accuracy in tasks requiring logical deduction., start_index=0, end_index=155, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=Similarly, self-reflection prompts ask the model to evaluate its own responses, fostering iterative improvements., start_index=0, end_index=113, token_count=21, level=0)],\n",
              " [RecursiveChunk(text=These techniques are particularly valuable in applications like legal research, scientific analysis, and technical writing, where precision and clarity are paramount., start_index=0, end_index=166, token_count=25, level=0)],\n",
              " [RecursiveChunk(text=By leveraging such methods, LLM engineers can adapt models to solve intricate problems, making them indispensable tools in high-stakes environments., start_index=0, end_index=148, token_count=26, level=0)],\n",
              " [RecursiveChunk(text=Another critical aspect of LLM engineering is integrating models with external tools and APIs to expand their functionality., start_index=0, end_index=124, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Through techniques like tool usage prompting and plugin development, LLMs can perform tasks beyond text generation, such as retrieving real-time data, running calculations, or interacting with software systems., start_index=0, end_index=210, token_count=36, level=0)],\n",
              " [RecursiveChunk(text=For example, an LLM integrated with a database API can provide detailed analytics based on structured data queries., start_index=0, end_index=115, token_count=21, level=0)],\n",
              " [RecursiveChunk(text=This seamless integration transforms LLMs into versatile agents capable of executing end-to-end workflows., start_index=0, end_index=106, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=It enhances their value in industries like finance, e-commerce, and AI-powered customer support., start_index=0, end_index=96, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=As LLMs become increasingly integrated into society, ethical considerations are a vital component of LLM engineering., start_index=0, end_index=117, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Engineers must address issues such as bias, fairness, and privacy to ensure responsible AI deployment., start_index=0, end_index=102, token_count=18, level=0)],\n",
              " [RecursiveChunk(text=Prompt design plays a significant role in mitigating biases by carefully framing tasks and curating training datasets., start_index=0, end_index=118, token_count=20, level=0)],\n",
              " [RecursiveChunk(text=Moreover, engineers are tasked with implementing safeguards against misuse, such as restricting harmful outputs or ensuring compliance with data privacy regulations., start_index=0, end_index=165, token_count=24, level=0)],\n",
              " [RecursiveChunk(text=Ethical LLM engineering not only protects users but also builds trust in AI systems, paving the way for their widespread acceptance and integration., start_index=0, end_index=148, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=The future of LLM engineering lies in the continued refinement of prompting techniques and the development of specialized models tailored to specific industries., start_index=0, end_index=161, token_count=25, level=0)],\n",
              " [RecursiveChunk(text=Emerging trends include adaptive prompt generation, where AI dynamically modifies prompts based on user behavior, and multi-modal integration, allowing models to process and generate text, images, and other data types seamlessly., start_index=0, end_index=229, token_count=42, level=0)],\n",
              " [RecursiveChunk(text=Additionally, advancements in reinforcement learning and fine-tuning will enable LLMs to learn from user feedback, improving their performance over time., start_index=0, end_index=153, token_count=27, level=0)],\n",
              " [RecursiveChunk(text=As the field evolves, LLM engineers and researchers will play a crucial role in shaping AI's impact on society., start_index=0, end_index=111, token_count=23, level=0)],\n",
              " [RecursiveChunk(text=They will drive innovation while upholding ethical and technical standards., start_index=0, end_index=75, token_count=11, level=0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}