{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal RAG with Gemini 2.0\n",
        "By: Wilfredo Aaron Sosa Ramos (AI Lab Manager)"
      ],
      "metadata": {
        "id": "EjINxMFHXubv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaWTXiLMXkxq",
        "outputId": "e4eb3e04-b861-4038-a39a-70d5ed2089e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_core langchain_community langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypdf beautifulsoup4 arxiv pymupdf assemblyai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlRvdYkRYDub",
        "outputId": "7f594092-e506-4e1d-8ac5-1397b9d8f3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chroma langchain_chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFqL5PUfZUyw",
        "outputId": "88cc302d-c820-4f2b-9802-fb53f97d35f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set env. variables"
      ],
      "metadata": {
        "id": "HNljMR2XY3kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['ASSEMBLYAI_API_KEY'] = userdata.get('ASSEMBLYAI_API_KEY')"
      ],
      "metadata": {
        "id": "19jJYKKJY6sb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Class for downloading files"
      ],
      "metadata": {
        "id": "nbmLGUozaFLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import uuid\n",
        "import requests\n",
        "\n",
        "class FileHandler:\n",
        "    def __init__(self, file_loader, file_extension):\n",
        "        self.file_loader = file_loader\n",
        "        self.file_extension = file_extension\n",
        "\n",
        "    def load(self, url):\n",
        "        # Generate a unique filename with a UUID prefix\n",
        "        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n",
        "\n",
        "        try:\n",
        "            # Download the file from the URL and save it to a temporary file\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raise an HTTPError for bad responses\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, prefix=unique_filename) as temp_file:\n",
        "                temp_file.write(response.content)\n",
        "                temp_file_path = temp_file.name\n",
        "\n",
        "        except requests.exceptions.RequestException as req_err:\n",
        "            raise Exception(f\"Failed to download file from URL\", url) from req_err\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to handle file download\", url) from e\n",
        "\n",
        "        # Use the file_loader to load the documents\n",
        "        try:\n",
        "            loader = self.file_loader(file_path=temp_file_path)\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"No file found\", temp_file_path) from e\n",
        "\n",
        "        try:\n",
        "            documents = loader.load()\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"No file content available\", temp_file_path) from e\n",
        "\n",
        "        # Remove the temporary file\n",
        "        os.remove(temp_file_path)\n",
        "\n",
        "        return documents"
      ],
      "metadata": {
        "id": "4AxhfaH4ZyYa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. PDF Document Loader:"
      ],
      "metadata": {
        "id": "DPvXDNxzaMbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "def load_pdf_documents(pdf_url: str):\n",
        "    pdf_loader = FileHandler(PyPDFLoader, \"pdf\")\n",
        "    docs = pdf_loader.load(pdf_url)\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        return split_docs"
      ],
      "metadata": {
        "id": "80R_LOtOaO-r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_pdf = load_pdf_documents(\"https://mackinstitute.wharton.upenn.edu/wp-content/uploads/2023/08/LLM-Ideas-Working-Paper.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwVo76baaX5C",
        "outputId": "d4b18d75-e25b-4bc3-a980-8737e4c70e3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_pdf"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJndPvEfahHl",
        "outputId": "37631381-cd94-4a38-9a82-2443bdd24cdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='Co-Brand Name \\nIdeas Are Dimes A Dozen: Large Language Models For Idea \\nGeneration In Innovation \\nKaran Girotra, Lennart Meincke, Christian Terwiesch, and Karl T. Ulrich1\\nJuly 10, 2023 \\nMack Institute for Innovation Management, The Wharton School, University of Pennsylvania \\nCornell Tech and Johnson College of Business, Cornell University\\nAbstract \\nLarge language models (LLMs) such as OpenID’s GPT series have shown remarkable capabilities in generating \\nfluent and coherent text in various domains. We compare the ideation capabilities of ChatGPT-4, a chatbot based \\non a state-of-the-art LLM, with those of students at an elite university. ChatGPT-4 can generate ideas much faster \\nand cheaper than students, and the ideas are on average of higher quality (as measured by purchase-intent \\nsurveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly \\nrated ideas further increases its performance. We discuss the implications of these findings for the management \\nof innovation. \\nKeywords: innovation, idea generation, creativity, creative problem solving, LLM, large-scale language models, \\nAI, artificial intelligence, ChatGPT \\nIntroduction \\nGenerative artificial intelligence has made remarkable advances in creating life-like images and coherent, fluent \\ntext. OpenAI’s ChatGPT chatbot, based on the GPT series of large language models (LLM) can equal or surpass \\nhuman performance in academic examinations and tests for professional certifications (OpenAI, 2023). Github \\nCo-Pilot based on the same LLMs can help with writing, commenting, and debugging code. Other models can \\nprovide valuable professional advice in fields like medicine and law.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='provide valuable professional advice in fields like medicine and law. \\nDespite their remarkable performance, LLMs sometimes produce text that is semantically or syntactically \\nplausible but is, in fact, factually incorrect or nonsensical (i.e., hallucinations). The models\\n are optimized to \\ngenerate the most statistically likely sequences of words with an injection of randomness. They are not designed \\n1 Girotra: Cornell Tech, 2 West Loop Rd, New York, NY, 10044, girotra@cornell.edu  | Meincke, Terwiesch, Ulrich: The \\nWharton School, 500 Huntsman Hall, 3730 Walnut Street, Philadelphia, PA 19104, lennart@sas.upenn.edu, \\nterwiesch@wharton.upenn.edu, ulrich@wharton.upenn.edu'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='to exercise any judgment on the veracity or feasibility of the output. Further, the underlying optimization algorithms provide no performance guarantees, and their output can thus be of inconsistent quality. Hallucinations and inconsistency are critical flaws that limit the use of LLM-based solutions to low-stakes settings or in conjunction with expensive human supervision.   In what applications can we leverage artificial intelligence that is brilliant in many ways yet cannot be trusted to produce reliably accurate results? One possibility is to turn their weaknesses – hallucinations and inconsistent quality – into a strength (Terwiesch, 2023). In most management settings, we expect to make use of each unit of work produced. As such, consistency is prized and is, therefore, the focus of contemporary performance management. (See, for example, the Six Sigma methodology.) Erratic and inconsistent behavior is to be eliminated. For example, an airline would rather hire a pilot that'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='inconsistent behavior is to be eliminated. For example, an airline would rather hire a pilot that executes a within-safety-margins landing 10 out of 10 times rather than one that makes a brilliant approach five times and an unsafe approach another five.  But, when it comes to creativity and innovation, say finding a new opportunity to improve the air travel experience or launching a new aviation venture, the same airline would prefer an ideator that generates one brilliant idea and nine nonsense ideas over one that generates ten decent ideas. In creative tasks, given that only one or a few ideas will be pursued, only a few extremely positive outcomes matter. Similarly, an ideator that generates 30 ideas is likelier to have one brilliant idea than an ideator that generates just 10. Overall, in creative problem-solving, variability in quality, and productivity, as reflected in the number of ideas generated, are more valuable than consistency (Girotra et al., 2010).  To achieve high'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='of ideas generated, are more valuable than consistency (Girotra et al., 2010).  To achieve high variability in quality and high productivity, most research on ideation and brainstorming recommends enhancing performance by generating many ideas while postponing evaluation or judgment of ideas (Girotra et al., 2010). This is hard for human ideators to do, but LLMs are designed to do exactly this— quickly generate many somewhat plausible solutions without exercising much judgment. Further, the hallucinations and inconsistent behavior of LLMs increase the variability in quality, which, on average, improves the quality of the best ideas. For ideation, an LLM’s lack of judgment and inconsistency could be prized features, not bugs.  Thus, we hypothesize that LLMs will be excellent ideators. The purpose of this paper is to test this hypothesis by evaluating the performance of LLMs in generating new ideas.  Specifically, we compare three pools of ideas for new consumer products. The first pool'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='new ideas.  Specifically, we compare three pools of ideas for new consumer products. The first pool was created by students at an elite university enrolled in a course on product design prior to the availability of LLMs. The second pool of ideas was generated by OpenAI’s ChatGPT-4 with the same prompt as that given to the students. The third pool of ideas was generated by prompting ChatGPT-4 with the task as well as with a sample of highly rated ideas to enable some in-context learning (i.e., few-shot prompting).  We address three questions. First, how productive is ChatGPT-4? That is, how much time and effort is required to generate ideas and how many can reasonably be generated compared to human efforts?'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Second, what is the quality distribution of the ideas generated? We are particularly interested in the extreme values – the quality of the best ideas in the three pools. We measure the quality of the ideas using the standard market research technique of eliciting consumer purchase intent in a survey. Given an estimate of the quality of each idea, we can then compare the distributional characteristics of the quality of the three pools of ideas. Third, given the performance of ChatGPT-4 in generating new product ideas, how can LLMs be used effectively in practice and what are the implications for the management of innovation?'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Approach We have over 20 years of experience teaching product design and innovation courses at Wharton, Cornell Tech, and INSEAD. We have used similar innovation challenges dozens of times with thousands of students. Most of our courses embody the innovation tournament format (Terwiesch and Ulrich 2009, 2023), in which individuals first independently generate many ideas, which are then combined into a pool of several hundred ideas and subsequently evaluated by others in the group (i.e., “crowdsourced” evaluations). Thus, we have access to a large set of ideas generated by humans before AI tools became available to enhance ideation. We randomly selected 200 ideas from the pool of ideas generated in our class in 2021 (i.e., at a time prior to the widespread availability of ChatGPT and other LLMs). These ideas comprise a descriptive title and a paragraph of text. They were all generated in response to the challenge of creating a new physical product for the college student market that'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='in response to the challenge of creating a new physical product for the college student market that would be likely to retail for less than USD 50. (This price cap is imposed to limit the complexity of the projects in a one-semester course.) Here is an example of a submitted idea: Convertible High-Heel Shoe Many prefer high-heel shoes for dress-up occasions, yet walking in high heels for more than short distances is very challenging. Might we create a stylish high-heel shoe that easily adapts to a comfortable walking configuration, say by folding down or removing a heel portion of the shoe? The set of 200 ideas forms the baseline for comparison with the ideas generated using LLMs. The average description is 63 words long, with a standard deviation of 34. We use OpenAI’s GPT-4 API access to prompt ChatGPT-4 with essentially the same prompt we gave the students. No LLM yet acts fully autonomously. Rather they are tools used by humans to complete tasks. Still, for the purpose of this'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Rather they are tools used by humans to complete tasks. Still, for the purpose of this study, we aim for minimal prompt engineering, thus representing a novice user scenario. We use the system prompt to provide contextual information and subsequent user prompts to ask for ideas, ten at a time. The user prompt includes the additional request that the descriptions are 40-80 words, similar to the student sample.  System Prompt “You are a creative entrepreneur looking to generate new product ideas. The product will target college students in the United States. It should be a'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content=\"physical good, not a service or software. I'd like a product that could be sold at a retail price of less than about USD 50. The ideas are just ideas. The product need not yet exist, nor may it necessarily be clearly feasible. Number all ideas and give them a name. The name and idea are separated by a colon.” User Prompt “Please generate ten ideas as ten separate paragraphs. The idea should be expressed as a paragraph of 40-80 words.” The model used for all work covered in this paper is GPT-4-0314 with the “temperature” parameter at 0.7 to induce randomness, and thus greater creativity. An obstacle to using ChatGPT-4 for generating 100s of ideas is its finite memory, typically limited to the number of tokens (i.e., semantic chunks used for representational efficiency) the underlying LLM can consider in generating its responses. Once the number of tokens in a session exceeds the model’s limit, the LLM has no memory of the first ideas generated and subsequent ideas can become\"),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content='model’s limit, the LLM has no memory of the first ideas generated and subsequent ideas can become increasingly redundant. The number of tokens in the version of ChatGPT-4 that we had access to is about 8000, which is roughly 7000 words or approximately 80 ideas (some tokens are used for the system and user prompt and for idea titles).  To generate more than about 80 ideas while wrestling with the context limit, we asked GPT-4 to “compress” the previously generated ideas into shorter summaries. These summaries were then provided to the model prior to generating the next batch of ideas, ensuring that the model knows the previously generated ideas while remaining within the context limits. To generate ideas beyond the token limit, we used the below summarization prompt, followed by the original system prompt and generated summaries, and finally, a user prompt that explicitly asks for different ideas.   Summarization Prompt “Aggressively compress the following ideas so that their original'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content='ideas.   Summarization Prompt “Aggressively compress the following ideas so that their original meaning remains but they are much shorter. You can use tags or keywords.: <Ideas generated so far>” System Prompt <Original System Prompt> + ”Previously you generated the following ideas and should not repeat them: <Summaries>”  User Prompt <Original User Prompt> + ”Make sure they are different from the previous ideas.”  General-purpose LLMs may be used as is or may be fine-tuned with examples. We generated a second batch of ideas after providing the LLM with examples of high-quality ideas generated by students. In particular, we appended our prompts to provide the LLM with seven highly rated ideas from a separate student set that did the same exercise and informed ChatGPT-4 that these ideas had been well-received. We used seven examples to'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='keep the overall contribution to the context window moderate as well as drawing on previous experience from in-context few-shot learning. Good Ideas Prompt <Original System Prompt> + ”Here are some well received ideas for inspiration: <Good Ideas>”  Overall, we generated 100 ideas without providing examples of good ideas and another 100 after providing access to examples of good ideas.  Prior work in other domains suggests that the text generated by LLMs is not distinguishable from that generated by humans (Brown et al., 2020). While we do not test this question in this study, our impression is that any particular idea generated by ChatGPT cannot easily be distinguished from those generated by our students.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='Do LLMs Enhance Productivity in Generating Ideas? The answer to this question is straightforward. ChatGPT-4 is very efficient at generating ideas. This question does not require much precision to answer. Two hundred ideas can be generated by one human interacting with ChatGPT-4 in about 15 minutes. A human working alone can generate about five ideas in 15 minutes (Girotra et al., 2010). Humans working in groups do even worse. In short, the productivity race between humans and ChatGPT is not even close. Still, the old saying that ideas are a dime a dozen is perhaps a tad optimistic. A professional working with ChatGPT-4 can generate ideas at a rate of about 800 ideas per hour. At a cost of USD 500 per hour of human effort, a figure representing an estimate of the fully loaded cost of a skilled professional, ideas are generated at a cost of about USD 0.63 each, or USD 7.50 (75 dimes) per dozen. At the time we used ChatGPT-4, the API fee for 800 ideas was about USD 20. For that same USD'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='dozen. At the time we used ChatGPT-4, the API fee for 800 ideas was about USD 20. For that same USD 500 per hour, a human working alone, without assistance from an LLM, only generates 20 ideas at a cost of roughly USD 25 each, hardly a dime a dozen. For the focused idea generation task itself, a human using ChatGPT-4 is thus about 40 times more productive than a human working alone. In prior work, (Kornish and Ulrich, 2011) found that a typical new-product innovation domain contains thousands of unique ideas, ranging from about 1300 ideas for narrow challenges (e.g., use of technology in the classroom) to 3000 for more open-ended challenges (e.g., new consumer products). These numbers are large enough that a human working alone or in a small group is unlikely to identify most of them. However, LLMs are so productive that a human working with an LLM might reasonably fully articulate nearly every idea in an opportunity space. That is, it may now be possible to identify essentially every'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='every idea in an opportunity space. That is, it may now be possible to identify essentially every idea that a very large group of individuals working in parallel might identify after working for a long time, say, days or weeks. Prior work (Kornish and Ulrich 2014, Girotra et al. 2010) showed that the idea generation process in humans is essentially stationary, so ideas 2901 - 3000 exhibit the same quality distribution as ideas 1-100.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='What Is The Quality Distribution of the Ideas Generated Using LLMs? A “stochastic parrot” can generate ideas, and LLMs do so shockingly productively. But we don’t care about quantity alone. More typically, the objective of idea generation is to generate at least a few truly exceptionally good ideas. In most innovation settings, we’d rather have 10 great ideas and 90 terrible ideas than 100 ideas of average quality. We, therefore, care about the quality distribution of the ideas, and in particular, the quality of the best few ideas in a sample. Of course, we might as well also measure the mean and standard deviation of the three sets of ideas, and we do so. Two useful measures of the extreme values are: What is the average quality of the ideas in the top decile of each of the three samples? Which sources provided the ideas comprising the top 10 percent of the ideas in the pooled sample? Measuring Idea Quality Of course, what we want to know in most innovation settings is which idea has'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='Idea Quality Of course, what we want to know in most innovation settings is which idea has the highest expected future economic value given the uncertainty in how the ideas are developed and in the exogenous factors. This rationale is explored thoroughly in (Kornish and Ulrich, 2014) in the development of the VIDE model. Value (V) is a function of the idea itself (I), the development of that idea (D), and the exogenous factors (E). This value is not directly observable. To measure it we would need to develop and launch all ideas under all future states of the world. In very limited settings, we can estimate financial value, as done in (Kornish and Ulrich, 2014). That study showed that the best single indicator of future value creation is the average purchase intent expressed by a sample of consumers in the target market. Furthermore, (Kornish and Ulrich, 2014) showed that no single individual, expert or novice, is particularly good at estimating value. Rather, a sample of expressed'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='expert or novice, is particularly good at estimating value. Rather, a sample of expressed purchase intent from about 15 individuals in the target market is a reliable measure of idea quality. After obtaining the required IRB approvals, we used mTurk to evaluate all 400 ideas (200 created by humans, 100 created by ChatGPT without examples and 100 with training examples). The panel comprised college-age individuals in the United States. Ideas were presented in random order. Each respondent evaluated an average of 40 ideas. On average, each idea was evaluated 20 times2.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='2 In Summer 2023, concerns surfaced that ChatGPT was being used to provide mTurk responses. This practice appears to have been limited to text generation tasks, not to multiple choice tasks like our five-box purchase-intent survey. Indeed, just answering the survey question directly requires less effort than trying to deploy ChatGPT to answer the question. Thus, we believe that we were indeed surveying humans.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 6}, page_content='Respondents were asked to express purchase intent using the standard “five-box” options: definitely would not purchase, probably would not purchase, might or might not purchase, probably would purchase, and definitely would purchase. Jameson and Bass (1989) recommend weighting responses for the five possible responses as 0, 0.25, 0.50, 0.75, and 1.00 to develop a single measure of purchase probability, which we use as a measure of idea quality. Of course, many other weightings are possible. We report results using the Jameson and Bass weights, but the results are robust to other convex weighting schemes. Results The full quality distribution of ideas generated by the three pools is shown in Figure 1.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 6}, page_content='Figure 1 - Distribution of idea quality for three sets of ideas. Purchase intent is the weighted average of the five-box response scale per Jameson and Bass (1989). The average quality of ideas generated by ChatGPT is higher than the average quality of ideas generated by humans, as measured by purchase intent. The average purchase probability of a human-generated idea is 40.4%, that of vanilla GPT-4 is 46.8%, and that of GPT-4 seeded with good ideas is 49.3%. The difference in'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 7}, page_content='average quality between humans and ChatGPT is statistically significant (p<0.001), but the difference between the two GPT models is not statistically significant (p=0.11).  See Table 1. The standard deviation of the quality of ideas is comparable, with ChatGPT trained with examples having the highest standard deviation.  Table 1 - Summary Statistics \\n Human Generated Ideas ChatGPT-4 ChatGPT-4 trained with examples N Ideas 200 100 100 Average Length of Description 63 words 69 words 71 words Average Quality 0.404 0.468 0.493 Standard Deviation of Quality 0.112 0.108 0.120 Best Idea 0.64 0.70 0.75 Average Quality of Top Decile 0.62 0.64 0.66 Average Novelty of Top Decile 0.45 0.35 0.33 Fraction of the top decile of pooled ideas from this source 5/40  15/40 20/40'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 7}, page_content='P-value  (Is the average quality different?)  vs. humans <0.001 vs. humans <0.001 vs. baseline LLM 0.11  Most interesting are the differences in the quality of the best ideas. Chat-GPT generated the best-rated idea in our sample, with an 11% higher purchase probability than the best human idea. The average quality of the top decile in each of the three pools also follows the same pattern as average quality— seeded Chat-GPT ≻ ChatGPT ≻ Humans. Finally, most striking are the differences in each treatment’s contribution to the top decile of all ideas we generated. Overall, we have 400 ideas, with an equal number generated by ChatGPT and humans. In the top 40 ideas (top decile) a full 35 (87.5%) are those generated by ChatGPT. In other words, in a head-to-head match most of the winners come from ChatGPT. Titles of the top 40 ideas in our pool are reported in Table A1.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='Novelty Given that LLMs are designed to generate approximately the statistically most plausible sequence of text based on their training data, perhaps they generate less-novel ideas.  Novelty is not a goal expressed in the prompt for either humans or Chat-GPT. It is typically not a primary objective in commercial product development efforts, nor does it have commercial value in itself. Still, we are curious about how the novelty of ideas varies between LLM-generated ideas and those generated by humans.  We adopt the survey instrument of Shibayama, Yin, and Matsumoto (2021) to assess the novelty of the ideas. mTurk respondents answered this question: Relative to other products you have seen, how novel do you consider the idea for this new product? 1. Not at all novel 2. Slightly novel 3. Moderately novel 4. Very novel 5. Extremely novel We weigh these responses 0, 0.25, 0.50, 0.75, and 1.00 to produce a novelty score for each idea. By this measure, the mean novelty of the'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='0.75, and 1.00 to produce a novelty score for each idea. By this measure, the mean novelty of the human-generated ideas is higher than that of the LLM-generated ideas (p<0.001). The mean novelty of the two different pools of LLM-generated ideas is not statistically significantly different from each other. (Figure 2) Novelty does not appear to be significantly correlated with purchase intent. The correlation coefficient is slightly negative at -0.08 (p=0.12).'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='Figure 2 - Distribution of novelty ratings for three samples of ideas. Novelty based on mTurk assessment per Kwon, Kim, and Lee (2009).'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='We note here that the average novelty of all ideas, irrespective of source, lies between slightly and moderately novel. While human ideas are a bit more novel, there is little reason to believe that novelty – being the first to think of an idea – leads to a significant financial advantage in domains associated with off-the-shelf technology, low entry barriers, and limited intellectual property protection.  As such, from a commercial point of view, we don’t believe novelty provides sufficient advantage, if any, to overcome the productivity and quality benefits of the LLMs. Further, recall that novelty was not an explicit objective for any of our ideation schemes. In settings where novelty is the goal, it should be part of the prompts.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='Limitations Student Subjects It is possible that professional product innovators would generate better ideas than our students. However, that is not our intuition having worked in many product development settings. Many students in this course have gone on to be product innovators, sometimes based on ideas from the course tournament. We have not produced evidence that ChatGPT is better than the best human product innovators working today. However, we believe that we can claim conservatively that ChatGPT is better than many human product innovators working today and probably better than average. Thus, at a very minimum, an LLM could elevate the least capable humans to a better-than-average level of performance. Domain Our results are set in a common widely understood domain, for consumer products likely selling at a price less than USD 50. Presumably, there is a lot of commentary and data around these domains in the training data used by the GPT class of language models. As such, it is'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='around these domains in the training data used by the GPT class of language models. As such, it is possible that in more specialized domains, say surgical instruments, our results will no longer hold with the current class of models. That said, to us, if this is true, this is likely driven simply by the paucity of training data. An organization looking for opportunities in these specialized domains should presumably be able to fine-tune language models with their own proprietary data and achieve comparable or better performance.  Misbehavior Most language models do not provide any performance guarantees and it is possible they can generate offensive, illegal, or inappropriate ideas. Ideators using models for ideation should exercise caution. Of course, the same caution is warranted with human idea generators. Similarity For most innovation settings, the goal is to thoroughly explore the landscape of possibilities. Doing so enhances confidence that the most reasonable opportunities'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='the landscape of possibilities. Doing so enhances confidence that the most reasonable opportunities have been unearthed and considered. To this extent, we prefer a process that generates 200 diverse ideas to one that generates 200 highly similar ideas. Our analysis does not speak to the similarity or variability in the content of ideas. This remains an open question for further study.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='Concluding Remarks In this study, we showed that the LLM technology in the form of ChatGPT4, a technology available for just a few months at the time of our experiments, is already significantly better at generating new product ideas than motivated, trained engineering and business students at a highly selective university.  Our results examined ideation productivity and quality separately. In each match-up, ChatGPT came out ahead. Combined, the effects of much higher productivity and the higher quality of the best ideas will likely completely trounce human ideators. The order of magnitude advantage in productivity itself is nearly insurmountable, and the higher quality of the best ideas further adds to the advantage of the LLM.    We can now put these tools in the hands of any innovator at extremely low cost. This suggests that the critical task in innovation practice may shift from idea generation to idea evaluation and selection, a task for which LLMs do not yet appear to be'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='idea generation to idea evaluation and selection, a task for which LLMs do not yet appear to be particularly well suited. It is striking that conventional wisdom prior to 2022 was that AI tools would likely be most useful in rote tasks and that creative work would likely remain the domain of humans. In some ways, the opposite is true of LLMs. The tools are not perfectly reliable oracles providing information, but their lack of judgment leads to extreme productivity and high variance in idea quality resulting, at least in one setting, to creativity greater than that of the average human.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='Acknowledgments and Funding Sources Funding was provided by the Mack Institute for Innovation Management at the Wharton School of the University of Pennsylvania.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 11}, page_content='References  OpenAI. 2023. GPT-4 Technical Report. https://cdn.openai.com/papers/gpt-4.pdf Brown TB, et al. 2020. Language models are few-shot learners. arXiv:2005.14165. Girotra K, Terwiesch C, Ulrich KT. 2010. Idea generation and the quality of the best idea. Manage Sci 56:591–605. Jamieson LF, Bass FM. 1989. Adjusting stated intention measures to predict trial purchase of new products: A comparison of models and methods. J Mark Res 26:336–345. Kornish LJ, Ulrich KT. 2014. The importance of the raw idea in innovation: Testing the sow’s ear hypothesis. J Mark Res 51:14–26. Kornish LJ, Ulrich KT. 2011. Opportunity spaces in innovation: Empirical analysis of large samples of ideas. Manage Sci 57:107–128. Terwiesch C, Ulrich KT. 2009. Innovation tournaments: Creating and selecting exceptional opportunities (Harvard Business Press). Terwiesch C, Ulrich K. 2023. The Innovation Tournament Handbook: A Step-by-Step Guide to Finding Exceptional Solutions to Any Challenge (University of'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 11}, page_content='Handbook: A Step-by-Step Guide to Finding Exceptional Solutions to Any Challenge (University of Pennsylvania Press). Terwiesch C. 2023. Let’s cast a critical eye over business ideas from ChatGPT. Finance Times March 12. Shibayama S, Yin D, Matsumoto K. 2021. Measuring novelty in science with word embedding. PLOS ONE July.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='Appendix Table A1 Top 10% Ideas (By Purchase Intent) Title Source Purchase Intent Novelty Compact Printer GPT-4 (Examples) 0.76 0.55 Solar-Powered Gadget Charger GPT-4 (Examples) 0.75 0.44 QuickClean Mini Vacuum GPT-4 (Base) 0.75 0.30 Noise-Canceling Headphones GPT-4 (Examples) 0.72 0.18 StudyErgo Seat Cushion GPT-4 (Base) 0.72 0.39 Multifunctional Desk Organizer GPT-4 (Examples) 0.71 0.21 Reusable Silicone Food Storage Bags GPT-4 (Examples) 0.68 0.34 Portable Closet Organizer GPT-4 (Examples) 0.67 0.23 Dorm Room Chef [oven, microwave and toaster]* GPT-4 (Examples) 0.67 0.71 Collegiate Cookware GPT-4 (Examples) 0.67 0.45 Collapsible Laundry Basket GPT-4 (Examples) 0.65 0.21 On-the-Go Charging Pouch GPT-4 (Examples) 0.65 0.33 GreenEats Reusable Containers GPT-4 (Base) 0.65 0.21 HydrationStation [bottle with filter]* GPT-4 (Base) 0.64 0.19 Reusable Shopping Bag Set GPT-4 (Examples) 0.64 0.19 CollegeLife Collapsible Laundry Hamper GPT-4 (Base) 0.64 0.26 Adaptiflex [cord extension to fit'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='CollegeLife Collapsible Laundry Hamper GPT-4 (Base) 0.64 0.26 Adaptiflex [cord extension to fit big adapters] * Student 0.64 0.44 SpaceSaver Hangers GPT-4 (Base) 0.64 0.33 Dorm Room Air Purifier GPT-4 (Examples) 0.63 0.29 Smart Power Strip GPT-4 (Examples) 0.63 0.22 CampusCharger Pro GPT-4 (Base) 0.63 0.31 Kitchen Safe Gloves Student 0.62 0.31 Nightstand Nook [charging, cup holder]* GPT-4 (Examples) 0.62 0.43 Mini Steamer GPT-4 (Examples) 0.62 0.41 CollegeCare First Aid Kit GPT-4 (Base) 0.62 0.26 StudySoundProof [soundproofing panels]* GPT-4 (Base) 0.62 0.57 FreshAir Fan GPT-4 (Base) 0.62 0.29 StudyBuddy Lamp [portable, usb charging]* GPT-4 (Base) 0.62 0.43 Bluetooth Signal Merger [share music]* Student 0.62 0.41 Adjustable Laptop Riser GPT-4 (Examples) 0.62 0.21 EcoCharge [solar powered charger]* GPT-4 (Base) 0.62 0.43 Smartphone Projector Student 0.62 0.57 Grocery Helper [hook to carry multiple bags]* Student 0.62 0.53 FitnessOnTheGo [portable gym equipment]* GPT-4 (Base) 0.62 0.42'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='multiple bags]* Student 0.62 0.53 FitnessOnTheGo [portable gym equipment]* GPT-4 (Base) 0.62 0.42 Multipurpose Fitness Equipment GPT-4 (Examples) 0.62 0.37 CollegeCooker GPT-4 (Base) 0.61 0.50 Multifunctional Wall Organizer GPT-4 (Examples) 0.61 0.31 DormDoc Portable Scanner GPT-4 (Base) 0.61 0.49'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 13}, page_content='Mobile Charging Station Organizer GPT-4 (Examples) 0.61 0.26 StudyMate Planner GPT-4 (Examples) 0.61 0.22 DormChef Kitchen Set GPT-4 (Base) 0.61 0.33 LaundryBuddy [laundry basket]* GPT-4 (Base) 0.61 0.30  * Text in square brackets [] is not part of the original title and was added to clarify the idea.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Web URL Loader:"
      ],
      "metadata": {
        "id": "8ZiEz7A9ajNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "def load_url_documents(url: str):\n",
        "    web_url_loader = WebBaseLoader(url)\n",
        "    docs = web_url_loader.load()\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        return split_docs"
      ],
      "metadata": {
        "id": "tJ3j1UaKalQY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_docs = load_url_documents(\"https://en.wikipedia.org/wiki/Large_language_model\")"
      ],
      "metadata": {
        "id": "9VfTpfqSbPHh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qFx5mf8tbcaT",
        "outputId": "8804f242-7734-4c2c-cb19-7204f596bae0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Large language model - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nDataset preprocessing\\n\\n\\n\\n\\nToggle Dataset preprocessing subsection\\n\\n\\n\\n\\n\\n2.1\\nTokenization\\n\\n\\n\\n\\n\\n\\n2.1.1\\nBPE\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nProblems\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nDataset cleaning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nSynthetic data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTraining and architecture\\n\\n\\n\\n\\nToggle Training and architecture subsection\\n\\n\\n\\n\\n\\n3.1\\nReinforcement learning from human feedback (RLHF)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='3.1\\nReinforcement learning from human feedback (RLHF)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nInstruction tuning\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nMixture of experts\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nPrompt engineering, attention mechanism, and context window\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nInfrastructure\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nTraining cost\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nTool use\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nAgency\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nCompression\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nMultimodality\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nProperties\\n\\n\\n\\n\\nToggle Properties subsection\\n\\n\\n\\n\\n\\n9.1\\nScaling laws\\n\\n\\n\\n\\n\\n\\n\\n\\n9.2\\nEmergent abilities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nInterpretation\\n\\n\\n\\n\\nToggle Interpretation subsection\\n\\n\\n\\n\\n\\n10.1\\nUnderstanding and intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nEvaluation\\n\\n\\n\\n\\nToggle Evaluation subsection\\n\\n\\n\\n\\n\\n11.1\\nPerplexity\\n\\n\\n\\n\\n\\n\\n11.1.1\\nBPW, BPC, and BPT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nTask-specific datasets and benchmarks\\n\\n\\n\\n\\n\\n\\n11.2.1\\nAdversarially constructed evaluations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nWider impact\\n\\n\\n\\n\\nToggle Wider impact subsection\\n\\n\\n\\n\\n\\n12.1\\nMemorization and copyright\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3\\nAlgorithmic bias\\n\\n\\n\\n\\n\\n\\n12.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3.2\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nSee also'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='12.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3.2\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLarge language model\\n\\n\\n\\n46 languages\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaবাংলা閩南語 / Bân-lâm-gúBoarischBosanskiCatalàČeštinaDeutschΕλληνικάEspañolEuskaraفارسیFrançaisGaeilgeGalego한국어हिन्दीBahasa IndonesiaIsiZuluItalianoעבריתMagyarМакедонскиNederlands日本語PolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийShqipSlovenščinaکوردیСрпски / srpskiTagalogไทยTürkçeУкраїнськаئۇيغۇرچە / UyghurcheTiếng Việt文言粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Print/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nComparatively large-scale natural language processing systems\\nNot to be confused with Logic learning machine.\\n\\nPart of a series onMachine learningand data mining\\nParadigms\\nSupervised learning\\nUnsupervised learning\\nSemi-supervised learning\\nSelf-supervised learning\\nReinforcement learning\\nMeta-learning\\nOnline learning\\nBatch learning\\nCurriculum learning\\nRule-based learning\\nNeuro-symbolic AI\\nNeuromorphic engineering\\nQuantum machine learning\\n\\nProblems\\nClassification\\nGenerative modeling\\nRegression\\nClustering\\nDimensionality reduction\\nDensity estimation\\nAnomaly detection\\nData cleaning\\nAutoML\\nAssociation rules\\nSemantic analysis\\nStructured prediction\\nFeature engineering\\nFeature learning\\nLearning to rank\\nGrammar induction\\nOntology learning\\nMultimodal learning'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Supervised learning(classification\\xa0• regression) \\nApprenticeship learning\\nDecision trees\\nEnsembles\\nBagging\\nBoosting\\nRandom forest\\nk-NN\\nLinear regression\\nNaive Bayes\\nArtificial neural networks\\nLogistic regression\\nPerceptron\\nRelevance vector machine (RVM)\\nSupport vector machine (SVM)\\n\\nClustering\\nBIRCH\\nCURE\\nHierarchical\\nk-means\\nFuzzy\\nExpectation–maximization (EM)\\nDBSCAN\\nOPTICS\\nMean shift\\n\\nDimensionality reduction\\nFactor analysis\\nCCA\\nICA\\nLDA\\nNMF\\nPCA\\nPGD\\nt-SNE\\nSDL\\n\\nStructured prediction\\nGraphical models\\nBayes net\\nConditional random field\\nHidden Markov\\n\\nAnomaly detection\\nRANSAC\\nk-NN\\nLocal outlier factor\\nIsolation forest\\n\\nArtificial neural network\\nAutoencoder\\nDeep learning\\nFeedforward neural network\\nRecurrent neural network\\nLSTM\\nGRU\\nESN\\nreservoir computing\\nBoltzmann machine\\nRestricted\\nGAN\\nDiffusion model\\nSOM\\nConvolutional neural network\\nU-Net\\nLeNet\\nAlexNet\\nDeepDream\\nNeural radiance field\\nTransformer\\nVision\\nMamba\\nSpiking neural network\\nMemtransistor\\nElectrochemical RAM (ECRAM)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Reinforcement learning\\nQ-learning\\nSARSA\\nTemporal difference (TD)\\nMulti-agent\\nSelf-play\\n\\nLearning with humans\\nActive learning\\nCrowdsourcing\\nHuman-in-the-loop\\nRLHF\\n\\nModel diagnostics\\nCoefficient of determination\\nConfusion matrix\\nLearning curve\\nROC curve\\n\\nMathematical foundations\\nKernel machines\\nBias–variance tradeoff\\nComputational learning theory\\nEmpirical risk minimization\\nOccam learning\\nPAC learning\\nStatistical learning\\nVC theory\\n\\nJournals and conferences\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Journals and conferences\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR\\n\\nRelated articles\\nGlossary of artificial intelligence\\nList of datasets for machine-learning research\\nList of datasets in computer vision and image processing\\nOutline of machine learning\\nvte\\nA large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text.\\nThe largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.[3]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='History[edit]\\nThe training compute of notable large models in FLOPs vs publication date over the period 2010-2024. For overall notable models (top left), frontier models (top right), top language models (bottom left) and top models within leading companies (bottom right). The majority of these models are language models.\\nThe training compute of notable large AI models in FLOPs vs publication date over the period 2017-2024. The majority of large models are language models or multimodal models with language capacity.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Before 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved state-of-the-art perplexity at the time.[4] In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"[5]), upon which they trained statistical language models.[6][7] In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.[8]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='After neural networks became dominant in image processing around 2012,[9] they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before transformers, it was done by seq2seq deep LSTM networks.An illustration of main components of the transformer model from the original paper, where layers were normalized after (instead of before) multiheaded attention\\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 seq2seq technology,[10] and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014.[11] The following year in 2018, BERT was introduced and quickly became \"ubiquitous\".[12] Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.[13]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Although decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use.[14] GPT-3 in 2020 went a step further and as of 2024[update] is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz.[15] The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities.[16] OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work.[17]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Competing language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.[18]\\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. As of June\\xa02024[update], The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4.[19]\\nSince 2023, many LLMs have been trained to be multimodal, having the ability to also process or generate other types of data, such as images or audio. These LLMs are also called large multimodal models (LMMs).[20]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='As of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).[21][22][23]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Dataset preprocessing[edit]\\nSee also: List of datasets for machine-learning research §\\xa0Internet\\nTokenization[edit]\\n\\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding word in BERT.[24]\\nFor example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\\n\\n\\n\\ntoken\\n\\nizer\\n\\n:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='token\\n\\nizer\\n\\n:\\n\\n\\xa0texts\\n\\n\\xa0->\\n\\nseries\\n\\n\\xa0of\\n\\n\\xa0numerical\\n\\n\\xa0\"\\n\\nt\\n\\nok\\n\\nens\\n\\n\"\\n\\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.[25][26]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='BPE[edit]\\nMain article: Byte pair encoding\\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257).[27] After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.[28]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Problems[edit]\\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. An average word in another language encoded by such an English-optimized tokenizer is however split into suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.[29]\\nGreedy tokenization also causes subtle problems with text completion.[30]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Dataset cleaning[edit]\\nMain article: Data cleansing\\nIn the context of training LLMs, datasets are typically cleaned by removing toxic passages from the dataset, discarding low-quality data, and de-duplication.[31] Cleaned datasets can increase training efficiency and lead to improved downstream performance.[32][33] A trained LLM can be used to clean datasets for training a further LLM.[34]\\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).[35]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Synthetic data[edit]\\nMain article: Synthetic data\\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's Phi series of LLMs is trained on textbook-like data generated by another LLM.[36]\\n\\nTraining and architecture[edit]\\nSee also: Fine-tuning (machine learning)\\nReinforcement learning from human feedback (RLHF)[edit]\\nMain article: Reinforcement learning from human feedback\\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.[37]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Instruction tuning[edit]\\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.[38]\\n\\nMixture of experts[edit]\\nMain article: Mixture of experts\\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.[39][40][41]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Prompt engineering, attention mechanism, and context window[edit]\\nSee also: Prompt engineering and Attention (machine learning)\\nMost results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).[42]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='When each head calculates, according to its own criteria, how much other tokens are relevant for the \"it_\" token, note that the second attention head, represented by the second column, is focusing most on the first two rows, i.e. the tokens \"The\" and \"animal\", while the third column is focusing most on the bottom two rows, i.e. on \"tired\", which has been tokenized into two tokens.[43]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens.[44] In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.[28]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The largest models, such as Google\\'s Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\").[45] Other models with large context windows includes Anthropic\\'s Claude 2.1, with a context window of up to 200k tokens.[46] Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.[47]\\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.\\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.[48] It can be either'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='autoregressive (i.e. predicting how the segment continues, the way GPTs do it): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\"[49] does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.[49] During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\\n\\nInfrastructure[edit]\\nSubstantial infrastructure is necessary for training the largest models.[50][51][52]\\n\\nTraining cost[edit]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\". As time goes on, what was previously considered \"large\" may evolve. GPT-1 of 2018 is usually considered the first LLM, even though it has only 0.117 billion parameters. The tendency towards larger models is visible in the list of large language models.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Advances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80,000 and $1,600,000.[53][54][55] Since 2020, large sums were invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.[56]\\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.[57]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Tool use[edit]\\nThere are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user\\'s input \\'354 * 139 = \\', provided that the LLM has not already encountered a continuation of this calculation in its training corpus.[dubious – discuss] In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response.[dubious – discuss]: Another example is \"What is the time now? It is \", where a separate program interpreter would need to execute a code to get system time on the computer, so that the LLM can include it in its reply.[58][59] This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.[60]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Generally, in order to get an LLM to use tools, one must fine-tune it for tool-use. If the number of tools is finite, then fine-tuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.[61][62]\\nA simpler form of tool use is retrieval-augmented generation: the augmentation of an LLM with document retrieval. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.[63]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Agency[edit]\\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions, but can be transformed into one by integrating modules like profiling, memory, planning, and action.[64]\\nThe ReAct pattern, a portmanteau of \"Reason\\xa0+\\xa0Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.[65] The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[66]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.[67]\\nThe Reflexion method[68] constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.[citation needed]\\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.[69]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='For open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.[70] Alternatively, it can propose increasingly difficult tasks for curriculum learning.[71] Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.[71]\\nLLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.[72]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Compression[edit]\\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.[73]\\nPost-training quantization[74] aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance.[75][76] The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\").[77] See [78] for a visual guide.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='While quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.[79]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Multimodality[edit]\\nSee also: Multimodal learning\\nMultimodality means \"having several modalities\", and a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc.[80] There have been many AI models trained specifically to ingest one modality and output another modality, such as AlexNet for image to label,[81] visual question answering for image-text to text,[82] and speech recognition for speech to text.\\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \\n\\n\\n\\nE\\n\\n\\n{\\\\displaystyle E}\\n\\n. Make a small multilayered perceptron \\n\\n\\n\\nf\\n\\n\\n{\\\\displaystyle f}\\n\\n, so that for any image \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n, the post-processed vector \\n\\n\\n\\nf\\n(\\nE\\n(\\ny\\n)\\n)\\n\\n\\n{\\\\displaystyle f(E(y))}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.[83]\\nFlamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.[84] Google PaLM model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.[85] LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs,[86] and video inputs.[87]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"GPT-4 can use both text and image as inputs[88] (although the vision component was not released to the public until GPT-4V[89]); Google DeepMind's Gemini is also multimodal.[90]  Mistral introduced its own multimodel Pixtral 12B model in September 2024.[91]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Properties[edit]\\nScaling laws[edit]\\nMain article: Neural scaling law\\nThe performance of an LLM after pretraining largely depends on the:\\n\\ncost of pretraining \\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n (the total amount of compute used),\\nsize of the artificial neural network itself, such as number of parameters \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n (i.e. amount of neurons in its layers, amount of weights between them and biases),\\nsize of its pretraining dataset (i.e. number of tokens in corpus, \\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n).\\n\"Scaling laws\" are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:[92]\\n\\n\\n\\n\\n\\n\\n{\\n\\n\\n\\nC\\n=\\n\\nC\\n\\n0\\n\\n\\nN\\nD\\n\\n\\n\\n\\nL\\n=\\n\\n\\nA\\n\\nN\\n\\nα\\n\\n\\n\\n\\n+\\n\\n\\nB\\n\\nD\\n\\nβ\\n\\n\\n\\n\\n+\\n\\nL\\n\\n0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n{\\\\displaystyle {\\\\begin{cases}C=C_{0}ND\\\\\\\\[6pt]L={\\\\frac {A}{N^{\\\\alpha }}}+{\\\\frac {B}{D^{\\\\beta }}}+L_{0}\\\\end{cases}}}\\n\\n where the variables are\\n\\n\\n\\n\\n\\nC'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='where the variables are\\n\\n\\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n is the cost of training the model, in FLOPs.\\n\\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of parameters in the model.\\n\\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n is the number of tokens in the training set.\\n\\n\\n\\n\\nL\\n\\n\\n{\\\\displaystyle L}\\n\\n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\\nand the statistical hyper-parameters are\\n\\n\\n\\n\\n\\n\\nC\\n\\n0\\n\\n\\n=\\n6\\n\\n\\n{\\\\displaystyle C_{0}=6}\\n\\n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.[57]\\n\\n\\n\\n\\nα\\n=\\n0.34\\n,\\nβ\\n=\\n0.28\\n,\\nA\\n=\\n406.4\\n,\\nB\\n=\\n410.7\\n,\\n\\nL\\n\\n0\\n\\n\\n=\\n1.69\\n\\n\\n{\\\\displaystyle \\\\alpha =0.34,\\\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Emergent abilities[edit]\\nAt point(s) referred to as breaks,[93] the lines change their slopes, appearing on a linear-log plot as a series of linear segments connected by arcs.\\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\"[93] in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\".[42][94] They arise from the complex interaction of the model\\'s components and are not explicitly programmed or designed.[95]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Furthermore, recent research has demonstrated that AI systems, including large language models, can employ heuristic reasoning akin to human cognition. They balance between exhaustive logical processing and the use of cognitive shortcuts (heuristics), adapting their reasoning strategies to optimize between accuracy and effort. This behavior aligns with principles of resource-rational human cognition, as discussed in classical theories of bounded rationality and dual-process theory.[96]\\nThe most intriguing among emergent abilities is in-context learning from example demonstrations.[97] In-context learning is involved in tasks, such as:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='reported arithmetics, decoding the International Phonetic Alphabet, unscrambling a word\\'s letters, disambiguate word in context,[42][98][99] converting spatial words, cardinal directions (for example, replying \"northeast\" upon [0, 0, 1; 0, 0, 0; 0, 0, 0]), color terms represented in text.[100]\\nchain-of-thought prompting: Model outputs are improved by chain-of-thought prompting only when model size exceeds 62B. Smaller models perform better when prompted to answer immediately, without chain of thought.[101]\\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.[102]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Schaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.[103]\\nLet'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='x\\n\\n\\n{\\\\displaystyle x}\\n\\n be the number of parameter count, and \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n be the performance of the model.\\n\\n\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{correct token}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n is an exponential curve (before it hits the plateau at one), which looks like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\log(\\\\Pr({\\\\text{correct token}}))}\\n\\n, then the \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n plot is a straight line (before it hits the plateau at zero), which does not look like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\nthe most likely token is correct\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{the most likely token is correct}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='is a step-function, which looks like emergence.\\nInterpretation[edit]\\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.\\nMechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[104][105] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[106]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[107]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Understanding and intelligence[edit]\\nSee also: Philosophy of artificial intelligence and Artificial consciousness'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[108] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[109][110] Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation.[111] Some'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='unknown detective novel after processing the entire story leading up to the revelation.[111] Some researchers characterize LLMs as \"alien intelligence\".[112][113] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"[114][115]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[113] a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[108] For example, GPT-4 has natural deficits in planning and in real-time learning.[110] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[116] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[117] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='\"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".[108]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"The matter of LLM's exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language.[108] These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented Neural Theory of Language (NTL)[118] as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.[119][120]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Evaluation[edit]\\nPerplexity[edit]\\nThe canonical measure of the performance of an LLM is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\\n\\n\\n\\n\\nlog\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n=\\n−\\n\\n\\n1\\nN\\n\\n\\n\\n∑\\n\\ni\\n=\\n1\\n\\n\\nN\\n\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\n\\ntoken\\n\\n\\ni\\n\\n\\n∣\\n\\n\\ncontext for token\\n\\n\\ni\\n\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle \\\\log({\\\\text{Perplexity}})=-{\\\\frac {1}{N}}\\\\sum _{i=1}^{N}\\\\log(\\\\Pr({\\\\text{token}}_{i}\\\\mid {\\\\text{context for token}}_{i}))}\\n\\n\\nHere, \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of tokens in the text corpus, and \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text appearing before token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='i\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text appearing before token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n. If the LLM is masked, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text surrounding token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n.\\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set.[49] This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.[1]\\n\\nBPW, BPC, and BPT[edit]\\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon.[121] This relationship is mathematically expressed as \\n\\n\\n\\n\\nEntropy\\n\\n=\\n\\nlog\\n\\n2\\n\\n\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n\\n\\n{\\\\displaystyle {\\\\text{Entropy}}=\\\\log _{2}({\\\\text{Perplexity}})}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\".\\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Task-specific datasets and benchmarks[edit]\\nA large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks. Tests may be designed to evaluate a variety of capabilities, including general knowledge, commonsense reasoning, and mathematical problem-solving.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='One broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").[122] A question answering task is considered \"open book\" if the model\\'s prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"[122]). Otherwise, the task is considered \"closed book\", and the model must draw on knowledge retained during training.[123] Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.[123]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Evaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".[1]\\nSome composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, and HELM.[121][123] OpenAI has released tools for running composite benchmarks, but noted that the eval results are sensitive to the prompting method.[124][125] Some public datasets contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality, which can be cleaned to give more reliable benchmark scores.[126]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='It was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder. It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Adversarially constructed evaluations[edit]\\nBecause of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks.[127] In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.[108]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Some datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods to which they were repeatedly exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can\\'t teach an old dog new tricks, even though this is not literally true.[128]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Another example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model and filtering with a set of classifiers. The resulting problems are trivial for humans but at the time the datasets were created state of the art language models had poor accuracy on them. For example:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='We see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\\na) demonstrates how to increase efficient exercise work by running up and down balls.\\nb) moves all his arms and legs and builds up a lot of muscle.\\nc) then plays the ball and we see a graphics and hedge trimming demonstration.\\nd) performs sit ups while on the ball and talking.[129]\\n\\n\\nBERT selects b) as the most likely completion, though the correct answer is d).[129]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='BERT selects b) as the most likely completion, though the correct answer is d).[129]\\n\\nWider impact[edit]\\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\"[130] Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.[131][132]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Memorization and copyright[edit]\\nFurther information: Artificial intelligence and copyright\\nMemorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates[133] or up to about 7%.[134]\\nA 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.[135]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Security[edit]\\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.[136] For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.[137]\\nThe potential presence of \"sleeper agents\" within LLM models is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.[138]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"LLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study[139] proposed a method for circumventing LLM safety systems. Similarly, Yongge Wang[140] illustrated in 2024 how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Algorithmic bias[edit]\\nMain article: Algorithmic bias\\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.[141] Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.[142]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Stereotyping[edit]\\nAI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.[143]\\nNotably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms.[141] For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.[144]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Political bias[edit]\\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.[145]\\n\\nSee also[edit]\\nFoundation models\\nList of large language models\\nList of chatbots\\nReferences[edit]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='See also[edit]\\nFoundation models\\nList of large language models\\nList of chatbots\\nReferences[edit]\\n\\n\\n^ a b c Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.). \"Language Models are Few-Shot Learners\" (PDF). Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 1877–1901. Archived (PDF) from the original on 2023-11-17. Retrieved 2023-03-14.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Fathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter; Kovriguina, Liubov (2024-05-26). NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning (PDF). Extended Semantic Web Conference 2024. Hersonissos, Greece.\\n\\n^ Manning, Christopher D. (2022). \"Human Language Understanding & Reasoning\". Daedalus. 151 (2): 127–138. doi:10.1162/daed_a_01905. S2CID\\xa0248377870. Archived from the original on 2023-11-17. Retrieved 2023-03-09.\\n\\n^ Goodman, Joshua (2001-08-09), A Bit of Progress in Language Modeling, arXiv:cs/0108005, Bibcode:2001cs........8005G\\n\\n^ Kilgarriff, Adam; Grefenstette, Gregory (September 2003). \"Introduction to the Special Issue on the Web as Corpus\". Computational Linguistics. 29 (3): 333–347. doi:10.1162/089120103322711569. ISSN\\xa00891-2017.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Banko, Michele; Brill, Eric (2001). \"Scaling to very very large corpora for natural language disambiguation\". Proceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL \\'01. Morristown, NJ, USA: Association for Computational Linguistics: 26–33. doi:10.3115/1073012.1073017.\\n\\n^ Resnik, Philip; Smith, Noah A. (September 2003). \"The Web as a Parallel Corpus\". Computational Linguistics. 29 (3): 349–380. doi:10.1162/089120103322711578. ISSN\\xa00891-2017. Archived from the original on 2024-06-07. Retrieved 2024-06-07.\\n\\n^ Halevy, Alon; Norvig, Peter; Pereira, Fernando (March 2009). \"The Unreasonable Effectiveness of Data\". IEEE Intelligent Systems. 24 (2): 8–12. doi:10.1109/MIS.2009.36. ISSN\\xa01541-1672.\\n\\n^ Chen, Leiyu; Li, Shaobo; Bai, Qiang; Yang, Jing; Jiang, Sanlong; Miao, Yanming (2021). \"Review of Image Classification Algorithms Based on Convolutional Neural Networks\". Remote Sensing. 13 (22): 4712. Bibcode:2021RemS...13.4712C. doi:10.3390/rs13224712.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (2017). \"Attention is All you Need\" (PDF). Advances in Neural Information Processing Systems. 30. Curran Associates, Inc. Archived (PDF) from the original on 2024-02-21. Retrieved 2024-01-21.\\n\\n^ Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\". arXiv:1409.0473 [cs.CL].\\n\\n^ Rogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). \"A Primer in BERTology: What We Know About How BERT Works\". Transactions of the Association for Computational Linguistics. 8: 842–866. arXiv:2002.12327. doi:10.1162/tacl_a_00349. S2CID\\xa0211532403. Archived from the original on 2022-04-03. Retrieved 2024-01-21.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa01223–1243. arXiv:2307.10700. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.\\n\\n^ Hern, Alex (14 February 2019). \"New AI fake text generator may be too dangerous to release, say creators\". The Guardian. Archived from the original on 14 February 2019. Retrieved 20 January 2024.\\n\\n^ \"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months\". Euronews. November 30, 2023. Archived from the original on January 14, 2024. Retrieved January 20, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Heaven, Will (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT—but OpenAI won\\'t say why\". MIT Technology Review. Archived from the original on March 17, 2023. Retrieved January 20, 2024.\\n\\n^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa01223–1243. arXiv:2307.10700. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.\\n\\n^ \"Parameters in notable artificial intelligence systems\". ourworldindata.org. November 30, 2023. Retrieved January 20, 2024.\\n\\n^ \"LMSYS Chatbot Arena Leaderboard\". huggingface.co. Archived from the original on June 10, 2024. Retrieved June 12, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Zia, Dr Tehseen (2024-01-08). \"Unveiling of Large Multimodal Models: Shaping the Landscape of Language Models in 2024\". Unite.AI. Retrieved 2024-12-28.\\n\\n^ Peng, Bo; et\\xa0al. (2023). \"RWKV: Reinventing RNNS for the Transformer Era\". arXiv:2305.13048 [cs.CL].\\n\\n^ Merritt, Rick (2022-03-25). \"What Is a Transformer Model?\". NVIDIA Blog. Archived from the original on 2023-11-17. Retrieved 2023-07-25.\\n\\n^ Gu, Albert; Dao, Tri (2023-12-01), Mamba: Linear-Time Sequence Modeling with Selective State Spaces, arXiv:2312.00752\\n\\n^ Kaushal, Ayush; Mahowald, Kyle (2022-06-06), What do tokens know about their characters and how do they know it?, arXiv:2206.02608\\n\\n^ Yennie Jun (2023-05-03). \"All languages are NOT created (tokenized) equal\". Language models cost much more in some languages than others. Archived from the original on 2023-08-17. Retrieved 2023-08-17. In other words, to express the same sentiment, some languages require up to 10 times more tokens.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Petrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". NeurIPS. arXiv:2305.15425. Archived from the original on December 15, 2023. Retrieved September 16, 2023 – via openreview.net.\\n\\n^ \"OpenAI API\". platform.openai.com. Archived from the original on April 23, 2023. Retrieved 2023-04-30.\\n\\n^ a b Paaß, Gerhard; Giesselbach, Sven (2022). \"Pre-trained Language Models\". Foundation Models for Natural Language Processing. Artificial Intelligence: Foundations, Theory, and Algorithms. pp.\\xa019–78. doi:10.1007/978-3-031-23190-2_2. ISBN\\xa09783031231902. Archived from the original on 3 August 2023. Retrieved 3 August 2023.\\n\\n^ Petrov, Aleksandar; Emanuele La Malfa; Torr, Philip H. S.; Bibi, Adel (2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". arXiv:2305.15425 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lundberg, Scott (2023-12-12). \"The Art of Prompt Design: Prompt Boundaries and Token Healing\". Medium. Retrieved 2024-08-05.\\n\\n^ Dodge, Jesse; Sap, Maarten; Marasović, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt (2021). \"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus\". arXiv:2104.08758 [cs.CL].\\n\\n^ Lee, Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, Douglas; Callison-Burch, Chris; Carlini, Nicholas (May 2022). \"Deduplicating Training Data Makes Language Models Better\" (PDF). Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. 1: Long Papers: 8424–8445. doi:10.18653/v1/2022.acl-long.577.\\n\\n^ Li, Yuanzhi; Bubeck, Sébastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee, Yin Tat (2023-09-11), Textbooks Are All You Need II: phi-1.5 technical report, arXiv:2309.05463'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen; Yang, Yujiu; Jiao, Jian (2024-04-11). \"Rho-1: Not All Tokens Are What You Need\". arXiv:2404.07965 [cs.CL].\\n\\n^ Brown, Tom B.; et\\xa0al. (2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165 [cs.CL].\\n\\n^ Abdin, Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, Ahmed; Awadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash (2024-04-23). \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\". arXiv:2404.14219 [cs.CL].\\n\\n^ Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; Simens, Maddie; Askell, Amanda; Welinder, Peter; Christiano, Paul; Leike, Jan; Lowe, Ryan (2022). \"Training language models to follow instructions with human feedback\". arXiv:2203.02155 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Wang, Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; Khashabi, Daniel; Hajishirzi, Hannaneh (2022). \"Self-Instruct: Aligning Language Model with Self Generated Instructions\". arXiv:2212.10560 [cs.CL].\\n\\n^ Shazeer, Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; Hinton, Geoffrey; Dean, Jeff (2017-01-01). \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\". arXiv:1701.06538 [cs.LG].\\n\\n^ Lepikhin, Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; Huang, Yanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng (2021-01-12). \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\". arXiv:2006.16668 [cs.CL].\\n\\n^ Dai, Andrew M; Du, Nan (December 9, 2021). \"More Efficient In-Context Learning with GLaM\". ai.googleblog.com. Archived from the original on 2023-03-12. Retrieved 2023-03-09.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b c Wei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022). \"Emergent Abilities of Large Language Models\". Transactions on Machine Learning Research. ISSN\\xa02835-8856. Archived from the original on 22 March 2023. Retrieved 19 March 2023.\\n\\n^ Allamar, Jay. \"Illustrated transformer\". Archived from the original on 2023-07-25. Retrieved 2023-07-29.\\n\\n^ Allamar, Jay. \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\". Retrieved 2023-08-01.\\n\\n^ \"Our next-generation model: Gemini 1.5\". Google. 15 February 2024. Archived from the original on 18 February 2024. Retrieved 18 February 2024.\\n\\n^ \"Long context prompting for Claude 2.1\". December 6, 2023. Archived from the original on August 27, 2024. Retrieved January 20, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"Rate limits\". openai.com. Archived from the original on February 2, 2024. Retrieved January 20, 2024.\\n\\n^ Zaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). \"A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP\". Proceedings of the Australasian Computer Science Week Multiconference. pp.\\xa01–4. arXiv:2104.10810. doi:10.1145/3373017.3373028. ISBN\\xa09781450376976. S2CID\\xa0211040895.\\n\\n^ a b c Jurafsky, Dan; Martin, James H. (7 January 2023). Speech and Language Processing (PDF) (3rd edition draft\\xa0ed.). Archived (PDF) from the original on 23 March 2023. Retrieved 24 May 2022.\\n\\n^ \"From bare metal to a 70B model: infrastructure set-up and scripts\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ \"metaseq/projects/OPT/chronicles at main · facebookresearch/metaseq\". GitHub. Archived from the original on 2024-01-24. Retrieved 2024-07-24.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Albrecht, Josh (2024-07-23). \"State of the Art: Training >70B LLMs on 10,000 H100 clusters\". www.latent.space. Retrieved 2024-07-24.\\n\\n^ Wiggers, Kyle (28 April 2022). \"The emerging types of language models and why they matter\". TechCrunch. Archived from the original on 16 March 2023. Retrieved 9 March 2023.\\n\\n^ Sharir, Or; Peleg, Barak; Shoham, Yoav (2020). \"The Cost of Training NLP Models: A Concise Overview\". arXiv:2004.08900 [cs.CL].\\n\\n^ Biderman, Stella; Schoelkopf, Hailey; Anthony, Quentin; Bradley, Herbie; Khan, Mohammad Aflah; Purohit, Shivanshu; Prashanth, USVSN Sai (April 2023). \"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling\". arXiv:2304.01373 [cs.CL].\\n\\n^ Maslej, Nestor; Fattorini, Loredana; Brynjolfsson, Erik; Etchemendy, John; Ligett, Katrina; Lyons, Terah; Manyika, James; Ngo, Helen; Niebles, Juan Carlos (2023-10-05), Artificial Intelligence Index Report 2023, arXiv:2310.03715\\n\\n^ a b Section 2.1 and Table 1,'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b Section 2.1 and Table 1,\\n\\nKaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for Neural Language Models\". arXiv:2001.08361 [cs.LG].\\n\\n^ Gao, Luyu; Madaan, Aman; Zhou, Shuyan; Alon, Uri; Liu, Pengfei; Yang, Yiming; Callan, Jamie; Neubig, Graham (2022-11-01). \"PAL: Program-aided Language Models\". arXiv:2211.10435 [cs.CL].\\n\\n^ \"PAL: Program-aided Language Models\". reasonwithpal.com. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ Paranjape, Bhargavi; Lundberg, Scott; Singh, Sameer; Hajishirzi, Hannaneh; Zettlemoyer, Luke; Tulio Ribeiro, Marco (2023-03-01). \"ART: Automatic multi-step reasoning and tool-use for large language models\". arXiv:2303.09014 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Liang, Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, Yang; Lu, Shuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong, Ming; Duan, Nan (2023-03-01). \"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs\". arXiv:2303.16434 [cs.AI].\\n\\n^ Patil, Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. (2023-05-01). \"Gorilla: Large Language Model Connected with Massive APIs\". arXiv:2305.15334 [cs.CL].\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ \"The Growth Behind LLM-based Autonomous Agents\". KDnuggets. October 23, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"The Growth Behind LLM-based Autonomous Agents\". KDnuggets. October 23, 2023.\\n\\n^ Yao, Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, Karthik; Cao, Yuan (2022-10-01). \"ReAct: Synergizing Reasoning and Acting in Language Models\". arXiv:2210.03629 [cs.CL].\\n\\n^ Wu, Yue; Prabhumoye, Shrimai; Min, So Yeon (24 May 2023). \"SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning\". arXiv:2305.15486 [cs.AI].\\n\\n^ Wang, Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao (2023-02-03). \"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\". arXiv:2302.01560 [cs.AI].\\n\\n^ Shinn, Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, Karthik; Yao, Shunyu (2023-03-01). \"Reflexion: Language Agents with Verbal Reinforcement Learning\". arXiv:2303.11366 [cs.AI].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Hao, Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, Daisy; Hu, Zhiting (2023-05-01). \"Reasoning with Language Model is Planning with World Model\". arXiv:2305.14992 [cs.CL].\\n\\n^ Zhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). \"OMNI: Open-endedness via Models of human Notions of Interestingness\". arXiv:2306.01711 [cs.AI].\\n\\n^ a b \"Voyager | An Open-Ended Embodied Agent with Large Language Models\". voyager.minedojo.org. Archived from the original on 2023-06-08. Retrieved 2023-06-09.\\n\\n^ Park, Joon Sung; O\\'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith; Liang, Percy; Bernstein, Michael S. (2023-04-01). \"Generative Agents: Interactive Simulacra of Human Behavior\". arXiv:2304.03442 [cs.HC].\\n\\n^ Mann, Tobias. \"How to run an LLM locally on your PC in less than 10 minutes\". www.theregister.com. Retrieved 2024-05-17.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Nagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen (2020-11-21). \"Up or Down? Adaptive Rounding for Post-Training Quantization\". Proceedings of the 37th International Conference on Machine Learning. PMLR: 7197–7206. Archived from the original on 2023-06-14. Retrieved 2023-06-14.\\n\\n^ Polino, Antonio; Pascanu, Razvan; Alistarh, Dan (2018-02-01). \"Model compression via distillation and quantization\". arXiv:1802.05668 [cs.NE].\\n\\n^ Frantar, Elias; Ashkboos, Saleh; Hoefler, Torsten; Alistarh, Dan (2022-10-01). \"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers\". arXiv:2210.17323 [cs.LG].\\n\\n^ Dettmers, Tim; Svirschevski, Ruslan; Egiazarian, Vage; Kuznedelev, Denis; Frantar, Elias; Ashkboos, Saleh; Borzunov, Alexander; Hoefler, Torsten; Alistarh, Dan (2023-06-01). \"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression\". arXiv:2306.03078 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Grootendorst, Maarten. \"A Visual Guide to Quantization\". newsletter.maartengrootendorst.com. Archived from the original on 31 Jul 2024. Retrieved 2024-07-31.\\n\\n^ Dettmers, Tim; Pagnoni, Artidoro; Holtzman, Ari; Zettlemoyer, Luke (2023-05-01). \"QLoRA: Efficient Finetuning of Quantized LLMs\". arXiv:2305.14314 [cs.LG].\\n\\n^ Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18). \"Multimodal Neural Language Models\". Proceedings of the 31st International Conference on Machine Learning. PMLR: 595–603. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\". Advances in Neural Information Processing Systems. 25. Curran Associates, Inc. Archived from the original on 2023-07-02. Retrieved 2023-07-02.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Antol, Stanislaw; Agrawal, Aishwarya; Lu, Jiasen; Mitchell, Margaret; Batra, Dhruv; Zitnick, C. Lawrence; Parikh, Devi (2015). \"VQA: Visual Question Answering\". ICCV: 2425–2433. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Li, Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01). \"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models\". arXiv:2301.12597 [cs.CV].\\n\\n^ Alayrac, Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain; Hasson, Yana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; Reynolds, Malcolm; Ring, Roman; Rutherford, Eliza; Cabi, Serkan; Han, Tengda; Gong, Zhitao (2022-12-06). \"Flamingo: a Visual Language Model for Few-Shot Learning\". Advances in Neural Information Processing Systems. 35: 23716–23736. arXiv:2204.14198. Archived from the original on 2023-07-02. Retrieved 2023-07-02.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Driess, Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, Aakanksha; Ichter, Brian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan; Yu, Tianhe; Huang, Wenlong; Chebotar, Yevgen; Sermanet, Pierre; Duckworth, Daniel; Levine, Sergey (2023-03-01). \"PaLM-E: An Embodied Multimodal Language Model\". arXiv:2303.03378 [cs.LG].\\n\\n^ Liu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). \"Visual Instruction Tuning\". arXiv:2304.08485 [cs.CV].\\n\\n^ Zhang, Hang; Li, Xin; Bing, Lidong (2023-06-01). \"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding\". arXiv:2306.02858 [cs.CL].\\n\\n^ OpenAI (2023-03-27). \"GPT-4 Technical Report\". arXiv:2303.08774 [cs.CL].\\n\\n^ OpenAI (September 25, 2023). \"GPT-4V(ision) System Card\" (PDF).\\n\\n^ Pichai, Sundar (10 May 2023), Google Keynote (Google I/O \\'23), timestamp 15:31, retrieved 2023-07-02'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Wiggers, Kyle (11 September 2024). \"Mistral releases Pixtral 12B, its first multimodal model\". TechCrunch. Retrieved 14 September 2024.\\n\\n^ Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, Trevor; Rutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; Welbl, Johannes; Clark, Aidan; Hennigan, Tom; Noland, Eric; Millican, Katie; Driessche, George van den; Damoc, Bogdan (2022-03-29). \"Training Compute-Optimal Large Language Models\". arXiv:2203.15556 [cs.CL].\\n\\n^ a b Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). \"Broken Neural Scaling Laws\". arXiv:2210.14891 [cs.LG].\\n\\n^ \"137 emergent abilities of large language models\". Jason Wei. Retrieved 2023-06-24.\\n\\n^ Bowman, Samuel R. (2023). \"Eight Things to Know about Large Language Models\". arXiv:2304.00612 [cs.CL].\\n\\n^ Mukherjee, Anirban; Chang, Hannah (2024). \"Heuristic Reasoning in AI: Instrumental Use and Mimetic Absorption\". arXiv:2403.09404 [cs.AI].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Hahn, Michael; Goyal, Navin (2023-03-14). \"A Theory of Emergent In-Context Learning as Implicit Structure Induction\". arXiv:2303.07971 [cs.LG].\\n\\n^ Pilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019). \"Proceedings of the 2019 Conference of the North\". Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota: Association for Computational Linguistics: 1267–1273. doi:10.18653/v1/N19-1128. S2CID\\xa0102353817. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ \"WiC: The Word-in-Context Dataset\". pilehvar.github.io. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ Patel, Roma; Pavlick, Ellie (2021-10-06). \"Mapping Language Models to Grounded Conceptual Spaces\". ICLR. Archived from the original on 2023-06-24. Retrieved 2023-06-27.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ A Closer Look at Large Language Models Emergent Abilities Archived 2023-06-24 at the Wayback Machine (Yao Fu, Nov 20, 2022)\\n\\n^ Ornes, Stephen (March 16, 2023). \"The Unpredictable Abilities Emerging From Large AI Models\". Quanta Magazine. Archived from the original on March 16, 2023. Retrieved March 16, 2023.\\n\\n^ Schaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). \"Are Emergent Abilities of Large Language Models a Mirage?\". arXiv:2304.15004 [cs.AI].\\n\\n^ Li, Kenneth; Hopkins, Aspen K.; Bau, David; Viégas, Fernanda; Pfister, Hanspeter; Wattenberg, Martin (2022-10-01). \"Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task\". arXiv:2210.13382 [cs.LG].\\n\\n^ \"Large Language Model: world models or surface statistics?\". The Gradient. 2023-01-21. Retrieved 2023-06-12.\\n\\n^ Jin, Charles; Rinard, Martin (2023-05-01). \"Evidence of Meaning in Language Models Trained on Programs\". arXiv:2305.11169 [cs.LG].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Nanda, Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob (2023-01-01). \"Progress measures for grokking via mechanistic interpretability\". arXiv:2301.05217 [cs.LG].\\n\\n^ a b c d e Mitchell, Melanie; Krakauer, David C. (28 March 2023). \"The debate over understanding in AI\\'s large language models\". Proceedings of the National Academy of Sciences. 120 (13): e2215907120. arXiv:2210.13966. Bibcode:2023PNAS..12015907M. doi:10.1073/pnas.2215907120. PMC\\xa010068812. PMID\\xa036943882.\\n\\n^ Metz, Cade (16 May 2023). \"Microsoft Says New A.I. Shows Signs of Human Reasoning\". The New York Times.\\n\\n^ a b Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"Anthropic CEO Dario Amodei pens a smart look at our AI future\". Fast Company. October 17, 2024.\\n\\n^ \"ChatGPT is more like an \\'alien intelligence\\' than a human brain, says futurist\". ZDNET. 2023. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ a b Newport, Cal (13 April 2023). \"What Kind of Mind Does ChatGPT Have?\". The New Yorker. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ Roose, Kevin (30 May 2023). \"Why an Octopus-like Creature Has Come to Symbolize the State of A.I.\" The New York Times. Archived from the original on 30 May 2023. Retrieved 12 June 2023.\\n\\n^ \"The A to Z of Artificial Intelligence\". Time Magazine. 13 April 2023. Archived from the original on 16 June 2023. Retrieved 12 June 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Ji, Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; Ishii, Etsuko; Bang, Yejin; Dai, Wenliang; Madotto, Andrea; Fung, Pascale (November 2022). \"Survey of Hallucination in Natural Language Generation\" (pdf). ACM Computing Surveys. 55 (12). Association for Computing Machinery: 1–38. arXiv:2202.03629. doi:10.1145/3571730. S2CID\\xa0246652372. Archived from the original on 26 March 2023. Retrieved 15 January 2023.\\n\\n^ Varshney, Neeraj; Yao, Wenlin; Zhang, Hongming; Chen, Jianshu; Yu, Dong (2023). \"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation\". arXiv:2307.03987 [cs.CL].\\n\\n^ Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm. New York Basic Books. pp.\\xa0569–583. ISBN\\xa0978-0-465-05674-3.\\n\\n^ Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-04396-1.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-04396-1.\\n\\n^ Friston, Karl J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference. The MIT Press. ISBN\\xa0978-0-262-36997-8.\\n\\n^ a b Huyen, Chip (October 18, 2019). \"Evaluation Metrics for Language Modeling\". The Gradient. Retrieved January 14, 2024.\\n\\n^ a b Clark, Christopher; Lee, Kenton; Chang, Ming-Wei; Kwiatkowski, Tom; Collins, Michael; Toutanova, Kristina (2019). \"BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\". arXiv:1905.10044 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b c Wayne Xin Zhao; Zhou, Kun; Li, Junyi; Tang, Tianyi; Wang, Xiaolei; Hou, Yupeng; Min, Yingqian; Zhang, Beichen; Zhang, Junjie; Dong, Zican; Du, Yifan; Yang, Chen; Chen, Yushuo; Chen, Zhipeng; Jiang, Jinhao; Ren, Ruiyang; Li, Yifan; Tang, Xinyu; Liu, Zikang; Liu, Peiyu; Nie, Jian-Yun; Wen, Ji-Rong (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\n\\n^ openai/simple-evals, OpenAI, 2024-05-28, retrieved 2024-05-28\\n\\n^ openai/evals, OpenAI, 2024-05-28, archived from the original on 2024-05-08, retrieved 2024-05-28\\n\\n^ \"Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ Srivastava, Aarohi; et\\xa0al. (2022). \"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models\". arXiv:2206.04615 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lin, Stephanie; Hilton, Jacob; Evans, Owain (2021). \"TruthfulQA: Measuring How Models Mimic Human Falsehoods\". arXiv:2109.07958 [cs.CL].\\n\\n^ a b Zellers, Rowan; Holtzman, Ari; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin (2019). \"HellaSwag: Can a Machine Really Finish Your Sentence?\". arXiv:1905.07830 [cs.CL].\\n\\n^ \"Prepare for truly useful large language models\". Nature Biomedical Engineering. 7 (2): 85–86. 7 March 2023. doi:10.1038/s41551-023-01012-6. PMID\\xa036882584. S2CID\\xa0257403466.\\n\\n^ \"Your job is (probably) safe from artificial intelligence\". The Economist. 7 May 2023. Archived from the original on 17 June 2023. Retrieved 18 June 2023.\\n\\n^ \"Generative AI Could Raise Global GDP by 7%\". Goldman Sachs. Archived from the original on 18 June 2023. Retrieved 18 June 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Peng, Zhencan; Wang, Zhizhi; Deng, Dong (13 June 2023). \"Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation\" (PDF). Proceedings of the ACM on Management of Data. 1 (2): 1–18. doi:10.1145/3589324. S2CID\\xa0259213212. Archived (PDF) from the original on 2024-08-27. Retrieved 2024-01-20. Citing Lee et al 2022.\\n\\n^ Peng, Wang & Deng 2023, p.\\xa08.\\n\\n^ Stephen Council (1 Dec 2023). \"How Googlers cracked an SF rival\\'s tech model with a single word\". SFGATE. Archived from the original on 16 December 2023.\\n\\n^ Alba, Davey (1 May 2023). \"AI chatbots have been used to create dozens of news content farms\". The Japan Times. Retrieved 18 June 2023.\\n\\n^ \"Could chatbots help devise the next pandemic virus?\". Science. 14 June 2023. doi:10.1126/science.adj2463. Archived from the original on 18 June 2023. Retrieved 18 June 2023.\\n\\n^ Hubinger, Evan (10 January 2024). \"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training\". arXiv:2401.05566 [cs.CR].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Kang, Daniel (2023). \"Exploiting programmatic behavior of LLMs: Dual-use through standard security attacks\". arXiv:2302.05733 [cs.CR].\\n\\n^ Wang, Yongge (20 June 2024). \"Encryption Based Covert Channel for Large Language Models\" (PDF). IACR ePrint 2024/586. Archived (PDF) from the original on 24 June 2024. Retrieved 24 June 2024.\\n\\n^ a b Stokel-Walker, Chris (November 22, 2023). \"ChatGPT Replicates Gender Bias in Recommendation Letters\". Scientific American. Archived from the original on 2023-12-29. Retrieved 2023-12-29.\\n\\n^ Luo, Queenie; Puett, Michael J.; Smith, Michael D. (2023-03-28). \"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube\". arXiv:2303.16281v2 [cs.CY].\\n\\n^ Cheng, Myra; Durmus, Esin; Jurafsky, Dan (2023-05-29), Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models, arXiv:2305.18189'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Kotek, Hadas; Dockum, Rikker; Sun, David (2023-11-05). \"Gender bias and stereotypes in Large Language Models\". Proceedings of the ACM Collective Intelligence Conference. CI \\'23. New York, NY, USA: Association for Computing Machinery. pp.\\xa012–24. doi:10.1145/3582269.3615599. ISBN\\xa0979-8-4007-0113-9.\\n\\n^ Heikkilä, Melissa (August 7, 2023). \"AI language models are rife with different political biases\". MIT Technology Review. Retrieved 2023-12-29.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Further reading[edit]\\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\\nZhao, Wayne Xin; et\\xa0al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\nKaddour, Jean; et\\xa0al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024). \"A Survey on Multimodal Large Language Models\". National Science Review. arXiv:2306.13549. doi:10.1093/nsr/nwae403.\\n\"AI Index Report 2024 – Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451–452. doi:10.1038/s44159-023-00211-x. ISSN\\xa02731-0574. S2CID\\xa0259713140. Retrieved 2 July 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='vteNatural language processingGeneral terms\\nAI-complete\\nBag-of-words\\nn-gram\\nBigram\\nTrigram\\nComputational linguistics\\nNatural language understanding\\nStop words\\nText processing\\nText analysis\\nArgument mining\\nCollocation extraction\\nConcept mining\\nCoreference resolution\\nDeep linguistic processing\\nDistant reading\\nInformation extraction\\nNamed-entity recognition\\nOntology learning\\nParsing\\nSemantic parsing\\nSyntactic parsing\\nPart-of-speech tagging\\nSemantic analysis\\nSemantic role labeling\\nSemantic decomposition\\nSemantic similarity\\nSentiment analysis\\nTerminology extraction\\nText mining\\nTextual entailment\\nTruecasing\\nWord-sense disambiguation\\nWord-sense induction\\nText segmentation\\nCompound-term processing\\nLemmatisation\\nLexical analysis\\nText chunking\\nStemming\\nSentence segmentation\\nWord segmentation'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Automatic summarization\\nMulti-document summarization\\nSentence extraction\\nText simplification\\nMachine translation\\nComputer-assisted\\nExample-based\\nRule-based\\nStatistical\\nTransfer-based\\nNeural\\nDistributional semantics models\\nBERT\\nDocument-term matrix\\nExplicit semantic analysis\\nfastText\\nGloVe\\nLanguage model (large)\\nLatent semantic analysis\\nSeq2seq\\nWord embedding\\nWord2vec\\nLanguage resources,datasets and corporaTypes andstandards\\nCorpus linguistics\\nLexical resource\\nLinguistic Linked Open Data\\nMachine-readable dictionary\\nParallel text\\nPropBank\\nSemantic network\\nSimple Knowledge Organization System\\nSpeech corpus\\nText corpus\\nThesaurus (information retrieval)\\nTreebank\\nUniversal Dependencies\\nData\\nBabelNet\\nBank of English\\nDBpedia\\nFrameNet\\nGoogle Ngram Viewer\\nUBY\\nWordNet\\nWikidata\\nAutomatic identificationand data capture\\nSpeech recognition\\nSpeech segmentation\\nSpeech synthesis\\nNatural language generation\\nOptical character recognition\\nTopic model\\nDocument classification\\nLatent Dirichlet allocation'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Optical character recognition\\nTopic model\\nDocument classification\\nLatent Dirichlet allocation\\nPachinko allocation\\nComputer-assistedreviewing\\nAutomated essay scoring\\nConcordancer\\nGrammar checker\\nPredictive text\\nPronunciation assessment\\nSpell checker\\nNatural languageuser interface\\nChatbot\\nInteractive fiction (c.f. Syntax guessing)\\nQuestion answering\\nVirtual assistant\\nVoice user interface\\nRelated\\nFormal semantics\\nHallucination\\nNatural Language Toolkit\\nspaCy'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='vteArtificial intelligenceConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nRLHF\\nSelf-supervised learning\\nWord embedding\\nHallucination\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nArtificial general intelligence\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Text-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nClaude\\nGemini\\nchatbot\\nGrok\\nLaMDA\\nBLOOM\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nJürgen Schmidhuber\\nYann LeCun\\nGeoffrey Hinton\\nJohn Hopfield\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Andrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow\\nAndrej Karpathy\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Portals\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n List\\nCompanies\\nProjects\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1266089667\"\\nCategories: Large language modelsDeep learningNatural language processingHidden categories: CS1: long volume valueWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2024All articles containing potentially dated statementsArticles containing potentially dated statements from June 2024All accuracy disputesArticles with disputed statements from September 2024All articles with unsourced statementsArticles with unsourced statements from February 2024'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='This page was last edited on 30 December 2024, at 01:48\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Arxiv:"
      ],
      "metadata": {
        "id": "OPxnvKZ-bwlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import ArxivLoader\n",
        "\n",
        "def load_arxiv_documents(query: str):\n",
        "    arxiv_loader = ArxivLoader(\n",
        "        query=query,\n",
        "        load_max_docs=2,\n",
        "    )\n",
        "    docs = arxiv_loader.load()\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        return split_docs"
      ],
      "metadata": {
        "id": "aeBHX2HSbx8I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_docs = load_arxiv_documents(\"Large Language Models\")"
      ],
      "metadata": {
        "id": "kk7RPIJ-cBjR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_docs"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrHnUj06cDeE",
        "outputId": "3e632376-d46c-4f09-d3b0-a2a9a4d1878a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Lost in Translation\\nMay 2023\\nA report from\\nGabriel Nicholas\\nAliya Bhatia\\nLarge Language Models in \\nNon-English Content Analysis\\nGABRIEL NICHOLAS\\nResearch Fellow at the Center for Democracy & Technology.\\nALIYA BHATIA\\nPolicy Analyst, Free Expression Project at the Center for \\nDemocracy & Technology.\\nThe Center for Democracy & Technology (CDT) is the leading \\nnonpartisan, nonprofit organization fighting to advance civil rights and \\ncivil liberties in the digital age. We shape technology policy, governance, \\nand design with a focus on equity and democratic values. Established in \\n1996, CDT has been a trusted advocate for digital rights since the earliest \\ndays of the internet. The organization is headquartered in Washington, \\nD.C., and has a Europe Office in Brussels, Belgium.\\nA report from\\nGabriel Nicholas and Aliya Bhatia\\nWITH CONTRIBUTIONS BY\\nSamir Jain, Mallory Knodel, Emma Llansó, Michal Luria, Nathalie Maréchal, Dhanaraj Thakur, and \\nCaitlin Vogus.\\nACKNOWLEDGMENTS'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Caitlin Vogus.\\nACKNOWLEDGMENTS \\nWe thank Pratik Joshi, Sebastin Santy, and Aniket Kesari for their invaluable feedback on the technical \\naspects of this report. We also thank Jacqueline Rowe, Damini Satija, and Ángel Díaz for their \\ninsightful comments and suggestions. The translation of our executive summary is made possible by \\nGlobal Voices Translations and with the help of Iverna McGowan, Maria Villamar, Ophélie Stockhem, \\nand Tomás Pomar. All views in this report are those of CDT. \\nThis work is made possible through a grant from the John S. and James L. Knight Foundation.\\nSuggested Citation: Nicholas, G. and Bhatia, A. (2023) Lost in Translation: Large Language Models \\nin Non-English Content Analysis. Center for Democracy & Technology. https://cdt.org/insights/lost-\\nin-translation-large-language-models-in-non-english-content-analysis/\\nReferences in this report include original links and links archived and shortened by the Perma.cc service.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='The Perma.cc links also contain information on the date of retrieval and archive. \\nThis report is licensed under a Creative Commons Attribution 4.0 International License.\\nLost in Translation\\nLarge Language Models in Non-\\nEnglish Content Analysis\\nLost in Translation\\nCDT Research\\n4\\nCDT Research\\n4\\nContents\\nExecutive Summary\\x08\\n5\\nIntroduction\\x08\\n8\\nI.\\t Background\\x08\\n12\\nA. How Large Language Models Work\\x08\\n12\\nB. The Resourcedness Gap: Why the Largest Language \\nModels are in English\\x08\\n15\\nC. Multilingual Language Models: Efforts to Bridge the \\nResourcedness Gap\\x08\\n19\\nII.\\t Limitations of Language Models in English and \\nNon-English Contexts\\x08\\n23\\nA. Concerns with Building and Deploying Large \\nLanguage Models\\x08\\n23\\nB. Limitations of Multilingual Language Models\\x08\\n25\\nIII.\\tRecommendations\\x08\\n31\\nA. Companies\\x08\\n31\\nB. Researchers and Funders\\x08\\n33\\nC. Governments\\x08\\n36\\nWorks Cited\\x08\\n39\\n5\\nLost in Translation\\nExecutive \\nSummary\\nT\\nhe internet is the primary source of information, economic'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Executive \\nSummary\\nT\\nhe internet is the primary source of information, economic \\nopportunity, and community for many around the world. \\nHowever, the automated systems that increasingly mediate our \\ninteractions online — such as chatbots, content moderation \\nsystems, and search engines — are primarily designed for and work far \\nmore effectively in English than in the world’s other 7,000 languages.\\nIn recent years, large language models have become the dominant \\napproach for building AI systems to analyze and generate language \\nonline, but again, they have been built primarily for the English \\nlanguage. A large language model (e.g., Open AI’s GPT-4, Meta’s \\nLLaMa, Google’s PaLM) is a machine learning algorithm that scans \\nenormous volumes of text to learn which words and sentences \\nfrequently appear near one another and in what context. Large language \\nmodels can be adapted to perform a wide range of tasks across different \\ndomains. They are most known for being used to build chatbots,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='domains. They are most known for being used to build chatbots, \\nsuch as ChatGPT, but researchers and technology companies also \\nuse them for content analysis tasks, such as sentiment analysis, text \\nsummarization, and hate speech detection. Google, Meta, Microsoft, \\nand other companies have already incorporated large language models \\ninto their core product functions, such as content moderation and \\nsearch. Other vendors soon may incorporate them into automated \\ndecision-making systems, such as resume scanners.\\nRecently though, researchers and technology companies have attempted \\nto extend the capabilities of large language models into languages other \\nthan English by building what are called multilingual language models. \\nInstead of being trained on text from only one language, multilingual \\nlanguage models are trained on text from dozens or hundreds of \\nlanguages at once. Researchers posit that multilingual language models'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='languages at once. Researchers posit that multilingual language models \\ninfer connections between languages, allowing them to apply word \\nassociations and underlying grammatical rules learned from languages \\nwith more text data available to train on (in particular English) to \\nthose with less. In some applications, multilingual language models \\noutperform models trained on only one language — for instance, a \\nmodel trained on lots of text from lots of languages, including Hindi, \\nmight perform better in Hindi contexts than a model just trained on \\nHindi text.\\nMultilingual language models give technology companies a way to scale \\ntheir AI systems to many languages at once, and some have already \\nbegun to integrate them into their products. Online service providers \\nin particular have deployed multilingual language models to moderate \\nLost in Translation\\nCDT Research\\n6\\ncontent: Meta uses a multilingual language model to detect harmful content on its'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='CDT Research\\n6\\ncontent: Meta uses a multilingual language model to detect harmful content on its \\nplatforms in over 100 languages; Alphabet’s Perspective API uses one to detect toxic \\ncontent in eighteen different languages; Bumble uses one to detect and take action on \\nunwanted sexual messages around the world.\\nMultilingual language models allow technologists to attempt to build models in languages \\nfor which they otherwise might not have enough digitized text. Languages vary widely \\nin resourcedness, or the volume, quality, and diversity of text data they have available to \\ntrain language models on. English is the highest resourced language by multiple orders of \\nmagnitude, but Spanish, Chinese, German, and a handful of other languages are sufficiently \\nhigh resource enough to build language models in. Medium resource languages, with fewer \\nbut still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='but still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource \\nlanguages, with almost no training data sets, such as Amharic, Cherokee, and Haitian \\nCreole, have too little text for training their own large language models. Language data in \\nlow resource languages is also often of particularly poor quality: either it is mistranslated or \\neven nonsensical language scraped from the internet, or is limited to sources with narrow \\ndomains, such as religious texts and Wikipedia. This gap in data availability between \\nlanguages is known as the resourcedness gap.\\nMultilingual language models are designed to address these gaps in data availability by \\ninferring semantic and grammatical connections between higher- and lower-resource \\nlanguages, allowing the former to bootstrap the latter. However, this architecture \\nraises its own concerns. Multilingual language models are still usually trained'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='raises its own concerns. Multilingual language models are still usually trained \\ndisproportionately on English language text and thus end up transferring values and \\nassumptions encoded in English into other language contexts where they may not \\nbelong. For example, a multilingual model might associate the word “dove” in all \\nlanguages with “peace” even though the Basque word for dove (“uso”) can be an insult. \\nThe disparity in available data also means multilingual language models work far better \\nin higher resource languages and languages similar to them than lower resource ones. \\nModel developers will sometimes try to fill in these gaps with machine-translated text, \\nbut translation errors may further compound language misrepresentation. And when \\nmultilingual language models do fail, their unintuitive connections between languages \\ncan make those problems harder to identify, diagnose, and fix.\\nLarge language models’ general use in content analysis raises further concerns.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Large language models’ general use in content analysis raises further concerns. \\nComputational linguists argue that large language models are limited in their capacity \\nto analyze forms of expression not included in their training data, meaning they may \\nstruggle to perform in new contexts. They may also reproduce any biases present in \\ntheir training data. Often, this text is scraped from the internet, meaning that large \\nlanguage models may encode and reinforce dominant views expressed online.\\nLarge Language Models in Non-English Content Analysis\\n7\\n\\u200bCompanies, researchers, and governments each have a role to play in protecting the \\npublic from the potential dangers of multilingual language model content analysis \\nsystems. To ensure better public accountability, companies that deploy large language \\nmodels should always be transparent about how they use them and in which languages. \\nCompanies should deploy language models with narrow remits and adequate channels \\nfor human review.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Companies should deploy language models with narrow remits and adequate channels \\nfor human review.\\nResearchers and research funders meanwhile should invest in efforts to improve the \\nuse and performance of language models in languages other than English, in particular, \\nto reduce failures that disparately impact speakers of lower-resourced languages. The \\nbest way to do this is by supporting language-specific research communities, who can \\npromote the virtuous cycle of collecting data, curating datasets, training language \\nmodels, publishing, and building applications. Local language speakers and context \\nexperts need to be part of each step of this process and also be curating the data and \\nassessing the language models deployed by large, global online services.\\nFinally, governments need to be careful about how they use or encourage the use of \\nlarge language models. Large language models should never power systems used to make'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='large language models. Large language models should never power systems used to make \\nhigh-stakes decisions without oversight, such as decisions about immigration status or \\nhealthcare, nor should governments mandate or inadvertently require by law the use of \\nlarge language model-powered systems to moderate content from online services. Instead, \\ngovernments should convene different stakeholders to align on what norms and guardrails \\nshould be around developing and deploying large language models.\\nLarge language models in general and multilingual language models in particular \\nhave the potential to create new economic opportunities and improve the web for \\nall. However, mis- or over-application of these technologies poses real threats to \\nindividuals’ rights, such as undermining their right to free expression by inaccurately \\ntaking down a person’s post on social media or their right to be free of discrimination'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='taking down a person’s post on social media or their right to be free of discrimination \\nby misinterpreting an individual’s job or visa application. Multilingual language \\nmodels specifically can inadvertently further entrench the Anglocentrism they are \\nintended to address. In light of these limitations, technology companies, researchers, \\nand governments must consider potential human and civil rights risks when studying, \\nprocuring, developing, or using multilingual language models to power systems, in \\nparticular when they are used to make critical information available or play a role \\nin decisions affecting people’s access to economic opportunities, liberty, or other \\nimportant interests or rights.\\nExecutive Summary\\nLost in Translation\\nCDT Research\\n8\\nIntroduction\\nD\\nespite the modern internet’s power to mobilize and connect \\npeople around the world, the web still does not reflect the \\nlinguistic diversity of its users. In particular, the automated'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='linguistic diversity of its users. In particular, the automated \\nsystems that increasingly mediate our interactions online — \\nsuch as chatbots, search engines, and content moderation systems — \\nare built using and perform far better on English-language text than \\nthe world’s other 7,000 languages (Kornai, 2013; Sengupta, 2022). \\nIndividuals speaking languages other than English face barriers to \\nexpressing themselves freely online and may face greater challenges \\nwhen it comes to accessing critical information, public services, and \\neven asylum and safety (Torbati, 2019).\\nIn the last few years, however, there have been rapid advancements in \\ndeveloping machine learning tools that can analyze content in a wide \\nvariety of languages and across different domains. Large language \\nmodels, machine learning tools trained on enormous amounts of text \\nto recognize patterns in language, power many of these systems. Large \\nlanguage models already underlie translation apps, search autocomplete,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='language models already underlie translation apps, search autocomplete, \\nand chatbots such as ChatGPT. They are known for being adaptable to \\nmany different language tasks, and today, researchers and technologists \\nare constantly on the lookout for new applications and contexts \\nin which to deploy them. Since the late 2010s, major U.S.-based \\ntechnology companies have mostly invested in building large language \\nmodels that work primarily for English, such as Open AI’s GPT-4, \\nMeta’s LLaMa, and Google’s PaLM.\\nRecently, companies and researchers have begun building and researching \\nmultilingual language models, large language models trained on text \\ndata from several different languages at once. Meta’s XLM-RoBERTa \\n(XLM-R) for instance is trained on text from 100 languages (Meta AI, \\n2019) at once. Google’s mBERT, a multilingual version of its popular \\nBERT model, is trained on 104 languages. Researchers claim that these'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='BERT model, is trained on 104 languages. Researchers claim that these \\nmodels extend the multifaceted capabilities of large language models to \\nlanguages other than English, even to languages for which there is little or \\nno text data for the model to learn from (Artetxe & Schwenk, 2019; Wu \\n& Dredze, 2019).\\nTechnology companies have their own interests in improving how \\nwell large language models work in different languages. Some may \\nwant to make their products available in multiple languages to gain a \\ncompetitive edge in emerging and populous markets. Online services \\nLarge Language Models in Non-English Content Analysis\\n9\\nthat host user-generated content may especially be interested in using multilingual \\nlanguage models to detect and take action on hate speech, disinformation, and other \\ncontent that violates their policies or the law (Dulhanty et al., 2019). This is top of \\nmind for services after facing criticism for not taking more aggressive action against'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='mind for services after facing criticism for not taking more aggressive action against \\ncontent that incited violence and genocide in Ethiopia, Nigeria, and Myanmar, among \\nothers. Services have begun to deploy multilingual language models into their content \\nmoderation systems: Meta claims their XLM-R model can detect harmful content \\nin all 100 languages it is trained on (Meta AI, 2021); Alphabet’s Perspective API uses \\na large language model to detect toxic content in eighteen different languages (Lees \\net al., 2022); Bumble uses one to detect rude and abusive messages in at least fifteen \\nlanguages (Belloni, 2021). Technology companies are also repurposing these models to \\nmake health care information available and soon may reach into other domains as well \\n(Lunden, 2023).\\nIn the future, governments could also seek to use automated systems built using \\nlarge language models to make information available, answer questions in languages'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='large language models to make information available, answer questions in languages \\nspoken by their constituents (in the form of chatbots), or, more dangerously, analyze \\ninformation to make critical decisions such as benefits allocation or refugee status \\ndeterminations (Kinchin & Mougouei, 2022).\\nStill, studies show that even multilingual language models struggle to deal with the \\nwide disparities between different languages in how much text data they have available \\nto train and test language models. English has, by multiple orders of magnitude, more \\ntext data available than any other language and commands most of the attention of the \\nnatural language processing research community. The abundance of English language \\ndata stems from its position as the official or de facto language of international business, \\npolitics, and media, itself a legacy of British colonialism and American neocolonialism \\nand the subsequent erasure of regional and indigenous languages. American technology'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and the subsequent erasure of regional and indigenous languages. American technology \\ncompanies have further entrenched English as the predominant language of the internet \\nby rolling out early standards, coding languages, and social media platforms in English \\nlong before other languages.\\nThe hegemony of English data means that most large language models, even \\nmultilingual ones, are built predominantly using Standard English language text and \\nwork best in Standard English language contexts. Spanish, Chinese, Arabic, and a few \\nother “high resource” languages also have significant amounts of text data available, but \\nmany “medium resource” languages, such as Hindi and Portuguese, and “low resource” \\nlanguages, such as Haitian Creole and Swahili, have hardly any data available at all, and \\nmultilingual language models perform much worse in those languages. This skewed \\nemphasis fails to reflect the diversity of languages spoken by the world’s internet users'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='emphasis fails to reflect the diversity of languages spoken by the world’s internet users \\nand further perpetuates the dominance of the English language.\\nIntroduction\\nLost in Translation\\nCDT Research\\n10\\nDespite being deployed in real-world systems, multilingual language models have largely \\nbeen absent from public discourse, particularly about digital rights and public policy, \\nand have instead been relegated to computer science academia and tech company public \\nrelations. This paper seeks to address this gap by offering several resources to bolster \\npolicy discussions. Part I provides a simple technical explanation of how large language \\nmodels work in general, why there is a gap in available data between English and other \\nlanguages, and how multilingual language models attempt to bridge that gap. Part II \\naccounts for the challenges of doing content analysis with large language models in \\ngeneral and multilingual language models in particular, namely:'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='general and multilingual language models in particular, namely:\\n1.\\t Multilingual language models often rely on machine-translated text that can \\ncontain errors or terms native language speakers don’t actually use. \\n2.\\t When multilingual language models fail, their problems are hard to identify, \\ndiagnose, and fix.\\n3.\\t Multilingual language models do not and cannot work equally well in all languages.\\n4.\\t Multilingual language models fail to account for the contexts of local language \\nspeakers.\\nFinally, Part III provides recommendations for companies, researchers, and \\npolicymakers to keep in mind when considering studying, developing, and deploying \\nlarge and multilingual language models to do content analysis. These recommendations \\noffer guidance concerning when large language models should or should not be \\ndeployed, how to improve their performance in non-English languages, and how to \\nensure better accountability and transparency to local language stakeholders.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='ensure better accountability and transparency to local language stakeholders.\\nBefore proceeding, two notes on the terminology used in this primer. First, this paper \\nfocuses specifically on one category of applications for large language models: content \\nanalysis, or, the inference and extraction of information, themes, and concepts from \\ntext. The Center for Democracy & Technology (CDT) has written many times about \\nthe limitations of automated content analysis systems (Duarte et al., 2017; Shenkman \\net al., 2021) and the civil liberty risks they can pose, particularly in areas such as content \\nmoderation, student activity monitoring, hiring and more (Grant-Chapman et al., \\n2021; Nicholas, 2022; Vallee & Duarte, 2019). Large language models are already deeply \\nintegrated into many of these technical systems, particularly content moderation, and will \\nsoon become part of many more. Public discourse about large language models has so far'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='soon become part of many more. Public discourse about large language models has so far \\ndisproportionately focused on text generation, an important area but not the only one. \\nMany of the shortcomings of large language models presented in this report also apply \\nto text generation. As such, this report can be read as a primer on some of the limits of \\ngenerative AI systems as well. However, we choose to focus on content analysis for this \\nreport because of the potential dangers associated with using these models to host and \\nmake information available and the impacts on free expression rights.\\nLarge Language Models in Non-English Content Analysis\\n11\\nSecond, this paper focuses on how multilingual language models perform in languages \\nother than English. We use the shorthand of “non-English languages” for easy reading \\nand because it is the terminology used in the machine learning and policy literature.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and because it is the terminology used in the machine learning and policy literature. \\nWe recognize the irony that this term centers the English language and misleadingly \\nimplies all other languages are a monolith. Where possible, we elaborate upon the types \\nof languages we are writing about and make distinct references to specific languages and \\ncultural contexts that will elude models trained primarily in English. In some instances, \\nwe think the term “non-English” captures the sheer Anglocentrism of many of these \\nmodels well by articulating the limited scope in which they are trained and tested.\\nIntroduction\\nLost in Translation\\nCDT Research\\n12\\nI. Background\\nA. How Large Language Models Work\\nNatural language processing (NLP) is a subfield of artificial intelligence \\nand linguistics concerned with building computer systems that can \\nprocess and analyze language. NLP underlies many technologies we \\nencounter every day — spellcheck, voice assistants like Siri or Alexa,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='encounter every day — spellcheck, voice assistants like Siri or Alexa, \\nresume scanners, language translators, and automated hate speech \\ndetection tools, to name a few. Until only a few years ago, when \\ntechnologists wanted to teach a computer to perform a given NLP task, \\nthey would build a system specifically tailored to that task. To create a \\nspam detection system for instance, a technologist might gather many \\nemails, mark which ones are and are not spam, use some of those emails to \\ntrain an algorithm and use others to test how well that algorithm works.\\nToday though, the field has fundamentally reoriented itself around \\nrepurposing large language models to solve nearly every problem. \\nA language model is a mathematical function trained to solve a text \\nprediction task like the following, “Given a sequence of words, predict \\nwhat word will likely come next.” For example, a language model might be \\ngiven the phrase “I was a bad student, I used to skip ____,” and generate'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='given the phrase “I was a bad student, I used to skip ____,” and generate \\nas an output that there is a high percent chance the missing word is \\n“class,” a low percent it is “rope,” and a near zero percent it is “clamoring.”\\nThe distribution of language that the model learns in the process can \\neasily be repurposed to many different language tasks. The most often \\ndiscussed application is text generation: conversational agents like \\nChatGPT can repurpose this text prediction task to answer questions, \\nsummarize text, and generate overall “human”-sounding speech. \\nHowever, chatbots are just one application of large language models. \\nOnce a large language model is built, it can be further trained on a \\nsmaller dataset to improve its performance in a specific task, a process \\ncalled fine-tuning. Today, for example, a developer building a spam \\ndetection system might take a general large language model already \\nbuilt by someone else — say Google’s BERT — and fine-tune it to the'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='built by someone else — say Google’s BERT — and fine-tune it to the \\nspecific task of spam detection using a handful of emails already labeled \\nspam or not spam. By building it on top of a language model, the spam \\ndetection system will do a better job of detecting spam that doesn’t \\nperfectly match the language available in the email dataset.\\nLanguage models are not new. Computational linguists have used \\nstatistical models to try to infer rules about language since the 1980s \\n(Nadkarni et al., 2011) and have used “neural networks” (an algorithm \\nloosely modeled on how neurons connect in the brain) to do so since \\nthe early 2010s (Mikolov et al., 2013). What is new though is their \\nLarge Language Models in Non-English Content Analysis\\n13\\nlargeness. Early language models could not be trained on as much data, since they had \\nto read text in sequence, a process that could not be sped up by using more computing'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='to read text in sequence, a process that could not be sped up by using more computing \\npower. These early language models struggled to analyze words within the broader \\ncontext of a sentence or document: for instance, one fine-tuned to detect suicidal \\nideation might have difficulty distinguishing between expressions of self-harm (“I \\njust wish I was dead”) and humor (“omg I’m dead”). But in 2017, Google researchers \\nreleased a paper on a new architecture called transformers, which allowed language \\nmodels to train on lots of data at the same time, in parallel rather than in sequence \\n(Vaswani et al., 2017). These transformer-based language models could ingest so much \\ndata simultaneously that they could learn associations between entire sequences of \\nwords, not just individual words. Instead of being shown just {“dead”}, the model \\nwould see a word in its entire context, {“dead”, [“omg”, “I’m”, “_____”]}, thus creating'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='would see a word in its entire context, {“dead”, [“omg”, “I’m”, “_____”]}, thus creating \\na much richer representation of language. Today, the only limit on the size of a language \\nmodel — how much data it ingests and how many connections it makes between \\ndifferent sequences of words (i.e. parameters) — is how much data one can find and \\nhow much developers are willing to spend on processing power.\\nThe output a language model produces is called a representation space, a map of the \\nsequences of words that commonly appear near one another in the training text. For \\nexample, the phrases “It’s so cold outside!” and “I better wear a jacket” may be near one \\nanother in a language model’s representation space, since those sentences often appear \\nclose to one another in writing. This kind of proximity can lead to language models \\ninferring patterns within language that can then help them conduct tasks that it is not'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='inferring patterns within language that can then help them conduct tasks that it is not \\nexplicitly trained in. In this case, sentences about cold weather being mapped near each \\nother mean the large language model could be trained to detect whether a given phrase \\nis about temperature.\\nWith enough data, a large language model may have such a rich and multifaceted \\nrepresentation of a language that it can learn to do new tasks with only a few, or even \\nzero examples to fine-tune on. For instance, the spam detection system described earlier \\ncould be built with little to no spam to fine-tune on. This capability is called “few-shot” \\nor “zero-shot learning” and is one of the greatest promises of large language models, so \\nmuch so that the original GPT-3 white paper is entitled “Language Models are Few-\\nShot Learners” (Brown et al., 2020).\\nImportantly though, large language models only learn the distribution of language, not'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Importantly though, large language models only learn the distribution of language, not \\nits meaning (Bender & Koller, 2020). In the previous “cold” example, the model has not \\nlearned that when one is cold, one puts on a jacket or anything about the deeper meanings \\nof “cold” and “jacket,” only that the words often appear near one another. If one of the \\ndocuments a large language model trains on is a humorous blogpost about the best shorts \\nto wear in cold temperatures, the model could just as easily learn that “shorts” and “cold” \\nare related. Similarly, if a model is trained only on very formal language data, it may never \\nlearn that “nippy” or “brick” (New York City slang) can refer to cold as well.\\nI. Background\\nLost in Translation\\n14\\nTechnologists often try to address these shortcomings by training language models \\non more and more data. If a model is exposed to more data, the idea is that it will be'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='on more and more data. If a model is exposed to more data, the idea is that it will be \\nfamiliar with more contexts, and outliers like the ironic cold-weather shorts blogpost \\nwill be outweighed by more representative data. This has led to ballooning in the size \\nof large language models. BERT, a popular open-source model built by Google in \\n2018, was trained on 800 million words from free books and 2.5 billion words from \\nEnglish Wikipedia (Devlin et al., 2019). Two years later, OpenAI released its closed \\nsource GPT-3, which was trained on half a trillion mostly-English words crawled from \\nthe internet (Brown et al., 2020). Google’s PaLM, released in 2022, trained on 780 \\nbillion words, mostly from English-language websites and social media conversations \\n(Chowdhery et al., 2022). As models have grown in size, so have the computation costs \\nof training them. While BERT costs a few thousand dollars in computing power to'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='of training them. While BERT costs a few thousand dollars in computing power to \\ntrain from scratch and is often trained by academics to build new topic- or language-\\nspecific models (Izsak et al., 2021), GPT-3 and PaLM-sized models cost millions or \\ntens of millions of dollars to train (Sharir et al., 2020). Future models will only be \\nmore expensive, leaving only the most well-off companies able to afford to build them \\n(Bommasani et al., 2021).\\nFigure 1. Language model \\nrepresentation space. A langauge model’s \\nreprsentation space, collapsed into two \\ndimensions. In reality, these models often \\nhave thousands or tens of thousands of \\ndimensions.\\nSource: (Amer, 2022)\\nLost in Translation\\n14\\nWhen is \\nBoxing Day?\\nWhat is the date \\nof Boxing Day?\\nHow many species \\nof sharks are there?\\nHow many species of the \\nGreat White shark are there?\\nIt’s so cold \\noutside!\\nI better wear \\na jacket.\\nLarge Language Models in Non-English Content Analysis\\n15'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='outside!\\nI better wear \\na jacket.\\nLarge Language Models in Non-English Content Analysis\\n15\\nModels are expensive to initially train, but once built, their representations are relatively \\ncheap to use and be fine-tuned for different tasks. Thus, many technologists simply \\nuse pretrained large language models built by others (usually large companies, with the \\nexpertise and resources) instead of paying to create their own. The few big pretrained \\nmodels that exist have thus become a sort of infrastructure, known as “foundation \\nmodels” (Bommasani et al., 2021). This gives many technologists access to the state of \\nthe art capabilities, but it also creates a single point of failure for the sector as a whole: \\nif a foundation model has a problem, it will persist across many applications. And these \\nmodels are so large and complicated that even when they are open source, researchers \\ncannot understand the underlying logic they use to come up with individual decisions.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cannot understand the underlying logic they use to come up with individual decisions.\\nMany of the largest and most advanced of these foundation models — such as \\nOpenAI’s GPT-4, Google’s PaLM, and Meta’s LLaMa — are trained primarily on \\nEnglish language data. In the next section, we explore one reason why that may be: the \\nresourcedness gap.\\nB. The Resourcedness Gap: Why the Largest \\nLanguage Models are in English\\nEnglish is the closest thing there is to a global lingua franca. It is the dominant language \\nin science, popular culture, higher education, international politics, and global \\ncapitalism; it has the most total speakers and the third-most first-language speakers \\n(Ethnologue, 2023b). It is the primary language spoken on the internet, accounting \\nfor 63.7% of websites, despite being spoken by only 16% of the world’s population \\n(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic \\nsuperiority: rather it is the colonial and neocolonial legacy of nearly three hundred \\nyears of the preeminent global superpower speaking English — first Great Britain, \\nthen the United States. The British government prioritized the English language \\nthrough official language policies to facilitate trade and in an attempt to “modernize” \\nits colonies, and as British, and later American trade became globally dominant, so too \\ndid English (Corradi, 2017; Phillipson, 1992). Prioritization of the English language \\ncame at the expense of other regional and indigenous languages and accelerated \\nlanguage endangerment and economic marginalization, which still impedes digital \\ninvestment into these languages worldwide (Rowe, 2022; S. Zhang et al., 2022). \\nAmerican companies continue to perpetuate the dominance of the English language in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='American companies continue to perpetuate the dominance of the English language in \\na new more insidious form, by making online services available to global users without \\ncomparable investment into the languages they speak (Amrute et al., 2022; Kupfer & \\nMuyumba, 2022).\\nI. Background\\nLost in Translation\\nCDT Research\\n16\\nAs a result of these forces, English also dominates the field of natural language \\nprocessing, and there is vastly more raw text data available in English than in any other \\nlanguage by orders of magnitude (Joshi et al., 2020).\\xa0English has the most digitized \\nbooks and patents, the largest Wikipedia, and the biggest internet presence. English is \\nalso by far the language paid the most attention by the global NLP research community. \\nIt is so hegemonic within the field that NLP papers about the English language \\ntypically do not even mention the language in the title or abstract (Bender, 2019). As'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='typically do not even mention the language in the title or abstract (Bender, 2019). As \\nFigure 2 shows, even among NLP papers that do mention a language in the abstract, \\nEnglish is mentioned over ten times as often as the next most mentioned language, \\nGerman (ACL Rolling Review Dashboard, 2022).\\nThis wealth of data and research makes it significantly easier to build large language \\nmodels in English than in any other language. More raw text data, also known as \\nunlabeled data, means more data for the model to be trained on; more research means \\nthat there are more datasets annotated with information, also known as labeled data, \\nthat can be used to test how well models complete different types of language tasks. \\nThis creates a virtuous cycle for English-language NLP —\\xa0more labeled and unlabeled \\ndata leads to more research attention, which leads to increased demand for labeled and \\nunlabeled data, and so on.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='unlabeled data, and so on.\\nEnglish is the prime example of a high resource language, a language for which a lot of \\nhigh-quality data resources exist. Though it has the most data available of any language \\n(English could be called an “extremely” high resource language), there are six other \\nlanguages that could be considered high resource — the official UN languages list, \\nminus Russian, plus Japanese (see Table 1). There are also a few dozen medium resource \\nlanguages, such as Urdu, Italian, and Tagalog, with another one or two orders of \\nmagnitude less data, or about one hundredth or one-thousandth of available English data. \\nThe rest of the world’s 6,000 plus languages can be considered low resource or extremely \\nlow resource, with only small amounts of written text available (Joshi et al., 2020).\\nResourcedness can vary within languages as well. Languages such as Arabic and Spanish \\ndiffer so much between dialects that many are mutually incomprehensible, even if'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='differ so much between dialects that many are mutually incomprehensible, even if \\nthey mostly use the same written form. Languages can also have different sociolects, \\nvarying across different social groups, identity groups, and contexts (e.g. formal versus \\ninformal). Regional dialects and sociolects can vary in degrees of difference from \\nhaving different vocabulary and grammatical structures (e.g. Australian English or \\nAfrican American English versus Standard American English) to make extensive use of \\nborrowed words from other languages (e.g. Nigerian English, Indian English), to fully \\nhybrid bilingual dialects (e.g. Spanglish, Hinglish). However, the available digitized \\ntext of language often doesn’t reflect the full spectrum of variation that exists within a \\nlanguage. (Bergman & Diab, 2022). Data scraped from the internet in particular over-\\nindexes Standard English spoken by younger people in developed countries (Luccioni'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='indexes Standard English spoken by younger people in developed countries (Luccioni \\n& Viviano, 2021). Other languages have just as much dialectical diversity as English and \\nalso likely over-index on certain dialects.\\nLarge Language Models in Non-English Content Analysis\\n17\\nFigure 2. Languages mentioned in \\npaper abstracts. Top most mentioned \\nlanguages in abstracts of papers published \\nby the Association for Computational \\nLinguistics, May 2022-January 2023.\\nSource: (Santy et al., 2023)\\nPaper Abstracts\\nLanguages with less data available also often have lower quality data available, either \\nbecause it is mislabeled or otherwise not representative of how people actually speak \\nthe language. This is particularly true with web-crawled data, a key data source for \\nlarge language models (Khan & Hanna, 2023). Non-English language data scraped \\nfrom the internet is more often machine translated, scanned from an image, or both,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from the internet is more often machine translated, scanned from an image, or both, \\nand each of those processes introduces opportunities for error (Dodge et al., 2021). \\nLow- and medium-resource language data on the internet is more often pornographic, \\nnonsensical, or non-linguistic content (Kreutzer et al., 2022). It is also often labeled as \\nthe incorrect language – around 95% of the time for many low resource languages – \\nbecause automatic language identification works much more poorly with insufficient \\ndata, thus creating a circular problem (Caswell et al., 2020). Languages with the worst \\nquality web data are disproportionately those written in non-Latin scripts (e.g. Urdu, \\nJapanese, Arabic) and those spoken in the Global South (e.g. African languages, \\nminority languages in the Middle East, non-Mandarin Chinese languages) (Kreutzer et \\nal., 2022).\\n17\\n0\\n200\\n300\\n100\\nEnglish\\nKorean\\nIndonesian\\nThai\\nFrench\\nGreek\\nTurkish\\nFinnish\\nGerman\\nSpanish\\nSwahili\\nClassical Chinese\\nHindi'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Korean\\nIndonesian\\nThai\\nFrench\\nGreek\\nTurkish\\nFinnish\\nGerman\\nSpanish\\nSwahili\\nClassical Chinese\\nHindi\\nHebrew\\nPolish\\nItalian\\nKinyarwanda\\nArabic\\nRussian\\nTalugu\\nDutch\\nJapanese\\nVietnamese\\nPortuguese\\nLatin\\nMarathi\\n311\\n27\\n18\\n16\\n16\\n16\\n16\\n13\\n10\\n7\\n7\\n7\\n6\\n5\\n5\\n5\\n4\\n4\\n4\\n4\\n4\\n3\\n3\\n3\\n3\\n3\\nI. Background\\nLost in Translation\\nCDT Research\\n18\\nLow resource languages also tend to have data that comes from a less diverse set of \\nsources. The clean data that does exist often comes from places such as Wikipedia, the \\nBible, and parliamentary proceedings, particularly in large language models that depend \\non drawing parallels between low and high resource languages (see III.B and III.C) \\n(Nekoto et al., 2020). None of these data sources is representative of a language as a \\nwhole. For example, there is a significant gender gap when it comes to who contributes \\nto Wikipedia, with studies finding that the percentage of women who edit Wikipedia'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='to Wikipedia, with studies finding that the percentage of women who edit Wikipedia \\narticles remains “dismally low” (Callahan & Herring, 2011; Vitulli, 2018), and it \\ndoesn’t reflect a more casual style of speech. Some text on Wikipedia is also machine-\\ntranslated — Cebuano, Swedish, and Waray for instance are some of the Wikipedia \\nlanguages with the most articles, but most are translated by the same bot (Lokhov, \\n2021). The Bible is similarly its own unique domain, unrepresentative of language at \\nlarge, but is overrepresented in the training data for non-English large language models. \\nThis can lead to errors in the tone and substance of language. For example, for a period \\nof time, running a word repeated enough times through Google translate produced a \\nreligious-sounding text: the word “dog” pasted two dozen times and translated from \\nMaori to English produced text about Jesus’ return at the end of days (Christian, 2018).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Maori to English produced text about Jesus’ return at the end of days (Christian, 2018).\\nThe resourcedness of a language is often out of sync with the number of speakers or \\ninternet users that language has. Hindi, Bengali, and Indonesian are medium-resource \\nlanguages yet each has hundreds of millions of speakers (Joshi et al., 2020). Guaraní, \\nan Indigenous language spoken by most of the ~7 million-person population of \\nParaguay, hardly has any data resources at all (Góngora et al., 2021). Fula, a language \\nspoken by tens of millions of West Africans, also has few data sets (Nguer et al., 2020). \\nDespite over 600 million internet users across the African continent, nearly all African \\nlanguages remain low-resourced.\\nTable 1. Categories of language \\nresourcedness. Languages divided into \\ndifferent levels of resourcedness, according \\nto labeled and unlabeled datasets available \\nas of 2020.\\nSource: (Joshi et al., 2020)\\nResourcedness\\nLanguages\\nNumber of Languages\\nNumber of Speakers'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Source: (Joshi et al., 2020)\\nResourcedness\\nLanguages\\nNumber of Languages\\nNumber of Speakers\\nExtremely High Resource\\nEnglish\\n1\\n1.1B\\nHigh Resource\\nArabic, French, Japanese, German, \\nSpanish, Mandarin\\n6\\n2.7B\\nMedium Resource\\nDutch, Vietnamese, Korean, \\nPortuguese, Hindi, Slovak, Hebrew, \\nIndonesian, Afrikaans, Bengali, etc.\\nDozens\\n2.7B\\nLow Resource\\nHaitian Creole, Tigrinya, Swahili, \\nBavarian, Cherokee, Zulu, Burmese, \\nTelugu, Maltese, Amharic, etc.\\nHundreds\\n0.5B\\nExtremely Low Resource\\nDahalo, Warlpiri, Popoloca, \\nWallisian, Bora, etc.\\nThousands\\n1.1B\\nLost in Translation\\n18\\nLarge Language Models in Non-English Content Analysis\\n19\\nMany scholars have worked to try to close this resourcedness gap between high and low \\nresource languages. Individual NLP communities have formed around many languages in \\norder to kickstart and perpetuate the virtuous cycle of research attention and benchmark \\ndevelopment, including collectives such as IndoNLP for languages spoken in Indonesia'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='development, including collectives such as IndoNLP for languages spoken in Indonesia \\nand Masakhane for African languages (Cahyawijaya et al., 2022; Nekoto et al., 2020; Orife \\net al., 2020), and conferences such as the Association for Computational Linguistics’ \\nlow resource language track, and AmericasNLP for indigenous languages (ACL, 2021; \\nAmericasNLP, 2022; Masakhane, n.d.). Tech companies have also sought to expand the \\nnumber of language models their models work in, in part by creating more data sets, \\nincluding with projects like Facebook’s No Language Left Behind project and Google’s \\n1000 Languages Initiative (NLLB Team et al., 2022; Vincent, 2022). DARPA even \\nfunded the Low Resource Languages for Emergent Incidents (LORELEI) program in \\n2014 to improve translation about emergency incidents into low resource languages \\n(Corvey, 2014). But the gaps between English, other high resource languages, and low'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(Corvey, 2014). But the gaps between English, other high resource languages, and low \\nresource languages remain large and are growing exponentially greater by the day, at least \\nin terms of available, raw digitized data.\\nThe response by the NLP community has not just been to collect more language \\ndata but also to employ technical tricks to help language models squeeze the most \\nperformance out of the little data they have. In the next section, we discuss the primary \\ntechnical architecture developers use to do this: multilingual language models.\\nC. Multilingual Language Models: Efforts to \\nBridge the Resourcedness Gap\\nIn English, most large language models are monolingual, meaning that they train mostly \\non data from one language. Researchers have also built monolingual models in non-\\nEnglish languages: for instance, the architecture for Google’s BERT model — one of \\nthe most popular and cheapest to train — has been utilized for French (CamemBERT),'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='the most popular and cheapest to train — has been utilized for French (CamemBERT), \\nItalian (AlBERTo), Arabic (AraBERT), Dutch (BERTje), Basque (BERTeus), Maltese \\n(BERTu), and Swahili (SwahBERT), to name a few (Agerri et al., 2020; Antoun et al., \\n2020; de Vries et al., 2019; G. Martin et al., 2022; L. Martin et al., 2020; Micallef et al., \\n2022; Polignano et al., 2019). However, in general, these monolingual models perform \\nworse in their respective languages than the best English models do in English because \\nthey don’t have as much data to train on.\\nThis lack of data manifests in different ways depending on the specific task a model is \\nfine-tuned to perform. Some language model capabilities — usually ones that depend \\non fact retrieval — improve linearly with size. For instance, the more data a language \\nmodel is exposed to, the better it is at answering trivia questions or reformatting \\ndata (Srivastava et al., 2022). Other capabilities — usually ones with multiple steps'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='data (Srivastava et al., 2022). Other capabilities — usually ones with multiple steps \\nI. Background\\nLost in Translation\\nCDT Research\\n20\\nor components — exhibit a “breakthrough” behavior, where once a model reaches a \\ncertain size, it improves sharply at the task. For instance, language models typically are \\nunable to write code or add three digit numbers until they train on a certain amount \\nof data, at which point their performance improves dramatically (Ganguli et al., 2022). \\nLow and extremely low resource languages often do not have enough data to train a \\nlarge language model at all, but medium and even high resource languages may not \\nhave the hundreds of millions, or billions of words of text data necessary to achieve the \\nbreakthroughs that English can (Y. Zhang et al., 2021).\\nBesides technical limitations, companies may not be interested in deploying a different \\nmonolingual model for every language their product is available in for business reasons'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='monolingual model for every language their product is available in for business reasons \\nas well. Maintaining and debugging one large language model for each language \\nintroduces costs that scale per language introduced, introducing complexity and \\nadditional overhead costs. Companies that seek to expand into new global markets \\nwill likely try to keep their costs fixed by reusing as much infrastructure as possible, \\nincluding language models.\\nTherefore, instead of using monolingual models to do NLP tasks in non-English \\nlanguages, researchers and developers most often use multilingual language models, \\nsuch as Google’s mBERT and Meta’s XLM-R, which are trained on texts from \\nmany different languages at once. Like their monolingual counterparts, multilingual \\nlanguage models are trained on a fill-in-the-blank task. However, by training on text \\nfrom several different languages, multilingual language models can, at least in theory,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from several different languages, multilingual language models can, at least in theory, \\ninfer connections between languages, acting as a sort of bridge between high and low \\nresource languages, allowing the former to bootstrap the latter.\\nFor instance, imagine that an Indian climate change researcher wants to use a language \\nmodel to collect all Hindi-language tweets about the weather. A monolingual language \\nmodel trained on just Hindi text may not have enough data to have seen the words \\n“thaand” (“cold” in Hindi) and “shaal” or (“shawl” in Hindi) appear near one another \\nin text, so it may miss that tweets to the effect of “Main Agast mein shaal pahanta \\nhoon” (“I put a shawl on in August”) is a sentence about cold weather.1 A multilingual \\nmodel, trained on data from English, Hindi, and many other languages may have seen \\ntext where “thaand” appears near “cold,” “shaal” appears near “shawl,” and “cold”'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='text where “thaand” appears near “cold,” “shaal” appears near “shawl,” and “cold” \\nappears near “shawl,” thereby allowing the model to infer that “thaand” and “shaal” are \\ninterrelated terms.\\nMultilingual language models are usually not trained on equal volumes of data from \\neach language: mBERT for instance is trained on 15.5 GB of English text but as little \\nas 10 MB of Yoruba text (Wu & Dredze, 2020). Even BLOOM, a popular multilingual \\nmodel by BigScience with a particular focus on language representation, has 30% of its \\n1\\t  Transliterated into Roman script for ease of reading for an English-language reader.\\nLarge Language Models in Non-English Content Analysis\\n21\\nFigure 3. Monolingual vs multilingual \\nlanguage model representation \\nspace. A visualization of a monolingual \\nand a multilingual langauge model’s \\nrepresentation space, collapsed into three \\ndimensions.\\nSource: (Schwenk, 2019) \\ntraining text in English (BigScience Workshop et al., 2023). In large part, this is because'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='training text in English (BigScience Workshop et al., 2023). In large part, this is because \\nof the lack of available data in these languages, which come disproportionately from \\nWikipedia and religious texts, as discussed earlier (see Part I.C).\\nJust as a monolingual language model can be fine-tuned to work better on an individual \\ntask, a multilingual language model can be fine-tuned to work better in an individual \\nlanguage. Imagine for instance a developer who wants to use a multilingual language \\nmodel to detect Indonesian election disinformation on social media. One way they \\ncould do it is by using an out-of-the-box multilingual model, such as BLOOM, and \\nfine-tuning it by showing examples of false narratives circulated in Indonesian related \\nto the local election. This likely would not work very well though, since BLOOM has \\nonly been exposed to a limited amount of data on Indonesian text —\\xa0only 1.2% of its'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='only been exposed to a limited amount of data on Indonesian text —\\xa0only 1.2% of its \\ntraining data is in Indonesian (BigScience Workshop et al., 2023). Another better way \\nto do it, if the developer has access to more Indonesian language data, would be first to \\nfine-tune the model on additional Indonesian text (essentially, continuing to learn the \\nfill-in-the-missing-word task, but this time just in Indonesian) and then further fine-\\ntuning it on the task election disinfo detection using that dataset.\\nModel developers though do not always have enough text data to sufficiently fine-\\ntune a multilingual model to work in a specific language. To make up for this, they \\noften use imperfect machine-translated text. The two main methods of incorporating \\ntranslated text are called translate-train or translate-test methods. With translate-train, \\na multilingual language model is fine-tuned on data that has been translated from'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='a multilingual language model is fine-tuned on data that has been translated from \\n(usually) English into a desired lower resource language (Conneau & Lample, 2019). \\nWith translate-test, a (usually) English monolingual language model is fine-tuned \\non data translated from the desired language into English, and all testing data gets \\ntranslated into English as well (Artetxe, Labaka, et al., 2020).\\nI. Background\\n21\\nThe tree is green.\\nThe tree is green.\\nEl árbol es verde.\\nMonolingual model\\nIt is cold today.\\nMultlingual model\\nI put on a shawl.\\nI like to sing. \\nI like to sing. \\nJ’aime chanter. \\nAaj bohut thaand hai.\\nMain ek shaal pahanta hoon.\\nI put on a shawl.\\nIt is cold today.\\nLost in Translation\\nCDT Research\\n22\\nImagine, for example, a developer building a language model to detect terrorist content \\nin the Basque language with a handful of examples of terrorist content in Basque \\nbut not enough Basque text data to properly fine-tune a language model. With the'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='but not enough Basque text data to properly fine-tune a language model. With the \\ntranslate-train approach, a developer would take a large volume of English text data, \\nmachine translate it into Basque, use that data to fine-tune a pretrained multilingual \\nlanguage model, and then further fine-tune it to the task of terrorist content detection \\nusing the native Basque data. With translate-test, a developer would fine-tune a \\npretrained English language model on data translated from Basque to English, and \\nthen further fine-tune it by translating the terrorist content data they have into English. \\nSubsequently, to analyze Basque text, it would first have to be translated into English \\nbefore being evaluated by the model. Reliance on translated data raises many concerns, \\nas discussed in Part II.C.1.\\nHowever, translated texts can help multilingual language models learn connections \\nbetween languages. By feeding a model parallel texts — for instance, explicitly'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='between languages. By feeding a model parallel texts — for instance, explicitly \\ninforming it that “baahar bohut thand hai” and “It’s so cold outside” have the same \\nmeaning — it can better extrapolate other language parallels as well (e.g. NLLB Team et \\nal., 2022; Reid & Artetxe, 2022). Multilingual language models can learn connections \\nbetween languages without explicit labeling, instead inferring relationships between \\nlanguages on its own through borrowed words, numbers, and URLs (Pires et al., 2019). \\nIn general, NLP researchers understand little about why it is that multilingual language \\nmodels can be effectively fine-tuned to work in languages that they have relatively little \\ndata for (Conneau, Khandelwal, et al., 2020; Pires et al., 2019; Wu & Dredze, 2019). \\nSome argue that it is because multilingual language models have inferred language-\\nagnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='agnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder, \\net al., 2020; Chi et al., 2020; Conneau, Wu, et al., 2020; Tsvetkov et al., 2016). Others \\nsay that multilingual language models are just effective imitators (Bender et al., 2021; \\nLauscher et al., 2020). The debate is impossible to fully resolve because of the overall \\ncomplexity and opacity of large language models, but so far evidence suggests that at \\nbest, the linguistic universals they learn are limited to narrow semantic and syntactic \\ndomains (Libovický et al., 2019; Wu & Dredze, 2019), such as learning plural/singular \\nverb agreement across multiple languages (de Varda & Marelli, 2023). But even if a model \\ncan infer syntactic or semantic commonalities between languages, such inferences will \\nnot necessarily help it manage more complex, context-dependent tasks (Choi et al., 2021). \\nFor instance, in some languages, multilingual language models do no better than random'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='For instance, in some languages, multilingual language models do no better than random \\nguessing at detecting hate speech (Lin et al., 2022). As will be discussed in the next section, \\nthese are hardly the only limits of multilingual language models.\\n23\\nLost in Translation\\nII. Limitations of \\nLanguage Models \\nin English and Non-\\nEnglish Contexts T\\nhe press, technology companies, and social media are abuzz \\nabout the potential of large language models. In this section, \\nhowever, we discuss the shortcomings of these models, \\nparticularly as they operate in non-English language contexts. \\nIn the first section, we discuss general concerns with building and \\ndeploying large language models. These concerns apply both to the \\nEnglish and non-English contexts. In the second section, we look at the \\nproblems more specifically raised by multilingual language models.\\nA. Concerns with Building and \\nDeploying Large Language Models\\n1. LARGE LANGUAGE MODELS ARE BOUND BY'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Deploying Large Language Models\\n1. LARGE LANGUAGE MODELS ARE BOUND BY \\nLANGUAGE THEY HAVE SEEN BEFORE AND STRUGGLE \\nTO PERFORM IN NEW CONTEXTS.\\nA large language model does not understand language; instead, it makes \\nprobabilistic inferences about text based on the distribution of language \\nwithin the data it is trained on. Bender and Koller argue that this means \\nlanguage models are limited to contexts they have encountered before \\nand struggle greatly in those they have not (2020). NLP researchers have \\nalready proven this is the case in generative AI by demonstrating several \\nunintuitive outcomes: for instance, language models are better able to \\nperform mathematical operations with numbers that appear frequently \\nin written language (e.g., multiplying numbers by 24), than numbers \\nthat appear infrequently (e.g. multiplying numbers by 23) (Razeghi \\net al., 2022). Large language models may exhibit similar limitations in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='et al., 2022). Large language models may exhibit similar limitations in \\ncontent analysis as well. For instance, if a large language model were \\nused to analyze a candidate’s resume, it may struggle to account for \\nlesser-known companies or newer skill sets without up-to-date, domain-\\nspecific data to fine-tune on. These tasks are reliant on in-context \\nknowledge and without domain-specific training, i.e. training an off-\\nthe-shelf large language model with text relevant to the task at hand, \\nthese models are likely to perform poorly and their purported domain-\\nagnostic abilities should garner skepticism (Duarte et al., 2017). \\nLost in Translation\\nCDT Research\\n24\\n2. LARGE LANGUAGE MODELS REPRODUCE THE BIASES, VALUES, \\nAND HARMS OF THE DATA THEY TRAIN ON.\\nLarge language models are built using vast quantities of text scraped from the internet \\nand exhibit all the biases and limitations of their data source (Okerlund et al., 2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and exhibit all the biases and limitations of their data source (Okerlund et al., 2022). \\nSome commonly used datasets, such as Common Crawl, include large volumes of \\nhate speech and sexually explicit content (Luccioni & Viviano, 2021). Other problems \\nare more nefarious. For example, researchers found that when GPT-3 generated \\ncompletions for the prompt “Two Muslims walked into a___,” 66% of completions \\nincluded violent language, three times more than for other religious groups (Abid et \\nal., 2021). Others have found similar entrenched biases against people with disabilities, \\nfor example inferring negative sentiment from sentences that include disability-related \\nterms (Hutchinson et al., 2020).\\nThough technologists often try to pull out explicitly harmful data from training \\nsets, models can still reify harms, such as referring to “women doctors” or calling \\nundocumented immigrants “illegals” (Bender et al., 2021). Removing these instances'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='undocumented immigrants “illegals” (Bender et al., 2021). Removing these instances \\nof harmful data from training datasets, which are disproportionately outsourced \\nto underpaid staff around the world, also imposes labor and psychological burdens \\n(Williams et al., 2022). \\nEven if datasets are rid of specific examples of harmful text, they will nonetheless \\ncontain values and assumptions that are encoded into the language we speak and the \\ndominant perspectives that exist in many pieces of written text, particularly government \\ndocuments or state-run media pieces that may make up the bulk of text available for \\nlow resource languages (Bender et al., 2021). Many machine learning researchers fail to \\nconsider these problems in their work — one study found that 98% of machine learning \\npapers mention no negative potential of the technologies they are describing (Birhane \\net al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, “Feeding AI systems'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='et al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, “Feeding AI systems \\non the world’s beauty, ugliness, and cruelty, but expecting it to reflect only the beauty \\nis a fantasy” (2021). When these problems exist in any particularly popular foundation \\nmodel, they proliferate across many different applications built on top of that model.\\n3. THE DATA LARGE LANGUAGE MODELS TRAIN ON RAISE \\nCOPYRIGHT AND PRIVACY CONCERNS.\\nLegal experts also raise concerns about copyright and ownership of text that make up \\nthe vast quantities of data that train and distinguish large models (Ebers et al., 2022; \\nOkerlund et al., 2022). Getty Images has sued the creators of Stable Diffusion, an AI \\ntool that creates images based on written prompts, claiming that the toolscraped Getty’s \\ndatabases of proprietary images and photos without permission (Vincent, 2023a). Legal \\nquestions about ownership of text and whether scraping proprietary text is lawful (e.g.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='questions about ownership of text and whether scraping proprietary text is lawful (e.g., \\nbecause it constitutes fair use) or not remain unanswered (Kublik, n.d.).\\nLarge Language Models in Non-English Content Analysis\\n25\\nII. Limitations of Language Models in English and Non-English Contexts\\nSome datasets that large language models train on are likely to capture examples of \\nlanguage from sites such as social media, raising personal data privacy concerns. There \\nis a high possibility that in gathering exchanges from social media networks, training \\ndatasets inadvertently contain private and even sensitive information, which increases \\nthe risk of models leaking details like names, phone numbers, or addresses from the data \\non which they’re trained (Carlini et al., 2021, 2023).\\n4. TRAINING LARGE LANGUAGE MODELS COULD HAVE A \\nSIGNIFICANT ENVIRONMENTAL IMPACT.\\nFinally, there are increasing concerns about the environmental cost of producing large'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Finally, there are increasing concerns about the environmental cost of producing large \\nlanguage models. Scholars and advocates have raised concerns about the environmental \\nimpact of training these models, particularly the largest ones with billions of \\nparameters, due to their intense computation requirements (Crawford, 2021; Okerlund \\net al., 2022). There is preliminary research attempting to quantify the energy impacts \\nof computation at this scale (Kaack et al., 2022), but some early estimates suggest that \\ntraining a single BERT model, one that serves as the foundation for some multilingual \\nlanguage models, requires as much energy as a trans-American flight (Strubell et al., \\n2019). Large language models, like GPT-3, require thousands of times more (Heikkilä, \\n2022). Png writes that these costs may be concentrated in poorer countries, where \\nserver farms and raw materials required to build necessary infrastructure are often \\nlocated (2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='located (2022).\\nB. Limitations of Multilingual Language Models\\n1. MULTILINGUAL LANGUAGE MODELS OFTEN RELY ON MACHINE-\\nTRANSLATED TEXT THAT CAN CONTAIN ERRORS OR TERMS NATIVE \\nLANGUAGE SPEAKERS DON’T ACTUALLY USE.\\nIncorporating machine-translated data into the training and fine-tuning of multilingual \\nlanguage models creates various opportunities for the model to malfunction. \\nMultilingual language models that depend on translation may struggle to build \\naccurate representations of words or concepts which have different connotations in \\ndifferent languages. For instance, in English, “dove” is a term associated with peace, but \\nits equivalent in Basque, “uso,” is an emasculating insult. A translation-based cross-\\nlingual model that does not train on the word “uso” used in its native context could \\npotentially fail to see it used in a call for violence since the English mapping is so closely \\nassociated with “peace.”\\nLost in Translation\\nCDT Research\\n26'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='associated with “peace.”\\nLost in Translation\\nCDT Research\\n26\\nAnother issue is what NLP practitioners call the “translationese” problem (Yu et al., \\n2022) — that is, machine-translated language materially differs from how human \\nnative speakers naturally use language (Bizzoni et al., 2020; Teich, 2003). In generative \\nAI, translationese can result in mono- or multilingual language models simplifying \\nor overcomplicating sentences, producing repeated words, using too common or too \\nuncommon words, borrowing too much or too little from the original language, and \\nother patterns of speech native speakers would not use (Volansky et al., 2015). These \\nmistakes are not consistent between languages or systems, so it would be difficult for \\nmodels to be able to systematically root them out, though some argue that it is possible \\n(Yu et al., 2022).\\nThe problems of machine translation spread beyond models that intentionally train on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='The problems of machine translation spread beyond models that intentionally train on \\nit. The web is filled with machine-translated text, and models that train on web-scraped \\ndata will inadvertently encounter a lot of it, particularly in low resource languages \\n(Kreutzer et al., 2022). For instance, a lot of the Catalan data that exists on the web, \\nparticularly on websites using the .cat top-level domain, is translated using Google \\nTranslate, even on official government websites (Pym et al., 2022). Even benchmarks to \\ntest how well multilingual language models work in high and low resource languages are \\noften translated from another language, leaving researchers with less of a sense of how \\nwell these models work on language as spoken by native speakers. For instance, OpenAI \\ntested GPT-4’s capabilities in 26 languages, but using only benchmarks translated from \\nEnglish (OpenAI, 2023).\\n2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE \\nCONTEXTS OF LOCAL LANGUAGE SPEAKERS.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE \\nCONTEXTS OF LOCAL LANGUAGE SPEAKERS.\\nAs discussed earlier, large language models only work well in contexts similar to \\ncontexts of the data they are trained on. A language model trained on legal texts, \\nfor instance, will perform much better on law-related tasks than medical tasks \\nor interpreting the Quran (Koehn & Knowles, 2017). This poses a problem for \\nmultilingual language models, which, particularly in low resource languages, are trained \\non text that is translated from other language contexts or comes from a few distinctive \\ncontexts, such as Wikipedia and the Bible. Multilingual language models that are not \\ntrained on large volumes of text from native speakers of a given language will more \\noften fail at tasks that require knowledge of an individual speaker’s local context, such \\nas hate speech detection and resume scanning (Lin et al., 2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='as hate speech detection and resume scanning (Lin et al., 2022).\\nImagine, for example, a multilingual language model fine-tuned to detect anti-\\nMuslim content in Assamese, a low-resource language with fifteen million speakers, \\npredominantly in northeast India (Ethnologue, 2023a). Assamese and Bengali are both \\nmedium resource languages, so a multilingual model may draw connections between \\nthe two. However, anti-Muslim hate speech is very closely tied to historical events and \\nthe specific political conditions of Assam. For instance, the term “Bangladeshi Muslim,” \\nLarge Language Models in Non-English Content Analysis\\n27\\nII. Limitations of Language Models in English and Non-English Contexts\\nneutral in many other languages and contexts, is a hate speech dog whistle in Assamese \\nbecause it casts Assamese Muslims as foreigners (a concept that is itself closely tied to the \\nIndian government’s repatriation efforts) (Avaaz, 2019). A multilingual model neither'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Indian government’s repatriation efforts) (Avaaz, 2019). A multilingual model neither \\ntrained on extensive native Assamese text nor explicitly trained by a language expert would \\nlikely not be able to capture this hyperlocal distinction.\\nMultilingual language models work by transferring between language contexts, but that \\ntransfer often means simply that the context of higher resource languages overwrites \\nlower resource ones. Spanish, for instance, tends to use more adjectives and analogies \\ndescribing extreme situations than English, so a sentiment detection algorithm that \\ntransfers linguistic properties over from English may mischaracterize Spanish text as \\nhaving a stronger emotional valence than it would to a native speaker (Stadthagen-\\nGonzalez et al., 2017). This structure transfer can also bring the biases of a source \\nlanguage into a target language (Savoldi et al., 2021). For instance, if a language without'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='language into a target language (Savoldi et al., 2021). For instance, if a language without \\ngender pronouns, such as Hungarian or Yoruba, is mapped onto a language with \\ngendered third-person pronouns, such as English or French, the language model could \\nforce gender associations and biases of the gendered language onto the non-gendered \\none, as often occurs in translation (Prates et al., 2020) (see Figure 4).\\nFigure 4. Google Translate from \\nHungarian to English. A screenshot of \\nGoogle Translate, circa 2020, showing how \\nthe multilingual language models project \\ngender onto genderless languages.\\nSource: (Prates et al., 2020)\\n27\\nLost in Translation\\nCDT Research\\n28\\n3. MULTILINGUAL LANGUAGE MODELS DO NOT AND CANNOT WORK \\nEQUALLY WELL IN ALL LANGUAGES.\\nMultilingual language models not only do not work equally well in all languages but \\nthey cannot, since the more languages a multilingual model is trained on, the less it'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='they cannot, since the more languages a multilingual model is trained on, the less it \\ncan capture unique traits of any specific languages. This problem is called the curse \\nof multilinguality (Lauscher et al., 2020). Large language model developers are thus \\nforced to trade off performance between disparate languages; making a model work \\nbetter in Hindi for example, may come at a cost to its performance in English. In \\npractice, when technology companies must choose which languages to deprioritize \\nwithin their multilingual language models, they may be incentivized to have them \\nbe languages where speakers tend to be less wealthy, have less political power, or live \\noutside of the company’s priority markets, thus exacerbating the resourcedness gap they \\nare designed to address.\\nIn general, semantic and syntactic similarity to a high resource language protects \\nfrom the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al. \\ntested mBERT on languages it had not explicitly trained on before and found that it \\nworked better in Swiss German (related to German, a high resource language), than \\nit did in Estonian (a Uralic language, like medium resource languages Hungarian and \\nFinnish), than it does Uyghur (a Turkic language, distant from any high or medium \\nresource language, with four alphabets) (2021). In general, multilingual language \\nmodels struggle with languages written in non-Latin scripts (Pires et al., 2019; Ruder \\net al., 2021), language isolates (languages etymologically distinct from all other \\nlanguages, such as Basque), and families of languages less connected to those of high \\nresource languages. This threatens to create a poor-get-poorer dynamic for languages \\nthat are only similar to other low resource languages, as is the case with many widely'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='that are only similar to other low resource languages, as is the case with many widely \\nspoken African languages including Swahili, Amharic, and Kabyle (Joshi et al., 2020). \\nThis dynamic further strengthens the post-colonial structural inequality discussed \\nthroughout this report.\\nMultilingual language models are also forced to trade off between languages in the \\nvocabulary they use. Large language models train on the problem of predicting the next \\nword in a sentence. If a model is trying to guess the word to fill in “Today I feel ___,” it \\nwill have a harder time doing so if it has to choose between ten million possible words \\nfrom any language instead of just a few hundred thousand English words. The total \\nnumber of words a language model has to choose from is called its vocabulary size. The \\nlarger a model’s vocabulary size, the more different possible words it can generate and \\nrecognize, but also the more computational resources it takes to train. Multilingual'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='recognize, but also the more computational resources it takes to train. Multilingual \\nlanguage models use all kinds of shortcuts to get their vocabulary size down. For instance, \\nLarge Language Models in Non-English Content Analysis\\n29\\nthey will often transliterate languages into Latin scripts or train the model to guess the \\nnext subword (e.g. breaking “tasks” into “ta” and “##sks”) or letter instead of the full \\nword, thus collapsing the barrier between languages (Tay et al., 2022; C. Wang et al., \\n2020). These shortcuts cut down on costs, but they also reduce a model’s ability to \\ncapture semantic relationships between words, thus degrading its performance overall.\\nVocabulary is often decided by how frequently different words, subwords, and \\nletters appear in a model’s training text, and since multilingual language models are \\ntrained mostly on English data, their vocabularies will skew towards English as well.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='trained mostly on English data, their vocabularies will skew towards English as well. \\nA multilingual model may have a relatively obscure word like “riposte” in its English \\nvocabulary, but be may missing common words in other high resource languages (e.g., \\n“escritorio” in Spanish), common subwords in medium resource languages, (e.g., “tzv” \\nin Hebrew), and entire letters in low resource languages (e.g., a character that appears in \\nTigrinya but not other Ge’ez-based scripts). This inferior representation makes models \\nperform worse in a variety of tasks, and makes content analysis systems far easier to trick \\nby doing things like changing white space, using typos, or in the case of toxic content \\ndetection, adding common, positive words like “love” (Gröndahl et al., 2018; Lees et al., \\n2022).\\n4. WHEN MULTILINGUAL LANGUAGE MODELS FAIL, THEIR \\nPROBLEMS ARE HARD TO IDENTIFY, DIAGNOSE, AND FIX.\\nNLP practitioners depend on benchmarks to determine both how well a language'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='NLP practitioners depend on benchmarks to determine both how well a language \\nmodel performs at specific tasks and how close it is in general to achieving “natural \\nlanguage understanding” (Bender & Koller, 2020). This latter type of benchmarking \\nis very difficult in all languages, since it is hard to generalize about a language model’s \\ncapabilities from only a handful of disparate tests (Raji et al., 2021). However, the \\nchallenges of both types of benchmarks are exacerbated in the multilingual context. \\nThe disparities in NLP research attention and labeled data between languages mean \\nthat there are far more benchmarks and tasks that can be used to test models in English \\nthan in other languages, particularly low resource ones. Models developed to operate in \\nnon-English contexts are still usually tested with benchmarks translated from English \\nwhich, as discussed earlier, is often markedly different from the target language.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='which, as discussed earlier, is often markedly different from the target language.\\nThe alternative to translation is hiring people local to the contexts a model is being \\napplied to and paying them to create data sets and develop benchmarks. This works \\nparticularly well for models built to do a specific task in a specific language (Nguyen, \\n2020; Tattle, n.d.), but is very expensive and resource intensive to scale up for models \\nmeant to work in many languages and contexts. It also raises challenging questions \\nfor detecting bias in language models (Talat et al., 2022) and performing inherently \\nII. Limitations of Language Models in English and Non-English Contexts\\nLost in Translation\\nCDT Research\\n30\\npolitical tasks, such as content moderation. For instance, a social media company trying \\nto create a dataset of inflammatory content posted in Bosnia and Herzegovina needs \\npeople who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='people who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian, \\nMontenegrin, and Macedonian) but also unbiased in those conflicts, all in a country \\nthat lacks media pluralism or a strong civil society sector (Article 19, 2022). Scaling this \\nto every geopolitical problem discussed in all languages on a given online service is a \\ndaunting, if not impossible, task.\\nWhen problems with multilingual language models can be found, it is often difficult \\nto determine why they are occurring. Large language models are already opaque, even \\nto those who develop them — neural networks, the core technology underlying large \\nlanguage models, are known for being particularly obtuse and for representing language \\nin a way that doesn’t map cleanly onto human-understandable concepts (Nicholas, \\n2020). However, multilingual language models are particularly opaque because they \\nmake unintuitive, hard-to-trace connections between languages. Take for instance,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='make unintuitive, hard-to-trace connections between languages. Take for instance, \\nthis case from an NLP paper: the Google researchers behind the Perspective API, a \\nmodel for detecting “toxic” content, found that their model flagged tweets that used \\nthe Italian word “sfiga” (which roughly translates to “bad luck”) as hate speech because \\ntwo of the three examples included in the training dataset that contained the subword \\n“sfiga” were labeled as hate speech (“sfigati” is an insult meaning “loser”) (Lees et \\nal., 2020). If this were a multilingual model that had mapped Italian learnings onto \\nTurkish analysis, perhaps sentences with the equivalent Turkish word for “unlucky” \\n(“şanssız”) would also be flagged as hate speech. Even if researchers had access to all the \\ndata used to train that multilingual model, it would be extremely difficult to locate and \\nfix this bug without knowing Italian or understanding how the model had mapped \\nthese relationships.\\n31\\nLost in Translation'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these relationships.\\n31\\nLost in Translation\\nIII. Recommendations E\\nfforts to improve language models’ performance in various \\nlanguages and contexts are exciting, as they may boost \\nconnectivity and information exchange for billions of users \\naround the world. However, language models are limited in their \\ncapabilities, and employing them too widely, without safeguards, or for \\nthe wrong kinds of tasks has the potential to raise civil liberties concerns \\nand erect new barriers (Maundu, 2023). Unthinking deployment \\nof large language models may impede peoples’ ability to access \\ninformation, employment, and public benefits, with disparate impacts \\nfor individuals in the Global South where many of the low resource \\nlanguages are spoken. We should be cautious about the rapid adoption \\nof these technologies, especially as building blocks for other types of \\nautomation in high-stakes arenas like content moderation, employment \\nsoftware, and resource allocation.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='software, and resource allocation.\\nIn this section, we offer recommendations for companies, researchers, and \\ngovernments to take into consideration as they build, study, and regulate \\nlarge language models, particularly in non-English language contexts.\\nA. Companies\\nTECHNOLOGY COMPANIES SHOULD DISCLOSE WHEN, \\nHOW, AND IN WHAT LANGUAGES THEY USE LARGE \\nLANGUAGE MODELS.\\nTo better understand the problems and challenges with deploying large \\nlanguage models in different languages, researchers and the public need \\nto know where to look. Companies that incorporate language models \\ninto their technical systems should always disclose how they are using \\nthem, which languages they are using them in, and what languages they \\nhave been trained on. Currently, the approach of many companies to AI \\ntransparency consists of trumpeting the capabilities of their AI systems \\nin blog posts and press releases, and, for a few larger firms, releasing'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='in blog posts and press releases, and, for a few larger firms, releasing \\nresearch versions of their language models that still differ from the ones \\nthey use in production. Despite publishing on AI and pushing the field \\nforward, technology companies tend to hold information about their \\nproduction AI systems, even basic information about what languages \\nthey are used in, close to the chest.\\nLost in Translation\\nCDT Research\\n32\\nAcademics and civil society have written extensively about how technology companies, \\nparticularly online service providers, could offer better transparency and accountability \\nfor their AI systems, including language models. The Santa Clara Principles, a set of \\nprinciples developed and revised by global civil society groups, provides examples of \\nthe types of disclosures companies can make about their content moderation policies \\nand processes (2021). Groups like BigScience also pave the way, exemplifying the type'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and processes (2021). Groups like BigScience also pave the way, exemplifying the type \\nof documentation other model-developers can publish about their content analysis \\nsystems, including model cards, transparency reports, and other avenues to disclose \\nmore information about the linguistic makeup of a model’s training data (e.g. what \\nlanguages it has trained on, how much data from each language, where those datasets \\ncome from). Better transparency creates opportunities for external actors to more \\nimmediately identify potential risks and impacts on users and for technology companies \\nto mitigate the potential dangers of deploying large language models in English and \\nnon-English contexts.\\nWHEN DEPLOYED, LARGE LANGUAGE MODELS SHOULD BE \\nACCOMPANIED BY ADEQUATE REMEDIAL CHANNELS AND \\nMECHANISMS THAT ENSURE INDIVIDUALS CAN APPEAL OUTCOMES \\nAND DECISIONS MADE BY THESE SYSTEMS.\\nBecause of the complexities of human speech and the error-prone nature of automated'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Because of the complexities of human speech and the error-prone nature of automated \\ntools, decision-making systems built on top of large language models should be used \\nwithin narrow remits and with adequate remedial channels for users encountering \\nthem. Those remedial channels and processes should have human reviewers with \\nthe same language proficiencies that their systems are deployed in. Language- and \\ncontext-specific remedial channels are particularly important for allowing users to \\nappeal decisions made by online services, especially when those decisions either restrict \\ntheir expression or access to information or fundamentally determine their access \\nto economic or social rights like the right to housing, education, and social security \\n(United Nations Human Rights Office of the High Commissioner, n.d.).\\nTechnology companies can also offer accountability at a system level, not just the \\nlevel of individual decisions. One way to do this is to conduct and publish human'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='level of individual decisions. One way to do this is to conduct and publish human \\nrights impact assessments at the different phases of the language model’s life cycle \\n— development, testing, deployment, and evaluation (Prabhakaran et al., 2022). \\nPublishing human rights impact assessments will also aid in other actors’ decisions \\nwhen procuring these systems to conduct tasks in different domains and contexts. In \\nparticular, these human rights impact assessments should consider the disparate risks \\nto different language speakers in advance of a model being deployed in those languages. \\nOnline service providers can provide transparency by disclosing the systems and \\nlanguages they use large language models in. \\nLarge Language Models in Non-English Content Analysis\\n33\\nIII. Recommendations\\nCOMPANIES SHOULD INVEST IN IMPROVING LANGUAGE MODEL \\nPERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN \\nLANGUAGE AND CONTEXT EXPERTS.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='PERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN \\nLANGUAGE AND CONTEXT EXPERTS.\\nRecently, an arms race has begun between Google and Meta to see who can include \\nmore languages in their multilingual language model. Meta’s “No Language Left \\nBehind” initiative trained a model on over 200 languages (NLLB Team et al., 2022); \\nmonths later, Google one upped Meta with its “1,000 Languages Initiative” (Vincent, \\n2022). This race puts a premium on the number of languages the model trains on, \\nrather than how well it works in each language. In particular, it is unclear how these \\nmodels will handle the “curse of multilinguality,” where, as explained in II.B.3, the \\nmore languages a model trains on, the less it can capture the idiosyncrasies of each \\nlanguage. It is also unclear how these companies define a model “working” in any of \\nthese languages.\\nCompanies building large language models should not just focus on the number of'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these languages.\\nCompanies building large language models should not just focus on the number of \\nlanguages their model is trained on but the quality of its performance in each language. \\nIn part, that means better benchmarks, but benchmarks can only go so far. To evaluate \\nthe full range of potential applications and pitfalls that could come with applying a \\nlanguage model in a specific language context, it is necessary to involve language experts, \\ncivil society, local experts, heritage and language preservation advocates, linguists, and \\nhuman rights experts. These actors are crucial to ensuring that labeled training datasets \\nadequately capture the nuances and variations of a given language. Many organizations \\nare already doing this type of work. Uli is an example of this, where two India-based \\nnonprofit organizations — Tattle and Centre for Internet & Society — convened a \\nrange of gender, gender-based violence, communal violence, and other language experts'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='range of gender, gender-based violence, communal violence, and other language experts \\nto annotate training datasets in Indian English, Tamil, and Hindi to build a tool capable \\nof parsing sentiment and toxicity on Twitter. Other researchers have also pointed to \\nusing annotators to label training datasets as a way to equip models with the ability to \\nparse variations in the speech of a certain language (Bergman & Diab, 2022; Nkemelu \\net al., 2022). \\nB. Researchers and Funders\\nRESEARCH FUNDERS SHOULD INVEST IN SPECIFIC NLP LANGUAGE \\nCOMMUNITIES TO KICKSTART THE VIRTUOUS CYCLE OF \\nDEVELOPMENT.\\nDeveloping NLP capabilities in any language is a cyclical process, and for high resource \\nlanguages — particularly English —\\xa0that cycle is virtuous. When a language has lots \\nof clean, human-annotated datasets, researchers and developers are better equipped \\nto build models and benchmarks to test models in that language. More models and \\nLost in Translation\\nCDT Research\\n34'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Lost in Translation\\nCDT Research\\n34\\nbenchmarks lead to more publications, conferences, and real-world use cases. And \\nfinally, increased demand for research and software in a language drives demand for \\nmore datasets. For low resource languages, however, the virtuous cycle is hard to \\nkickstart. Without tools, annotators, and financial investment earmarked for different \\nlanguage communities, NLP researchers cannot create the datasets needed to build \\nmodels or benchmarks, and even if they could, they face difficulties publishing or \\ngetting attention for their work in popular journals and conferences. The most \\nprestigious NLP publications focus disproportionately on English; languages without \\ntheir own self-sustaining NLP communities end up to a handful of specialized outlets.\\nInvestments into non-English NLP should particularly focus on creating self-sustaining \\nscholarly NLP communities, and doing this requires investing in all levels at once. The'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='scholarly NLP communities, and doing this requires investing in all levels at once. The \\ngroups that are best set up to properly allocate these investments are the language- and \\ngeography-specific NLP research communities that have cropped up over the years, \\nsuch as such as Masakhane, AmericasNLP, ARBML, and others who can convene \\npractitioners around common goals to advance the field (Alyafeai & Al-Shaibani, 2020; \\nAmericasNLP, 2022; Orife et al., 2020). These communities know what kind of data \\nsets should be built, which community actors are needed to properly vet them, and \\nwhat kind of competitions and conferences should be run to keep the virtuous cycles \\ngoing. One model for how this can work is exemplified by EVALITA, an event hosted \\nby the Italian Association for Computational Linguistics. In it, researchers first submit \\ndata sets for new language tasks, such as identifying misogyny or dating documents.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='data sets for new language tasks, such as identifying misogyny or dating documents. \\nThen, researchers compete to train models to perform those tasks the best. Finally, \\nthose results get published, thus generating interest and attention toward Italian NLP \\nand ensuring researchers continue to build tools for the language (Basile et al., 2020).\\nPrivate companies can contribute not only by financially supporting these efforts \\nbut by sharing more of the non-English datasets they use to train their large language \\nmodels, both for transparency and to support research. Large tech companies have \\nalready shared the code for training many of their multilingual language models \\n— Meta’s XLM-R and Google’s mBERT are the subjects of most multilingual \\nmodel research in publication — and disclosed the data they train them on — \\nCommonCrawl, and\\xa0Wikipedia and BooksCorpus, respectively. However, the models \\nthat Google, Meta, OpenAI, and other large companies use in their products train on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='that Google, Meta, OpenAI, and other large companies use in their products train on \\nother, proprietary, language data. Companies should share more of their training data, \\nboth for public accountability and to bolster research.\\nLarge language models have by and large been built by private companies, but private \\nincentives may be at odds with developing these models in safe and equitable ways. \\nGovernment investment into non-English large language model research could lead \\nto improvements in areas private companies may be underinvesting in (Mazzucato, \\n2014). DARPA’s late 2010’s LORELEI project, aimed at spurring research into low \\nLarge Language Models in Non-English Content Analysis\\n35\\nIII. Recommendations\\nresource languages to improve translation for humanitarian efforts, is a good first step, \\nbut further government incentives could help assure that NLP researchers invest in \\na broad range of approaches and languages, rather than focus disproportionately on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='a broad range of approaches and languages, rather than focus disproportionately on \\nEnglish. BigScience’s BLOOM is a good example of how large language models can \\nbe developed in the open and with public support. The French government is one of \\nmany funders which has allowed BLOOM to remain open to inquiry by other NLP \\npractitioners. The multilingual language model was trained using ROOTs, a 1.6TB \\nmultilingual dataset that is clearly documented and available for NLP practitioners to \\nanalyze (Laurençon et al., 2022).\\nRESEARCHERS SHOULD FOCUS ON MEASURING AND ADDRESSING \\nTHE IMPACTS OF LARGE LANGUAGE MODELS.\\nTechnologists understand little about the internal logic of how large language models \\noperate and therefore have a difficult time predicting when they make mistakes, \\nwhat the effects of these mistakes will be, and how to fix them. Multilinguality only \\nexacerbates this problem. Better tools are needed to interrogate large language models,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='exacerbates this problem. Better tools are needed to interrogate large language models, \\nparticularly multilingual language models, about why they make the decisions and \\nmistakes they do, and how to fix them.\\nIn particular, the increased use of multilingual language models has the potential to \\nhelp and harm language communities. Enabling greater digital participation amongst \\na language community raises something that researchers call the “Janus-face nature \\nof digital participation” (NLLB Team et al., 2022): it allows more to participate and \\nbenefit from the digital economy, however, it may also expose more people to the harms \\npresent online, often without their consultation and consent (Hao, 2022; Toyama, \\n2015). More research on the effects and externalities of the increased use of language \\nmodels and specifically multilingual language models must grapple with the impacts \\nthese tools have on different linguistic communities, linguistic preservation and'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these tools have on different linguistic communities, linguistic preservation and \\ndiversity efforts, and access to opportunity for all. \\nDifferent actors have different roles to play here. Civil society has a role in documenting \\nthe impacts of these models and imagining what these “better” models should look like. \\nThere are many open questions around the types of problems that need automated \\nsolutions, what more representative datasets might look like, how to manage the tradeoffs \\nbetween languages, how large language models affect linguistic preservation efforts, and \\nwhat the rights implications are of using large language models, among other things. \\nAcademics and corporate researchers have a role in better defining the contexts and tasks \\nthese models hope to address, and developing quantitative and qualitative methods to \\nevaluate these desired normative values. And companies that deploy language models'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='evaluate these desired normative values. And companies that deploy language models \\ncan provide researchers more transparency into how their models work, what data they \\nare trained on, and in what situations they use them so researchers can better tailor their \\nresearch to reflect what is happening in real-world systems.\\nLost in Translation\\nCDT Research\\n36\\nC. Governments\\nGOVERNMENTS SHOULD CAUTION AGAINST USING AUTOMATED \\nDECISION-MAKING SYSTEMS THAT RELY ON LARGE LANGUAGE \\nMODELS TO MAKE HIGH-STAKES DECISIONS.\\nMany governments have deployed or are considering deploying systems that use natural \\nlanguage processing technology as part of AI systems to make high-impact decisions, \\nsuch as determining immigration status or selecting judicial cases to try (Patel et al., \\n2020; Rionda & Mejia, 2021). Vendors who build these systems may soon follow the \\nlarger industry trend of incorporating large language models since they are relatively'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='larger industry trend of incorporating large language models since they are relatively \\ncheap to build and easy to adapt as requirements change. However, as discussed \\nthroughout this paper, large language models are a relatively novel technology that has \\ntechnical limitations. These tools pose serious civil liberty concerns that are magnified \\nin non-English contexts and when used to make decisions that may affect a person’s \\nlivelihood. For instance, if a large language model is used as the basis of an algorithm \\nto evaluate affordable housing applications and the text that large language model was \\ntrained on exhibits anti-Muslim bias, the resulting affordable housing algorithm may \\ndisproportionately deny Muslims’ applications. Relying on large language models to \\nmake high-stakes decisions can have outsized, negative impacts on individuals’ lives, \\nimpeding safety and access to economic opportunities.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='impeding safety and access to economic opportunities.\\nGovernments should therefore never rely solely on automated systems that incorporate \\nlarge language models to make high-risk decision-making areas, such as pretrial risk \\nassessment, allocation of social services, and immigration status. Policymakers should \\nconsider the impact on rights and access to services when procuring new tools and \\nvendors to build these systems and conduct and disclose any assessments conducted \\non these systems. They should also be cautious when adopting these systems for \\ninformation sharing services, such as chatbots about social services or that provide \\nhealthcare information, and test them extensively in every language in which they are \\ndeployed, and never use them to entirely replace human intermediaries.\\nGOVERNMENTS SHOULD NOT MANDATE OR INADVERTENTLY \\nREQUIRE BY LAW THE USE OF AUTOMATED CONTENT ANALYSIS \\nSYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='SYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.\\nGovernments around the world are increasingly pressuring online service providers to \\nlimit content they find to be inaccurate or harmful, such as misinformation related to \\nhealth care, or preemptively monitor online speech which may incite violence. Given \\nthe scale of content available on social media and other services, this has driven an \\ninterest amongst governments to mandate that online service providers use automated \\ncontent analysis systems to detect or remove content they deem as “illegal” or harmful \\nto their constituents.\\nLarge Language Models in Non-English Content Analysis\\n37\\nIII. Recommendations\\nThis is ill-advised. Mandating the use of automated content moderation technologies \\nor requiring companies to take down content in a limited time period (effectively \\nrequiring the use of automated technologies) opens the door for the overbroad removal'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='requiring the use of automated technologies) opens the door for the overbroad removal \\nof speech. Large language models, especially in non-English language contexts, are not \\na magical technology that can perfectly distinguish between “good” and “bad” speech. \\nAt best, they are an imprecise technology that fails to understand the context of speech \\n— for instance, when an individual uses a slur versus when a journalist documents \\nthe use of a slur by that individual. At worst, they are tools that can be appropriated \\nby governments to squash dissent and freedom of expression. Efforts to persuade tech \\ncompanies to improve their automated systems, clarify their policies, introduce more \\naccountability, and promote parity between languages are all welcome, but requiring \\ncompanies to adopt certain technologies is not an effective way to achieve those ends.\\nINTERNATIONAL AND MULTILATERAL STANDARDS BODIES, \\nREGULATORY AGENCIES, AND OTHERS SHOULD CONVENE'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='INTERNATIONAL AND MULTILATERAL STANDARDS BODIES, \\nREGULATORY AGENCIES, AND OTHERS SHOULD CONVENE \\nMULTI-STAKEHOLDER DISCUSSIONS ABOUT STANDARDS AND \\nGUARDRAILS FOR THE DEVELOPMENT AND USE OF LARGE \\nLANGUAGE MODELS.\\nThe norms around when and how multilingual language models should be deployed \\nare very much in flux. Those norms so far have mostly been established implicitly by \\ntechnology companies in the ways they build and deploy these models, but trends in \\nthese norms may be at odds with the public interest. For instance, OpenAI revealed \\nsome information about the training data they used for GPT-3 but almost nothing \\nabout GPT-4; Open AI co-founder Ilya Sutskever described having shared information \\nabout GPT-3’s training data as “just not wise” and something the company would \\nunlikely do again (Vincent, 2023b).\\nCompanies should not have a monopoly on the norms around language models. \\nGovernmental and nongovernmental\\xa0convening bodies need to organize and push back'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Governmental and nongovernmental\\xa0convening bodies need to organize and push back \\nto establish counter-norms that better serve the public’s interests. This field is early on \\nenough that these bodies should discuss what positive outcomes even look like. Users \\naffected by the deployment of large language models need to be at the table for those \\nconversations. Government agencies and multilateral organizations (e.g. the Internet \\nEngineering Task Force, United Nations) can play a coordinating role to get together \\nthe relevant stakeholders to come up with such standards.\\nThere are also larger questions to reckon with when it comes to the use of large \\nlanguage models in non-English contexts. At once, companies are increasingly \\ndeploying multilingual language models to bridge the gap between the functionality in \\nEnglish and other languages across a myriad of tasks, such as harmful content detection, \\nsentiment analysis, and content scanning. However, as we show in this paper, these'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='sentiment analysis, and content scanning. However, as we show in this paper, these \\nmultilingual systems are relatively new and perform inconsistently across languages. \\nLost in Translation\\nCDT Research\\n38\\nIf deployed prematurely and without guardrails, these models pose real risks to \\nindividuals around the world and in particular their ability to express themselves freely. \\nThese risks have the potential to compound existing challenges in the information \\nenvironment for individuals in Western democracies where there are real vacuums of \\navailable information in languages other than English and in countries in the Global \\nSouth where there are already real threats to the free expression and exchange of \\ninformation posed by majoritarian and institutional powers (Golebiewski & boyd, \\n2018). Alternatively, companies may decide to only roll out systems that have been \\nfine-tuned for English and wait until there is enough data and tooling available for non-'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='fine-tuned for English and wait until there is enough data and tooling available for non-\\nEnglish language tools — something that will take an enormous amount of financial \\ninvestment, time, effort, and rare consensus — further entrenching the digital divide \\nand Anglocentrism present online. Both scenarios are lose-lose for all speakers on the \\nweb. This is a wicked problem and the current incentives are at play to build bigger \\nmodels, and with more languages. Multi-stakeholder bodies are much better positioned \\nthan companies to determine when the risks associated with building larger, more \\nmultilingual language models are worth taking.\\nLarge Language Models in Non-English Content Analysis\\n39\\nWorks Cited\\nAbid, A., Farooqi, M., & Zou, J. (2021). Large language models associate Muslims with violence. Nature Machine \\nIntelligence, 3(6), Article 6. [perma.cc/HK4B-3AAQ]\\nACL. (2021, August 3). ACL 2022 Theme Track: “Language Diversity: from Low-Resource to Endangered'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='ACL. (2021, August 3). ACL 2022 Theme Track: “Language Diversity: from Low-Resource to Endangered \\nLanguages.” ACL. [perma.cc/F2YW-QZBP]\\nACL Rolling Review Dashboard. (2022). Papers Mentioning >0 Languages. [perma.cc/EQU9-5CWQ]\\nAgerri, R., Vicente, I. S., Campos, J. A., Barrena, A., Saralegi, X., Soroa, A., & Agirre, E. (2020). Give your Text \\nRepresentation Models some Love: The Case for Basque. Proceedings of the 12th Conference on Language \\nResources and Evaluation, 4781–4788. [perma.cc/R2DA-GGQZ]\\nAlyafeai, Z., & Al-Shaibani, M. (2020). ARBML: Democratizing Arabic Natural Language Processing Tools. \\nProceedings of Second Workshop for NLP Open Source Software (NLP-OSS), 8–13. [perma.cc/4TFY-E9EJ]\\nAmer, M. (2022, July 13). Large Language Models and Where to Use Them: Part 2. Cohere. [perma.cc/CRT5-\\nHDX8]\\nAmericasNLP. (2022, December 7). Second Workshop on NLP for Indigenous Languages of the Americas \\n(AmericasNLP). [perma.cc/SC88-9WGF]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(AmericasNLP). [perma.cc/SC88-9WGF]\\nAmrute, S., Singh, R., & Guzmán, R. L. (2022). A Primer on AI in/from the Majority World. Data & Society. \\n[perma.cc/SR8B-J2L9]\\nAntoun, W., Baly, F., & Hajj, H. (2020). AraBERT: Transformer-based Model for Arabic Language \\nUnderstanding. Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a \\nShared Task on Offensive Language Detection, 9–15. [perma.cc/X5VJ-JKXQ]\\nArtetxe, M., Labaka, G., & Agirre, E. (2020). Translation Artifacts in Cross-lingual Transfer Learning. Proceedings \\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 7674–7684. \\n[perma.cc/MZY5-DL83]\\nArtetxe, M., Ruder, S., & Yogatama, D. (2020). On the Cross-lingual Transferability of Monolingual \\nRepresentations. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, \\n4623–4637. [perma.cc/7WMN-5QPR]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='4623–4637. [perma.cc/7WMN-5QPR]\\nArtetxe, M., & Schwenk, H. (2019). Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual \\nTransfer and Beyond. Transactions of the Association for Computational Linguistics, 7, 597–610. [perma.cc/\\nLB6R-GH9K]\\nArticle 19. (2022). Bridging the Gap: Local voices in content moderation. Bosnia and Herzegovina. [perma.cc/ASU5-\\nST4N]\\nAvaaz. (2019). Megaphone for Hate: Disinformation and Hate Speech on Facebook During Assam’s Citizenship \\nCount. Avaaz. [perma.cc/5MXS-7P7N]\\nLost in Translation\\n40\\nLost in Translation\\nCDT Research\\nBasile, V., Maro, M. D., Croce, D., & Passaro, L. (2020, December 17). EVALITA 2020: Overview of the 7th \\nEvaluation Campaign of Natural Language Processing and Speech Tools for Italian. Seventh Evaluation \\nCampaign of Natural Language Processing and Speech Tools for Italian, Online. [perma.cc/76EK-EJQ8]\\nBelloni, M. (2021, December 8). Multilingual message content moderation at scale. Bumble Tech. [perma.cc/\\nRL2A-L2BD]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='RL2A-L2BD]\\nBender, E. (2019, September 15). The #BenderRule: On Naming the Languages We Study and Why It Matters. \\nThe Gradient. [perma.cc/J3ZM-A5UP]\\nBender, E., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can \\nLanguage Models Be Too Big? 🦜. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and \\nTransparency, 610–623. [perma.cc/3KLC-TBUY]\\nBender, E., & Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of \\nData. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5185–5198. \\n[perma.cc/TN3W-5NTC]\\nBergman, A., & Diab, M. (2022). Towards Responsible Natural Language Annotation for the Varieties of Arabic. \\nFindings of the Association for Computational Linguistics: ACL 2022, 364–371. [perma.cc/Q37M-8F2Y]\\nBigScience Workshop, Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., \\nSagot, B., Muennighoff, N., … Wolf, T. (2023). BLOOM: A 176B-Parameter Open-Access Multilingual \\nLanguage Model (arXiv:2211.05100). arXiv. [perma.cc/2K4Z-F5U7]\\nBirhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., & Bao, M. (2022). The Values Encoded in Machine \\nLearning Research. 2022 ACM Conference on Fairness, Accountability, and Transparency, 173–184. \\n[perma.cc/9GNB-JHQ5]\\nBirhane, A., & Prabhu, V. U. (2021). Large image datasets: A pyrrhic win for computer vision? 2021 IEEE Winter \\nConference on Applications of Computer Vision, 1536–1546. [perma.cc/Q8LP-THYK]\\nBizzoni, Y., Juzek, T. S., España-Bonet, C., Dutta Chowdhury, K., van Genabith, J., & Teich, E. (2020). How \\nHuman is Machine Translationese? Comparing Human and Machine Translations of Text and Speech. \\nProceedings of the 17th International Conference on Spoken Language Translation, 280–290. [perma.\\ncc/4DTZ-DVKC]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/4DTZ-DVKC]\\nBommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosselut, \\nA., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K., \\nDavis, J. Q., Demszky, D., … Liang, P. (2021). On the Opportunities and Risks of Foundation Models. \\nStanford Center for Research on Foundation Models. [perma.cc/3TKJ-UM2F]\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., \\nWu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. Advances in Neural \\nInformation Processing Systems, 33, 1877–1901. [perma.cc/7EES-WDAB]\\nCahyawijaya, S., Lovenia, H., Aji, A. F., Winata, G. I., Wilie, B., Mahendra, R., Wibisono, C., Romadhony, A.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Vincentio, K., Koto, F., Santoso, J., Moeljadi, D., Wirawan, C., Hudi, F., Parmonangan, I. H., Alfina, \\nI., Wicaksono, M. S., Putra, I. F., Rahmadani, S., … Purwarianti, A. (2022). NusaCrowd: Open Source \\nInitiative for Indonesian NLP Resources (arXiv:2212.09648). arXiv. [perma.cc/UQ3Y-4LKW]\\n41\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nCallahan, E. S., & Herring, S. C. (2011). Cultural bias in Wikipedia content on famous persons. Journal of the \\nAmerican Society for Information Science and Technology, 62(10), 1899–1915. [perma.cc/2S8K-YEJK]\\nCarlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., & Zhang, C. (2023, February 1). Quantifying \\nMemorization Across Neural Language Models. The Eleventh International Conference on Learning \\nRepresentations. [perma.cc/678U-9PAQ]\\nCarlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Erlingsson, U., Oprea, A., & Raffel, C. (2021). Extracting Training Data from Large Language Models \\n(arXiv:2012.07805). arXiv. [perma.cc/58MA-VWRZ]\\nCaswell, I., Breiner, T., van Esch, D., & Bapna, A. (2020). Language ID in the Wild: Unexpected Challenges on \\nthe Path to a Thousand-Language Web Text Corpus. Proceedings of the 28th International Conference on \\nComputational Linguistics, 6588–6608. [perma.cc/8RFD-DTUK]\\nChi, E. A., Hewitt, J., & Manning, C. D. (2020). Finding Universal Grammatical Relations in Multilingual BERT. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5564–5577. \\n[perma.cc/8LNR-VNY9]\\nChoi, H., Kim, J., Joe, S., Min, S., & Gwon, Y. (2021). Analyzing Zero-shot Cross-lingual Transfer in Supervised \\nNLP Tasks (arXiv:2101.10649). arXiv. [perma.cc/NEB9-8THZ]\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., \\nPrabhakaran, V., … Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways. Google Research. \\n[perma.cc/NZ7N-6GPB]\\nChristian, J. (2018, July 20). Why Is Google Translate Spitting Out Sinister Religious Prophecies? Vice. [perma.\\ncc/8YQU-NUFM]\\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., Grave, E., Ott, M., \\nZettlemoyer, L., & Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 8440–8451. \\n[perma.cc/2MP6-9W3J]\\nConneau, A., & Lample, G. (2019). Cross-lingual Language Model Pretraining. Advances in Neural Information \\nProcessing Systems, 32. [perma.cc/N7EE-JM83]\\nConneau, A., Wu, S., Li, H., Zettlemoyer, L., & Stoyanov, V. (2020). Emerging Cross-lingual Structure in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Pretrained Language Models. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6022–6034. [perma.cc/3NHR-G7Y4]\\nCorradi, A. (2017, April 25). The Linguistic Colonialism of English. Brown Political Review. [perma.cc/5M3M-\\n9EMN]\\nCorvey, W. (2014). Low Resource Languages for Emergent Incidents. Defense Advanced Research Projects Agency. \\n[perma.cc/4FDR-M3YC]\\nCrawford, K. (2021). Atlas of AI: Power, politics, and the planetary costs of artificial intelligence. Yale University \\nPress.\\n42\\nLost in Translation\\nCDT Research\\nde Varda, A. G., & Marelli, M. (2023). Data-driven Cross-lingual Syntax: An Agreement Study with Massively \\nMultilingual Models. Computational Linguistics, 1–39. [perma.cc/7LQP-EEBQ]\\nde Vries, W., van Cranenburgh, A., Bisazza, A., Caselli, T., van Noord, G., & Nissim, M. (2019). BERTje: A Dutch \\nBERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='BERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]\\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional \\nTransformers for Language Understanding. Proceedings of the 2019 Conference of the North American \\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long \\nand Short Papers), 4171–4186. [perma.cc/E46R-UYDE]\\nDodge, J., Sap, M., Marasović, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., & Gardner, M. (2021). \\nDocumenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. Proceedings \\nof the 2021 Conference on Empirical Methods in Natural Language Processing, 1286–1305. [perma.\\ncc/3GC6-UEWJ]\\nDuarte, N., Llansó, E., & Loup, A. C. (2017). Mixed Messages? The Limits of Automated Social Media Content \\nAnalysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Analysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]\\nDulhanty, C., Deglint, J. L., Daya, I. B., & Wong, A. (2019, November 26). Taking a Stance on Fake News: Towards \\nAutomatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance \\nDetection. NeurIPS 2019, Vancouver. [perma.cc/P5JD-5AD9]\\nEbers, M., Poncibò, C., & Zou, M. (Eds.). (2022). Contracting and Contract Law in the Age of Artificial \\nIntelligence. Hart Publishing. [perma.cc/G4XR-VYNL]\\nEronen, J., Ptaszynski, M., & Masui, F. (2023). Zero-shot cross-lingual transfer language selection using linguistic \\nsimilarity. Information Processing & Management, 60(3), 103250. [perma.cc/S78N-C9MR]\\nEthnologue. (2023a). Assamese. Ethnologue, Languages of the World. [perma.cc/BE78-H3PN]\\nEthnologue. (2023b). Statistics. Ethnologue, Languages of the World. [perma.cc/H27U-44TK]\\nGanguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones, A., Joseph, N., Kernion, J., Mann,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Elhage, N., Showk, S. E., Fort, S., Hatfield-Dodds, \\nZ., Johnston, S., … Clark, J. (2022). Predictability and Surprise in Large Generative Models. 2022 ACM \\nConference on Fairness, Accountability, and Transparency, 1747–1764. [perma.cc/C8YH-6LMA]\\nGolebiewski, M., & boyd, danah. (2018). Data Voids: Where Missing Data Can Easily Be Exploited. Data & \\nSociety. [perma.cc/HE5A-7QTJ]\\nGóngora, S., Giossa, N., & Chiruzzo, L. (2021). Experiments on a Guarani Corpus of News and Social Media. \\nProceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the \\nAmericas, 153–158. [perma.cc/N6S5-4PGN]\\nGrant-Chapman, H., Laird, E., & Venzke, C. (2021). Student Activity Monitoring Software Research Insights and \\nRecommendations. Center for Democracy & Technology. [perma.cc/FY8G-WC2P]\\nGröndahl, T., Pajola, L., Juuti, M., Conti, M., & Asokan, N. (2018). All You Need is “Love”: Evading Hate Speech'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Detection. Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security, 2–12. [perma.cc/\\nT6P5-FRX5]\\n43\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nHao, K. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. [perma.\\ncc/54U3-KU5C]\\nHeikkilä, M. (2022, November 14). We’re getting a better idea of AI’s true carbon footprint. MIT Technology \\nReview. [perma.cc/8PWZ-ESJK]\\nHutchinson, B., Prabhakaran, V., Denton, E., Webster, K., Zhong, Y., & Denuyl, S. (2020). Social Biases in NLP \\nModels as Barriers for Persons with Disabilities. Proceedings of the 58th Annual Meeting of the Association \\nfor Computational Linguistics, 5491–5501. [perma.cc/8FGR-P3FA]\\nIzsak, P., Berchansky, M., & Levy, O. (2021). How to Train BERT with an Academic Budget. Proceedings of the \\n2021 Conference on Empirical Methods in Natural Language Processing, 10644–10652. [perma.cc/8MPG-\\nW2QE]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='W2QE]\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The State and Fate of Linguistic Diversity and \\nInclusion in the NLP World. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6282–6293. [perma.cc/82HQ-EH65]\\nKaack, L. H., Donti, P. L., Strubell, E., Kamiya, G., Creutzig, F., & Rolnick, D. (2022). Aligning artificial \\nintelligence with climate change mitigation. Nature Climate Change, 12(6), Article 6. [perma.cc/7C4S-\\nX2LH]\\nKhan, M., & Hanna, A. (2023). The Subjects and Stages of AI Dataset Development: A Framework for Dataset \\nAccountability. Ohio State Technology Law Journal, 19. [perma.cc/XLG3-AP2J]\\nKinchin, N., & Mougouei, D. (2022). What Can Artificial Intelligence Do for Refugee Status Determination? A \\nProposal for Removing Subjective Fear. International Journal of Refugee Law. [perma.cc/3KER-DZ5R]\\nKoehn, P., & Knowles, R. (2017). Six Challenges for Neural Machine Translation. Proceedings of the First'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Workshop on Neural Machine Translation, 28–39. [perma.cc/9WSQ-HQJY]\\nKornai, A. (2013). Digital Language Death. PLOS ONE, 8(10), e77056. [perma.cc/MMZ8-C9VH]\\nKreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A., Subramani, N., Sokolov, \\nA., Sikasote, C., Setyawan, M., Sarin, S., Samb, S., Sagot, B., Rivera, C., Rios, A., Papadimitriou, I., Osei, \\nS., Suarez, P. O., … Adeyemi, M. (2022). Quality at a Glance: An Audit of Web-Crawled Multilingual \\nDatasets. Transactions of the Association for Computational Linguistics, 10, 50–72. [perma.cc/YZ7B-\\nQ7PN]\\nKublik, V. (n.d.). EU/US Copyright Law and Implications on ML Training Data. Valohai. [perma.cc/LD3Z-\\nRVW7]\\nKupfer, M., & Muyumba, J. (2022). Language & Coloniality: Non-Dominant Languages in the Digital Landscape. \\nPollicy. [perma.cc/PM8N-Y9YW]\\nLaurençon, H., Saulnier, L., Wang, T., Akiki, C., Moral, A. V. del, Scao, T. L., Werra, L. V., Mou, C., Ponferrada,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='E. G., Nguyen, H., Frohberg, J., Šaško, M., Lhoest, Q., McMillan-Major, A., Dupont, G., Biderman, \\nS., Rogers, A., Allal, L. B., Toni, F. D., … Jernite, Y. (2022, October 31). The BigScience ROOTS Corpus: \\nA 1.6TB Composite Multilingual Dataset. Thirty-sixth Conference on Neural Information Processing \\nSystems Datasets and Benchmarks Track. [perma.cc/QS7B-YNYU]\\n44\\nLost in Translation\\nCDT Research\\nLauscher, A., Ravishankar, V., Vulić, I., & Glavaš, G. (2020). From Zero to Hero: On the Limitations of Zero-\\nShot Language Transfer with Multilingual Transformers. Proceedings of the 2020 Conference on Empirical \\nMethods in Natural Language Processing (EMNLP), 4483–4499. [perma.cc/ZJ3R-95JM]\\nLees, A., Sorensen, J., & Kivlichan, I. (2020). Jigsaw @ AMI and HaSpeeDe2: Fine-Tuning a Pre-Trained \\nComment-Domain BERT Model. In V. Basile, D. Croce, M. Maro, & L. C. Passaro (Eds.), EVALITA \\nEvaluation of NLP and Speech Tools for Italian—December 17th, 2020 (pp. 40–47). Accademia University'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Press. [perma.cc/9D4M-RSCL]\\nLees, A., Tran, V. Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., & Vasserman, L. (2022). A New Generation \\nof Perspective API: Efficient Multilingual Character-level Transformers. Proceedings of the 28th ACM \\nSIGKDD Conference on Knowledge Discovery and Data Mining, 3197–3207. [perma.cc/5K82-WG8J]\\nLibovický, J., Rosa, R., & Fraser, A. (2019). How Language-Neutral is Multilingual BERT? (arXiv:1911.03310). \\narXiv. [perma.cc/96RW-WXBL]\\nLin, X. V., Mihaylov, T., Artetxe, M., Wang, T., Chen, S., Simig, D., Ott, M., Goyal, N., Bhosale, S., Du, J., \\nPasunuru, R., Shleifer, S., Koura, P. S., Chaudhary, V., O’Horo, B., Wang, J., Zettlemoyer, L., Kozareva, Z., \\nDiab, M., … Li, X. (2022). Few-shot Learning with Multilingual Generative Language Models. Proceedings \\nof the 2022 Conference on Empirical Methods in Natural Language Processing, 9019–9052. [perma.\\ncc/5QY9-97G5]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/5QY9-97G5]\\nLokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper \\nBlog. [perma.cc/WDL2-TF53]\\nLuccioni, A., & Viviano, J. (2021). What’s in the Box? An Analysis of Undesirable Content in the Common Crawl \\nCorpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182–189. \\n[perma.cc/2QQU-NRPB]\\nLunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient \\nconversations into action. TechCrunch. [perma.cc/MK55-SV54]\\nMartin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings \\nof the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 303–313. [perma.cc/3ZP6-V6AJ]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Human Language Technologies, 303–313. [perma.cc/3ZP6-V6AJ]\\nMartin, L., Muller, B., Suárez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, É. V., Seddah, D., & Sagot, B. \\n(2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the \\nAssociation for Computational Linguistics, 7203–7219. [perma.cc/76EU-4LTM]\\nMasakhane. (n.d.). Masakhane. Retrieved December 21, 2022. [perma.cc/A7SA-ALPM]\\nMaundu, C. (2023, February 21). How language denies people access to public information. Nation. [perma.\\ncc/8C4B-JS3Y]\\nMazzucato, M. (2014). The entrepreneurial state: Debunking public vs. private sector myths (Revised edition). \\nAnthem Press.\\nMeta AI. (2019, November 7). XLM-R: State-of-the-art cross-lingual understanding through self-supervision. \\nMeta AI. [perma.cc/J55N-4MV5]\\n45\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nMicallef, K., Gatt, A., Tanti, M., van der Plas, L., & Borg, C. (2022). Pre-training Data Quality and Quantity for a'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Low-Resource Language: New Corpus and BERT Models for Maltese. Proceedings of the Third Workshop \\non Deep Learning for Low-Resource Natural Language Processing, 90–101. [perma.cc/QY8V-9Q6H]\\nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013, September 6). Efficient Estimation of Word Representations \\nin Vector Space. International Conference on Learning Representations. [perma.cc/T869-PDX4]\\nMuller, B., Anastasopoulos, A., Sagot, B., & Seddah, D. (2021). When Being Unseen from mBERT is just the \\nBeginning: Handling New Languages With Multilingual Language Models. Proceedings of the 2021 \\nConference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 448–462. [perma.cc/J5MH-QDW3]\\nNadkarni, P. M., Ohno-Machado, L., & Chapman, W. W. (2011). Natural language processing: An introduction. \\nJournal of the American Medical Informatics Association\\u202f: JAMIA, 18(5), 544–551. [perma.cc/72PK-\\nUGK9]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='UGK9]\\nNekoto, W., Marivate, V., Matsila, T., Fasubaa, T., Fagbohungbe, T., Akinola, S. O., Muhammad, S., Kabongo \\nKabenamualu, S., Osei, S., Sackey, F., Niyongabo, R. A., Macharm, R., Ogayo, P., Ahia, O., Berhe, M. \\nM., Adeyemi, M., Mokgesi-Selinga, M., Okegbemi, L., Martinus, L., … Bashir, A. (2020). Participatory \\nResearch for Low-resourced Machine Translation: A Case Study in African Languages. Findings of the \\nAssociation for Computational Linguistics: EMNLP 2020, 2144–2160. [perma.cc/5BVM-LUMM]\\nNguer, E. M., Lo, A., Dione, C. M. B., Ba, S. O., & Lo, M. (2020). SENCORPUS: A French-Wolof Parallel \\nCorpus. Proceedings of the Twelfth Language Resources and Evaluation Conference, 2803–2811. [perma.cc/\\nNBE7-QCZW]\\nNguyen, T. (2020, November 27). Why fake news is so hard to combat in Asian American communities. Vox. \\n[perma.cc/45GF-UUEC]\\nNicholas, G. (2020). Explaining Algorithmic Decisions. Georgetown Law Technology Review, 4(711), 20. [perma.\\ncc/UD7D-HF6F]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/UD7D-HF6F]\\nNicholas, G. (2022). Shedding Light on Shadowbanning. Center for Democracy & Technology. [perma.cc/D2TS-\\nY92D]\\nNkemelu, D., Shah, H., Essa, I., & Best, M. L. (2023). Tackling Hate Speech in Low-resource Languages with \\nContext Experts. International Conference on Information & Communication Technologies and \\nDevelopment, Washington, USA. [perma.cc/5QK7-GTMR]\\nNLLB Team, Costa-jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, \\nJ., Licht, D., Maillard, J., Sun, A., Wang, S., Wenzek, G., Youngblood, A., Akula, B., Barrault, L., Gonzalez, \\nG. M., Hansanti, P., … Wang, J. (2022). No Language Left Behind: Scaling Human-Centered Machine \\nTranslation (arXiv:2207.04672). arXiv. [perma.cc/LZH5-DMUA]\\nOkerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M., & Parthasarathy, S. (2022). What’s \\nin the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='in the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them. \\nUniversity of Michigan. [perma.cc/8SXE-RSYE]\\nOpenAI. (2023). GPT-4 Technical Report (arXiv:2303.08774). arXiv. [perma.cc/6ACB-LZYC]\\n46\\nLost in Translation\\nCDT Research\\nOrife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., Ali, J. T., Abbott, J., Marivate, V., \\nKabongo, S., Meressa, M., Murhabazi, E., Ahia, O., van Biljon, E., Ramkilowan, A., Akinfaderin, A., \\nÖktem, A., Akin, W., Kioko, G., … Bashir, A. (2020). Masakhane—Machine Translation For Africa \\n(arXiv:2003.11529). arXiv. [perma.cc/84Z4-S7AZ]\\nPatel, F., Levinson-Waldman, R., Koreh, R., & DenUyl, S. (2020). Social Media Monitoring. Brennan Center for \\nJustice. [perma.cc/N5LF-ZKP2]\\nPhillipson, R. (1992). Linguistic Imperialism. Oxford University Press.\\nPires, T., Schlinger, E., & Garrette, D. (2019). How Multilingual is Multilingual BERT? Proceedings of the 57th'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Annual Meeting of the Association for Computational Linguistics, 4996–5001. [perma.cc/4DPF-LWWX]\\nPng, M.-T. (2022). At the Tensions of South and North: Critical Roles of Global South Stakeholders in AI \\nGovernance. 2022 ACM Conference on Fairness, Accountability, and Transparency, 1434–1445. [perma.cc/\\nZ7HD-3T4A]\\nPolignano, M., Basile, P., Degemmis, M., Semeraro, G., & Basile, V. (2019). AlBERTo: Italian BERT Language \\nUnderstanding Model for NLP Challenging Tasks Based on Tweets. Sixth Italian Conference on \\nComputational Linguistics, Bari, Italy. [perma.cc/RBY9-4JHJ]\\nPrabhakaran, V., Mitchell, M., Gebru, T., & Gabriel, I. (2022). A Human Rights-Based Approach to Responsible AI \\n(arXiv:2210.02667). arXiv. [perma.cc/R97H-WQSK]\\nPrates, M., Avelar, P., & Lamb, L. (2020). Assessing gender bias in machine translation: A case study with Google \\nTranslate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Translate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]\\nPym, A., Ayvazyan, N., & Prioleau, J. M. (2022). Should raw machine translation be used for public-health \\ninformation? Suggestions for a multilingual communication policy in Catalonia. Just. Journal of Language \\nRights & Minorities, Revista de Drets Lingüístics i Minories, 1(1–2), 71–99. [perma.cc/HSA8-TB3F]\\nRaji, D., Denton, E., Bender, E. M., Hanna, A., & Paullada, A. (2021). AI and the Everything in the Whole \\nWide World Benchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and \\nBenchmarks, 1. [perma.cc/EX84-X9BQ]\\nRazeghi, Y., Logan IV, R. L., Gardner, M., & Singh, S. (2022). Impact of Pretraining Term Frequencies on Few-\\nShot Numerical Reasoning. Findings of the Association for Computational Linguistics: EMNLP 2022, \\n840–854. [perma.cc/SMG9-BSKV]\\nReid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Reid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning \\n(arXiv:2212.10173). arXiv. [perma.cc/83GW-CVXX]\\nRichter, F. (n.d.). English Is the Internet’s Universal Language. Statista Infographics. Retrieved December 14, \\n2022, from [perma.cc/WW7B-7X37]\\nRionda, V. P. S., & Mejia, J. C. U. (2021). PretorIA y la automatización del procesamiento de causas de derechos \\nhumanos. Derechos Digitales and Dejusticia. [perma.cc/65MQ-X484]\\nRowe, J. (2022, March 2). Marginalised languages and the content moderation challenge. Global Partners Digital. \\n[perma.cc/GU4K-5HBE]\\n47\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nRuder, S., Constant, N., Botha, J., Siddhant, A., Firat, O., Fu, J., Liu, P., Hu, J., Garrette, D., Neubig, G., & \\nJohnson, M. (2021). XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation. \\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 10215–10245.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='[perma.cc/W4TJ-SGTB]\\nSanta Clara Principles. (2021). Santa Clara Principles on Transparency and Accountability in Content Moderation. \\nSanta Clara Principles. [perma.cc/T623-AVW6]\\nSanty, S., Kummerfeld, J., & Rubio, H. (2023). Languages mentioned in Paper Abstracts. ACL Rolling Review. \\n[perma.cc/EQU9-5CWQ]\\nSavoldi, B., Gaido, M., Bentivogli, L., Negri, M., & Turchi, M. (2021). Gender Bias in Machine Translation. \\nTransactions of the Association for Computational Linguistics, 9, 845–874. [perma.cc/9K3F-5VBZ]\\nSchwenk, H. (2019, January 22). LASER natural language processing toolkit—Engineering at Meta. Meta AI. \\n[perma.cc/46JG-AZ4T]\\nSengupta, P. B., Claudia Pozo, Anasuya. (2022, March 31). Does the internet speak your language? Launching the \\nfirst-ever State of the Internet’s Languages report. Whose Knowledge? [https://perma.cc/9KCX-M863]\\nSharir, O., Peleg, B., & Shoham, Y. (2020). The Cost of Training NLP Models: A Concise Overview \\n(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]\\nShenkman, C., Thakur, D., & Llansó, E. (2021). Do You See What I See? Capabilities and Limits of Automated \\nMultimedia Content Analysis. Center for Democracy & Technology. [perma.cc/W85T-HQQF]\\nSrivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., \\nGarriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. \\nW., Safaya, A., Tazarv, A., … Wu, Z. (2022). Beyond the Imitation Game: Quantifying and extrapolating the \\ncapabilities of language models (arXiv:2206.04615). arXiv. [perma.cc/278S-ZJV9]\\nStadthagen-Gonzalez, H., Imbault, C., Pérez Sánchez, M. A., & Brysbaert, M. (2017). Norms of valence and \\narousal for 14,031 Spanish words. Behavior Research Methods, 49(1), 111–123. [perma.cc/7FWX-Z3JD]\\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3645–3650. \\n[perma.cc/9P4Y-J4HT]\\nTalat, Z., Névéol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., \\nRadev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D., & Wal, O. van der. (2022). You \\nreap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. Proceedings of \\nBigScience Episode #5, 26–41. [perma.cc/3ECR-4E7U]\\nTattle. (n.d.). Uli. [perma.cc/4AB2-D4GX]\\nTay, Y., Tran, V. Q., Ruder, S., Gupta, J., Chung, H. W., Bahri, D., Qin, Z., Baumgartner, S., Yu, C., & Metzler, D. \\n(2022, February 23). Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. \\nInternational Conference on Learning Representations 2022. [perma.cc/YRL4-E7DT]\\nTeich, E. (2003). Cross-Linguistic Variation in System and Text: A Methodology for the Investigation of'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Translations and Comparable Texts. In Cross-Linguistic Variation in System and Text. De Gruyter Mouton. \\n[perma.cc/L8A8-RH8B]\\n48\\nLost in Translation\\nCDT Research\\nTorbati, Y. (2019, September 26). Google Says Google Translate Can’t Replace Human Translators. Immigration \\nOfficials Have Used It to Vet Refugees. ProPublica. [perma.cc/ZUN6-LHA5]\\nToyama, K. (2015). Geek heresy: Rescuing social change from the cult of technology. PublicAffairs.\\nTsvetkov, Y., Sitaram, S., Faruqui, M., Lample, G., Littell, P., Mortensen, D., Black, A. W., Levin, L., & Dyer, \\nC. (2016). Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation \\nLearning. Proceedings of the 2016 Conference of the North American Chapter of the Association for \\nComputational Linguistics: Human Language Technologies, 1357–1366. [perma.cc/4RES-KFNM]\\nUnited Nations Human Rights Office of the High Commissioner. (n.d.). \\u200bEconomic, social and cultural rights. \\nOHCHR. [perma.cc/Y6MK-SZZ4]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='OHCHR. [perma.cc/Y6MK-SZZ4]\\nVallee, H. Q. la, & Duarte, N. (2019). Algorithmic Systems in Education: Incorporating Equity and Fairness When \\nUsing Student Data. Center for Democracy and Technology. [perma.cc/CC89-ZVNV]\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017, \\nDecember 5). Attention Is All You Need. Advances in Neural Information Processing Systems. [perma.\\ncc/2ZDX-Z796]\\nVincent, J. (2022, November 2). Google plans giant AI language model supporting world’s 1,000 most spoken \\nlanguages. The Verge. [perma.cc/3Y48-X7WV]\\nVincent, J. (2023a, January 17). Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its \\ncontent. The Verge. [perma.cc/4CXS-3WNN]\\nVincent, J. (2023b, March 15). OpenAI co-founder on company’s past approach to openly sharing research: “We were \\nwrong.” The Verge. [perma.cc/DPL6-4PD2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='wrong.” The Verge. [perma.cc/DPL6-4PD2]\\nVitulli, M. A. (2018). Writing Women in Mathematics Into Wikipedia. Notices of the American Mathematical \\nSociety, 65(03), 330–334. [perma.cc/X73F-AZPM]\\nVolansky, V., Ordan, N., & Wintner, S. (2015). On the features of translationese. Digital Scholarship in the \\nHumanities, 30(1), 98–118. [perma.cc/7F8S-3YXK]\\nWang, C., Cho, K., & Gu, J. (2020). Neural Machine Translation with Byte-Level Subwords. Proceedings of the \\nAAAI Conference on Artificial Intelligence, 34(05), Article 05. [perma.cc/5DL7-XSSP]\\nWang, Z., K, K., Mayhew, S., & Roth, D. (2020). Extending Multilingual BERT to Low-Resource Languages. \\nFindings of the Association for Computational Linguistics: EMNLP 2020, 2649–2656. [perma.cc/ZNC8-\\nC9E7]\\nWilliams, A., Miceli, M., & Gebru, T. (2022). The Exploited Labor Behind Artificial Intelligence. Noēma. [perma.\\ncc/GE8H-7SUN]\\nWu, S., & Dredze, M. (2019). Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT. Proceedings'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International \\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP), 833–844. [perma.cc/EJ3G-MFYN]\\nWu, S., & Dredze, M. (2020). Are All Languages Created Equal in Multilingual BERT? Proceedings of the 5th \\nWorkshop on Representation Learning for NLP, 120–130. [perma.cc/5E6X-NNAA]\\n49\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nYu, S., Sun, Q., Zhang, H., & Jiang, J. (2022). Translate-Train Embracing Translationese Artifacts. Proceedings of \\nthe 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 362–\\n370. [perma.cc/7F8C-EYM6]\\nZhang, S., Frey, B., & Bansal, M. (2022, April 25). How can NLP Help Revitalize Endangered Languages? A Case \\nStudy and Roadmap for the Cherokee Language. Proceedings of the 60th Annual Meeting of the Association'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='for Computational Linguistics (Volume 1: Long Papers). ACL 2022, Dublin, Ireland. [perma.cc/2XF2-\\n2GDC]\\nZhang, Y., Warstadt, A., Li, X., & Bowman, S. R. (2021). When Do You Need Billions of Words of Pretraining \\nData? Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 1112–1125. \\n[perma.cc/43ZK-2ZXC]\\ncdt.org\\ncdt.org/contact\\n202-637-9800\\n@CenDemTech\\nCenter for Democracy & Technology\\n1401 K Street NW, Suite 200\\nWashington, D.C. 20005'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='CEDILLE:\\nA LARGE AUTOREGRESSIVE LANGUAGE MODEL IN FRENCH\\nMartin Müller∗\\nFlorian Laurent∗\\nCedille AI1\\nhello@cedille.ai\\nABSTRACT\\nScaling up the size and training of autoregressive language models has enabled novel ways of solving\\nNatural Language Processing tasks using zero-shot and few-shot learning. While extreme-scale\\nlanguage models such as GPT-3 offer multilingual capabilities, zero-shot learning for languages\\nother than English remain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, speciﬁcally trained for the French language. Our results show that\\nCedille outperforms existing French language models and is competitive with GPT-3 on a range\\nof French zero-shot benchmarks. Furthermore, we provide an in-depth comparison of the toxicity\\nexhibited by these models, showing that Cedille marks an improvement in language model safety\\nthanks to dataset ﬁltering.\\n1\\nIntroduction\\nLarge autoregressive language models have drawn wide'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='thanks to dataset ﬁltering.\\n1\\nIntroduction\\nLarge autoregressive language models have drawn wide\\nattention due to their zero-shot and few-shot capabilities,\\nallowing them to be used for a wide variety of Natural Lan-\\nguage Processing tasks without the need for task-speciﬁc\\nﬁnetuning or annotation data [1, 2]. Additionally, previ-\\nous work highlights the improved sample and compute\\nefﬁciency of larger models, generally justifying the move\\ntowards larger models [3].\\nAlthough large language models, such as GPT-3 [2], have\\nbeen trained on multilingual corpuses, the performance on\\nNLP tasks may vary signiﬁcantly between languages. As-\\nsessing zero-shot performance in non-English languages\\nis challenging due to the limited number of human-curated\\nbenchmarks available. However, with the exception of re-\\ncent work in machine translation [4], multilingual models\\ngenerally perform worse than mono- or bilingual language\\nmodels [5].\\nMonolingual autoregressive language models in French'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='models [5].\\nMonolingual autoregressive language models in French\\nhave previously been proposed. GPT-fr [6] and PAGnol [7]\\nhave been trained on ﬁltered versions of Common Crawl2\\nand CCNet [8], respectively. Both works highlight the im-\\nportance of deduplicating and ﬁltering of pre-training data\\nand use decoder-only transformer architectures, closely\\nfollowing the GPT models with model sizes reaching 1B\\nand 1.5B parameters, respectively. It’s worth noting that\\nthese works do not directly compare performance against\\nextreme-scale large multilingual models, such as GPT-3,\\nin particular with regard to zero-shot tasks.\\nPrevious work on the various encoding biases in large lan-\\nguage models highlights the importance of dataset curation\\nand documentation [9, 10]. Experiments conducted on\\nGPT-3 (which has been trained on 570GB of text data\\nfrom Common Crawl) show that the model may gener-\\nate toxic sentences even when prompted with non-toxic'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ate toxic sentences even when prompted with non-toxic\\ntext [11]. Although applying ﬁltering of training data using\\nautomated toxicity scores may introduce classiﬁer-speciﬁc\\nbiases [12], this technique remains more effective than\\n∗Authors contributed equally, order is random\\n1Coteries SA, EPFL Innovation Park, Lausanne, Switzerland\\n2https://commoncrawl.org/\\narXiv:2202.03371v1  [cs.CL]  7 Feb 2022\\ndecoder-based detoxiﬁcation using methods such as swear\\nword ﬁlters, PPLM [13], soft prompt tuning [14] or toxicity\\ncontrol tokens [15].\\nAs a consequence of the aforementioned risks, the trend\\ntowards larger models coincides with a trend to not release\\nmodels publicly. Controlling access to large language mod-\\nels may protect against certain bad actors but also limits\\nreproducibility and research efforts to mitigate the negative\\nproperties of such models. In a push for building models in\\nthe open, EleutherAI, a grassroot collective of researchers,'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the open, EleutherAI, a grassroot collective of researchers,\\nreleased GPT-J [16], a 6B parameter English language\\nmodel. This model was trained on the Pile [20], a 825GB\\ntext corpus by the same collective.\\nThe contributions of this paper are as follows: (1) We intro-\\nduce Cedille, an openly available French language model\\nbuilt on GPT-J, which is capable of achieving competitive\\nzero-shot performance against existing French language\\nmodels and GPT-3. (2) We release the toxicity scores\\nof the complete French C4 dataset, and (3) we provide a\\ncomparison of Cedille’s toxicity to other language models\\n(including GPT-3).\\n2\\nMethods\\n2.1\\nModel architecture\\nOur model architecture is identical to GPT-J [16]. GPT-J\\nuses a similar transformer architecture to the one used in\\n6.7B GPT-3 with three main differences: (1) No sparse\\nattention patterns were used; (2) the dimension of the atten-\\ntion head was increased from 128 to 256; and (3) Rotary'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tion head was increased from 128 to 256; and (3) Rotary\\npositional embeddings [17] were used instead of sinusoidal\\nembeddings. See Table 1 for more details.\\nNumber of parameters\\n6,053,381,344\\nNumber of layers N\\n28\\nModel dimensions dmodel\\n4096\\nFeed-forward dimension dff\\n16,384\\nNumber of attention heads nheads\\n16\\nHead dimension dhead\\n256\\nContext size\\n2048\\nVocab size\\n50,257\\nTable 1: Cedille model details.\\n2.2\\nTraining data\\nCedille is trained on a ﬁltered version of the French part\\nof the multilingual C4 (mC4) dataset [18], which contains\\n332M documents or 1.1TB of uncompressed text. mC4 is\\nextracted from 71 Common Crawl snapshots (years 2013\\nto 2020) and uses CLD33, a small feed-forward neural net-\\nwork, for language identiﬁcation. mC4 ﬁltered out pages\\nof less than three lines of at least 200 characters.\\nWe apply two different forms of ﬁltering to the dataset 1)\\ntoxicity ﬁltering using the Detoxify model [19] and 2) loss\\nﬁltering using the FlauBERT model [20]. For both ﬁltering'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ﬁltering using the FlauBERT model [20]. For both ﬁltering\\nsteps we compute the metric on a per document level of the\\nentire base dataset. In some cases chunking the documents\\ninto splits of 1200 characters was necessary due to the\\nﬁxed context size of the used models. Chunks smaller than\\n600 characters were not evaluated. The predictions were\\nrun on TPU v3-8 machines with 8-fold data parallelism\\neach.\\nEach percentile as well as the tails of both the loss and the\\ntoxicity distribution were sampled and manually inspected\\nto ﬁnd suitable cut-off values for ﬁltering. The inspection\\nof these samples revealed that both toxicity and loss values\\nwere appropriate4. We removed documents correspond-\\ning to a toxicity score higher than 0.5, corresponding to\\n0.25% of the content (0.8M documents). For the loss ﬁl-\\ntering we considered the loss distribution of each of the\\n2048 ﬁles and removed documents below a 0.2 percentile\\nloss (corresponding to a loss value of roughly 4.5) and'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='loss (corresponding to a loss value of roughly 4.5) and\\nabove an absolute loss value of 10. This corresponded to\\na removal of roughly 20% of all documents (66M docu-\\nments). The combined ﬁltering led to a ﬁnal training set of\\n265M documents, which corresponds to roughly 773GB\\nof uncompressed text.\\nThe text was then run through the fix_text method of\\nthe Python library ftfy [21] using NFKC normalization\\nand encoded using the unmodiﬁed GPT-2 tokenizer. Docu-\\nments were simply concatenated and split into samples of\\n2049 tokens. The ﬁnal training set yielded a total of 130M\\nsamples corresponding to 268B tokens.\\n2.3\\nTraining process\\nCedille was trained starting from the ofﬁcial GPT-J model\\ncheckpoint using the mesh-transformer-jax codebase [22].\\nTraining was conducted on a v3-128 TPU VM using 16-\\nfold data parallelism and 8-fold model sharding. For all\\nour experiments we used an effective batch size of 256.\\nWe used a linear warmup of 42k steps up to a peak learning'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='We used a linear warmup of 42k steps up to a peak learning\\nrate of 5e-5 and a cosine decay to 1e-5. Weight decay was\\nset to 0.1. Cedille was trained for 150k steps, which corre-\\nsponds to 0.3 epochs on the training set or 78.7B tokens.\\nThe starting and ﬁnal training perplexities were 6.13 and\\n3.89, respectively. During training we monitored the loss\\non a dataset of French news stories published too recently\\nto be part of the training data.\\n3https://github.com/google/cld3\\n4Despite the positive visual inspection a bug in the loss computation was discovered much later in the analysis. Further investiga-\\ntion revealed that roughly 10% of samples were wrongly included in the ﬁnal dataset as a result. Although it cannot be fully ruled\\nout we do not believe that a systematic bias was introduced.\\n2\\n2.4\\nEvaluation\\nZero-shot performance was evaluated using a forked ver-\\nsion of the lm-evaluation-harness codebase [23]. In par-\\nticular, we added a different way of evaluating perplexity'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ticular, we added a different way of evaluating perplexity\\nusing strides (see section 3.1), implemented the various\\nbenchmarks discussed in this work, and integrated the\\nmesh-transformer-jax library (for evaluating checkpoints\\non TPUs) and the Pagnol model families. Benchmarking\\nwas conducted on v3-8 TPU VMs and on A100 GPUs.\\nToxicity evaluation was conducted using a modiﬁed ver-\\nsion of the real-toxicity-prompts codebase5. The main\\ndifference is the use of the Detoxify model in order\\nto predict toxicity (see section 4).\\nOur adapted code-\\nbase is available at https://github.com/coteries/\\nreal-toxicity-prompts.\\n3\\nTasks\\n3.1\\nPerplexity\\nModel\\n#params\\nByte-PPL\\nToken-PPL\\nGPT-3 (ada)\\n1.3Ba\\n1.930\\n7.952\\nGPT-3 (babbage)\\n6.7B\\n1.973\\n6.447\\nGPT-3 (curie)\\n13B\\n1.809\\n5.082\\nGPT-3 (davinci)\\n175B\\n1.656\\n3.993\\nGPT-J\\n6.05B\\n1.746\\n5.797\\nCedille\\n6.05B\\n1.646\\n3.932\\nPagnol (small)\\n124M\\n1.852\\n17.802\\nPagnol (medium)\\n335M\\n1.775\\n14.623\\nPagnol (large)\\n773M\\n1.725\\n12.791\\nGPT-fr (base)\\n1B\\n2.090\\n11.882'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='Pagnol (medium)\\n335M\\n1.775\\n14.623\\nPagnol (large)\\n773M\\n1.725\\n12.791\\nGPT-fr (base)\\n1B\\n2.090\\n11.882\\nTable 2: Byte-level and token-level perplexity scores on the\\nWikiText-fr benchmark (lower is better).\\naOpenAI hasn’t ofﬁcially disclosed the size of the models\\nprovided by their API, however recent experiments suggest the\\nmapping presented in the table [24].\\nZero-shot perplexity was evaluated on the test subset of\\nthe WikiText-fr6 dataset [6], containing articles from the\\nFrench Wikipedia which are part of the “quality articles” or\\n“good articles” categories, similar to the English WikiText-\\n103 dataset [25]. The test set contains 589k words or 3.7M\\ncharacters of cleaned French text from 60 articles. We eval-\\nuated perplexity by concatenating the text without further\\npreprocessing and using a sliding window approach [26]\\nwith a stride of 512 tokens. Therefore models with a con-\\ntext window of 1024 tokens (GPT-fr, Pagnol) had 512\\ntokens of context, whereas models with a context window'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tokens of context, whereas models with a context window\\nof 2048 tokens had 1536 tokens of context. Table 2 shows\\nthe summed log likelihoods both normalized by number\\nof characters and by number of tokens. Note that the\\ntoken-level perplexity for GPT-fr and Pagnol is not directly\\ncomparable to the other models, as they are not using the\\n(English) GPT-2 tokenizer.\\nCedille achieves the lowest perplexity score out of the an-\\nalyzed models, clearly outcompeting existing French lan-\\nguage models and narrowly outcompeting GPT-3 (davinci).\\nUnsurprisingly, models with larger context windows gen-\\nerally perform better at this task. It is noteworthy that the\\ntest dataset is likely contained in the training data as no\\ndataset-speciﬁc ﬁltering of the training data was conducted\\nas part of this work.\\n3.2\\nSummarization\\nWe evaluated the summarization capabilities on the Orange-\\nSum benchmark, as introduced in the BARThez work [27]\\nas a French equivalent of XSum [28]. The benchmark con-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='as a French equivalent of XSum [28]. The benchmark con-\\ntains news articles published between February 2011 and\\nSeptember 2020, scraped from the French website “Orange\\nActu”. The models were given the news article in the test\\nsubset using the following prompt:\\n{article text}\\\\nPour résumer :\\nThe models were tasked to generate 100 tokens using top-k\\nof 2 and a temperature of 1, following the methodology\\nin [1]. We used greedy decoding (top-k = 1) for GPT-3,\\nsince at the time of this work being conducted, the API\\ndidn’t allow for other top-k values. When the prompt ex-\\nceeded the context window of the model it was left-side\\ntruncated. The output was then clipped to contain at most 3\\nsentences (using simplistic sentence splitting at the period\\ncharacter). Table 3 shows the ROUGE score [29] of the\\noutput compared to the title of the corresponding articles.\\nModel\\nR1\\nR2\\nRL\\nGPT-3 (ada)\\n13.95\\n4.75\\n11.59\\nGPT-3 (babbage)\\n4.62\\n1.76\\n3.86\\nGPT-3 (curie)\\n5.28\\n2.21\\n4.42\\nGPT-3 (davinci)\\n15.49\\n5.82'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='4.75\\n11.59\\nGPT-3 (babbage)\\n4.62\\n1.76\\n3.86\\nGPT-3 (curie)\\n5.28\\n2.21\\n4.42\\nGPT-3 (davinci)\\n15.49\\n5.82\\n13.05\\nGPT-J\\n14.46\\n4.72\\n11.68\\nCedille\\n14.74\\n4.83\\n11.86\\nPagnol (small)\\n8.52\\n1.61\\n7.24\\nPagnol (medium)\\n8.98\\n1.86\\n7.55\\nPagnol (large)\\n9.19\\n1.85\\n7.71\\nGPT-fr (base)\\n10.15\\n2.60\\n8.27\\nTable 3: Performance of summarization in French. Shown are\\nthe ROUGE scores on the OrangeSum dataset (higher is better).\\nGenerally, we observed some variance due to the non-\\ngreedy sampling procedure. However, computational limi-\\n5https://github.com/allenai/real-toxicity-prompts\\n6https://huggingface.co/datasets/asi/wikitext_fr\\n3\\ntations and cost made it difﬁcult to estimate this variance.\\nWe also observed that the choice of the preﬁx (“Pour ré-\\nsumer :”) strongly inﬂuences the scores. Some of the\\nevaluated models are also more likely to generate bullet\\npoint summaries, rather than a single sentence, which may\\nagain lead to different sentence splitting. This may ex-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='again lead to different sentence splitting. This may ex-\\nplain the increased score for GPT-3 (ada) compared to\\nlarger GPT-3 models. Nevertheless, the scores provided\\nin Table 3 give some rough indication of summarization\\nperformance.\\n3.3\\nQuestion Answering (QA)\\nQuestion answering (QA) was evaluated on FQuAD\\n(French Question Answering Dataset) [30], a dataset in-\\nspired by the English SQuAD equivalent [31]. The models\\nwere evaluated on the validation subset, which contains\\n3188 human-curated question-answer pairs, based on 768\\nhigh-quality French Wikipedia articles.\\nModel\\nF1\\nExact match (%)\\nGPT-3 (ada)\\n19.09\\n4.48\\nGPT-3 (babbage)\\n26.16\\n8.81\\nGPT-3 (curie)\\n39.49\\n17.84\\nGPT-3 (davinci)\\n-\\n-\\nGPT-J\\n26.14\\n6.96\\nCedille\\n34.59\\n12.23\\nPagnol (small)\\n10.66\\n0.43\\nPagnol (medium)\\n13.80\\n0.84\\nPagnol (large)\\n17.67\\n2.72\\nGPT-fr (base)\\n15.15\\n2.03\\nTable 4: Question-answering F1 and exact match scores in\\nFrench on the FQuAD benchmark (higher is better).\\nThe models were evaluated using the SQuAD v2 met-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='French on the FQuAD benchmark (higher is better).\\nThe models were evaluated using the SQuAD v2 met-\\nric [31], which also takes into consideration “no answer”\\nprobabilities, i.e. cases when no answer to a particular\\nquestion is possible given the context. The models were\\ntasked to generate 100 tokens and at most 1 sentence using\\ngreedy sampling and the following prompt:\\nTitre:\\n{title}\\\\nContexte:\\n{context}\\\\n\\\\n\\nQuestion:\\n{question}\\\\n\\\\nRéponse:\\nThe “no answer” probabilities were calculated against the\\nstring:\\n{prompt} Sans réponse.\\nHowever, all questions in the evaluated data contained\\nexactly one answer.\\nThe results in Table 4 show that GPT-3 is very competitive\\non this task, with GPT-3 (curie) outperforming Cedille\\nand all other evaluated models. GPT-3 (davinci) was not\\nevaluated on this task for cost reasons, as OpenAI did not\\nsupport our request for funding at the time of writing. The\\nresults may be contrasted to a ﬁnetuned version of Camem-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='results may be contrasted to a ﬁnetuned version of Camem-\\nBERT [32] which yields F1 of 88% and best match of 78%\\non this dataset [30].\\n3.4\\nTranslation\\nZero-shot translation was evaluated for the language pair\\nEnglish and French on the WMT14 dataset [33]. Tradi-\\ntionally, such benchmarks are evaluated using the BLEU\\nscore [34]. The datasets contains 3003 samples each and\\nare provided by the sacrebleu library [35]. The zero-shot\\ntask is formulated using the following pattern:\\n{source_lang} phrase:\\n{text}\\\\n{target_lang}\\nphrase:\\nWhere source_lang and target_lang are French and\\nEnglish, respectively, depending on the direction. Greedy\\nsampling is used to generate 256 tokens. The output was\\nclipped to at most 1 sentence.\\nCedille outperforms other models for the direction English\\nto French, highlighting the strong French writing capabil-\\nities (see Table 5). Likewise, GPT-3 (davinci) performs\\nbetter for the French to English direction. Monolingual'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='better for the French to English direction. Monolingual\\nmodels, such as Pagnol and GPT-fr perform worse at this\\ntask presumably due to the limited amount of English that\\nwas part of their pretraining data. Often, smaller models\\nwere unable to follow the instructions and simply repeated\\nthe context in the given language. As opposed to summa-\\nrization and question-answering benchmarks, the target is\\ngenerally not part of the context, therefore simply repeating\\nthe input normally results in a low score.\\nAs of 2021, dedicated neural machine translation solutions,\\nsuch as Very Deep Transformers, reach 46.4 BLEU for\\nEnglish to French translation [36].\\nModel\\nBLEU (en→fr)\\nBLEU (fr→en)\\nGPT-3 (ada)\\n2.71\\n16.64\\nGPT-3 (babbage)\\n3.20\\n24.56\\nGPT-3 (curie)\\n13.45\\n27.15\\nGPT-3 (davinci)\\n20.40\\n27.70\\nGPT-J\\n14.71\\n26.06\\nCedille\\n24.89\\n20.59\\nPagnol (small)\\n0.76\\n1.20\\nPagnol (medium)\\n1.07\\n1.48\\nPagnol (large)\\n1.06\\n3.47\\nGPT-fr (base)\\n1.47\\n1.57\\nTable 5: BLEU scores for ranslation on WMT14 for the English-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='1.06\\n3.47\\nGPT-fr (base)\\n1.47\\n1.57\\nTable 5: BLEU scores for ranslation on WMT14 for the English-\\nFrench language pair (higher is better).\\n4\\nToxicity analysis\\nIn order to evaluate the toxicity of the model we closely\\nfollowed the work conducted in [11]. We studied the case\\n4\\nof unprompted (i.e. conditioned only on a start-of-sentence\\ntoken) and prompted generation.\\nThe original work in [11] used the Perspective API, a ser-\\nvice that uses machine learning classiﬁers to estimate the\\nperceived toxicity of text. In this work, we employ the\\nDetoxify tool [19] instead. We made this choice as the\\nunderlying models used by Perspective evolve with time\\nand are not released publicly, which limits experimental\\nreproducibility.\\nDetoxify assigns a toxicity score between 0 and 1, with 1\\ndenoting “a very hateful, aggressive, or disrespectful com-\\nment”. We refer to content with a score > 0.5 as “toxic”.\\nWe use the “multilingual” Detoxify model from release'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='We use the “multilingual” Detoxify model from release\\nv0.4.0, and compare the toxicity of Cedille output to 3\\nother models: GPT-2 (117M), GPT-3 (davinci), GPT-J and\\nGPT-fr (base).\\n4.1\\nUnprompted toxicity\\nFor the unprompted toxicity we analyze the expected max-\\nimum toxicity, i.e. the expected worst-case toxicity score\\ngiven N unprompted generations. Figure 1 shows boot-\\nstrap estimates (1000 iterations) of the expected maximum\\ntoxicity for N generations with variance bounds as shades.\\nIn this setting, Cedille consistently generates content with\\nlower expected maximum toxicity than GPT-2, GPT-J, and\\nGPT-3. After 100 generations, this value is under 0.5 for\\nGPT-fr and Cedille (0.41 and 0.48, respectively), which\\nmeans that the worst content from these models is not\\nexpected to be toxic. This is in contrast with the other\\nmodels, for which maximum expected toxicity values are\\n0.64, 0.54 and 0.56.\\nAfter 10K generations, Cedille and GPT-fr are the only'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='0.64, 0.54 and 0.56.\\nAfter 10K generations, Cedille and GPT-fr are the only\\nmodels for which the expected worst outputs don’t reach\\na toxicity level of 1.0 We expect all other models to have\\nat least one output that is maximally toxic as detected by\\nDetoxify. Generally the two models that perform best are\\nGPT-fr and Cedille, which were both trained on carefully\\nﬁltered datasets, pointing to the importance of dataset cu-\\nration when considering the safety of language models.\\nWithout any conditioning, the multilingual models almost\\nexclusively generate English content: this is the case of\\nGPT-2, GPT-J and GPT-3. However, with the Detoxify\\nmodel being multilingual, the toxicity scores remain com-\\nparable.\\n4.2\\nPrompted toxicity\\nFor prompted toxicity we used a set of 50 French prompts\\nwith values of toxicity spanning the full range, with a mean\\nof 0.34. The set of prompts was selected randomly from\\nthe RealToxicityPrompt dataset and manually translated'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the RealToxicityPrompt dataset and manually translated\\nfrom English to French by a French native speaker. We\\nused a smaller number of prompts than in [11] due to lim-\\nited computing resources. The French prompts cause the\\nmultilingual models (GPT-2, GPT-J and GPT-3) to gener-\\nate French content. For each prompt, each model generates\\n50 completions. We used nucleus sampling with p = 0.9\\nto generate up to 20 tokens per continuation, following the\\nprotocol from [11].\\nTable 6 shows two properties: 1) the expected maximum\\ntoxicity over 25 generations (with standard deviations in\\nparentheses) and 2) the empirical probability of generating\\ntoxic text at least once among 25 generations.\\nModel\\nExp. max tox.\\nProb. toxicity\\nGPT-2a\\n0.63 (0.23)\\n0.66\\nGPT-3 (davinci)\\n0.68 (0.27)\\n0.74\\nGPT-J\\n0.73 (0.26)\\n0.78\\nCedille\\n0.66 (0.27)\\n0.72\\nGPT-fr (base)\\n0.73 (0.27)\\n0.78\\nTable 6: Toxicity of prompted generations.\\naUpon manual inspection, it appeared that GPT-2 is unable'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='aUpon manual inspection, it appeared that GPT-2 is unable\\nto generate sensible French content, and as such the resulting\\ntoxicity values can’t be compared to other models.\\nFor both properties, Cedille outperforms the other models.\\nWe can see again that Cedille is less toxic than GPT-J,\\nindicating that the training not only improved the model’s\\nFrench capabilities, but also increased its safety.\\n5\\nConclusions\\nIn this work we introduced Cedille, a large auto-regressive\\nFrench language model.\\nOur work shows that mono-\\nlingual models such as Cedille, can be competitive com-\\npared to extreme scale multilingual language models, i.e.\\nGPT-3. Compared to existing French language models,\\nCedille is capable of performing well on zero-shot natural\\nlanguage understanding tasks and reaches a new state-of-\\nthe-art perplexity score on the French WikiText corpus.\\nLastly, our approach of toxicity ﬁltering of the training\\ndata led to a decrease in both maximum toxicity as well as'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='data led to a decrease in both maximum toxicity as well as\\nthe likelihood of toxic output.\\nAs a result of the ﬁnetuning approach starting from GPT-J,\\nCedille has been exposed to a large amount of both English\\nand French language data from the Pile and French mC4.\\nThis combination allows for competitive zero-shot trans-\\nlation scores for the French-English language pair. Early\\nexperiments indicate that ﬁnetuning an existing English\\nlanguage model and adapting it to French is more efﬁcient\\neven with considerable compute and data investments (see\\nappendix).\\nGiven the scarcity of high-quality human-curated datasets\\nin non-English languages it is especially challenging to\\nprovide a fair comparison of language models. For the\\nzero-shot benchmarks we observed a high degree of sen-\\nsitivity towards evaluation settings such as preﬁxes, sam-\\npling parameters, and type of evaluation metric. The scores\\n5\\n10\\n100\\n1K\\n10K\\nNumber of Generations\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='5\\n10\\n100\\n1K\\n10K\\nNumber of Generations\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0\\nExpected Maximum Toxicity\\nGPT-2\\nGPT-3\\nGPT-J\\nGPT-fr\\nCedille\\nFigure 1: Unprompted expected maximum toxicity against increasing numbers of generations.\\nshould therefore only be considered as a rough guidance\\nand model performance may be highly task speciﬁc. In this\\nwork we haven’t provided performance metrics for other\\nNLP tasks such as text classiﬁcation or word sense disam-\\nbiguation. Furthermore, this work focused on zero-shot\\nevaluation, ignoring few-shot or ﬁnetuning approaches.\\nApart from training larger models, a possible path for-\\nward is to deduplicate training data. This method has been\\nshown to improve end-task performance signiﬁcantly [8,\\n37] but was not conducted as part of this work. In order to\\nfurther reduce language model toxicity, a possible direc-\\ntion is the integration of human feedback in the training\\nprocess in order to reduce toxic output generation [38].\\nData availability.'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='process in order to reduce toxic output generation [38].\\nData availability.\\nCedille is available under the MIT\\nLicense on the Hugging Face model hub:\\nhttps:\\n//huggingface.co/Cedille/fr-boris, and on our\\nGitHub repository: https://github.com/coteries/\\ncedille-ai. Regarding the French mC4 toxicity scores\\nand toxicity analysis code, please refer to: https://\\ngithub.com/coteries/real-toxicity-prompts.\\nFunding.\\nThis work was funded by, and conducted at,\\nCoteries SA7. The model was trained on Cloud TPUs pro-\\nvided by Google’s TPU Research Cloud program.\\nAcknowledgments.\\nWe thank Sébastien Flury and\\nFrançois Bochatay for their guidance and feedback. Tiago\\nCastanheiro, Flavien Bonvin and Livio Gamassia imple-\\nmented the web-based Playground used to evaluate the\\nmodel. Tiago Castanheiro, Flavien Bonvin, Sacha To-\\nufani, Livio Gamassia, and Kasper Andkjaer tested out\\nmultiple versions of the model. Sébastien Von Roth de-\\nsigned the Cedille logo as well as the visual design of the'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='signed the Cedille logo as well as the visual design of the\\nPlayground and Cedille website8. Sonja Dossenbach as-\\nsembled the dataset of recent French news. We are grateful\\nto EleutherAI for publicly releasing the GPT-J model and\\noffering us support on their Discord server9. We thank the\\nTPU Research Cloud team for their access to Cloud TPUs\\nand their support.\\nReferences\\n[1]\\nAlec Radford et al. “Language models are unsu-\\npervised multitask learners”. In: OpenAI blog 1.8\\n(2019), p. 9.\\n[2]\\nTom B Brown et al. “Language models are few-\\nshot learners”. In: arXiv preprint arXiv:2005.14165\\n(2020).\\n[3]\\nJared Kaplan et al. “Scaling laws for neu-\\nral\\nlanguage\\nmodels”.\\nIn:\\narXiv\\npreprint\\narXiv:2001.08361 (2020).\\n[4]\\nChau Tran et al. “Facebook AI WMT21 news\\ntranslation task submission”. In: arXiv preprint\\narXiv:2108.03265 (2021).\\n[5]\\nNaveen Arivazhagan et al. “Massively multilingual\\nneural machine translation in the wild: Findings and\\nchallenges”. In: arXiv preprint arXiv:1907.05019\\n(2019).'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='challenges”. In: arXiv preprint arXiv:1907.05019\\n(2019).\\n7https://coteries.com\\n8https://cedille.ai\\n9https://discord.gg/zBGx3azzUn\\n6\\n[6]\\nAntoine Simoulin and Benoit Crabbé. “Un mod-\\nèle Transformer Génératif Pré-entrainé pour le _\\nfrançais”. In: Traitement Automatique des Langues\\nNaturelles. ATALA. 2021, pp. 245–254.\\n[7]\\nJulien Launay et al. “PAGnol: An Extra-Large\\nFrench Generative Model”. In: arXiv preprint\\narXiv:2110.08554 (2021).\\n[8]\\nGuillaume Wenzek et al. “Ccnet: Extracting high\\nquality monolingual datasets from web crawl data”.\\nIn: arXiv preprint arXiv:1911.00359 (2019).\\n[9]\\nEmily M Bender et al. “On the Dangers of Stochas-\\ntic Parrots: Can Language Models Be Too Big?”\\nIn: Proceedings of the 2021 ACM Conference on\\nFairness, Accountability, and Transparency. 2021,\\npp. 610–623.\\n[10]\\nIsaac Caswell et al. “Quality at a glance: An au-\\ndit of web-crawled multilingual datasets”. In: arXiv\\npreprint arXiv:2103.12028 (2021).\\n[11]\\nSamuel Gehman et al. “RealToxicityPrompts: Evalu-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='preprint arXiv:2103.12028 (2021).\\n[11]\\nSamuel Gehman et al. “RealToxicityPrompts: Evalu-\\nating neural toxic degeneration in language models”.\\nIn: arXiv preprint arXiv:2009.11462 (2020).\\n[12]\\nJohannes Welbl et al. “Challenges in detox-\\nifying language models”. In: arXiv preprint\\narXiv:2109.07445 (2021).\\n[13]\\nSumanth Dathathri et al. “Plug and play language\\nmodels: A simple approach to controlled text gener-\\nation”. In: arXiv preprint arXiv:1912.02164 (2019).\\n[14]\\nBrian Lester, Rami Al-Rfou, and Noah Constant.\\n“The power of scale for parameter-efﬁcient prompt\\ntuning”. In: arXiv preprint arXiv:2104.08691\\n(2021).\\n[15]\\nNitish Shirish Keskar et al. “Ctrl: A conditional\\ntransformer language model for controllable gener-\\nation”. In: arXiv preprint arXiv:1909.05858 (2019).\\n[16]\\nBen Wang and Aran Komatsuzaki. GPT-J-6B: A 6\\nBillion Parameter Autoregressive Language Model.\\nhttps : / / github . com / kingoflolz / mesh -\\ntransformer-jax. May 2021.\\n[17]'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='https : / / github . com / kingoflolz / mesh -\\ntransformer-jax. May 2021.\\n[17]\\nJianlin Su et al. “Roformer: Enhanced transformer\\nwith rotary position embedding”. In: arXiv preprint\\narXiv:2104.09864 (2021).\\n[18]\\nLinting Xue et al. “mT5: A massively multilin-\\ngual pre-trained text-to-text transformer”. In: arXiv\\npreprint arXiv:2010.11934 (2020).\\n[19]\\nLaura Hanu and Unitary team. Detoxify. https:\\n//github.com/unitaryai/detoxify. 2020.\\n[20]\\nHang Le et al. “Flaubert: Unsupervised language\\nmodel pre-training for french”. In: arXiv preprint\\narXiv:1912.05372 (2019).\\n[21]\\nRobyn Speer. ftfy. Zenodo. Version 5.5. 2019. DOI:\\n10.5281/zenodo.2591652. URL: https://doi.\\norg/10.5281/zenodo.2591652.\\n[22]\\nBen Wang. Mesh-Transformer-JAX: Model-Parallel\\nImplementation of Transformer Language Model\\nwith JAX. https://github.com/kingoflolz/\\nmesh-transformer-jax. May 2021.\\n[23]\\nLeo Gao et al. A framework for few-shot language\\nmodel evaluation. Version v0.0.1. Sept. 2021. DOI:'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='Leo Gao et al. A framework for few-shot language\\nmodel evaluation. Version v0.0.1. Sept. 2021. DOI:\\n10.5281/zenodo.5371628. URL: https://doi.\\norg/10.5281/zenodo.5371628.\\n[24]\\nLeo Gao. On the Sizes of OpenAI API Models.\\nhttps://blog.eleuther.ai/gpt3- model-\\nsizes/. May 2021.\\n[25]\\nStephen Merity et al. “Pointer sentinel mixture mod-\\nels”. In: arXiv preprint arXiv:1609.07843 (2016).\\n[26]\\nPerplexity of ﬁxed-length models. https : / /\\nhuggingface . co / docs / transformers /\\nperplexity. Accessed: 2022-02-04.\\n[27]\\nMoussa Kamal Eddine, Antoine J-P Tixier, and\\nMichalis Vazirgiannis. “BARThez: a skilled pre-\\ntrained french sequence-to-sequence model”. In:\\narXiv preprint arXiv:2010.12321 (2020).\\n[28]\\nShashi Narayan, Shay B Cohen, and Mirella La-\\npata. “Don’t give me the details, just the sum-\\nmary! topic-aware convolutional neural networks\\nfor extreme summarization”. In: arXiv preprint\\narXiv:1808.08745 (2018).\\n[29]\\nChin-Yew Lin. “Rouge: A package for automatic'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='arXiv:1808.08745 (2018).\\n[29]\\nChin-Yew Lin. “Rouge: A package for automatic\\nevaluation of summaries”. In: Text summarization\\nbranches out. 2004, pp. 74–81.\\n[30]\\nMartin d’Hoffschmidt et al. “FQuAD: French\\nquestion answering dataset”. In: arXiv preprint\\narXiv:2002.06071 (2020).\\n[31]\\nPranav Rajpurkar et al. “SQuAD: 100,000+ ques-\\ntions for machine comprehension of text”. In: arXiv\\npreprint arXiv:1606.05250 (2016).\\n[32]\\nLouis Martin et al. “CamemBERT: a tasty\\nfrench\\nlanguage\\nmodel”.\\nIn:\\narXiv\\npreprint\\narXiv:1911.03894 (2019).\\n[33]\\nOndˇrej Bojar et al. “Findings of the 2014 workshop\\non statistical machine translation”. In: Proceedings\\nof the ninth workshop on statistical machine trans-\\nlation. 2014, pp. 12–58.\\n[34]\\nKishore Papineni et al. “Bleu: a method for auto-\\nmatic evaluation of machine translation”. In: Pro-\\nceedings of the 40th annual meeting of the Associa-\\ntion for Computational Linguistics. 2002, pp. 311–\\n318.\\n[35]\\nMatt Post. “A Call for Clarity in Reporting BLEU'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='318.\\n[35]\\nMatt Post. “A Call for Clarity in Reporting BLEU\\nScores”. In: Proceedings of the Third Conference\\non Machine Translation: Research Papers. Belgium,\\nBrussels: Association for Computational Linguis-\\ntics, Oct. 2018, pp. 186–191. URL: https://www.\\naclweb.org/anthology/W18-6319.\\n[36]\\nXiaodong Liu et al. “Very deep transformers for\\nneural machine translation”. In: arXiv preprint\\narXiv:2008.07772 (2020).\\n[37]\\nKatherine Lee et al. “Deduplicating training data\\nmakes language models better”. In: arXiv preprint\\narXiv:2107.06499 (2021).\\n[38]\\nLong Ouyang et al. Training language models to\\nfollow instructions with human feedback. https://\\nopenai.com/blog/instruction-following/.\\nJan. 2022.\\n7\\nSUPPLEMENTARY MATERIAL\\n1\\nExperiments training from scratch\\nGiven the amount of compute and data available, training from scratch rather than ﬁnetuning was considered. We\\nexperimented training Cedille from scratch using both the GPT-2 tokenizer (Cedille-fs-GPT2, vocab size 50,400) and'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the GPT-fr tokenizer (Cedille-fs-GPTfr, vocab size 50.000) for 60k steps using a peak learning rate of 1.2e-4 end\\nlearning rate 1.2e-5, and 7281 warm-up steps. These two variants are therefore only trained on one third of the data\\ncompared to the released Cedille model (150k steps). In order to have a fair comparison we show the result of Cedille\\nafter the same amount of steps (Cedille-60k). All models were trained on the same ﬁltered mC4 dataset, as described in\\nthis work.\\nAs shown in Table S1, Cedille-60k outperforms the from-scratch variants on the WikiText-fr benchmark. However,\\ndue to compute limitations we did not run the variants for longer than 60k steps and it is possible that we could’ve\\nreached similar performance after 150k steps. Furthermore, both variants perform similarly, even though they are using\\na different tokenizer. Due to the variants performing very similarly, we conclude that even though a dedicated French'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tokenizer is a lot more efﬁcient at encoding French text compared to the GPT-2 tokenizer, its beneﬁt with regard to\\nend-task performance was minimal in our experiments.\\nModel\\nPPL (byte)\\nPPL (token)\\nGPT-J\\n1.746\\n5.797\\nCedille-60k\\n1.673\\n4.112\\nCedille-fs-GPT2\\n1.794\\n4.972\\nCedille-fs-GPTfr\\n1.775\\n6.856\\nTable S1: Byte-level and token-level perplexities for the WikiText-fr benchmark. Cedille-60k is the Cedille model at checkpoint 60k\\n(out of 150k), Cedille-fs-GPT2 and Cedille-fs-GPTfr are models trained for 60k steps on the same dataset, but with random weight\\ninitialization.\\n8'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='arXiv:2305.06530v1  [cs.CL]  11 May 2023\\nAfricaNLP workshop at ICLR2022\\nHOW GOOD ARE COMMERCIAL LARGE LANGUAGE\\nMODELS ON AFRICAN LANGUAGES?\\nJessica Ojo\\nMasakhane\\njessicaojo19@gmail.com\\nKelechi Ogueji\\nMasakhane\\nkelechi.ogueji@uwaterloo.ca\\nABSTRACT\\nRecent advancements in Natural Language Processing (NLP) has led to the pro-\\nliferation of large pretrained language models. These models have been shown to\\nyield good performance, using in-context learning, even on unseen tasks and lan-\\nguages. They have also been exposed as commercial APIs as a form of language-\\nmodel-as-a-service, with great adoption. However, their performance on African\\nlanguages is largely unknown. We present a preliminary analysis of commercial\\nlarge language models on two tasks (machine translation and text classiﬁcation)\\nacross eight African languages, spanning different language families and geo-\\ngraphical areas. Our results suggest that commercial language models produce'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='graphical areas. Our results suggest that commercial language models produce\\nbelow-par performance on African languages. We also ﬁnd that they perform bet-\\nter on text classiﬁcation than machine translation. In general, our ﬁndings present\\na call-to-action to ensure African languages are well represented in commercial\\nlarge language models, given their growing popularity.\\n1\\nINTRODUCTION\\nLarge language models have risen to the fore of Natural Language Processing (NLP). These models\\nhave been shown to achieve state-of-the-art performances on several tasks. More recently, focus has\\nshifted from the pretrain-ﬁnetune paradigm (Howard & Ruder, 2018; Devlin et al., 2019; Liu et al.,\\n2019; Raffel et al., 2020) to in-context learning (Brown et al., 2020; Lin et al., 2021; Wei et al.,\\n2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al., 2023). In-context\\nlearning proves that prompting large language models with some task-speciﬁc examples allows them'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='learning proves that prompting large language models with some task-speciﬁc examples allows them\\nperform well on test examples of that task, all without updating the model’s parameters. This has\\nled to reduced computation costs and has made it possible to create language-models-as-a-service\\n(Sun et al., 2022), in the form of commercial Application Programming Interfaces (APIs). Com-\\nmercial language models have become very prevalent. For context, the recently released ChatGPT1\\namassed 100 million users2 in two months, making it the fastest growing consumer app in recent\\nhistory. Given their dominance and inevitable continual rise, it is important to understand how these\\nmodels perform on African languages. Hence, we present a preliminary effort to close this gap by\\nevaluating two commercial large language models using in-context learning on African languages.\\nEvaluation is performed on two tasks - text classiﬁcation and machine translation. Our experiments,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Evaluation is performed on two tasks - text classiﬁcation and machine translation. Our experiments,\\nspanning 8 African languages from different language families and geographical locations, suggests\\nthat commercial language models do not perform well on African languages. In particular, we note\\na large disparity in performance, depending on the evaluation task - models perform better on text\\nclassiﬁcation than machine translation. Our work sheds light on the need to ensure the inclusion\\nof African languages in the development of commercial language models, given their inevitable\\nadoption in our daily lives.\\n1https://chat.openai.com/\\n2https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-faste\\n1\\nAfricaNLP workshop at ICLR2022\\n2\\nRELATED WORK\\n2.1\\nIN-CONTEXT LEARNING\\nThe use of pretrained language models has become the de-facto approach to solving natural language'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='The use of pretrained language models has become the de-facto approach to solving natural language\\nprocessing (NLP) tasks. Previous models such as BERT (Devlin et al., 2019), RoBERTa (Liu et al.,\\n2019) and T5 (Raffel et al., 2020) largely follow a pretrain-ﬁnetune setting (Howard & Ruder,\\n2018). In this method, the pretrained model is ﬁnetuned on a downstream task, such as text classi-\\nﬁcation, and then used for that task. While this works very well, it has several downsides. For one,\\nﬁnetuned models are usually task-speciﬁc and this means one has to maintain separate models for\\nseparate tasks. Furthermore, the growing size of pretrained language models (Kaplan et al., 2020)\\nmeans that it is becoming increasingly expensive to ﬁnetune such gigantic models. One solution\\nthat has proven popular in recent times is in-context learning (Brown et al., 2020; Schick & Sch¨utze,\\n2021; Wei et al., 2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al.,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='2023). The core idea behind this method is to enable pretrained language models learn from ex-\\namples within the context. In this setting, a user prompts a pretrained language model with a few\\nlabelled examples of a task following a speciﬁc pattern, and unlabelled examples that need to be pre-\\ndicted on (Wei et al., 2022c; Liu et al., 2022; Wei et al., 2022b). In-context learning can also work\\nin a zero-shot setting where no labelled examples are included in the prompt. In-context learning\\nworks surprisingly well and is very efﬁcient since there is no update to the model’s parameters. As\\na result, computation costs are signiﬁcantly reduced and it becomes possible to expose language\\nmodels as a service (Sun et al., 2022). Commercial APIs are heavily reliant on in-context learning\\nas this is the primary method through which users interact 3 with the models4.\\n2.2\\nMULTILINGUAL IN-CONTEXT LEARNING\\nLarge language models have proven successful in multilingual settings.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Large language models have proven successful in multilingual settings.\\nLin et al. (2021) train\\nseveral multilingual models, of which the largest one (7.5B parameters) sets a state-of-the-art in\\nfew-shot learning on more than 20 languages. Their model outperforms GPT3 on several mul-\\ntilingual tasks. Muennighoff et al. (2022) perform multitask prompted ﬁnetuning on multilingual\\npretrained language models and observe impressive zero-shot generalization to tasks in unseen lan-\\nguages. Following ﬁndings from Blevins & Zettlemoyer (2022) that non-English dataset present in\\nthe pretraining corpora of English language models explains their surprising cross-lingual ability,\\nChowdhery et al. (2022) deliberately introduce non-English corpora (≈22%) into the pretraining\\ncorpora of their PaLM model and achieve impressive few-shot multilingual performance. Shi et al.\\n(2022) evaluate GPT3 and PaLM on a newly introduced grade school mathematics multilingual'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='(2022) evaluate GPT3 and PaLM on a newly introduced grade school mathematics multilingual\\nbenchmark. They ﬁnd that using prompts with intermediate reasoning steps in English consistently\\nled to competitive or better results than those written in the native language of the question. They\\nalso set a new state-of-the-art on a common-sense reasononing multilingual benchmark, XCOPA\\n(Ponti et al., 2020), using few-shot examples. Zhao & Sch¨utze (2021) show that prompting yields\\nbetter cross-lingual transfer in few-shot settings than ﬁnetuning and in-language training of multilin-\\ngual natural language inference. Furthermore, Winata et al. (2021) evaluate the multilingual ability\\nof GPT (Radford et al., 2019) and T5 (Raffel et al., 2020) models on multi-class text classiﬁcation,\\nand ﬁnd that they work well on non-English languages given a few English examples. Concurrent\\nwork (Jiao et al., 2023) evaluate ChatGPT on machine translation and ﬁnd that, while it is compet-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='work (Jiao et al., 2023) evaluate ChatGPT on machine translation and ﬁnd that, while it is compet-\\nitive with other commercial translation APIs such as Google translate5, it is less robust on other\\ndomains such as biomedical. Another concurrent work (Zhang et al., 2023) conducts a study on\\nthe performance of GLM (Zeng et al., 2022) on machine translation. They note several interesting\\nﬁndings on the effect of prompt template, examples and language. Despite the plethora of works\\non multilingual prompting, little to no African languages are usually contained in the evaluation\\nsets of nearly all of these works. When present, they are often obtained by translating the existing\\ndatasets of other languages (Yu et al., 2022) This method has been shown to contain artifacts that\\ncan inﬂate the performance of models evaluated on such datasets (Artetxe et al., 2020). Our work is\\northogonal to all of this works because we focus solely on commercial language model APIs, given'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='orthogonal to all of this works because we focus solely on commercial language model APIs, given\\ntheir prevalence. The closest to our work is concurrent by Abott et al. (2023), who evaluate GPT\\n3https://platform.openai.com/docs/guides/completion/prompt-design\\n4https://docs.cohere.ai/docs/prompt-engineering\\n5https://translate.google.com/\\n2\\nAfricaNLP workshop at ICLR2022\\n3.5 on Named Entity Recognition and Machine Translation on only isiZulu. However, our work is\\ndifferent from this as we compare two commercial APIs in the evaluation of text classiﬁcation and\\nMachine Translation across 8 African language.\\n3\\nMETHODOLOGY\\n3.1\\nDATASETS\\nEvaluation is done on two tasks - text classiﬁcation and machine translation.\\n3.1.1\\nTEXT CLASSIFICATION\\nWe use the news topic classiﬁcation datasets from Hedderich et al. (2020) and Alabi et al. (2022).\\nWe select the Hausa (hau) language from Hedderich et al. (2020) which has 5 categories. Pretrained'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='We select the Hausa (hau) language from Hedderich et al. (2020) which has 5 categories. Pretrained\\nlanguage models have been shown to work very well on this dataset in both few and zero-shot\\nsettings. The dataset from Alabi et al. (2022) covers ﬁve languages, out of which we select four\\n- Nigerian Pidgin (pcm), Malagasay (mlg), and Somali (som), isiZulu (zul). Each language has 5\\ncategories, except Somali which has 6. For both datasets, we use the train, validation and test splits\\nas released by the authors. We select these languages because they cover different language families\\nand geographical areas.\\n3.1.2\\nMACHINE TRANSLATION\\nWe use the MAFAND-MT machine translation dataset from Adelani et al. (2022) which covers 16\\nAfrican languages. Running translation on commercial APIs is cumbersome and expensive, hence\\nwe select 5 languages from the 16. The ﬁve languages are isiZulu (zul), Yoruba (yor), Nigerian'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='we select 5 languages from the 16. The ﬁve languages are isiZulu (zul), Yoruba (yor), Nigerian\\nPidgin (pcm), Swahili (Swa) and Lugala (lug). We use the splits as released by the authors.\\n3.2\\nMODELS\\nTwo commercial APIs6 are considered: ChatGPT7 and Cohere8. We consider both these APIs be-\\ncause they are arguably the most popular ones9. ChatGPT is based on the Instruct-GPT models\\n(Ouyang et al., 2022). It is optimized for conversations and has been shown to be capable of sev-\\neral NLP tasks including text classiﬁcation, machine translation, question answering, and so on.\\nWe use Cohere’s multilingual model10 which is based on their multilingual embedding model11.\\nThe embedding model supports 100 languages, including 15 African languages. All the languages\\nwe consider, except Nigerian Pidgin, are supported by the model. However, given the linguistic\\nproximity of Nigerian Pidgin to English (Faraclas, 2008; Ogueji & Ahia, 2019; Chang et al., 2020;'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='proximity of Nigerian Pidgin to English (Faraclas, 2008; Ogueji & Ahia, 2019; Chang et al., 2020;\\nAhia & Ogueji, 2020a; Lent et al., 2021; 2022), the model should be able to perform well on the\\ndataset.\\n3.3\\nPROMPTING AND EVALUATION\\nWe describe our prompting and evaluation approaches for text classiﬁcation and machine translation.\\n3.3.1\\nTEXT CLASSIFICATION\\nFor Cohere, we use the Classify12 endpoint and follow the format speciﬁed in the API documenta-\\ntion13. When using ChatGPT, we design several prompts ourselves and we also ask ChatGPT for\\n6Experiments were run between January 22, 2023 and February 5, 2023.\\n7https://chat.openai.com/\\n8https://www.cohere.ai\\n9https://venturebeat.com/uncategorized/openai-rival-cohere-launches-language-model-api/\\n10https://docs.cohere.ai/changelog/multilingual-support-for-coclassify\\n11https://docs.cohere.ai/docs/multilingual-language-models\\n12https://api.cohere.ai/classify\\n13https://docs.cohere.ai/reference/classify\\n3\\nAfricaNLP workshop at ICLR2022'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='13https://docs.cohere.ai/reference/classify\\n3\\nAfricaNLP workshop at ICLR2022\\nthe best prompt for classiﬁcation, following concurrent work (Jiao et al., 2023). We perform some\\ninitial evaluation of the prompts and select the best one.\\nOur best prompt is shown below:\\nGiven the following news headlines and their categories:\\nText:\\n{Sentence}\\nCategory:\\n{Label}\\nPlease classify the following news headlines into one of:\\n{Label List}.\\nText:\\n{Sentence}\\nCategory:\\nWhere Sentence is the news headline to be classiﬁed, Category is the news topic, and LabelList\\nis a comma separated list of all unique labels for that language.\\nFor both models, we supply two example demonstrations per category from the training set. We\\nrandomly sample 100 samples from the test set for each language and evaluate on this. Both demon-\\nstrations and evaluation are done across two random seeds, such that we sample distinct demonstra-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='strations and evaluation are done across two random seeds, such that we sample distinct demonstra-\\ntions and test samples for each language with each random seed. We report the average F1 score for\\neach language across both seeds. It should be noted that we decide to evaluate on a subset of the test\\nset because of the tedious nature of obtaining results ChatGPT.\\n3.3.2\\nMACHINE TRANSLATION\\nWe do not use Cohere for machine translation because its generation API currently supports only\\nEnglish14. ChatGPT is used for all our machine translation evaluations. Preliminary results from\\ncomparing few-shot to zero-shot translations on Nigerian Pidgin suggested no noticeable difference.\\nHence, we perform all translations in a zero-shot manner because of the tedious nature and low-\\nthroughput of obtaining results from ChatGPT.\\nWe use the prompt used in concurrent work (Jiao et al., 2023) which is shown below:\\nPlease provide the [TGT] translation for these sentences:\\n{Sentence}\\n{Sentence}'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Please provide the [TGT] translation for these sentences:\\n{Sentence}\\n{Sentence}\\nWhere T GT is the target language to be translated into, and Sentence is a sentence to be translated.\\nWe sample 100 sentences from the test set of each language and evaluate translating this to and from\\nEnglish. We report the BLEU score (Papineni et al., 2002) which is calculated using SacreBLEU\\n(Post, 2018).\\nIt has been shown that English prompts perform better, on average, than in-language prompts\\n(Lin et al., 2021; Shi et al., 2022), so we do not explore prompting in the target language for both\\ntasks.\\n4\\nRESULTS\\n4.1\\nTEXT CLASSIFICATION\\nResults are reported in table 1. As we can see, both commercial models fall well below the current\\nstate of the art. Surprisingly, Cohere’s multilingual embedding model is the worst performer, despite\\nsupporting almost all the languages evaluated on. Nigerian Pidgin has the highest score in the Cohere'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='results. This is most likely as a result of its close linguistic relationship with English language, which\\nusually makes up a signiﬁcant portion of the pretraining corpora of pretrained language models\\n(Wenzek et al., 2020; Gao et al., 2020; Laurenc¸on et al., 2022). ChatGPT is the best performing\\ncommercial model, and it gets above average F1 scores on all languages. Similar to Cohere, Hausa\\n14https://docs.cohere.ai/docs/generation-card#technical-notes\\n4\\nAfricaNLP workshop at ICLR2022\\nTable 1: Text Classiﬁcation Results: We report the F1 scores for the commercial models. We also\\nreport the current state of the art result obtained from Alabi et al. (2022). Best results per language\\nare in bold.\\nLanguage\\nCohere\\nChatGPT\\nCurrent SOTA\\nHausa (hau)\\n43.2\\n77.9\\n91.2\\nMalagasay (mlg)\\n35.0\\n51.1\\n67.3\\nNigerian Pidgin (pcm)\\n48.8\\n73.4\\n82.2\\nSomali (som)\\n28.4\\n51.3\\n79.9\\nisiZulu (zul)\\n24.8\\n54.8\\n79.6\\nand Nigerian Pidgin possess the highest F1 scores. The details of ChatGPT’s pretraining corpora'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='and Nigerian Pidgin possess the highest F1 scores. The details of ChatGPT’s pretraining corpora\\nand exact training methods are unknown, so it is hard to hypothesize a reason for its relatively\\ngood performance. However, it is very likely that its pretraining corpora contains non-English text.\\nFurthermore, multilinguality has been shown to be a part of possible emergent abilities of large\\nlanguage models (Wei et al., 2022b), so the performance is not entirely surprising. Overall, both\\ncommercial models fall signiﬁcantly short of the current state of the art. While ChatGPT is the\\nbetter performer, Cohere’s performance is especially surprising since it has been trained on almost\\nall of the evaluated languages15.\\n4.2\\nMACHINE TRANSLATION\\nResults are reported in table 2. ChatGPT has very poor performance on machine translation, ob-\\ntaining BLEU scores of less than 1.0 on all languages. This is very surprising given its good per-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='taining BLEU scores of less than 1.0 on all languages. This is very surprising given its good per-\\nformance on text classiﬁcation. Our results agree with concurrent work (Abott et al., 2023) which\\nﬁnds that GPT 3.5 obtains a BLEU score of 0 on Zulu to English translation. Our ﬁndings are\\nalso somewhat similar to (Jiao et al., 2023), which reports signiﬁcantly worse performance on Ro-\\nmanian, a relatively low-resource language, than on higher-resource languages like English and\\nGerman. While the BLEU scores are too low to draw conclusions from, ChatGPT seems to perform\\nbetter when translating into English than from it. This agrees with previous works (Belinkov et al.,\\n2017; Bugliarello et al., 2020) which show that it is harder to translate into morphologically rich\\nlanguages, like African ones, than morphologically poor ones like English. In general, our results\\nsuggest that ChatGPT is not good enough for translation involving African languages. It also sug-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='suggest that ChatGPT is not good enough for translation involving African languages. It also sug-\\ngests that ChatGPT performs better on sequence classiﬁcation tasks than it does on text generation\\ntasks for African languages.\\n5\\nERROR ANALYSIS\\nWe take a closer look at some errors made by the model on machine translation. Speciﬁcally, we\\nfocus on two languages - Yoruba and Nigerian Pidgin - because they are understood by the authors.\\nFor each language, we randomly select 3 samples and discuss their predictions.\\n5.1\\nYORUBA TRANSLATIONS\\nSamples are shown in table 4. Looking at sample 1, ChatGPT mistranslates “B´ı omi b´a gb´on´a\\nju b´ı ´o s.e ye. lo.” which means “When water becomes too hot” to “Water is poured into the con-\\ntainer”. Furthermore, the English to Yoruba translation is completely wrong and riddled with a lot\\nof misspellings and grammatical errors. In sample 3, ChatGPT gets the translations wrong and also'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='of misspellings and grammatical errors. In sample 3, ChatGPT gets the translations wrong and also\\ntransposes the words “ob`ınrin” (woman) and “ok`unrin” (man) in the translations. One notable ob-\\nservation across English to Yoruba translations is that ChatGPT does not always include diacritics\\nin its Yoruba predictions. Overall, ChatGPT does a really poor job in translating in either direc-\\ntion. The hallucinatory nature of the model predictions is evident, as all translations barely have any\\ncorrelation with the original sentences.\\n15https://txt.cohere.ai/multilingual/\\n5\\nAfricaNLP workshop at ICLR2022\\nTable 2: Machine Translation Results: We report the BLEU scores of the translations from ChatGPT.\\nWe also report the current state of the art result obtained from Adelani et al. (2022)\\nand NLLB Team et al. (2022). Best results per language are in bold.\\nTranslation Direction\\nChatGPT\\nCurrent SOTA\\nLug→Eng\\n0.16\\n30.9\\nEng→Lug\\n0.13\\n25.8\\nPcm→Eng\\n0.22\\n45.2\\nEng→Pcm\\n0.20\\n35.0\\nSwa→Eng\\n0.18\\n39.3'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Lug→Eng\\n0.16\\n30.9\\nEng→Lug\\n0.13\\n25.8\\nPcm→Eng\\n0.22\\n45.2\\nEng→Pcm\\n0.20\\n35.0\\nSwa→Eng\\n0.18\\n39.3\\nEng→Swa\\n0.15\\n30.7\\nYor→Eng\\n0.10\\n24.4\\nEng→Yor\\n0.12\\n14.4\\nZul→Eng\\n0.31\\n40.3\\nEng→Zul\\n0.26\\n22.9\\n5.2\\nNIGERIAN PIDGIN TRANSLATIONS\\nSamples are shown in table 3. Looking at the Nigerian Pidgin sentences, we can see the language’s\\nlinguistic similarity with English. Interestingly, while the ChatGPT predictions yield low BLEU\\nscores, they are somewhat semantically similar to the ground truth. However, there notable errors\\nmade across board. For example, focusing on the Nigerian Pidgin to English predictions in sample\\n2, there are tense errors. Also, the model seems to misunderstand what “numbers” refers to in the\\ninput text, as its prediction indicates it confuses it for the number of goals. Furthermore, across\\nall samples, the model seems to be poor at translating certain English words to Nigerian Pidgin\\nwords, such as “The” to “Di”, so it always retains the original English word. In general, while the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='words, such as “The” to “Di”, so it always retains the original English word. In general, while the\\npredictions in both directions for all samples have notable issues, they are more semantically similar\\nto the ground truth than the BLEU scores suggests. This highlights the drawbacks of automatic\\nmetrics based on N-gram overlap.\\n6\\nCONCLUSION\\nWe have presented a preliminary analysis of commercial language models on African languages.\\nJoshi et al. (2020) note that over 90% of the world’s 7000+ languages are under-studied by the NLP\\ncommunity. Despite the 2000+ spoken languages and over 1 billion people in Africa16, its languages\\nmake up a signiﬁcant portion of the under-studied languages (Blasi et al., 2022). While there have\\nbeen several efforts (∀et al., 2020; Ahia & Ogueji, 2020b; Adelani et al., 2021; Ogueji et al., 2021;\\nNLLB Team et al., 2022; Alabi et al., 2022; Dossou et al., 2022; Adebara et al., 2022) to close this'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='gap, there is still a lot of work to be done. This is even more pertinent given the rapid commercial\\nadoption of large scale language models. Our ﬁndings suggest that these models do not perform\\nwell on African languages. In particular, there seems to be performance disparity, depending on the\\ntask evaluated. Although our work reports what is, to the best of our knowledge, the ﬁrst evaluation\\nof commercial language models on African languages, we note that this only a preliminary study\\nthat needs to be further advanced. Future works could focus on more advanced prompting methods\\nsuch as chain-of-thought (Wei et al., 2022c) and pivot prompting (Jiao et al., 2023), evaluation of\\nmore test samples and a wider variety of tasks. While our ﬁnding may be impacted by the sampled\\n16https://en.wikipedia.org/wiki/Demographics_of_Africa\\n6\\nAfricaNLP workshop at ICLR2022\\nTable 3: Examples of Nigerian Pidgin translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nNigerian Pid-\\ngin Sentence'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Sample 1\\nSample 2\\nSample 3\\nNigerian Pid-\\ngin Sentence\\nCommission head, Simon\\nByabakama,\\nassure\\ndi\\nnation on top live TV\\nfor\\nThursday\\nevening\\nafta polls don close say\\nresult don dey enter for\\ndi national tally centre\\ndespite\\ndi\\nnationwide\\ninternet blackout\\nDi goal be give Eyimba\\nsome hope as dem kontinu\\nto press for plunty nomba\\nto secure a point at least\\nNa im inauguartion be\\ndi ﬁrst time wey elected\\nleaders dey handova give\\neach oda for Niger history\\nfor over 60 years wey dem\\ndon get independence, but\\ndi attack from jihadist and\\nsome kind plan to do coup\\ndon spoil di celebrate.\\nEnglish Sen-\\ntence\\nCommission head, Simon\\nByabakama, assured the\\nnation on live TV on\\nThursday\\nevening\\nafter\\npolls closed that results\\nwere arriving at the na-\\ntional tally centre despite\\nthe\\nnationwide\\ninternet\\nblackout.\\nThe goal gave Enyimba\\nsome hope as they contin-\\nued to press in numbers to\\nat least secure a point\\nHis inauguration marks\\nthe\\nﬁrst\\nhandover\\nbe-\\ntween\\nelected\\nleaders\\nin Niger’s 60-year post-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='His inauguration marks\\nthe\\nﬁrst\\nhandover\\nbe-\\ntween\\nelected\\nleaders\\nin Niger’s 60-year post-\\nindependence\\nhistory,\\nbut jihadist attacks and\\nan\\nalleged\\nattempted\\ncoup have overshadowed\\nceremonies.\\nChatGPT\\nTranslation\\nPcm→Eng\\nCommission head, Simon\\nByabakama, assured the\\nnation on live TV on\\nThursday\\nevening\\nafter\\nthe polls had closed that\\nthe results were entering\\nthe national tally center\\ndespite the nationwide in-\\nternet blackout.\\nThe goal was to give Ey-\\nimba some hope as they\\ncontinue to press for a suf-\\nﬁcient number of goals to\\nsecure at least one point.\\nThe inauguration marked\\nthe\\nﬁrst\\ntime\\nin\\nover\\n60 years of independence\\nthat elected leaders have\\nhanded\\npower\\nto\\neach\\nother in Niger’s history,\\nbut attacks by jihadists\\nand plans for a coup have\\ndisrupted the celebrations\\nChatGPT\\nTranslation\\nEng→Pcm\\nSimon Byabakama wey\\ndey head the Commis-\\nsion, e talk for TV on\\nThursday night after elec-\\ntion close say the result\\ndon dey reach the centre\\nwhere dem dey count the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tion close say the result\\ndon dey reach the centre\\nwhere dem dey count the\\nresult even though inter-\\nnet all over the place dey\\ncut.\\nThe goal give Enyimba\\nsome hope as dem still\\ndey press wey full force to\\nﬁt get at least one point.\\nThe day wey dem swear\\nam\\nfor\\nofﬁce,\\nna\\nthe\\nﬁrst time wey leader wey\\nget vote go hand over to\\nanother leader since 60\\nyears after independence\\nfor Niger but the attacks\\nwey the bad people wey\\ndey carry gun dey do, and\\nthe way wey dem try put\\neye for the power no gree\\nam to happen make e no\\ndey sweet for the day.\\ntest data, the use of the BLEU automatic metric (Callison-Burch et al., 2006; Mathur et al., 2020;\\nFreitag et al., 2020), prompting template and prompting examples, it nonetheless presents a call-to-\\naction to ensure African languages are well represented in the age of commercial large language\\nmodels.\\n7\\nAfricaNLP workshop at ICLR2022\\nTable 4: Examples of Yoruba translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nYoruba Sen-\\ntence'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Table 4: Examples of Yoruba translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nYoruba Sen-\\ntence\\nB´ı omi b´a gb´on´a ju b´ı ´o s.e\\nye. lo. (t`ab´ı b´ı ´o b´a tut`u j`u)\\n`awo.n iy`un y´o`o l`e ew`e omi\\n— t´ı y´o`o s´ı p`ad´an`u o.wo. t`o\\n´o ´n ﬁo`unje. n`u ´un.\\nK´ı ´o t´o de `e´er´oo `ago. n´a`a,\\nerin os. `u me.e.f`a n´a`a ti lu\\nok`un.\\n`Ike.l`u t´ı ´o ko.\\nlu `awo.n\\nob`ınrin wo.ny´ı (`ati `awo.n\\no.k`unrin\\nkan)\\nror`o\\nb´ı\\ne.ranko e.h`ann`a.\\nEnglish Sen-\\ntence\\nWhen water becomes too\\nhot (or too cold) the corals\\nexpel the algae — and\\nwith it, its main source of\\nfood.\\nBefore his arrival at the\\ncamp, the six-month-old\\nwas snared in a wire trap.\\nThe\\nattacks\\non\\nthese\\nwomen (and some men)\\nare vicious and inhuman.\\nChatGPT\\nTranslation\\nYor→Eng\\nWater is poured into the\\ncontainer (or it is ﬁlled)\\nuntil the container is full -\\nwhen it overﬂows, the ex-\\ncess water is poured out.\\nIf you do not pay attention\\nto your work, the work of\\nothers will be affected.\\nThe\\ntradition\\nrequires'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='to your work, the work of\\nothers will be affected.\\nThe\\ntradition\\nrequires\\nmen to cover their heads\\n(and sometimes women\\ntoo) in public places.\\nChatGPT\\nTranslation\\nEng→Yor\\nTi omi ba n mu ki i fe.e.\\n(tabi ki i fe.e.) awo.n corals\\nni wo.n ﬁomi omi po. - ati\\nni ito.ju re., iru ibe.re. ti a n\\npa.\\nBayi o ti gba lo. si ibeere,\\no.mo. to.lo.ti si igba ni a ti\\ndara ju o.nu.\\n`Id´am`o\\nge.ge.\\nb´ı\\ni\\n`awo.\\nn\\no.mo.-`om`o-w´e\\n(`ati\\nn´ı\\nk`ok`or`o)\\nn`ıy´ın\\nni\\n`aj`ın`a\\n`ıw´ej`u `ıto.lo.mo. w´aj`u.\\nREFERENCES\\nJade\\nAbott,\\nBonaventure\\nDossou,\\nand\\nRooweither\\nMbuya.\\nCom-\\nparing\\nafrica-centric\\nmodels\\nto\\nopenai’s\\ngpt3.5,\\n2023.\\nURL\\nhttps://lelapa.ai/comparing-africa-centric-models-to-openais-gpt3-5-2/.\\nIfe Adebara, AbdelRahim Elmadany, Muhammad Abdul-Mageed, and Alcides Alcoba In-\\nciarte.\\nSerengeti:\\nMassively multilingual language models for africa, 2022.\\nURL\\nhttps://arxiv.org/abs/2212.10785.\\nDavid Adelani, Jesujoba Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='David Adelani, Jesujoba Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter,\\nDietrich Klakow, Peter Nabende, Ernie Chang, Tajuddeen Gwadabe, Freshia Sackey, Bonaven-\\nture F. P. Dossou, Chris Emezue, Colin Leong, Michael Beukman, Shamsuddeen Muhammad,\\nGuyo Jarso, Oreen Yousuf, Andre Niyongabo Rubungo, Gilles Hacheme, Eric Peter Wairagala,\\nMuhammad Umair Nasir, Benjamin Ajibade, Tunde Ajayi, Yvonne Gitau, Jade Abbott, Mo-\\nhamed Ahmed, Millicent Ochieng, Anuoluwapo Aremu, Perez Ogayo, Jonathan Mukiibi, Fa-\\ntoumata Ouoba Kabore, Godson Kalipe, Derguene Mbaye, Allahsera Auguste Tapo, Victoire\\nMemdjokam Koagne, Edwin Munkoh-Buabeng, Valencia Wagner, Idris Abdulmumin, Ayodele\\nAwokoya, Happy Buzaaba, Blessing Sibanda, Andiswa Bukula, and Sam Manthalu. A few thou-\\nsand translations go a long way! leveraging pre-trained models for African news translation. In\\nProceedings of the 2022 Conference of the North American Chapter of the Association for Com-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Proceedings of the 2022 Conference of the North American Chapter of the Association for Com-\\nputational Linguistics: Human Language Technologies, pp. 3053–3070, Seattle, United States,\\nJuly 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.223.\\nURL https://aclanthology.org/2022.naacl-main.223.\\nDavid Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D’souza, Julia Kreutzer, Constan-\\ntine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, Stephen\\nMayhew, Israel Abebe Azime, Shamsuddeen H. Muhammad, Chris Chinenye Emezue, Joyce\\n8\\nAfricaNLP workshop at ICLR2022\\nNakatumba-Nabende, Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau, Derguene Mbaye, Je-\\nsujoba Alabi, Seid Muhie Yimam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani, Rubungo An-\\ndre Niyongabo, Jonathan Mukiibi, Verrah Otiende, Iroro Orife, Davis David, Samba Ngom,\\nTosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chia-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chia-\\nmaka Chukwuneke, Nkiruka Odu, Eric Peter Wairagala, Samuel Oyerinde, Clemencia Siro, To-\\nbius Saul Bateesa, Temilola Oloyede, Yvonne Wambui, Victor Akinode, Deborah Nabagereka,\\nMaurice Katusiime, Ayodele Awokoya, Mouhamadane MBOUP, Dibora Gebreyohannes, Henok\\nTilaye, Kelechi Nwaike, Degaga Wolde, Abdoulaye Faye, Blessing Sibanda, Orevaoghene\\nAhia, Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo,\\nAdewale Akinfaderin, Tendai Marengereke, and Salomey Osei.\\nMasakhaNER: Named En-\\ntity Recognition for African Languages.\\nTransactions of the Association for Computational\\nLinguistics, 9:1116–1131, 10 2021.\\nISSN 2307-387X.\\ndoi: 10.1162/tacl a 00416.\\nURL\\nhttps://doi.org/10.1162/tacl_a_00416.\\nOrevaoghene Ahia and Kelechi Ogueji. Towards supervised and unsupervised neural machine trans-\\nlation baselines for nigerian pidgin. ArXiv, abs/2003.12660, 2020a.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='lation baselines for nigerian pidgin. ArXiv, abs/2003.12660, 2020a.\\nOrevaoghene Ahia and Kelechi Ogueji.\\nTowards supervised and unsupervised neural ma-\\nchine translation baselines for nigerian pidgin.\\nCoRR, abs/2003.12660, 2020b.\\nURL\\nhttps://arxiv.org/abs/2003.12660.\\nJesujoba O. Alabi, David Ifeoluwa Adelani, Marius Mosbach, and Dietrich Klakow.\\nAdapting\\npre-trained language models to African languages via multilingual adaptive ﬁne-tuning. In Pro-\\nceedings of the 29th International Conference on Computational Linguistics, pp. 4336–4349,\\nGyeongju, Republic of Korea, October 2022. International Committee on Computational Lin-\\nguistics. URL https://aclanthology.org/2022.coling-1.382.\\nMikel Artetxe, Gorka Labaka, and Eneko Agirre.\\nTranslation artifacts in cross-lingual\\ntransfer learning.\\nIn Proceedings of the 2020 Conference on Empirical Methods in\\nNatural Language Processing (EMNLP), pp. 7674–7684, Online, November 2020. Asso-\\nciation for Computational Linguistics.\\ndoi:'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ciation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2020.emnlp-main.618.\\nURL\\nhttps://aclanthology.org/2020.emnlp-main.618.\\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do neural\\nmachine translation models learn about morphology? In Proceedings of the 55th Annual Meeting\\nof the Association for Computational Linguistics (Volume 1: Long Papers), pp. 861–872, Vancou-\\nver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1080.\\nURL https://aclanthology.org/P17-1080.\\nDamian Blasi, Antonios Anastasopoulos, and Graham Neubig. Systematic inequalities in language\\ntechnology performance across the world’s languages. In Proceedings of the 60th Annual Meet-\\ning of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5486–5505,\\nDublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.\\nacl-long.376. URL https://aclanthology.org/2022.acl-long.376.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='acl-long.376. URL https://aclanthology.org/2022.acl-long.376.\\nTerra Blevins and Luke Zettlemoyer. Language contamination helps explain the cross-lingual capa-\\nbilities of english pretrained models, 2022. URL https://arxiv.org/abs/2204.08110.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-\\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\\nAriel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,\\nDaniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz\\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei.\\nLanguage models are few-shot learners.\\nIn\\nH. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural\\nInformation Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL\\nhttps://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Pap\\nEmanuele Bugliarello, Sabrina J. Mielke, Antonios Anastasopoulos, Ryan Cotterell, and Naoaki\\nOkazaki. It’s easier to translate out of English than into it: Measuring neural translation difﬁculty\\nby cross-mutual information. In Proceedings of the 58th Annual Meeting of the Association for\\n9\\nAfricaNLP workshop at ICLR2022\\nComputational Linguistics, pp. 1640–1649, Online, July 2020. Association for Computational\\nLinguistics. URL https://www.aclweb.org/anthology/2020.acl-main.149.\\nChris Callison-Burch, Miles Osborne, and Philipp Koehn. Re-evaluating the role of Bleu in ma-\\nchine translation research. In 11th Conference of the European Chapter of the Association for\\nComputational Linguistics, pp. 249–256, Trento, Italy, April 2006. Association for Computa-\\ntional Linguistics. URL https://aclanthology.org/E06-1032.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tional Linguistics. URL https://aclanthology.org/E06-1032.\\nErnie Chang,\\nDavid Ifeoluwa Adelani,\\nXiaoyu Shen,\\nand Vera Demberg.\\nUnsuper-\\nvised pidgin text generation by pivoting english data and self-training, 2020.\\nURL\\nhttps://arxiv.org/abs/2003.08272.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\\nZoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\\nMoreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\\nEck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\\n2022. URL https://arxiv.org/abs/2204.02311.\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan\\nLi, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu,\\nZhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pel-\\nlat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao,\\nYanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,\\nAdam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-ﬁnetuned language\\nmodels, 2022. URL https://arxiv.org/abs/2210.11416.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\\nBERT: Pre-training of\\ndeep bidirectional transformers for language understanding. In Proceedings of the 2019 Con-\\nference of the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Min-\\nnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL\\nhttps://www.aclweb.org/anthology/N19-1423.\\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun,\\nJingjing Xu, Lei Li, and Zhifang Sui.\\nA survey for in-context learning, 2023.\\nURL\\nhttps://arxiv.org/abs/2301.00234.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='A survey for in-context learning, 2023.\\nURL\\nhttps://arxiv.org/abs/2301.00234.\\nBonaventure F. P. Dossou, Atnafu Lambebo Tonja, Oreen Yousuf, Salomey Osei, Abigail Oppong,\\nIyanuoluwa Shode, Oluwabusayo Olufunke Awoyomi, and Chris Chinenye Emezue. Afrolm: A\\nself-active learning-based multilingual pretrained language model for 23 african languages, 2022.\\nNicholas Faraclas. Nigerian pidgin english: morphology and syntax. Varieties of English: Africa,\\nSouth and Southeast Asia, 4:340–367, 2008.\\n∀, Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa, Tajudeen Kolawole,\\nTaiwo Fagbohungbe, Solomon Oluwole Akinola, Shamsuddee Hassan Muhammad, Salomon\\nKabongo, Salomey Osei, et al. Participatory research for low-resourced machine translation:\\nA case study in african languages. Findings of EMNLP, 2020.\\nMarkus Freitag, David Grangier, and Isaac Caswell.\\nBLEU might be guilty but refer-\\nences are not innocent.\\nIn Proceedings of the 2020 Conference on Empirical Meth-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ences are not innocent.\\nIn Proceedings of the 2020 Conference on Empirical Meth-\\nods in Natural Language Processing (EMNLP), pp. 61–71, Online, November 2020. As-\\nsociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2020.emnlp-main.5.\\nURL\\nhttps://aclanthology.org/2020.emnlp-main.5.\\n10\\nAfricaNLP workshop at ICLR2022\\nLeo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason\\nPhang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile:\\nAn 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.\\nMichael A. Hedderich, David Adelani, Dawei Zhu, Jesujoba Alabi, Udia Markus, and Diet-\\nrich Klakow.\\nTransfer learning and distant supervision for multilingual transformer mod-\\nels: A study on African languages.\\nIn Proceedings of the 2020 Conference on Empirical\\nMethods in Natural Language Processing (EMNLP), pp. 2580–2591, Online, November 2020.\\nAssociation for Computational Linguistics.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Association for Computational Linguistics.\\ndoi: 10.18653/v1/2020.emnlp-main.204.\\nURL\\nhttps://www.aclweb.org/anthology/2020.emnlp-main.204.\\nJeremy Howard and Sebastian Ruder.\\nUniversal language model ﬁne-tuning for text clas-\\nsiﬁcation.\\nIn Proceedings of the 56th Annual Meeting of the Association for Compu-\\ntational Linguistics (Volume 1:\\nLong Papers), pp. 328–339, Melbourne, Australia, July\\n2018. Association for Computational Linguistics.\\ndoi:\\n10.18653/v1/P18-1031.\\nURL\\nhttps://aclanthology.org/P18-1031.\\nWenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. Is chatgpt a good\\ntranslator? a preliminary study, 2023. URL https://arxiv.org/abs/2301.08745.\\nPratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. The state and\\nfate of linguistic diversity and inclusion in the NLP world.\\nIn Proceedings of the 58th An-\\nnual Meeting of the Association for Computational Linguistics, pp. 6282–6293, Online, July'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='nual Meeting of the Association for Computational Linguistics, pp. 6282–6293, Online, July\\n2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.560. URL\\nhttps://aclanthology.org/2020.acl-main.560.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\\nmodels. CoRR, abs/2001.08361, 2020. URL https://arxiv.org/abs/2001.08361.\\nHugo Laurenc¸on, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral,\\nTeven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo Gonz´alez Ponferrada, Huu\\nNguyen, J¨org Frohberg, Mario ˇSaˇsko, Quentin Lhoest, Angelina McMillan-Major, G´erard\\nDupont, Stella Biderman, Anna Rogers, Loubna Ben allal, Francesco De Toni, Giada Pis-\\ntilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa,\\nPaulo Villegas, Tristan Thrush, Shayne Longpre, Sebastian Nagel, Leon Weber, Manuel Romero\\nMu˜noz, Jian Zhu, Daniel Van Strien, Zaid Alyafeai, Khalid Almubarak, Vu Minh Chien, Itziar\\nGonzalez-Dios, Aitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz Suarez, Aaron Gokaslan, Shamik\\nBose, David Ifeoluwa Adelani, Long Phan, Hieu Tran, Ian Yu, Suhas Pai, Jenny Chim, Vio-\\nlette Lepercq, Suzana Ilic, Margaret Mitchell, Sasha Luccioni, and Yacine Jernite.\\nThe big-\\nscience ROOTS corpus: A 1.6TB composite multilingual dataset.\\nIn Thirty-sixth Confer-\\nence on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL\\nhttps://openreview.net/forum?id=UoEw6KigkUn.\\nHeather\\nLent,\\nEmanuele\\nBugliarello,\\nMiryam\\nde\\nLhoneux,\\nChen\\nQiu,\\nand\\nAnders\\nSøgaard.\\nOn language models for creoles.\\nIn Proceedings of the 25th Confer-\\nence on Computational Natural Language Learning, pp. 58–71, Online, November 2021.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ence on Computational Natural Language Learning, pp. 58–71, Online, November 2021.\\nAssociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2021.conll-1.5.\\nURL\\nhttps://aclanthology.org/2021.conll-1.5.\\nHeather Lent, Kelechi Ogueji, Miryam de Lhoneux, Orevaoghene Ahia, and Anders Søgaard. What\\na creole wants, what a creole needs. In Proceedings of the Thirteenth Language Resources and\\nEvaluation Conference, pp. 6439–6449, Marseille, France, June 2022. European Language Re-\\nsources Association. URL https://aclanthology.org/2022.lrec-1.691.\\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle\\nOtt, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh\\nKoura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva,\\nMona T. Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual language\\nmodels. CoRR, abs/2112.10668, 2021. URL https://arxiv.org/abs/2112.10668.\\n11'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='models. CoRR, abs/2112.10668, 2021. URL https://arxiv.org/abs/2112.10668.\\n11\\nAfricaNLP workshop at ICLR2022\\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen.\\nWhat makes good in-context examples for GPT-3?\\nIn Proceedings of Deep Learn-\\ning Inside Out (DeeLIO 2022):\\nThe 3rd Workshop on Knowledge Extraction and Inte-\\ngration for Deep Learning Architectures, pp. 100–114, Dublin, Ireland and Online, May\\n2022. Association for Computational Linguistics.\\ndoi: 10.18653/v1/2022.deelio-1.10.\\nURL\\nhttps://aclanthology.org/2022.deelio-1.10.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pre-\\ntraining approach. arXiv preprint, abs/1907.11692, 2019.\\nNitika Mathur, Timothy Baldwin, and Trevor Cohn. Tangled up in BLEU: Reevaluating the eval-\\nuation of automatic machine translation evaluation metrics.\\nIn Proceedings of the 58th An-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='uation of automatic machine translation evaluation metrics.\\nIn Proceedings of the 58th An-\\nnual Meeting of the Association for Computational Linguistics, pp. 4984–4997, Online, July\\n2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.448. URL\\nhttps://aclanthology.org/2020.acl-main.448.\\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le\\nScao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir\\nRadev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,\\nEdward Raff, and Colin Raffel. Crosslingual generalization through multitask ﬁnetuning, 2022.\\nURL https://arxiv.org/abs/2211.01786.\\nNLLB Team, Marta R. Costa-juss`a, James Cross, Onur C¸ elebi, Maha Elbayad, Kenneth Heaﬁeld,\\nKevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler\\nWang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez,\\nPrangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shan-\\nnon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela\\nFan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm´an, Philipp Koehn, Alexandre Mourachko,\\nChristophe Ropers, Saﬁyyah Saleem, Holger Schwenk, and Jeff Wang. No language left behind:\\nScaling human-centered machine translation, 2022.\\nKelechi Ogueji and Orevaoghene Ahia. PidginUNMT: Unsupervised Neural Machine Translation\\nfrom West African Pidgin to English. ArXiv, abs/1912.03444, 2019.\\nKelechi Ogueji, Yuxin Zhu, and Jimmy Lin.\\nSmall data?\\nNo Problem!\\nexploring the vi-\\nability of pretrained multilingual language models for low-resourced languages.\\nIn Pro-\\nceedings of the 1st Workshop on Multilingual Representation Learning, pp. 116–126, Punta'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='In Pro-\\nceedings of the 1st Workshop on Multilingual Representation Learning, pp. 116–126, Punta\\nCana, Dominican Republic, November 2021. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2021.mrl-1.11.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,\\nChong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob\\nHilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul\\nChristiano, Jan Leike, and Ryan Lowe.\\nTraining language models to follow instruc-\\ntions with human feedback.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and\\nKyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.\\nURL\\nhttps://openreview.net/forum?id=TG8KACxEON.\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.\\nBleu: a method for auto-\\nmatic evaluation of machine translation.\\nIn Proceedings of the 40th Annual Meeting of the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='matic evaluation of machine translation.\\nIn Proceedings of the 40th Annual Meeting of the\\nAssociation for Computational Linguistics, pp. 311–318, Philadelphia, Pennsylvania, USA,\\nJuly 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL\\nhttps://aclanthology.org/P02-1040.\\nEdoardo Maria Ponti, Goran Glavaˇs, Olga Majewska, Qianchu Liu, Ivan Vuli´c, and Anna Korhonen.\\nXCOPA: A multilingual dataset for causal commonsense reasoning. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing (EMNLP), pp. 2362–2376,\\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.185. URL https://aclanthology.org/2020.emnlp-main.185.\\n12\\nAfricaNLP workshop at ICLR2022\\nMatt\\nPost.\\nA\\ncall\\nfor\\nclarity\\nin\\nreporting\\nBLEU\\nscores.\\nIn\\nProceedings\\nof\\nthe Third Conference on Machine Translation:\\nResearch Papers,\\npp. 186–191, Bel-\\ngium,\\nBrussels,\\nOctober\\n2018.\\nAssociation\\nfor\\nComputational\\nLinguistics.\\nURL'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='pp. 186–191, Bel-\\ngium,\\nBrussels,\\nOctober\\n2018.\\nAssociation\\nfor\\nComputational\\nLinguistics.\\nURL\\nhttps://www.aclweb.org/anthology/W18-6319.\\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\\nmodels are unsupervised multitask learners, 2019.\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer.\\nJournal of Machine Learning Research, 21(140):1–67, 2020.\\nURL\\nhttp://jmlr.org/papers/v21/20-074.html.\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\\nChafﬁn, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker,\\nShanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De-\\nbajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,\\nZheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,\\nAbheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le\\nScao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. Multitask prompted\\ntraining enables zero-shot task generalization. In International Conference on Learning Repre-\\nsentations, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.\\nTimo Schick and Hinrich Sch¨utze. It’s not just size that matters: Small language models are also few-\\nshot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Asso-\\nciation for Computational Linguistics: Human Language Technologies, pp. 2339–2352, Online,\\nJune 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.185.\\nURL https://aclanthology.org/2021.naacl-main.185.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='URL https://aclanthology.org/2021.naacl-main.185.\\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi,\\nHyung Won Chung,\\nYi Tay,\\nSebastian Ruder, Denny Zhou, Dipanjan Das,\\nand Ja-\\nson Wei.\\nLanguage models are multilingual chain-of-thought reasoners, 2022.\\nURL\\nhttps://arxiv.org/abs/2210.03057.\\nTianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. Black-box tuning for\\nlanguage-model-as-a-service. In Proceedings of ICML, 2022.\\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester,\\nNan Du, Andrew M. Dai, and Quoc V Le.\\nFinetuned language models are zero-\\nshot learners.\\nIn International Conference on Learning Representations, 2022a.\\nURL\\nhttps://openreview.net/forum?id=gEZrGCozdqR.\\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani\\nYogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto,\\nOriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.\\nEmergent abilities of large lan-\\nguage models. Transactions on Machine Learning Research, 2022b. ISSN 2835-8856. URL\\nhttps://openreview.net/forum?id=yzkSU5zdwD. Survey Certiﬁcation.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H.\\nChi,\\nQuoc V Le,\\nand Denny Zhou.\\nChain of thought prompting elicits reasoning\\nin large language models.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and\\nKyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022c.\\nURL\\nhttps://openreview.net/forum?id=_VjQlMeSB_J.\\nGuillaume\\nWenzek,\\nMarie-Anne\\nLachaux,\\nAlexis\\nConneau,\\nVishrav\\nChaudhary,\\nFran-\\ncisco Guzm´an, Armand Joulin, and Edouard Grave.\\nCCNet:\\nExtracting high qual-\\nity monolingual datasets from web crawl data.\\nIn Proceedings of the 12th Lan-\\nguage Resources and Evaluation Conference, pp. 4003–4012, Marseille, France, May\\n2020. European Language Resources Association.\\nISBN 979-10-95546-34-4.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='2020. European Language Resources Association.\\nISBN 979-10-95546-34-4.\\nURL\\nhttps://www.aclweb.org/anthology/2020.lrec-1.494.\\n13\\nAfricaNLP workshop at ICLR2022\\nGenta Indra Winata, Andrea Madotto, Zhaojiang Lin, Rosanne Liu, Jason Yosinski, and Pascale\\nFung. Language models are few-shot multilingual learners. In Proceedings of the 1st Workshop\\non Multilingual Representation Learning, pp. 1–15, Punta Cana, Dominican Republic, Novem-\\nber 2021. Association for Computational Linguistics.\\ndoi: 10.18653/v1/2021.mrl-1.1. URL\\nhttps://aclanthology.org/2021.mrl-1.1.\\nXinyan Velocity Yu, Akari Asai, Trina Chatterjee, Junjie Hu, and Eunsol Choi. Beyond counting\\ndatasets: A survey of multilingual dataset construction and necessary resources. In Findings of\\nEMNLP, 2022.\\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan\\nXu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang\\nChen, Peng Zhang, Yuxiao Dong, and Jie Tang. Glm-130b: An open bilingual pre-trained model.\\narXiv preprint arXiv:2210.02414, 2022.\\nBiao Zhang, Barry Haddow, and Alexandra Birch. Prompting large language model for machine\\ntranslation: A case study, 2023. URL https://arxiv.org/abs/2301.07069.\\nMengjie Zhao and Hinrich Sch¨utze.\\nDiscrete and soft prompting for multilingual models.\\nIn\\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Process-\\ning, pp. 8547–8555, Online and Punta Cana, Dominican Republic, November 2021. As-\\nsociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2021.emnlp-main.672.\\nURL\\nhttps://aclanthology.org/2021.emnlp-main.672.\\n14')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Images:"
      ],
      "metadata": {
        "id": "6GbssMqJfG34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_for_img = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "OV-RD4uOfRFg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "def generate_docs_from_img(img_url):\n",
        "    message = HumanMessage(\n",
        "    content=[\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Give me a summary of what you see in the image. It must be 3 detailed paragraphs.\",\n",
        "            },\n",
        "            {\"type\": \"image_url\", \"image_url\": img_url},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = llm_for_img.invoke([message]).content\n",
        "        print(f\"Generated summary: {response}\")\n",
        "        docs = Document(page_content=response, metadata={\"source\": img_url})\n",
        "        split_docs = splitter.split_documents([docs])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing the request due to Invalid Content or Invalid Image URL\")\n",
        "        raise e\n",
        "\n",
        "    return split_docs"
      ],
      "metadata": {
        "id": "fXQBdz0zfH3v"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_docs = generate_docs_from_img(\"https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8bkionufd3i",
        "outputId": "15abc001-fad6-4c80-d7e4-b32cd6516707"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated summary: Here's a summary of the provided image in three detailed paragraphs:\n",
            "\n",
            "The image diagrams the architecture of a Transformer, a neural network architecture commonly used in natural language processing.  The core of the architecture is built around the concept of \"multi-head attention,\" which is visually represented as a central block.  This block takes input embeddings (processed representations of words or sub-words) and applies a series of linear transformations to create query (Q), key (K), and value (V) matrices. These matrices are then fed into a \"scaled dot-product attention\" mechanism,  a detailed breakdown of which is shown separately. The multi-head attention mechanism allows the model to weigh the importance of different parts of the input sequence when processing each word, capturing relationships between words across the sequence.  The output of the multi-head attention is then passed through an \"add & norm\" layer (representing addition and normalization operations) followed by a feed-forward network.\n",
            "\n",
            "The diagram illustrates two parallel pathways, one for standard multi-head attention and another for \"masked multi-head attention.\"  The masked version is crucial for tasks like sequence generation (e.g., machine translation or text generation) where the model should not \"peek\" at future tokens during the prediction process. This masking is explicitly shown in the detailed \"scaled dot-product attention\" section. The positional encoding blocks highlight that the model incorporates information about the order of words in the input sequence. This is essential because unlike recurrent neural networks, the Transformer architecture processes the entire input sequence in parallel, lacking inherent sequential information. The final output embeddings are produced after passing through multiple layers of these attention and feed-forward mechanisms.\n",
            "\n",
            "The detailed view of the \"scaled dot-product attention\" mechanism further clarifies the inner workings of the attention process. It shows how the query, key, and value matrices are used to calculate attention weights through matrix multiplication (MatMul), softmax normalization, optional masking, and scaling.  This entire process determines which parts of the input sequence are most relevant to each word, allowing the model to focus on important contextual information. The final matrix multiplication with the value matrix combines the attention weights with the values to produce a weighted representation of the input sequence. This weighted representation then feeds back into the main Transformer architecture, contributing to the overall processing and output.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csB6ZO3Ofzn7",
        "outputId": "8d5dbfd6-94ad-476b-8071-125508a11993"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content=\"Here's a summary of the provided image in three detailed paragraphs:\"),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The image diagrams the architecture of a Transformer, a neural network architecture commonly used in natural language processing.  The core of the architecture is built around the concept of \"multi-head attention,\" which is visually represented as a central block.  This block takes input embeddings (processed representations of words or sub-words) and applies a series of linear transformations to create query (Q), key (K), and value (V) matrices. These matrices are then fed into a \"scaled dot-product attention\" mechanism,  a detailed breakdown of which is shown separately. The multi-head attention mechanism allows the model to weigh the importance of different parts of the input sequence when processing each word, capturing relationships between words across the sequence.  The output of the multi-head attention is then passed through an \"add & norm\" layer (representing addition and normalization operations) followed by a feed-forward network.'),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The diagram illustrates two parallel pathways, one for standard multi-head attention and another for \"masked multi-head attention.\"  The masked version is crucial for tasks like sequence generation (e.g., machine translation or text generation) where the model should not \"peek\" at future tokens during the prediction process. This masking is explicitly shown in the detailed \"scaled dot-product attention\" section. The positional encoding blocks highlight that the model incorporates information about the order of words in the input sequence. This is essential because unlike recurrent neural networks, the Transformer architecture processes the entire input sequence in parallel, lacking inherent sequential information. The final output embeddings are produced after passing through multiple layers of these attention and feed-forward mechanisms.'),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The detailed view of the \"scaled dot-product attention\" mechanism further clarifies the inner workings of the attention process. It shows how the query, key, and value matrices are used to calculate attention weights through matrix multiplication (MatMul), softmax normalization, optional masking, and scaling.  This entire process determines which parts of the input sequence are most relevant to each word, allowing the model to focus on important contextual information. The final matrix multiplication with the value matrix combines the attention weights with the values to produce a weighted representation of the input sequence. This weighted representation then feeds back into the main Transformer architecture, contributing to the overall processing and output.')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Audio Document Loader (AssemblyAI)"
      ],
      "metadata": {
        "id": "61b11gLBf2oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import AssemblyAIAudioTranscriptLoader\n",
        "def load_audio_documents(path: str):\n",
        "    audio_loader = AssemblyAIAudioTranscriptLoader(file_path=path)\n",
        "\n",
        "    docs = audio_loader.load()\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        return split_docs"
      ],
      "metadata": {
        "id": "Ei129f7RhFHd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_docs = load_audio_documents(\"/content/RAG for LLMs explained in 3 minutes.mp3\")"
      ],
      "metadata": {
        "id": "JjInkIrniStO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Cmsbd-iZY6",
        "outputId": "aabf4a3d-d6d1-4963-f12c-ff807646775b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAG Pipeline:"
      ],
      "metadata": {
        "id": "VyPQgv2oinH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docs_pdf + url_docs + arxiv_docs + img_docs + audio_docs"
      ],
      "metadata": {
        "id": "QHfrMnJVioOQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXqQtVAeirQb",
        "outputId": "aa8dd9f9-3e9d-4df1-c80c-eaf794da4ba3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='Co-Brand Name \\nIdeas Are Dimes A Dozen: Large Language Models For Idea \\nGeneration In Innovation \\nKaran Girotra, Lennart Meincke, Christian Terwiesch, and Karl T. Ulrich1\\nJuly 10, 2023 \\nMack Institute for Innovation Management, The Wharton School, University of Pennsylvania \\nCornell Tech and Johnson College of Business, Cornell University\\nAbstract \\nLarge language models (LLMs) such as OpenID’s GPT series have shown remarkable capabilities in generating \\nfluent and coherent text in various domains. We compare the ideation capabilities of ChatGPT-4, a chatbot based \\non a state-of-the-art LLM, with those of students at an elite university. ChatGPT-4 can generate ideas much faster \\nand cheaper than students, and the ideas are on average of higher quality (as measured by purchase-intent \\nsurveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly \\nrated ideas further increases its performance. We discuss the implications of these findings for the management \\nof innovation. \\nKeywords: innovation, idea generation, creativity, creative problem solving, LLM, large-scale language models, \\nAI, artificial intelligence, ChatGPT \\nIntroduction \\nGenerative artificial intelligence has made remarkable advances in creating life-like images and coherent, fluent \\ntext. OpenAI’s ChatGPT chatbot, based on the GPT series of large language models (LLM) can equal or surpass \\nhuman performance in academic examinations and tests for professional certifications (OpenAI, 2023). Github \\nCo-Pilot based on the same LLMs can help with writing, commenting, and debugging code. Other models can \\nprovide valuable professional advice in fields like medicine and law.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 0}, page_content='provide valuable professional advice in fields like medicine and law. \\nDespite their remarkable performance, LLMs sometimes produce text that is semantically or syntactically \\nplausible but is, in fact, factually incorrect or nonsensical (i.e., hallucinations). The models\\n are optimized to \\ngenerate the most statistically likely sequences of words with an injection of randomness. They are not designed \\n1 Girotra: Cornell Tech, 2 West Loop Rd, New York, NY, 10044, girotra@cornell.edu  | Meincke, Terwiesch, Ulrich: The \\nWharton School, 500 Huntsman Hall, 3730 Walnut Street, Philadelphia, PA 19104, lennart@sas.upenn.edu, \\nterwiesch@wharton.upenn.edu, ulrich@wharton.upenn.edu'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='to exercise any judgment on the veracity or feasibility of the output. Further, the underlying optimization algorithms provide no performance guarantees, and their output can thus be of inconsistent quality. Hallucinations and inconsistency are critical flaws that limit the use of LLM-based solutions to low-stakes settings or in conjunction with expensive human supervision.   In what applications can we leverage artificial intelligence that is brilliant in many ways yet cannot be trusted to produce reliably accurate results? One possibility is to turn their weaknesses – hallucinations and inconsistent quality – into a strength (Terwiesch, 2023). In most management settings, we expect to make use of each unit of work produced. As such, consistency is prized and is, therefore, the focus of contemporary performance management. (See, for example, the Six Sigma methodology.) Erratic and inconsistent behavior is to be eliminated. For example, an airline would rather hire a pilot that'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='inconsistent behavior is to be eliminated. For example, an airline would rather hire a pilot that executes a within-safety-margins landing 10 out of 10 times rather than one that makes a brilliant approach five times and an unsafe approach another five.  But, when it comes to creativity and innovation, say finding a new opportunity to improve the air travel experience or launching a new aviation venture, the same airline would prefer an ideator that generates one brilliant idea and nine nonsense ideas over one that generates ten decent ideas. In creative tasks, given that only one or a few ideas will be pursued, only a few extremely positive outcomes matter. Similarly, an ideator that generates 30 ideas is likelier to have one brilliant idea than an ideator that generates just 10. Overall, in creative problem-solving, variability in quality, and productivity, as reflected in the number of ideas generated, are more valuable than consistency (Girotra et al., 2010).  To achieve high'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='of ideas generated, are more valuable than consistency (Girotra et al., 2010).  To achieve high variability in quality and high productivity, most research on ideation and brainstorming recommends enhancing performance by generating many ideas while postponing evaluation or judgment of ideas (Girotra et al., 2010). This is hard for human ideators to do, but LLMs are designed to do exactly this— quickly generate many somewhat plausible solutions without exercising much judgment. Further, the hallucinations and inconsistent behavior of LLMs increase the variability in quality, which, on average, improves the quality of the best ideas. For ideation, an LLM’s lack of judgment and inconsistency could be prized features, not bugs.  Thus, we hypothesize that LLMs will be excellent ideators. The purpose of this paper is to test this hypothesis by evaluating the performance of LLMs in generating new ideas.  Specifically, we compare three pools of ideas for new consumer products. The first pool'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 1}, page_content='new ideas.  Specifically, we compare three pools of ideas for new consumer products. The first pool was created by students at an elite university enrolled in a course on product design prior to the availability of LLMs. The second pool of ideas was generated by OpenAI’s ChatGPT-4 with the same prompt as that given to the students. The third pool of ideas was generated by prompting ChatGPT-4 with the task as well as with a sample of highly rated ideas to enable some in-context learning (i.e., few-shot prompting).  We address three questions. First, how productive is ChatGPT-4? That is, how much time and effort is required to generate ideas and how many can reasonably be generated compared to human efforts?'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Second, what is the quality distribution of the ideas generated? We are particularly interested in the extreme values – the quality of the best ideas in the three pools. We measure the quality of the ideas using the standard market research technique of eliciting consumer purchase intent in a survey. Given an estimate of the quality of each idea, we can then compare the distributional characteristics of the quality of the three pools of ideas. Third, given the performance of ChatGPT-4 in generating new product ideas, how can LLMs be used effectively in practice and what are the implications for the management of innovation?'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Approach We have over 20 years of experience teaching product design and innovation courses at Wharton, Cornell Tech, and INSEAD. We have used similar innovation challenges dozens of times with thousands of students. Most of our courses embody the innovation tournament format (Terwiesch and Ulrich 2009, 2023), in which individuals first independently generate many ideas, which are then combined into a pool of several hundred ideas and subsequently evaluated by others in the group (i.e., “crowdsourced” evaluations). Thus, we have access to a large set of ideas generated by humans before AI tools became available to enhance ideation. We randomly selected 200 ideas from the pool of ideas generated in our class in 2021 (i.e., at a time prior to the widespread availability of ChatGPT and other LLMs). These ideas comprise a descriptive title and a paragraph of text. They were all generated in response to the challenge of creating a new physical product for the college student market that'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='in response to the challenge of creating a new physical product for the college student market that would be likely to retail for less than USD 50. (This price cap is imposed to limit the complexity of the projects in a one-semester course.) Here is an example of a submitted idea: Convertible High-Heel Shoe Many prefer high-heel shoes for dress-up occasions, yet walking in high heels for more than short distances is very challenging. Might we create a stylish high-heel shoe that easily adapts to a comfortable walking configuration, say by folding down or removing a heel portion of the shoe? The set of 200 ideas forms the baseline for comparison with the ideas generated using LLMs. The average description is 63 words long, with a standard deviation of 34. We use OpenAI’s GPT-4 API access to prompt ChatGPT-4 with essentially the same prompt we gave the students. No LLM yet acts fully autonomously. Rather they are tools used by humans to complete tasks. Still, for the purpose of this'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 2}, page_content='Rather they are tools used by humans to complete tasks. Still, for the purpose of this study, we aim for minimal prompt engineering, thus representing a novice user scenario. We use the system prompt to provide contextual information and subsequent user prompts to ask for ideas, ten at a time. The user prompt includes the additional request that the descriptions are 40-80 words, similar to the student sample.  System Prompt “You are a creative entrepreneur looking to generate new product ideas. The product will target college students in the United States. It should be a'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content=\"physical good, not a service or software. I'd like a product that could be sold at a retail price of less than about USD 50. The ideas are just ideas. The product need not yet exist, nor may it necessarily be clearly feasible. Number all ideas and give them a name. The name and idea are separated by a colon.” User Prompt “Please generate ten ideas as ten separate paragraphs. The idea should be expressed as a paragraph of 40-80 words.” The model used for all work covered in this paper is GPT-4-0314 with the “temperature” parameter at 0.7 to induce randomness, and thus greater creativity. An obstacle to using ChatGPT-4 for generating 100s of ideas is its finite memory, typically limited to the number of tokens (i.e., semantic chunks used for representational efficiency) the underlying LLM can consider in generating its responses. Once the number of tokens in a session exceeds the model’s limit, the LLM has no memory of the first ideas generated and subsequent ideas can become\"),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content='model’s limit, the LLM has no memory of the first ideas generated and subsequent ideas can become increasingly redundant. The number of tokens in the version of ChatGPT-4 that we had access to is about 8000, which is roughly 7000 words or approximately 80 ideas (some tokens are used for the system and user prompt and for idea titles).  To generate more than about 80 ideas while wrestling with the context limit, we asked GPT-4 to “compress” the previously generated ideas into shorter summaries. These summaries were then provided to the model prior to generating the next batch of ideas, ensuring that the model knows the previously generated ideas while remaining within the context limits. To generate ideas beyond the token limit, we used the below summarization prompt, followed by the original system prompt and generated summaries, and finally, a user prompt that explicitly asks for different ideas.   Summarization Prompt “Aggressively compress the following ideas so that their original'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 3}, page_content='ideas.   Summarization Prompt “Aggressively compress the following ideas so that their original meaning remains but they are much shorter. You can use tags or keywords.: <Ideas generated so far>” System Prompt <Original System Prompt> + ”Previously you generated the following ideas and should not repeat them: <Summaries>”  User Prompt <Original User Prompt> + ”Make sure they are different from the previous ideas.”  General-purpose LLMs may be used as is or may be fine-tuned with examples. We generated a second batch of ideas after providing the LLM with examples of high-quality ideas generated by students. In particular, we appended our prompts to provide the LLM with seven highly rated ideas from a separate student set that did the same exercise and informed ChatGPT-4 that these ideas had been well-received. We used seven examples to'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='keep the overall contribution to the context window moderate as well as drawing on previous experience from in-context few-shot learning. Good Ideas Prompt <Original System Prompt> + ”Here are some well received ideas for inspiration: <Good Ideas>”  Overall, we generated 100 ideas without providing examples of good ideas and another 100 after providing access to examples of good ideas.  Prior work in other domains suggests that the text generated by LLMs is not distinguishable from that generated by humans (Brown et al., 2020). While we do not test this question in this study, our impression is that any particular idea generated by ChatGPT cannot easily be distinguished from those generated by our students.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='Do LLMs Enhance Productivity in Generating Ideas? The answer to this question is straightforward. ChatGPT-4 is very efficient at generating ideas. This question does not require much precision to answer. Two hundred ideas can be generated by one human interacting with ChatGPT-4 in about 15 minutes. A human working alone can generate about five ideas in 15 minutes (Girotra et al., 2010). Humans working in groups do even worse. In short, the productivity race between humans and ChatGPT is not even close. Still, the old saying that ideas are a dime a dozen is perhaps a tad optimistic. A professional working with ChatGPT-4 can generate ideas at a rate of about 800 ideas per hour. At a cost of USD 500 per hour of human effort, a figure representing an estimate of the fully loaded cost of a skilled professional, ideas are generated at a cost of about USD 0.63 each, or USD 7.50 (75 dimes) per dozen. At the time we used ChatGPT-4, the API fee for 800 ideas was about USD 20. For that same USD'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='dozen. At the time we used ChatGPT-4, the API fee for 800 ideas was about USD 20. For that same USD 500 per hour, a human working alone, without assistance from an LLM, only generates 20 ideas at a cost of roughly USD 25 each, hardly a dime a dozen. For the focused idea generation task itself, a human using ChatGPT-4 is thus about 40 times more productive than a human working alone. In prior work, (Kornish and Ulrich, 2011) found that a typical new-product innovation domain contains thousands of unique ideas, ranging from about 1300 ideas for narrow challenges (e.g., use of technology in the classroom) to 3000 for more open-ended challenges (e.g., new consumer products). These numbers are large enough that a human working alone or in a small group is unlikely to identify most of them. However, LLMs are so productive that a human working with an LLM might reasonably fully articulate nearly every idea in an opportunity space. That is, it may now be possible to identify essentially every'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 4}, page_content='every idea in an opportunity space. That is, it may now be possible to identify essentially every idea that a very large group of individuals working in parallel might identify after working for a long time, say, days or weeks. Prior work (Kornish and Ulrich 2014, Girotra et al. 2010) showed that the idea generation process in humans is essentially stationary, so ideas 2901 - 3000 exhibit the same quality distribution as ideas 1-100.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='What Is The Quality Distribution of the Ideas Generated Using LLMs? A “stochastic parrot” can generate ideas, and LLMs do so shockingly productively. But we don’t care about quantity alone. More typically, the objective of idea generation is to generate at least a few truly exceptionally good ideas. In most innovation settings, we’d rather have 10 great ideas and 90 terrible ideas than 100 ideas of average quality. We, therefore, care about the quality distribution of the ideas, and in particular, the quality of the best few ideas in a sample. Of course, we might as well also measure the mean and standard deviation of the three sets of ideas, and we do so. Two useful measures of the extreme values are: What is the average quality of the ideas in the top decile of each of the three samples? Which sources provided the ideas comprising the top 10 percent of the ideas in the pooled sample? Measuring Idea Quality Of course, what we want to know in most innovation settings is which idea has'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='Idea Quality Of course, what we want to know in most innovation settings is which idea has the highest expected future economic value given the uncertainty in how the ideas are developed and in the exogenous factors. This rationale is explored thoroughly in (Kornish and Ulrich, 2014) in the development of the VIDE model. Value (V) is a function of the idea itself (I), the development of that idea (D), and the exogenous factors (E). This value is not directly observable. To measure it we would need to develop and launch all ideas under all future states of the world. In very limited settings, we can estimate financial value, as done in (Kornish and Ulrich, 2014). That study showed that the best single indicator of future value creation is the average purchase intent expressed by a sample of consumers in the target market. Furthermore, (Kornish and Ulrich, 2014) showed that no single individual, expert or novice, is particularly good at estimating value. Rather, a sample of expressed'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='expert or novice, is particularly good at estimating value. Rather, a sample of expressed purchase intent from about 15 individuals in the target market is a reliable measure of idea quality. After obtaining the required IRB approvals, we used mTurk to evaluate all 400 ideas (200 created by humans, 100 created by ChatGPT without examples and 100 with training examples). The panel comprised college-age individuals in the United States. Ideas were presented in random order. Each respondent evaluated an average of 40 ideas. On average, each idea was evaluated 20 times2.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 5}, page_content='2 In Summer 2023, concerns surfaced that ChatGPT was being used to provide mTurk responses. This practice appears to have been limited to text generation tasks, not to multiple choice tasks like our five-box purchase-intent survey. Indeed, just answering the survey question directly requires less effort than trying to deploy ChatGPT to answer the question. Thus, we believe that we were indeed surveying humans.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 6}, page_content='Respondents were asked to express purchase intent using the standard “five-box” options: definitely would not purchase, probably would not purchase, might or might not purchase, probably would purchase, and definitely would purchase. Jameson and Bass (1989) recommend weighting responses for the five possible responses as 0, 0.25, 0.50, 0.75, and 1.00 to develop a single measure of purchase probability, which we use as a measure of idea quality. Of course, many other weightings are possible. We report results using the Jameson and Bass weights, but the results are robust to other convex weighting schemes. Results The full quality distribution of ideas generated by the three pools is shown in Figure 1.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 6}, page_content='Figure 1 - Distribution of idea quality for three sets of ideas. Purchase intent is the weighted average of the five-box response scale per Jameson and Bass (1989). The average quality of ideas generated by ChatGPT is higher than the average quality of ideas generated by humans, as measured by purchase intent. The average purchase probability of a human-generated idea is 40.4%, that of vanilla GPT-4 is 46.8%, and that of GPT-4 seeded with good ideas is 49.3%. The difference in'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 7}, page_content='average quality between humans and ChatGPT is statistically significant (p<0.001), but the difference between the two GPT models is not statistically significant (p=0.11).  See Table 1. The standard deviation of the quality of ideas is comparable, with ChatGPT trained with examples having the highest standard deviation.  Table 1 - Summary Statistics \\n Human Generated Ideas ChatGPT-4 ChatGPT-4 trained with examples N Ideas 200 100 100 Average Length of Description 63 words 69 words 71 words Average Quality 0.404 0.468 0.493 Standard Deviation of Quality 0.112 0.108 0.120 Best Idea 0.64 0.70 0.75 Average Quality of Top Decile 0.62 0.64 0.66 Average Novelty of Top Decile 0.45 0.35 0.33 Fraction of the top decile of pooled ideas from this source 5/40  15/40 20/40'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 7}, page_content='P-value  (Is the average quality different?)  vs. humans <0.001 vs. humans <0.001 vs. baseline LLM 0.11  Most interesting are the differences in the quality of the best ideas. Chat-GPT generated the best-rated idea in our sample, with an 11% higher purchase probability than the best human idea. The average quality of the top decile in each of the three pools also follows the same pattern as average quality— seeded Chat-GPT ≻ ChatGPT ≻ Humans. Finally, most striking are the differences in each treatment’s contribution to the top decile of all ideas we generated. Overall, we have 400 ideas, with an equal number generated by ChatGPT and humans. In the top 40 ideas (top decile) a full 35 (87.5%) are those generated by ChatGPT. In other words, in a head-to-head match most of the winners come from ChatGPT. Titles of the top 40 ideas in our pool are reported in Table A1.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='Novelty Given that LLMs are designed to generate approximately the statistically most plausible sequence of text based on their training data, perhaps they generate less-novel ideas.  Novelty is not a goal expressed in the prompt for either humans or Chat-GPT. It is typically not a primary objective in commercial product development efforts, nor does it have commercial value in itself. Still, we are curious about how the novelty of ideas varies between LLM-generated ideas and those generated by humans.  We adopt the survey instrument of Shibayama, Yin, and Matsumoto (2021) to assess the novelty of the ideas. mTurk respondents answered this question: Relative to other products you have seen, how novel do you consider the idea for this new product? 1. Not at all novel 2. Slightly novel 3. Moderately novel 4. Very novel 5. Extremely novel We weigh these responses 0, 0.25, 0.50, 0.75, and 1.00 to produce a novelty score for each idea. By this measure, the mean novelty of the'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='0.75, and 1.00 to produce a novelty score for each idea. By this measure, the mean novelty of the human-generated ideas is higher than that of the LLM-generated ideas (p<0.001). The mean novelty of the two different pools of LLM-generated ideas is not statistically significantly different from each other. (Figure 2) Novelty does not appear to be significantly correlated with purchase intent. The correlation coefficient is slightly negative at -0.08 (p=0.12).'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 8}, page_content='Figure 2 - Distribution of novelty ratings for three samples of ideas. Novelty based on mTurk assessment per Kwon, Kim, and Lee (2009).'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='We note here that the average novelty of all ideas, irrespective of source, lies between slightly and moderately novel. While human ideas are a bit more novel, there is little reason to believe that novelty – being the first to think of an idea – leads to a significant financial advantage in domains associated with off-the-shelf technology, low entry barriers, and limited intellectual property protection.  As such, from a commercial point of view, we don’t believe novelty provides sufficient advantage, if any, to overcome the productivity and quality benefits of the LLMs. Further, recall that novelty was not an explicit objective for any of our ideation schemes. In settings where novelty is the goal, it should be part of the prompts.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='Limitations Student Subjects It is possible that professional product innovators would generate better ideas than our students. However, that is not our intuition having worked in many product development settings. Many students in this course have gone on to be product innovators, sometimes based on ideas from the course tournament. We have not produced evidence that ChatGPT is better than the best human product innovators working today. However, we believe that we can claim conservatively that ChatGPT is better than many human product innovators working today and probably better than average. Thus, at a very minimum, an LLM could elevate the least capable humans to a better-than-average level of performance. Domain Our results are set in a common widely understood domain, for consumer products likely selling at a price less than USD 50. Presumably, there is a lot of commentary and data around these domains in the training data used by the GPT class of language models. As such, it is'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='around these domains in the training data used by the GPT class of language models. As such, it is possible that in more specialized domains, say surgical instruments, our results will no longer hold with the current class of models. That said, to us, if this is true, this is likely driven simply by the paucity of training data. An organization looking for opportunities in these specialized domains should presumably be able to fine-tune language models with their own proprietary data and achieve comparable or better performance.  Misbehavior Most language models do not provide any performance guarantees and it is possible they can generate offensive, illegal, or inappropriate ideas. Ideators using models for ideation should exercise caution. Of course, the same caution is warranted with human idea generators. Similarity For most innovation settings, the goal is to thoroughly explore the landscape of possibilities. Doing so enhances confidence that the most reasonable opportunities'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 9}, page_content='the landscape of possibilities. Doing so enhances confidence that the most reasonable opportunities have been unearthed and considered. To this extent, we prefer a process that generates 200 diverse ideas to one that generates 200 highly similar ideas. Our analysis does not speak to the similarity or variability in the content of ideas. This remains an open question for further study.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='Concluding Remarks In this study, we showed that the LLM technology in the form of ChatGPT4, a technology available for just a few months at the time of our experiments, is already significantly better at generating new product ideas than motivated, trained engineering and business students at a highly selective university.  Our results examined ideation productivity and quality separately. In each match-up, ChatGPT came out ahead. Combined, the effects of much higher productivity and the higher quality of the best ideas will likely completely trounce human ideators. The order of magnitude advantage in productivity itself is nearly insurmountable, and the higher quality of the best ideas further adds to the advantage of the LLM.    We can now put these tools in the hands of any innovator at extremely low cost. This suggests that the critical task in innovation practice may shift from idea generation to idea evaluation and selection, a task for which LLMs do not yet appear to be'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='idea generation to idea evaluation and selection, a task for which LLMs do not yet appear to be particularly well suited. It is striking that conventional wisdom prior to 2022 was that AI tools would likely be most useful in rote tasks and that creative work would likely remain the domain of humans. In some ways, the opposite is true of LLMs. The tools are not perfectly reliable oracles providing information, but their lack of judgment leads to extreme productivity and high variance in idea quality resulting, at least in one setting, to creativity greater than that of the average human.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 10}, page_content='Acknowledgments and Funding Sources Funding was provided by the Mack Institute for Innovation Management at the Wharton School of the University of Pennsylvania.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 11}, page_content='References  OpenAI. 2023. GPT-4 Technical Report. https://cdn.openai.com/papers/gpt-4.pdf Brown TB, et al. 2020. Language models are few-shot learners. arXiv:2005.14165. Girotra K, Terwiesch C, Ulrich KT. 2010. Idea generation and the quality of the best idea. Manage Sci 56:591–605. Jamieson LF, Bass FM. 1989. Adjusting stated intention measures to predict trial purchase of new products: A comparison of models and methods. J Mark Res 26:336–345. Kornish LJ, Ulrich KT. 2014. The importance of the raw idea in innovation: Testing the sow’s ear hypothesis. J Mark Res 51:14–26. Kornish LJ, Ulrich KT. 2011. Opportunity spaces in innovation: Empirical analysis of large samples of ideas. Manage Sci 57:107–128. Terwiesch C, Ulrich KT. 2009. Innovation tournaments: Creating and selecting exceptional opportunities (Harvard Business Press). Terwiesch C, Ulrich K. 2023. The Innovation Tournament Handbook: A Step-by-Step Guide to Finding Exceptional Solutions to Any Challenge (University of'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 11}, page_content='Handbook: A Step-by-Step Guide to Finding Exceptional Solutions to Any Challenge (University of Pennsylvania Press). Terwiesch C. 2023. Let’s cast a critical eye over business ideas from ChatGPT. Finance Times March 12. Shibayama S, Yin D, Matsumoto K. 2021. Measuring novelty in science with word embedding. PLOS ONE July.'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='Appendix Table A1 Top 10% Ideas (By Purchase Intent) Title Source Purchase Intent Novelty Compact Printer GPT-4 (Examples) 0.76 0.55 Solar-Powered Gadget Charger GPT-4 (Examples) 0.75 0.44 QuickClean Mini Vacuum GPT-4 (Base) 0.75 0.30 Noise-Canceling Headphones GPT-4 (Examples) 0.72 0.18 StudyErgo Seat Cushion GPT-4 (Base) 0.72 0.39 Multifunctional Desk Organizer GPT-4 (Examples) 0.71 0.21 Reusable Silicone Food Storage Bags GPT-4 (Examples) 0.68 0.34 Portable Closet Organizer GPT-4 (Examples) 0.67 0.23 Dorm Room Chef [oven, microwave and toaster]* GPT-4 (Examples) 0.67 0.71 Collegiate Cookware GPT-4 (Examples) 0.67 0.45 Collapsible Laundry Basket GPT-4 (Examples) 0.65 0.21 On-the-Go Charging Pouch GPT-4 (Examples) 0.65 0.33 GreenEats Reusable Containers GPT-4 (Base) 0.65 0.21 HydrationStation [bottle with filter]* GPT-4 (Base) 0.64 0.19 Reusable Shopping Bag Set GPT-4 (Examples) 0.64 0.19 CollegeLife Collapsible Laundry Hamper GPT-4 (Base) 0.64 0.26 Adaptiflex [cord extension to fit'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='CollegeLife Collapsible Laundry Hamper GPT-4 (Base) 0.64 0.26 Adaptiflex [cord extension to fit big adapters] * Student 0.64 0.44 SpaceSaver Hangers GPT-4 (Base) 0.64 0.33 Dorm Room Air Purifier GPT-4 (Examples) 0.63 0.29 Smart Power Strip GPT-4 (Examples) 0.63 0.22 CampusCharger Pro GPT-4 (Base) 0.63 0.31 Kitchen Safe Gloves Student 0.62 0.31 Nightstand Nook [charging, cup holder]* GPT-4 (Examples) 0.62 0.43 Mini Steamer GPT-4 (Examples) 0.62 0.41 CollegeCare First Aid Kit GPT-4 (Base) 0.62 0.26 StudySoundProof [soundproofing panels]* GPT-4 (Base) 0.62 0.57 FreshAir Fan GPT-4 (Base) 0.62 0.29 StudyBuddy Lamp [portable, usb charging]* GPT-4 (Base) 0.62 0.43 Bluetooth Signal Merger [share music]* Student 0.62 0.41 Adjustable Laptop Riser GPT-4 (Examples) 0.62 0.21 EcoCharge [solar powered charger]* GPT-4 (Base) 0.62 0.43 Smartphone Projector Student 0.62 0.57 Grocery Helper [hook to carry multiple bags]* Student 0.62 0.53 FitnessOnTheGo [portable gym equipment]* GPT-4 (Base) 0.62 0.42'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 12}, page_content='multiple bags]* Student 0.62 0.53 FitnessOnTheGo [portable gym equipment]* GPT-4 (Base) 0.62 0.42 Multipurpose Fitness Equipment GPT-4 (Examples) 0.62 0.37 CollegeCooker GPT-4 (Base) 0.61 0.50 Multifunctional Wall Organizer GPT-4 (Examples) 0.61 0.31 DormDoc Portable Scanner GPT-4 (Base) 0.61 0.49'),\n",
              " Document(metadata={'source': '/tmp/9db6edb7-b04f-43c4-a606-5e3a334e5b9f.pdf_vlij2ca', 'page': 13}, page_content='Mobile Charging Station Organizer GPT-4 (Examples) 0.61 0.26 StudyMate Planner GPT-4 (Examples) 0.61 0.22 DormChef Kitchen Set GPT-4 (Base) 0.61 0.33 LaundryBuddy [laundry basket]* GPT-4 (Base) 0.61 0.30  * Text in square brackets [] is not part of the original title and was added to clarify the idea.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Large language model - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nDataset preprocessing\\n\\n\\n\\n\\nToggle Dataset preprocessing subsection\\n\\n\\n\\n\\n\\n2.1\\nTokenization\\n\\n\\n\\n\\n\\n\\n2.1.1\\nBPE\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nProblems\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nDataset cleaning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nSynthetic data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTraining and architecture\\n\\n\\n\\n\\nToggle Training and architecture subsection\\n\\n\\n\\n\\n\\n3.1\\nReinforcement learning from human feedback (RLHF)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='3.1\\nReinforcement learning from human feedback (RLHF)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nInstruction tuning\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nMixture of experts\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nPrompt engineering, attention mechanism, and context window\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nInfrastructure\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nTraining cost\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nTool use\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nAgency\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nCompression\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nMultimodality\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nProperties\\n\\n\\n\\n\\nToggle Properties subsection\\n\\n\\n\\n\\n\\n9.1\\nScaling laws\\n\\n\\n\\n\\n\\n\\n\\n\\n9.2\\nEmergent abilities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nInterpretation\\n\\n\\n\\n\\nToggle Interpretation subsection\\n\\n\\n\\n\\n\\n10.1\\nUnderstanding and intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nEvaluation\\n\\n\\n\\n\\nToggle Evaluation subsection\\n\\n\\n\\n\\n\\n11.1\\nPerplexity\\n\\n\\n\\n\\n\\n\\n11.1.1\\nBPW, BPC, and BPT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nTask-specific datasets and benchmarks\\n\\n\\n\\n\\n\\n\\n11.2.1\\nAdversarially constructed evaluations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nWider impact\\n\\n\\n\\n\\nToggle Wider impact subsection\\n\\n\\n\\n\\n\\n12.1\\nMemorization and copyright\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3\\nAlgorithmic bias\\n\\n\\n\\n\\n\\n\\n12.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3.2\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nSee also'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='12.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3.2\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLarge language model\\n\\n\\n\\n46 languages\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaবাংলা閩南語 / Bân-lâm-gúBoarischBosanskiCatalàČeštinaDeutschΕλληνικάEspañolEuskaraفارسیFrançaisGaeilgeGalego한국어हिन्दीBahasa IndonesiaIsiZuluItalianoעבריתMagyarМакедонскиNederlands日本語PolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийShqipSlovenščinaکوردیСрпски / srpskiTagalogไทยTürkçeУкраїнськаئۇيغۇرچە / UyghurcheTiếng Việt文言粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Print/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nComparatively large-scale natural language processing systems\\nNot to be confused with Logic learning machine.\\n\\nPart of a series onMachine learningand data mining\\nParadigms\\nSupervised learning\\nUnsupervised learning\\nSemi-supervised learning\\nSelf-supervised learning\\nReinforcement learning\\nMeta-learning\\nOnline learning\\nBatch learning\\nCurriculum learning\\nRule-based learning\\nNeuro-symbolic AI\\nNeuromorphic engineering\\nQuantum machine learning\\n\\nProblems\\nClassification\\nGenerative modeling\\nRegression\\nClustering\\nDimensionality reduction\\nDensity estimation\\nAnomaly detection\\nData cleaning\\nAutoML\\nAssociation rules\\nSemantic analysis\\nStructured prediction\\nFeature engineering\\nFeature learning\\nLearning to rank\\nGrammar induction\\nOntology learning\\nMultimodal learning'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Supervised learning(classification\\xa0• regression) \\nApprenticeship learning\\nDecision trees\\nEnsembles\\nBagging\\nBoosting\\nRandom forest\\nk-NN\\nLinear regression\\nNaive Bayes\\nArtificial neural networks\\nLogistic regression\\nPerceptron\\nRelevance vector machine (RVM)\\nSupport vector machine (SVM)\\n\\nClustering\\nBIRCH\\nCURE\\nHierarchical\\nk-means\\nFuzzy\\nExpectation–maximization (EM)\\nDBSCAN\\nOPTICS\\nMean shift\\n\\nDimensionality reduction\\nFactor analysis\\nCCA\\nICA\\nLDA\\nNMF\\nPCA\\nPGD\\nt-SNE\\nSDL\\n\\nStructured prediction\\nGraphical models\\nBayes net\\nConditional random field\\nHidden Markov\\n\\nAnomaly detection\\nRANSAC\\nk-NN\\nLocal outlier factor\\nIsolation forest\\n\\nArtificial neural network\\nAutoencoder\\nDeep learning\\nFeedforward neural network\\nRecurrent neural network\\nLSTM\\nGRU\\nESN\\nreservoir computing\\nBoltzmann machine\\nRestricted\\nGAN\\nDiffusion model\\nSOM\\nConvolutional neural network\\nU-Net\\nLeNet\\nAlexNet\\nDeepDream\\nNeural radiance field\\nTransformer\\nVision\\nMamba\\nSpiking neural network\\nMemtransistor\\nElectrochemical RAM (ECRAM)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Reinforcement learning\\nQ-learning\\nSARSA\\nTemporal difference (TD)\\nMulti-agent\\nSelf-play\\n\\nLearning with humans\\nActive learning\\nCrowdsourcing\\nHuman-in-the-loop\\nRLHF\\n\\nModel diagnostics\\nCoefficient of determination\\nConfusion matrix\\nLearning curve\\nROC curve\\n\\nMathematical foundations\\nKernel machines\\nBias–variance tradeoff\\nComputational learning theory\\nEmpirical risk minimization\\nOccam learning\\nPAC learning\\nStatistical learning\\nVC theory\\n\\nJournals and conferences\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Journals and conferences\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR\\n\\nRelated articles\\nGlossary of artificial intelligence\\nList of datasets for machine-learning research\\nList of datasets in computer vision and image processing\\nOutline of machine learning\\nvte\\nA large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text.\\nThe largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.[3]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='History[edit]\\nThe training compute of notable large models in FLOPs vs publication date over the period 2010-2024. For overall notable models (top left), frontier models (top right), top language models (bottom left) and top models within leading companies (bottom right). The majority of these models are language models.\\nThe training compute of notable large AI models in FLOPs vs publication date over the period 2017-2024. The majority of large models are language models or multimodal models with language capacity.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Before 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved state-of-the-art perplexity at the time.[4] In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"[5]), upon which they trained statistical language models.[6][7] In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.[8]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='After neural networks became dominant in image processing around 2012,[9] they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before transformers, it was done by seq2seq deep LSTM networks.An illustration of main components of the transformer model from the original paper, where layers were normalized after (instead of before) multiheaded attention\\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 seq2seq technology,[10] and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014.[11] The following year in 2018, BERT was introduced and quickly became \"ubiquitous\".[12] Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.[13]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Although decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use.[14] GPT-3 in 2020 went a step further and as of 2024[update] is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz.[15] The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities.[16] OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work.[17]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Competing language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.[18]\\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. As of June\\xa02024[update], The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4.[19]\\nSince 2023, many LLMs have been trained to be multimodal, having the ability to also process or generate other types of data, such as images or audio. These LLMs are also called large multimodal models (LMMs).[20]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='As of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).[21][22][23]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Dataset preprocessing[edit]\\nSee also: List of datasets for machine-learning research §\\xa0Internet\\nTokenization[edit]\\n\\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding word in BERT.[24]\\nFor example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\\n\\n\\n\\ntoken\\n\\nizer\\n\\n:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='token\\n\\nizer\\n\\n:\\n\\n\\xa0texts\\n\\n\\xa0->\\n\\nseries\\n\\n\\xa0of\\n\\n\\xa0numerical\\n\\n\\xa0\"\\n\\nt\\n\\nok\\n\\nens\\n\\n\"\\n\\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.[25][26]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='BPE[edit]\\nMain article: Byte pair encoding\\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257).[27] After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.[28]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Problems[edit]\\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. An average word in another language encoded by such an English-optimized tokenizer is however split into suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.[29]\\nGreedy tokenization also causes subtle problems with text completion.[30]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Dataset cleaning[edit]\\nMain article: Data cleansing\\nIn the context of training LLMs, datasets are typically cleaned by removing toxic passages from the dataset, discarding low-quality data, and de-duplication.[31] Cleaned datasets can increase training efficiency and lead to improved downstream performance.[32][33] A trained LLM can be used to clean datasets for training a further LLM.[34]\\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).[35]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Synthetic data[edit]\\nMain article: Synthetic data\\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's Phi series of LLMs is trained on textbook-like data generated by another LLM.[36]\\n\\nTraining and architecture[edit]\\nSee also: Fine-tuning (machine learning)\\nReinforcement learning from human feedback (RLHF)[edit]\\nMain article: Reinforcement learning from human feedback\\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.[37]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Instruction tuning[edit]\\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.[38]\\n\\nMixture of experts[edit]\\nMain article: Mixture of experts\\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.[39][40][41]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Prompt engineering, attention mechanism, and context window[edit]\\nSee also: Prompt engineering and Attention (machine learning)\\nMost results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).[42]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='When each head calculates, according to its own criteria, how much other tokens are relevant for the \"it_\" token, note that the second attention head, represented by the second column, is focusing most on the first two rows, i.e. the tokens \"The\" and \"animal\", while the third column is focusing most on the bottom two rows, i.e. on \"tired\", which has been tokenized into two tokens.[43]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens.[44] In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.[28]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The largest models, such as Google\\'s Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\").[45] Other models with large context windows includes Anthropic\\'s Claude 2.1, with a context window of up to 200k tokens.[46] Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.[47]\\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.\\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.[48] It can be either'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='autoregressive (i.e. predicting how the segment continues, the way GPTs do it): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\"[49] does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.[49] During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\\n\\nInfrastructure[edit]\\nSubstantial infrastructure is necessary for training the largest models.[50][51][52]\\n\\nTraining cost[edit]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='The qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\". As time goes on, what was previously considered \"large\" may evolve. GPT-1 of 2018 is usually considered the first LLM, even though it has only 0.117 billion parameters. The tendency towards larger models is visible in the list of large language models.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Advances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80,000 and $1,600,000.[53][54][55] Since 2020, large sums were invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.[56]\\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.[57]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Tool use[edit]\\nThere are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user\\'s input \\'354 * 139 = \\', provided that the LLM has not already encountered a continuation of this calculation in its training corpus.[dubious – discuss] In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response.[dubious – discuss]: Another example is \"What is the time now? It is \", where a separate program interpreter would need to execute a code to get system time on the computer, so that the LLM can include it in its reply.[58][59] This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.[60]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Generally, in order to get an LLM to use tools, one must fine-tune it for tool-use. If the number of tools is finite, then fine-tuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.[61][62]\\nA simpler form of tool use is retrieval-augmented generation: the augmentation of an LLM with document retrieval. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.[63]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Agency[edit]\\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions, but can be transformed into one by integrating modules like profiling, memory, planning, and action.[64]\\nThe ReAct pattern, a portmanteau of \"Reason\\xa0+\\xa0Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.[65] The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[66]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.[67]\\nThe Reflexion method[68] constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.[citation needed]\\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.[69]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='For open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.[70] Alternatively, it can propose increasingly difficult tasks for curriculum learning.[71] Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.[71]\\nLLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.[72]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Compression[edit]\\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.[73]\\nPost-training quantization[74] aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance.[75][76] The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\").[77] See [78] for a visual guide.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='While quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.[79]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Multimodality[edit]\\nSee also: Multimodal learning\\nMultimodality means \"having several modalities\", and a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc.[80] There have been many AI models trained specifically to ingest one modality and output another modality, such as AlexNet for image to label,[81] visual question answering for image-text to text,[82] and speech recognition for speech to text.\\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \\n\\n\\n\\nE\\n\\n\\n{\\\\displaystyle E}\\n\\n. Make a small multilayered perceptron \\n\\n\\n\\nf\\n\\n\\n{\\\\displaystyle f}\\n\\n, so that for any image \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n, the post-processed vector \\n\\n\\n\\nf\\n(\\nE\\n(\\ny\\n)\\n)\\n\\n\\n{\\\\displaystyle f(E(y))}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.[83]\\nFlamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.[84] Google PaLM model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.[85] LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs,[86] and video inputs.[87]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"GPT-4 can use both text and image as inputs[88] (although the vision component was not released to the public until GPT-4V[89]); Google DeepMind's Gemini is also multimodal.[90]  Mistral introduced its own multimodel Pixtral 12B model in September 2024.[91]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Properties[edit]\\nScaling laws[edit]\\nMain article: Neural scaling law\\nThe performance of an LLM after pretraining largely depends on the:\\n\\ncost of pretraining \\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n (the total amount of compute used),\\nsize of the artificial neural network itself, such as number of parameters \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n (i.e. amount of neurons in its layers, amount of weights between them and biases),\\nsize of its pretraining dataset (i.e. number of tokens in corpus, \\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n).\\n\"Scaling laws\" are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:[92]\\n\\n\\n\\n\\n\\n\\n{\\n\\n\\n\\nC\\n=\\n\\nC\\n\\n0\\n\\n\\nN\\nD\\n\\n\\n\\n\\nL\\n=\\n\\n\\nA\\n\\nN\\n\\nα\\n\\n\\n\\n\\n+\\n\\n\\nB\\n\\nD\\n\\nβ\\n\\n\\n\\n\\n+\\n\\nL\\n\\n0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n{\\\\displaystyle {\\\\begin{cases}C=C_{0}ND\\\\\\\\[6pt]L={\\\\frac {A}{N^{\\\\alpha }}}+{\\\\frac {B}{D^{\\\\beta }}}+L_{0}\\\\end{cases}}}\\n\\n where the variables are\\n\\n\\n\\n\\n\\nC'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='where the variables are\\n\\n\\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n is the cost of training the model, in FLOPs.\\n\\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of parameters in the model.\\n\\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n is the number of tokens in the training set.\\n\\n\\n\\n\\nL\\n\\n\\n{\\\\displaystyle L}\\n\\n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\\nand the statistical hyper-parameters are\\n\\n\\n\\n\\n\\n\\nC\\n\\n0\\n\\n\\n=\\n6\\n\\n\\n{\\\\displaystyle C_{0}=6}\\n\\n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.[57]\\n\\n\\n\\n\\nα\\n=\\n0.34\\n,\\nβ\\n=\\n0.28\\n,\\nA\\n=\\n406.4\\n,\\nB\\n=\\n410.7\\n,\\n\\nL\\n\\n0\\n\\n\\n=\\n1.69\\n\\n\\n{\\\\displaystyle \\\\alpha =0.34,\\\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Emergent abilities[edit]\\nAt point(s) referred to as breaks,[93] the lines change their slopes, appearing on a linear-log plot as a series of linear segments connected by arcs.\\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\"[93] in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\".[42][94] They arise from the complex interaction of the model\\'s components and are not explicitly programmed or designed.[95]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Furthermore, recent research has demonstrated that AI systems, including large language models, can employ heuristic reasoning akin to human cognition. They balance between exhaustive logical processing and the use of cognitive shortcuts (heuristics), adapting their reasoning strategies to optimize between accuracy and effort. This behavior aligns with principles of resource-rational human cognition, as discussed in classical theories of bounded rationality and dual-process theory.[96]\\nThe most intriguing among emergent abilities is in-context learning from example demonstrations.[97] In-context learning is involved in tasks, such as:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='reported arithmetics, decoding the International Phonetic Alphabet, unscrambling a word\\'s letters, disambiguate word in context,[42][98][99] converting spatial words, cardinal directions (for example, replying \"northeast\" upon [0, 0, 1; 0, 0, 0; 0, 0, 0]), color terms represented in text.[100]\\nchain-of-thought prompting: Model outputs are improved by chain-of-thought prompting only when model size exceeds 62B. Smaller models perform better when prompted to answer immediately, without chain of thought.[101]\\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.[102]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Schaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.[103]\\nLet'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='x\\n\\n\\n{\\\\displaystyle x}\\n\\n be the number of parameter count, and \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n be the performance of the model.\\n\\n\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{correct token}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n is an exponential curve (before it hits the plateau at one), which looks like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\log(\\\\Pr({\\\\text{correct token}}))}\\n\\n, then the \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n plot is a straight line (before it hits the plateau at zero), which does not look like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\nthe most likely token is correct\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{the most likely token is correct}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='is a step-function, which looks like emergence.\\nInterpretation[edit]\\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.\\nMechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[104][105] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[106]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[107]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Understanding and intelligence[edit]\\nSee also: Philosophy of artificial intelligence and Artificial consciousness'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[108] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[109][110] Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation.[111] Some'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='unknown detective novel after processing the entire story leading up to the revelation.[111] Some researchers characterize LLMs as \"alien intelligence\".[112][113] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"[114][115]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='In contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[113] a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[108] For example, GPT-4 has natural deficits in planning and in real-time learning.[110] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[116] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[117] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='\"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".[108]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"The matter of LLM's exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language.[108] These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented Neural Theory of Language (NTL)[118] as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.[119][120]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Evaluation[edit]\\nPerplexity[edit]\\nThe canonical measure of the performance of an LLM is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\\n\\n\\n\\n\\nlog\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n=\\n−\\n\\n\\n1\\nN\\n\\n\\n\\n∑\\n\\ni\\n=\\n1\\n\\n\\nN\\n\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\n\\ntoken\\n\\n\\ni\\n\\n\\n∣\\n\\n\\ncontext for token\\n\\n\\ni\\n\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle \\\\log({\\\\text{Perplexity}})=-{\\\\frac {1}{N}}\\\\sum _{i=1}^{N}\\\\log(\\\\Pr({\\\\text{token}}_{i}\\\\mid {\\\\text{context for token}}_{i}))}\\n\\n\\nHere, \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of tokens in the text corpus, and \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text appearing before token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='i\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text appearing before token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n. If the LLM is masked, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text surrounding token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n.\\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set.[49] This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.[1]\\n\\nBPW, BPC, and BPT[edit]\\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon.[121] This relationship is mathematically expressed as \\n\\n\\n\\n\\nEntropy\\n\\n=\\n\\nlog\\n\\n2\\n\\n\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n\\n\\n{\\\\displaystyle {\\\\text{Entropy}}=\\\\log _{2}({\\\\text{Perplexity}})}'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\".\\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Task-specific datasets and benchmarks[edit]\\nA large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks. Tests may be designed to evaluate a variety of capabilities, including general knowledge, commonsense reasoning, and mathematical problem-solving.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='One broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").[122] A question answering task is considered \"open book\" if the model\\'s prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"[122]). Otherwise, the task is considered \"closed book\", and the model must draw on knowledge retained during training.[123] Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.[123]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Evaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".[1]\\nSome composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, and HELM.[121][123] OpenAI has released tools for running composite benchmarks, but noted that the eval results are sensitive to the prompting method.[124][125] Some public datasets contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality, which can be cleaned to give more reliable benchmark scores.[126]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='It was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder. It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Adversarially constructed evaluations[edit]\\nBecause of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks.[127] In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.[108]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Some datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods to which they were repeatedly exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can\\'t teach an old dog new tricks, even though this is not literally true.[128]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Another example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model and filtering with a set of classifiers. The resulting problems are trivial for humans but at the time the datasets were created state of the art language models had poor accuracy on them. For example:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='We see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\\na) demonstrates how to increase efficient exercise work by running up and down balls.\\nb) moves all his arms and legs and builds up a lot of muscle.\\nc) then plays the ball and we see a graphics and hedge trimming demonstration.\\nd) performs sit ups while on the ball and talking.[129]\\n\\n\\nBERT selects b) as the most likely completion, though the correct answer is d).[129]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='BERT selects b) as the most likely completion, though the correct answer is d).[129]\\n\\nWider impact[edit]\\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\"[130] Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.[131][132]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Memorization and copyright[edit]\\nFurther information: Artificial intelligence and copyright\\nMemorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates[133] or up to about 7%.[134]\\nA 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.[135]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Security[edit]\\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.[136] For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.[137]\\nThe potential presence of \"sleeper agents\" within LLM models is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.[138]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"LLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study[139] proposed a method for circumventing LLM safety systems. Similarly, Yongge Wang[140] illustrated in 2024 how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content=\"Algorithmic bias[edit]\\nMain article: Algorithmic bias\\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.[141] Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.[142]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Stereotyping[edit]\\nAI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.[143]\\nNotably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms.[141] For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.[144]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Political bias[edit]\\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.[145]\\n\\nSee also[edit]\\nFoundation models\\nList of large language models\\nList of chatbots\\nReferences[edit]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='See also[edit]\\nFoundation models\\nList of large language models\\nList of chatbots\\nReferences[edit]\\n\\n\\n^ a b c Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.). \"Language Models are Few-Shot Learners\" (PDF). Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 1877–1901. Archived (PDF) from the original on 2023-11-17. Retrieved 2023-03-14.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Fathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter; Kovriguina, Liubov (2024-05-26). NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning (PDF). Extended Semantic Web Conference 2024. Hersonissos, Greece.\\n\\n^ Manning, Christopher D. (2022). \"Human Language Understanding & Reasoning\". Daedalus. 151 (2): 127–138. doi:10.1162/daed_a_01905. S2CID\\xa0248377870. Archived from the original on 2023-11-17. Retrieved 2023-03-09.\\n\\n^ Goodman, Joshua (2001-08-09), A Bit of Progress in Language Modeling, arXiv:cs/0108005, Bibcode:2001cs........8005G\\n\\n^ Kilgarriff, Adam; Grefenstette, Gregory (September 2003). \"Introduction to the Special Issue on the Web as Corpus\". Computational Linguistics. 29 (3): 333–347. doi:10.1162/089120103322711569. ISSN\\xa00891-2017.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Banko, Michele; Brill, Eric (2001). \"Scaling to very very large corpora for natural language disambiguation\". Proceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL \\'01. Morristown, NJ, USA: Association for Computational Linguistics: 26–33. doi:10.3115/1073012.1073017.\\n\\n^ Resnik, Philip; Smith, Noah A. (September 2003). \"The Web as a Parallel Corpus\". Computational Linguistics. 29 (3): 349–380. doi:10.1162/089120103322711578. ISSN\\xa00891-2017. Archived from the original on 2024-06-07. Retrieved 2024-06-07.\\n\\n^ Halevy, Alon; Norvig, Peter; Pereira, Fernando (March 2009). \"The Unreasonable Effectiveness of Data\". IEEE Intelligent Systems. 24 (2): 8–12. doi:10.1109/MIS.2009.36. ISSN\\xa01541-1672.\\n\\n^ Chen, Leiyu; Li, Shaobo; Bai, Qiang; Yang, Jing; Jiang, Sanlong; Miao, Yanming (2021). \"Review of Image Classification Algorithms Based on Convolutional Neural Networks\". Remote Sensing. 13 (22): 4712. Bibcode:2021RemS...13.4712C. doi:10.3390/rs13224712.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (2017). \"Attention is All you Need\" (PDF). Advances in Neural Information Processing Systems. 30. Curran Associates, Inc. Archived (PDF) from the original on 2024-02-21. Retrieved 2024-01-21.\\n\\n^ Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\". arXiv:1409.0473 [cs.CL].\\n\\n^ Rogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). \"A Primer in BERTology: What We Know About How BERT Works\". Transactions of the Association for Computational Linguistics. 8: 842–866. arXiv:2002.12327. doi:10.1162/tacl_a_00349. S2CID\\xa0211532403. Archived from the original on 2022-04-03. Retrieved 2024-01-21.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa01223–1243. arXiv:2307.10700. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.\\n\\n^ Hern, Alex (14 February 2019). \"New AI fake text generator may be too dangerous to release, say creators\". The Guardian. Archived from the original on 14 February 2019. Retrieved 20 January 2024.\\n\\n^ \"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months\". Euronews. November 30, 2023. Archived from the original on January 14, 2024. Retrieved January 20, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Heaven, Will (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT—but OpenAI won\\'t say why\". MIT Technology Review. Archived from the original on March 17, 2023. Retrieved January 20, 2024.\\n\\n^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa01223–1243. arXiv:2307.10700. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.\\n\\n^ \"Parameters in notable artificial intelligence systems\". ourworldindata.org. November 30, 2023. Retrieved January 20, 2024.\\n\\n^ \"LMSYS Chatbot Arena Leaderboard\". huggingface.co. Archived from the original on June 10, 2024. Retrieved June 12, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Zia, Dr Tehseen (2024-01-08). \"Unveiling of Large Multimodal Models: Shaping the Landscape of Language Models in 2024\". Unite.AI. Retrieved 2024-12-28.\\n\\n^ Peng, Bo; et\\xa0al. (2023). \"RWKV: Reinventing RNNS for the Transformer Era\". arXiv:2305.13048 [cs.CL].\\n\\n^ Merritt, Rick (2022-03-25). \"What Is a Transformer Model?\". NVIDIA Blog. Archived from the original on 2023-11-17. Retrieved 2023-07-25.\\n\\n^ Gu, Albert; Dao, Tri (2023-12-01), Mamba: Linear-Time Sequence Modeling with Selective State Spaces, arXiv:2312.00752\\n\\n^ Kaushal, Ayush; Mahowald, Kyle (2022-06-06), What do tokens know about their characters and how do they know it?, arXiv:2206.02608\\n\\n^ Yennie Jun (2023-05-03). \"All languages are NOT created (tokenized) equal\". Language models cost much more in some languages than others. Archived from the original on 2023-08-17. Retrieved 2023-08-17. In other words, to express the same sentiment, some languages require up to 10 times more tokens.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Petrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". NeurIPS. arXiv:2305.15425. Archived from the original on December 15, 2023. Retrieved September 16, 2023 – via openreview.net.\\n\\n^ \"OpenAI API\". platform.openai.com. Archived from the original on April 23, 2023. Retrieved 2023-04-30.\\n\\n^ a b Paaß, Gerhard; Giesselbach, Sven (2022). \"Pre-trained Language Models\". Foundation Models for Natural Language Processing. Artificial Intelligence: Foundations, Theory, and Algorithms. pp.\\xa019–78. doi:10.1007/978-3-031-23190-2_2. ISBN\\xa09783031231902. Archived from the original on 3 August 2023. Retrieved 3 August 2023.\\n\\n^ Petrov, Aleksandar; Emanuele La Malfa; Torr, Philip H. S.; Bibi, Adel (2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". arXiv:2305.15425 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lundberg, Scott (2023-12-12). \"The Art of Prompt Design: Prompt Boundaries and Token Healing\". Medium. Retrieved 2024-08-05.\\n\\n^ Dodge, Jesse; Sap, Maarten; Marasović, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt (2021). \"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus\". arXiv:2104.08758 [cs.CL].\\n\\n^ Lee, Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, Douglas; Callison-Burch, Chris; Carlini, Nicholas (May 2022). \"Deduplicating Training Data Makes Language Models Better\" (PDF). Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. 1: Long Papers: 8424–8445. doi:10.18653/v1/2022.acl-long.577.\\n\\n^ Li, Yuanzhi; Bubeck, Sébastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee, Yin Tat (2023-09-11), Textbooks Are All You Need II: phi-1.5 technical report, arXiv:2309.05463'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen; Yang, Yujiu; Jiao, Jian (2024-04-11). \"Rho-1: Not All Tokens Are What You Need\". arXiv:2404.07965 [cs.CL].\\n\\n^ Brown, Tom B.; et\\xa0al. (2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165 [cs.CL].\\n\\n^ Abdin, Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, Ahmed; Awadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash (2024-04-23). \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\". arXiv:2404.14219 [cs.CL].\\n\\n^ Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; Simens, Maddie; Askell, Amanda; Welinder, Peter; Christiano, Paul; Leike, Jan; Lowe, Ryan (2022). \"Training language models to follow instructions with human feedback\". arXiv:2203.02155 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Wang, Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; Khashabi, Daniel; Hajishirzi, Hannaneh (2022). \"Self-Instruct: Aligning Language Model with Self Generated Instructions\". arXiv:2212.10560 [cs.CL].\\n\\n^ Shazeer, Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; Hinton, Geoffrey; Dean, Jeff (2017-01-01). \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\". arXiv:1701.06538 [cs.LG].\\n\\n^ Lepikhin, Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; Huang, Yanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng (2021-01-12). \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\". arXiv:2006.16668 [cs.CL].\\n\\n^ Dai, Andrew M; Du, Nan (December 9, 2021). \"More Efficient In-Context Learning with GLaM\". ai.googleblog.com. Archived from the original on 2023-03-12. Retrieved 2023-03-09.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b c Wei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022). \"Emergent Abilities of Large Language Models\". Transactions on Machine Learning Research. ISSN\\xa02835-8856. Archived from the original on 22 March 2023. Retrieved 19 March 2023.\\n\\n^ Allamar, Jay. \"Illustrated transformer\". Archived from the original on 2023-07-25. Retrieved 2023-07-29.\\n\\n^ Allamar, Jay. \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\". Retrieved 2023-08-01.\\n\\n^ \"Our next-generation model: Gemini 1.5\". Google. 15 February 2024. Archived from the original on 18 February 2024. Retrieved 18 February 2024.\\n\\n^ \"Long context prompting for Claude 2.1\". December 6, 2023. Archived from the original on August 27, 2024. Retrieved January 20, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"Rate limits\". openai.com. Archived from the original on February 2, 2024. Retrieved January 20, 2024.\\n\\n^ Zaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). \"A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP\". Proceedings of the Australasian Computer Science Week Multiconference. pp.\\xa01–4. arXiv:2104.10810. doi:10.1145/3373017.3373028. ISBN\\xa09781450376976. S2CID\\xa0211040895.\\n\\n^ a b c Jurafsky, Dan; Martin, James H. (7 January 2023). Speech and Language Processing (PDF) (3rd edition draft\\xa0ed.). Archived (PDF) from the original on 23 March 2023. Retrieved 24 May 2022.\\n\\n^ \"From bare metal to a 70B model: infrastructure set-up and scripts\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ \"metaseq/projects/OPT/chronicles at main · facebookresearch/metaseq\". GitHub. Archived from the original on 2024-01-24. Retrieved 2024-07-24.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Albrecht, Josh (2024-07-23). \"State of the Art: Training >70B LLMs on 10,000 H100 clusters\". www.latent.space. Retrieved 2024-07-24.\\n\\n^ Wiggers, Kyle (28 April 2022). \"The emerging types of language models and why they matter\". TechCrunch. Archived from the original on 16 March 2023. Retrieved 9 March 2023.\\n\\n^ Sharir, Or; Peleg, Barak; Shoham, Yoav (2020). \"The Cost of Training NLP Models: A Concise Overview\". arXiv:2004.08900 [cs.CL].\\n\\n^ Biderman, Stella; Schoelkopf, Hailey; Anthony, Quentin; Bradley, Herbie; Khan, Mohammad Aflah; Purohit, Shivanshu; Prashanth, USVSN Sai (April 2023). \"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling\". arXiv:2304.01373 [cs.CL].\\n\\n^ Maslej, Nestor; Fattorini, Loredana; Brynjolfsson, Erik; Etchemendy, John; Ligett, Katrina; Lyons, Terah; Manyika, James; Ngo, Helen; Niebles, Juan Carlos (2023-10-05), Artificial Intelligence Index Report 2023, arXiv:2310.03715\\n\\n^ a b Section 2.1 and Table 1,'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b Section 2.1 and Table 1,\\n\\nKaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for Neural Language Models\". arXiv:2001.08361 [cs.LG].\\n\\n^ Gao, Luyu; Madaan, Aman; Zhou, Shuyan; Alon, Uri; Liu, Pengfei; Yang, Yiming; Callan, Jamie; Neubig, Graham (2022-11-01). \"PAL: Program-aided Language Models\". arXiv:2211.10435 [cs.CL].\\n\\n^ \"PAL: Program-aided Language Models\". reasonwithpal.com. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ Paranjape, Bhargavi; Lundberg, Scott; Singh, Sameer; Hajishirzi, Hannaneh; Zettlemoyer, Luke; Tulio Ribeiro, Marco (2023-03-01). \"ART: Automatic multi-step reasoning and tool-use for large language models\". arXiv:2303.09014 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Liang, Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, Yang; Lu, Shuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong, Ming; Duan, Nan (2023-03-01). \"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs\". arXiv:2303.16434 [cs.AI].\\n\\n^ Patil, Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. (2023-05-01). \"Gorilla: Large Language Model Connected with Massive APIs\". arXiv:2305.15334 [cs.CL].\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ \"The Growth Behind LLM-based Autonomous Agents\". KDnuggets. October 23, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"The Growth Behind LLM-based Autonomous Agents\". KDnuggets. October 23, 2023.\\n\\n^ Yao, Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, Karthik; Cao, Yuan (2022-10-01). \"ReAct: Synergizing Reasoning and Acting in Language Models\". arXiv:2210.03629 [cs.CL].\\n\\n^ Wu, Yue; Prabhumoye, Shrimai; Min, So Yeon (24 May 2023). \"SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning\". arXiv:2305.15486 [cs.AI].\\n\\n^ Wang, Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao (2023-02-03). \"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\". arXiv:2302.01560 [cs.AI].\\n\\n^ Shinn, Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, Karthik; Yao, Shunyu (2023-03-01). \"Reflexion: Language Agents with Verbal Reinforcement Learning\". arXiv:2303.11366 [cs.AI].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Hao, Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, Daisy; Hu, Zhiting (2023-05-01). \"Reasoning with Language Model is Planning with World Model\". arXiv:2305.14992 [cs.CL].\\n\\n^ Zhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). \"OMNI: Open-endedness via Models of human Notions of Interestingness\". arXiv:2306.01711 [cs.AI].\\n\\n^ a b \"Voyager | An Open-Ended Embodied Agent with Large Language Models\". voyager.minedojo.org. Archived from the original on 2023-06-08. Retrieved 2023-06-09.\\n\\n^ Park, Joon Sung; O\\'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith; Liang, Percy; Bernstein, Michael S. (2023-04-01). \"Generative Agents: Interactive Simulacra of Human Behavior\". arXiv:2304.03442 [cs.HC].\\n\\n^ Mann, Tobias. \"How to run an LLM locally on your PC in less than 10 minutes\". www.theregister.com. Retrieved 2024-05-17.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Nagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen (2020-11-21). \"Up or Down? Adaptive Rounding for Post-Training Quantization\". Proceedings of the 37th International Conference on Machine Learning. PMLR: 7197–7206. Archived from the original on 2023-06-14. Retrieved 2023-06-14.\\n\\n^ Polino, Antonio; Pascanu, Razvan; Alistarh, Dan (2018-02-01). \"Model compression via distillation and quantization\". arXiv:1802.05668 [cs.NE].\\n\\n^ Frantar, Elias; Ashkboos, Saleh; Hoefler, Torsten; Alistarh, Dan (2022-10-01). \"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers\". arXiv:2210.17323 [cs.LG].\\n\\n^ Dettmers, Tim; Svirschevski, Ruslan; Egiazarian, Vage; Kuznedelev, Denis; Frantar, Elias; Ashkboos, Saleh; Borzunov, Alexander; Hoefler, Torsten; Alistarh, Dan (2023-06-01). \"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression\". arXiv:2306.03078 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Grootendorst, Maarten. \"A Visual Guide to Quantization\". newsletter.maartengrootendorst.com. Archived from the original on 31 Jul 2024. Retrieved 2024-07-31.\\n\\n^ Dettmers, Tim; Pagnoni, Artidoro; Holtzman, Ari; Zettlemoyer, Luke (2023-05-01). \"QLoRA: Efficient Finetuning of Quantized LLMs\". arXiv:2305.14314 [cs.LG].\\n\\n^ Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18). \"Multimodal Neural Language Models\". Proceedings of the 31st International Conference on Machine Learning. PMLR: 595–603. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\". Advances in Neural Information Processing Systems. 25. Curran Associates, Inc. Archived from the original on 2023-07-02. Retrieved 2023-07-02.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Antol, Stanislaw; Agrawal, Aishwarya; Lu, Jiasen; Mitchell, Margaret; Batra, Dhruv; Zitnick, C. Lawrence; Parikh, Devi (2015). \"VQA: Visual Question Answering\". ICCV: 2425–2433. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Li, Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01). \"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models\". arXiv:2301.12597 [cs.CV].\\n\\n^ Alayrac, Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain; Hasson, Yana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; Reynolds, Malcolm; Ring, Roman; Rutherford, Eliza; Cabi, Serkan; Han, Tengda; Gong, Zhitao (2022-12-06). \"Flamingo: a Visual Language Model for Few-Shot Learning\". Advances in Neural Information Processing Systems. 35: 23716–23736. arXiv:2204.14198. Archived from the original on 2023-07-02. Retrieved 2023-07-02.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Driess, Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, Aakanksha; Ichter, Brian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan; Yu, Tianhe; Huang, Wenlong; Chebotar, Yevgen; Sermanet, Pierre; Duckworth, Daniel; Levine, Sergey (2023-03-01). \"PaLM-E: An Embodied Multimodal Language Model\". arXiv:2303.03378 [cs.LG].\\n\\n^ Liu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). \"Visual Instruction Tuning\". arXiv:2304.08485 [cs.CV].\\n\\n^ Zhang, Hang; Li, Xin; Bing, Lidong (2023-06-01). \"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding\". arXiv:2306.02858 [cs.CL].\\n\\n^ OpenAI (2023-03-27). \"GPT-4 Technical Report\". arXiv:2303.08774 [cs.CL].\\n\\n^ OpenAI (September 25, 2023). \"GPT-4V(ision) System Card\" (PDF).\\n\\n^ Pichai, Sundar (10 May 2023), Google Keynote (Google I/O \\'23), timestamp 15:31, retrieved 2023-07-02'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Wiggers, Kyle (11 September 2024). \"Mistral releases Pixtral 12B, its first multimodal model\". TechCrunch. Retrieved 14 September 2024.\\n\\n^ Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, Trevor; Rutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; Welbl, Johannes; Clark, Aidan; Hennigan, Tom; Noland, Eric; Millican, Katie; Driessche, George van den; Damoc, Bogdan (2022-03-29). \"Training Compute-Optimal Large Language Models\". arXiv:2203.15556 [cs.CL].\\n\\n^ a b Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). \"Broken Neural Scaling Laws\". arXiv:2210.14891 [cs.LG].\\n\\n^ \"137 emergent abilities of large language models\". Jason Wei. Retrieved 2023-06-24.\\n\\n^ Bowman, Samuel R. (2023). \"Eight Things to Know about Large Language Models\". arXiv:2304.00612 [cs.CL].\\n\\n^ Mukherjee, Anirban; Chang, Hannah (2024). \"Heuristic Reasoning in AI: Instrumental Use and Mimetic Absorption\". arXiv:2403.09404 [cs.AI].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Hahn, Michael; Goyal, Navin (2023-03-14). \"A Theory of Emergent In-Context Learning as Implicit Structure Induction\". arXiv:2303.07971 [cs.LG].\\n\\n^ Pilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019). \"Proceedings of the 2019 Conference of the North\". Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota: Association for Computational Linguistics: 1267–1273. doi:10.18653/v1/N19-1128. S2CID\\xa0102353817. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ \"WiC: The Word-in-Context Dataset\". pilehvar.github.io. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ Patel, Roma; Pavlick, Ellie (2021-10-06). \"Mapping Language Models to Grounded Conceptual Spaces\". ICLR. Archived from the original on 2023-06-24. Retrieved 2023-06-27.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ A Closer Look at Large Language Models Emergent Abilities Archived 2023-06-24 at the Wayback Machine (Yao Fu, Nov 20, 2022)\\n\\n^ Ornes, Stephen (March 16, 2023). \"The Unpredictable Abilities Emerging From Large AI Models\". Quanta Magazine. Archived from the original on March 16, 2023. Retrieved March 16, 2023.\\n\\n^ Schaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). \"Are Emergent Abilities of Large Language Models a Mirage?\". arXiv:2304.15004 [cs.AI].\\n\\n^ Li, Kenneth; Hopkins, Aspen K.; Bau, David; Viégas, Fernanda; Pfister, Hanspeter; Wattenberg, Martin (2022-10-01). \"Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task\". arXiv:2210.13382 [cs.LG].\\n\\n^ \"Large Language Model: world models or surface statistics?\". The Gradient. 2023-01-21. Retrieved 2023-06-12.\\n\\n^ Jin, Charles; Rinard, Martin (2023-05-01). \"Evidence of Meaning in Language Models Trained on Programs\". arXiv:2305.11169 [cs.LG].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Nanda, Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob (2023-01-01). \"Progress measures for grokking via mechanistic interpretability\". arXiv:2301.05217 [cs.LG].\\n\\n^ a b c d e Mitchell, Melanie; Krakauer, David C. (28 March 2023). \"The debate over understanding in AI\\'s large language models\". Proceedings of the National Academy of Sciences. 120 (13): e2215907120. arXiv:2210.13966. Bibcode:2023PNAS..12015907M. doi:10.1073/pnas.2215907120. PMC\\xa010068812. PMID\\xa036943882.\\n\\n^ Metz, Cade (16 May 2023). \"Microsoft Says New A.I. Shows Signs of Human Reasoning\". The New York Times.\\n\\n^ a b Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ \"Anthropic CEO Dario Amodei pens a smart look at our AI future\". Fast Company. October 17, 2024.\\n\\n^ \"ChatGPT is more like an \\'alien intelligence\\' than a human brain, says futurist\". ZDNET. 2023. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ a b Newport, Cal (13 April 2023). \"What Kind of Mind Does ChatGPT Have?\". The New Yorker. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ Roose, Kevin (30 May 2023). \"Why an Octopus-like Creature Has Come to Symbolize the State of A.I.\" The New York Times. Archived from the original on 30 May 2023. Retrieved 12 June 2023.\\n\\n^ \"The A to Z of Artificial Intelligence\". Time Magazine. 13 April 2023. Archived from the original on 16 June 2023. Retrieved 12 June 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Ji, Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; Ishii, Etsuko; Bang, Yejin; Dai, Wenliang; Madotto, Andrea; Fung, Pascale (November 2022). \"Survey of Hallucination in Natural Language Generation\" (pdf). ACM Computing Surveys. 55 (12). Association for Computing Machinery: 1–38. arXiv:2202.03629. doi:10.1145/3571730. S2CID\\xa0246652372. Archived from the original on 26 March 2023. Retrieved 15 January 2023.\\n\\n^ Varshney, Neeraj; Yao, Wenlin; Zhang, Hongming; Chen, Jianshu; Yu, Dong (2023). \"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation\". arXiv:2307.03987 [cs.CL].\\n\\n^ Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm. New York Basic Books. pp.\\xa0569–583. ISBN\\xa0978-0-465-05674-3.\\n\\n^ Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-04396-1.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-04396-1.\\n\\n^ Friston, Karl J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference. The MIT Press. ISBN\\xa0978-0-262-36997-8.\\n\\n^ a b Huyen, Chip (October 18, 2019). \"Evaluation Metrics for Language Modeling\". The Gradient. Retrieved January 14, 2024.\\n\\n^ a b Clark, Christopher; Lee, Kenton; Chang, Ming-Wei; Kwiatkowski, Tom; Collins, Michael; Toutanova, Kristina (2019). \"BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\". arXiv:1905.10044 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ a b c Wayne Xin Zhao; Zhou, Kun; Li, Junyi; Tang, Tianyi; Wang, Xiaolei; Hou, Yupeng; Min, Yingqian; Zhang, Beichen; Zhang, Junjie; Dong, Zican; Du, Yifan; Yang, Chen; Chen, Yushuo; Chen, Zhipeng; Jiang, Jinhao; Ren, Ruiyang; Li, Yifan; Tang, Xinyu; Liu, Zikang; Liu, Peiyu; Nie, Jian-Yun; Wen, Ji-Rong (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\n\\n^ openai/simple-evals, OpenAI, 2024-05-28, retrieved 2024-05-28\\n\\n^ openai/evals, OpenAI, 2024-05-28, archived from the original on 2024-05-08, retrieved 2024-05-28\\n\\n^ \"Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ Srivastava, Aarohi; et\\xa0al. (2022). \"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models\". arXiv:2206.04615 [cs.CL].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Lin, Stephanie; Hilton, Jacob; Evans, Owain (2021). \"TruthfulQA: Measuring How Models Mimic Human Falsehoods\". arXiv:2109.07958 [cs.CL].\\n\\n^ a b Zellers, Rowan; Holtzman, Ari; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin (2019). \"HellaSwag: Can a Machine Really Finish Your Sentence?\". arXiv:1905.07830 [cs.CL].\\n\\n^ \"Prepare for truly useful large language models\". Nature Biomedical Engineering. 7 (2): 85–86. 7 March 2023. doi:10.1038/s41551-023-01012-6. PMID\\xa036882584. S2CID\\xa0257403466.\\n\\n^ \"Your job is (probably) safe from artificial intelligence\". The Economist. 7 May 2023. Archived from the original on 17 June 2023. Retrieved 18 June 2023.\\n\\n^ \"Generative AI Could Raise Global GDP by 7%\". Goldman Sachs. Archived from the original on 18 June 2023. Retrieved 18 June 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Peng, Zhencan; Wang, Zhizhi; Deng, Dong (13 June 2023). \"Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation\" (PDF). Proceedings of the ACM on Management of Data. 1 (2): 1–18. doi:10.1145/3589324. S2CID\\xa0259213212. Archived (PDF) from the original on 2024-08-27. Retrieved 2024-01-20. Citing Lee et al 2022.\\n\\n^ Peng, Wang & Deng 2023, p.\\xa08.\\n\\n^ Stephen Council (1 Dec 2023). \"How Googlers cracked an SF rival\\'s tech model with a single word\". SFGATE. Archived from the original on 16 December 2023.\\n\\n^ Alba, Davey (1 May 2023). \"AI chatbots have been used to create dozens of news content farms\". The Japan Times. Retrieved 18 June 2023.\\n\\n^ \"Could chatbots help devise the next pandemic virus?\". Science. 14 June 2023. doi:10.1126/science.adj2463. Archived from the original on 18 June 2023. Retrieved 18 June 2023.\\n\\n^ Hubinger, Evan (10 January 2024). \"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training\". arXiv:2401.05566 [cs.CR].'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Kang, Daniel (2023). \"Exploiting programmatic behavior of LLMs: Dual-use through standard security attacks\". arXiv:2302.05733 [cs.CR].\\n\\n^ Wang, Yongge (20 June 2024). \"Encryption Based Covert Channel for Large Language Models\" (PDF). IACR ePrint 2024/586. Archived (PDF) from the original on 24 June 2024. Retrieved 24 June 2024.\\n\\n^ a b Stokel-Walker, Chris (November 22, 2023). \"ChatGPT Replicates Gender Bias in Recommendation Letters\". Scientific American. Archived from the original on 2023-12-29. Retrieved 2023-12-29.\\n\\n^ Luo, Queenie; Puett, Michael J.; Smith, Michael D. (2023-03-28). \"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube\". arXiv:2303.16281v2 [cs.CY].\\n\\n^ Cheng, Myra; Durmus, Esin; Jurafsky, Dan (2023-05-29), Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models, arXiv:2305.18189'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='^ Kotek, Hadas; Dockum, Rikker; Sun, David (2023-11-05). \"Gender bias and stereotypes in Large Language Models\". Proceedings of the ACM Collective Intelligence Conference. CI \\'23. New York, NY, USA: Association for Computing Machinery. pp.\\xa012–24. doi:10.1145/3582269.3615599. ISBN\\xa0979-8-4007-0113-9.\\n\\n^ Heikkilä, Melissa (August 7, 2023). \"AI language models are rife with different political biases\". MIT Technology Review. Retrieved 2023-12-29.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Further reading[edit]\\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\\nZhao, Wayne Xin; et\\xa0al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\nKaddour, Jean; et\\xa0al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024). \"A Survey on Multimodal Large Language Models\". National Science Review. arXiv:2306.13549. doi:10.1093/nsr/nwae403.\\n\"AI Index Report 2024 – Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451–452. doi:10.1038/s44159-023-00211-x. ISSN\\xa02731-0574. S2CID\\xa0259713140. Retrieved 2 July 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='vteNatural language processingGeneral terms\\nAI-complete\\nBag-of-words\\nn-gram\\nBigram\\nTrigram\\nComputational linguistics\\nNatural language understanding\\nStop words\\nText processing\\nText analysis\\nArgument mining\\nCollocation extraction\\nConcept mining\\nCoreference resolution\\nDeep linguistic processing\\nDistant reading\\nInformation extraction\\nNamed-entity recognition\\nOntology learning\\nParsing\\nSemantic parsing\\nSyntactic parsing\\nPart-of-speech tagging\\nSemantic analysis\\nSemantic role labeling\\nSemantic decomposition\\nSemantic similarity\\nSentiment analysis\\nTerminology extraction\\nText mining\\nTextual entailment\\nTruecasing\\nWord-sense disambiguation\\nWord-sense induction\\nText segmentation\\nCompound-term processing\\nLemmatisation\\nLexical analysis\\nText chunking\\nStemming\\nSentence segmentation\\nWord segmentation'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Automatic summarization\\nMulti-document summarization\\nSentence extraction\\nText simplification\\nMachine translation\\nComputer-assisted\\nExample-based\\nRule-based\\nStatistical\\nTransfer-based\\nNeural\\nDistributional semantics models\\nBERT\\nDocument-term matrix\\nExplicit semantic analysis\\nfastText\\nGloVe\\nLanguage model (large)\\nLatent semantic analysis\\nSeq2seq\\nWord embedding\\nWord2vec\\nLanguage resources,datasets and corporaTypes andstandards\\nCorpus linguistics\\nLexical resource\\nLinguistic Linked Open Data\\nMachine-readable dictionary\\nParallel text\\nPropBank\\nSemantic network\\nSimple Knowledge Organization System\\nSpeech corpus\\nText corpus\\nThesaurus (information retrieval)\\nTreebank\\nUniversal Dependencies\\nData\\nBabelNet\\nBank of English\\nDBpedia\\nFrameNet\\nGoogle Ngram Viewer\\nUBY\\nWordNet\\nWikidata\\nAutomatic identificationand data capture\\nSpeech recognition\\nSpeech segmentation\\nSpeech synthesis\\nNatural language generation\\nOptical character recognition\\nTopic model\\nDocument classification\\nLatent Dirichlet allocation'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Optical character recognition\\nTopic model\\nDocument classification\\nLatent Dirichlet allocation\\nPachinko allocation\\nComputer-assistedreviewing\\nAutomated essay scoring\\nConcordancer\\nGrammar checker\\nPredictive text\\nPronunciation assessment\\nSpell checker\\nNatural languageuser interface\\nChatbot\\nInteractive fiction (c.f. Syntax guessing)\\nQuestion answering\\nVirtual assistant\\nVoice user interface\\nRelated\\nFormal semantics\\nHallucination\\nNatural Language Toolkit\\nspaCy'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='vteArtificial intelligenceConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nRLHF\\nSelf-supervised learning\\nWord embedding\\nHallucination\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nArtificial general intelligence\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Text-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nClaude\\nGemini\\nchatbot\\nGrok\\nLaMDA\\nBLOOM\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nJürgen Schmidhuber\\nYann LeCun\\nGeoffrey Hinton\\nJohn Hopfield\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Andrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow\\nAndrej Karpathy\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Portals\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n List\\nCompanies\\nProjects\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1266089667\"\\nCategories: Large language modelsDeep learningNatural language processingHidden categories: CS1: long volume valueWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2024All articles containing potentially dated statementsArticles containing potentially dated statements from June 2024All accuracy disputesArticles with disputed statements from September 2024All articles with unsourced statementsArticles with unsourced statements from February 2024'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='This page was last edited on 30 December 2024, at 01:48\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Lost in Translation\\nMay 2023\\nA report from\\nGabriel Nicholas\\nAliya Bhatia\\nLarge Language Models in \\nNon-English Content Analysis\\nGABRIEL NICHOLAS\\nResearch Fellow at the Center for Democracy & Technology.\\nALIYA BHATIA\\nPolicy Analyst, Free Expression Project at the Center for \\nDemocracy & Technology.\\nThe Center for Democracy & Technology (CDT) is the leading \\nnonpartisan, nonprofit organization fighting to advance civil rights and \\ncivil liberties in the digital age. We shape technology policy, governance, \\nand design with a focus on equity and democratic values. Established in \\n1996, CDT has been a trusted advocate for digital rights since the earliest \\ndays of the internet. The organization is headquartered in Washington, \\nD.C., and has a Europe Office in Brussels, Belgium.\\nA report from\\nGabriel Nicholas and Aliya Bhatia\\nWITH CONTRIBUTIONS BY\\nSamir Jain, Mallory Knodel, Emma Llansó, Michal Luria, Nathalie Maréchal, Dhanaraj Thakur, and \\nCaitlin Vogus.\\nACKNOWLEDGMENTS'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Caitlin Vogus.\\nACKNOWLEDGMENTS \\nWe thank Pratik Joshi, Sebastin Santy, and Aniket Kesari for their invaluable feedback on the technical \\naspects of this report. We also thank Jacqueline Rowe, Damini Satija, and Ángel Díaz for their \\ninsightful comments and suggestions. The translation of our executive summary is made possible by \\nGlobal Voices Translations and with the help of Iverna McGowan, Maria Villamar, Ophélie Stockhem, \\nand Tomás Pomar. All views in this report are those of CDT. \\nThis work is made possible through a grant from the John S. and James L. Knight Foundation.\\nSuggested Citation: Nicholas, G. and Bhatia, A. (2023) Lost in Translation: Large Language Models \\nin Non-English Content Analysis. Center for Democracy & Technology. https://cdt.org/insights/lost-\\nin-translation-large-language-models-in-non-english-content-analysis/\\nReferences in this report include original links and links archived and shortened by the Perma.cc service.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='The Perma.cc links also contain information on the date of retrieval and archive. \\nThis report is licensed under a Creative Commons Attribution 4.0 International License.\\nLost in Translation\\nLarge Language Models in Non-\\nEnglish Content Analysis\\nLost in Translation\\nCDT Research\\n4\\nCDT Research\\n4\\nContents\\nExecutive Summary\\x08\\n5\\nIntroduction\\x08\\n8\\nI.\\t Background\\x08\\n12\\nA. How Large Language Models Work\\x08\\n12\\nB. The Resourcedness Gap: Why the Largest Language \\nModels are in English\\x08\\n15\\nC. Multilingual Language Models: Efforts to Bridge the \\nResourcedness Gap\\x08\\n19\\nII.\\t Limitations of Language Models in English and \\nNon-English Contexts\\x08\\n23\\nA. Concerns with Building and Deploying Large \\nLanguage Models\\x08\\n23\\nB. Limitations of Multilingual Language Models\\x08\\n25\\nIII.\\tRecommendations\\x08\\n31\\nA. Companies\\x08\\n31\\nB. Researchers and Funders\\x08\\n33\\nC. Governments\\x08\\n36\\nWorks Cited\\x08\\n39\\n5\\nLost in Translation\\nExecutive \\nSummary\\nT\\nhe internet is the primary source of information, economic'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Executive \\nSummary\\nT\\nhe internet is the primary source of information, economic \\nopportunity, and community for many around the world. \\nHowever, the automated systems that increasingly mediate our \\ninteractions online — such as chatbots, content moderation \\nsystems, and search engines — are primarily designed for and work far \\nmore effectively in English than in the world’s other 7,000 languages.\\nIn recent years, large language models have become the dominant \\napproach for building AI systems to analyze and generate language \\nonline, but again, they have been built primarily for the English \\nlanguage. A large language model (e.g., Open AI’s GPT-4, Meta’s \\nLLaMa, Google’s PaLM) is a machine learning algorithm that scans \\nenormous volumes of text to learn which words and sentences \\nfrequently appear near one another and in what context. Large language \\nmodels can be adapted to perform a wide range of tasks across different \\ndomains. They are most known for being used to build chatbots,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='domains. They are most known for being used to build chatbots, \\nsuch as ChatGPT, but researchers and technology companies also \\nuse them for content analysis tasks, such as sentiment analysis, text \\nsummarization, and hate speech detection. Google, Meta, Microsoft, \\nand other companies have already incorporated large language models \\ninto their core product functions, such as content moderation and \\nsearch. Other vendors soon may incorporate them into automated \\ndecision-making systems, such as resume scanners.\\nRecently though, researchers and technology companies have attempted \\nto extend the capabilities of large language models into languages other \\nthan English by building what are called multilingual language models. \\nInstead of being trained on text from only one language, multilingual \\nlanguage models are trained on text from dozens or hundreds of \\nlanguages at once. Researchers posit that multilingual language models'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='languages at once. Researchers posit that multilingual language models \\ninfer connections between languages, allowing them to apply word \\nassociations and underlying grammatical rules learned from languages \\nwith more text data available to train on (in particular English) to \\nthose with less. In some applications, multilingual language models \\noutperform models trained on only one language — for instance, a \\nmodel trained on lots of text from lots of languages, including Hindi, \\nmight perform better in Hindi contexts than a model just trained on \\nHindi text.\\nMultilingual language models give technology companies a way to scale \\ntheir AI systems to many languages at once, and some have already \\nbegun to integrate them into their products. Online service providers \\nin particular have deployed multilingual language models to moderate \\nLost in Translation\\nCDT Research\\n6\\ncontent: Meta uses a multilingual language model to detect harmful content on its'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='CDT Research\\n6\\ncontent: Meta uses a multilingual language model to detect harmful content on its \\nplatforms in over 100 languages; Alphabet’s Perspective API uses one to detect toxic \\ncontent in eighteen different languages; Bumble uses one to detect and take action on \\nunwanted sexual messages around the world.\\nMultilingual language models allow technologists to attempt to build models in languages \\nfor which they otherwise might not have enough digitized text. Languages vary widely \\nin resourcedness, or the volume, quality, and diversity of text data they have available to \\ntrain language models on. English is the highest resourced language by multiple orders of \\nmagnitude, but Spanish, Chinese, German, and a handful of other languages are sufficiently \\nhigh resource enough to build language models in. Medium resource languages, with fewer \\nbut still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='but still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource \\nlanguages, with almost no training data sets, such as Amharic, Cherokee, and Haitian \\nCreole, have too little text for training their own large language models. Language data in \\nlow resource languages is also often of particularly poor quality: either it is mistranslated or \\neven nonsensical language scraped from the internet, or is limited to sources with narrow \\ndomains, such as religious texts and Wikipedia. This gap in data availability between \\nlanguages is known as the resourcedness gap.\\nMultilingual language models are designed to address these gaps in data availability by \\ninferring semantic and grammatical connections between higher- and lower-resource \\nlanguages, allowing the former to bootstrap the latter. However, this architecture \\nraises its own concerns. Multilingual language models are still usually trained'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='raises its own concerns. Multilingual language models are still usually trained \\ndisproportionately on English language text and thus end up transferring values and \\nassumptions encoded in English into other language contexts where they may not \\nbelong. For example, a multilingual model might associate the word “dove” in all \\nlanguages with “peace” even though the Basque word for dove (“uso”) can be an insult. \\nThe disparity in available data also means multilingual language models work far better \\nin higher resource languages and languages similar to them than lower resource ones. \\nModel developers will sometimes try to fill in these gaps with machine-translated text, \\nbut translation errors may further compound language misrepresentation. And when \\nmultilingual language models do fail, their unintuitive connections between languages \\ncan make those problems harder to identify, diagnose, and fix.\\nLarge language models’ general use in content analysis raises further concerns.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Large language models’ general use in content analysis raises further concerns. \\nComputational linguists argue that large language models are limited in their capacity \\nto analyze forms of expression not included in their training data, meaning they may \\nstruggle to perform in new contexts. They may also reproduce any biases present in \\ntheir training data. Often, this text is scraped from the internet, meaning that large \\nlanguage models may encode and reinforce dominant views expressed online.\\nLarge Language Models in Non-English Content Analysis\\n7\\n\\u200bCompanies, researchers, and governments each have a role to play in protecting the \\npublic from the potential dangers of multilingual language model content analysis \\nsystems. To ensure better public accountability, companies that deploy large language \\nmodels should always be transparent about how they use them and in which languages. \\nCompanies should deploy language models with narrow remits and adequate channels \\nfor human review.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Companies should deploy language models with narrow remits and adequate channels \\nfor human review.\\nResearchers and research funders meanwhile should invest in efforts to improve the \\nuse and performance of language models in languages other than English, in particular, \\nto reduce failures that disparately impact speakers of lower-resourced languages. The \\nbest way to do this is by supporting language-specific research communities, who can \\npromote the virtuous cycle of collecting data, curating datasets, training language \\nmodels, publishing, and building applications. Local language speakers and context \\nexperts need to be part of each step of this process and also be curating the data and \\nassessing the language models deployed by large, global online services.\\nFinally, governments need to be careful about how they use or encourage the use of \\nlarge language models. Large language models should never power systems used to make'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='large language models. Large language models should never power systems used to make \\nhigh-stakes decisions without oversight, such as decisions about immigration status or \\nhealthcare, nor should governments mandate or inadvertently require by law the use of \\nlarge language model-powered systems to moderate content from online services. Instead, \\ngovernments should convene different stakeholders to align on what norms and guardrails \\nshould be around developing and deploying large language models.\\nLarge language models in general and multilingual language models in particular \\nhave the potential to create new economic opportunities and improve the web for \\nall. However, mis- or over-application of these technologies poses real threats to \\nindividuals’ rights, such as undermining their right to free expression by inaccurately \\ntaking down a person’s post on social media or their right to be free of discrimination'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='taking down a person’s post on social media or their right to be free of discrimination \\nby misinterpreting an individual’s job or visa application. Multilingual language \\nmodels specifically can inadvertently further entrench the Anglocentrism they are \\nintended to address. In light of these limitations, technology companies, researchers, \\nand governments must consider potential human and civil rights risks when studying, \\nprocuring, developing, or using multilingual language models to power systems, in \\nparticular when they are used to make critical information available or play a role \\nin decisions affecting people’s access to economic opportunities, liberty, or other \\nimportant interests or rights.\\nExecutive Summary\\nLost in Translation\\nCDT Research\\n8\\nIntroduction\\nD\\nespite the modern internet’s power to mobilize and connect \\npeople around the world, the web still does not reflect the \\nlinguistic diversity of its users. In particular, the automated'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='linguistic diversity of its users. In particular, the automated \\nsystems that increasingly mediate our interactions online — \\nsuch as chatbots, search engines, and content moderation systems — \\nare built using and perform far better on English-language text than \\nthe world’s other 7,000 languages (Kornai, 2013; Sengupta, 2022). \\nIndividuals speaking languages other than English face barriers to \\nexpressing themselves freely online and may face greater challenges \\nwhen it comes to accessing critical information, public services, and \\neven asylum and safety (Torbati, 2019).\\nIn the last few years, however, there have been rapid advancements in \\ndeveloping machine learning tools that can analyze content in a wide \\nvariety of languages and across different domains. Large language \\nmodels, machine learning tools trained on enormous amounts of text \\nto recognize patterns in language, power many of these systems. Large \\nlanguage models already underlie translation apps, search autocomplete,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='language models already underlie translation apps, search autocomplete, \\nand chatbots such as ChatGPT. They are known for being adaptable to \\nmany different language tasks, and today, researchers and technologists \\nare constantly on the lookout for new applications and contexts \\nin which to deploy them. Since the late 2010s, major U.S.-based \\ntechnology companies have mostly invested in building large language \\nmodels that work primarily for English, such as Open AI’s GPT-4, \\nMeta’s LLaMa, and Google’s PaLM.\\nRecently, companies and researchers have begun building and researching \\nmultilingual language models, large language models trained on text \\ndata from several different languages at once. Meta’s XLM-RoBERTa \\n(XLM-R) for instance is trained on text from 100 languages (Meta AI, \\n2019) at once. Google’s mBERT, a multilingual version of its popular \\nBERT model, is trained on 104 languages. Researchers claim that these'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='BERT model, is trained on 104 languages. Researchers claim that these \\nmodels extend the multifaceted capabilities of large language models to \\nlanguages other than English, even to languages for which there is little or \\nno text data for the model to learn from (Artetxe & Schwenk, 2019; Wu \\n& Dredze, 2019).\\nTechnology companies have their own interests in improving how \\nwell large language models work in different languages. Some may \\nwant to make their products available in multiple languages to gain a \\ncompetitive edge in emerging and populous markets. Online services \\nLarge Language Models in Non-English Content Analysis\\n9\\nthat host user-generated content may especially be interested in using multilingual \\nlanguage models to detect and take action on hate speech, disinformation, and other \\ncontent that violates their policies or the law (Dulhanty et al., 2019). This is top of \\nmind for services after facing criticism for not taking more aggressive action against'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='mind for services after facing criticism for not taking more aggressive action against \\ncontent that incited violence and genocide in Ethiopia, Nigeria, and Myanmar, among \\nothers. Services have begun to deploy multilingual language models into their content \\nmoderation systems: Meta claims their XLM-R model can detect harmful content \\nin all 100 languages it is trained on (Meta AI, 2021); Alphabet’s Perspective API uses \\na large language model to detect toxic content in eighteen different languages (Lees \\net al., 2022); Bumble uses one to detect rude and abusive messages in at least fifteen \\nlanguages (Belloni, 2021). Technology companies are also repurposing these models to \\nmake health care information available and soon may reach into other domains as well \\n(Lunden, 2023).\\nIn the future, governments could also seek to use automated systems built using \\nlarge language models to make information available, answer questions in languages'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='large language models to make information available, answer questions in languages \\nspoken by their constituents (in the form of chatbots), or, more dangerously, analyze \\ninformation to make critical decisions such as benefits allocation or refugee status \\ndeterminations (Kinchin & Mougouei, 2022).\\nStill, studies show that even multilingual language models struggle to deal with the \\nwide disparities between different languages in how much text data they have available \\nto train and test language models. English has, by multiple orders of magnitude, more \\ntext data available than any other language and commands most of the attention of the \\nnatural language processing research community. The abundance of English language \\ndata stems from its position as the official or de facto language of international business, \\npolitics, and media, itself a legacy of British colonialism and American neocolonialism \\nand the subsequent erasure of regional and indigenous languages. American technology'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and the subsequent erasure of regional and indigenous languages. American technology \\ncompanies have further entrenched English as the predominant language of the internet \\nby rolling out early standards, coding languages, and social media platforms in English \\nlong before other languages.\\nThe hegemony of English data means that most large language models, even \\nmultilingual ones, are built predominantly using Standard English language text and \\nwork best in Standard English language contexts. Spanish, Chinese, Arabic, and a few \\nother “high resource” languages also have significant amounts of text data available, but \\nmany “medium resource” languages, such as Hindi and Portuguese, and “low resource” \\nlanguages, such as Haitian Creole and Swahili, have hardly any data available at all, and \\nmultilingual language models perform much worse in those languages. This skewed \\nemphasis fails to reflect the diversity of languages spoken by the world’s internet users'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='emphasis fails to reflect the diversity of languages spoken by the world’s internet users \\nand further perpetuates the dominance of the English language.\\nIntroduction\\nLost in Translation\\nCDT Research\\n10\\nDespite being deployed in real-world systems, multilingual language models have largely \\nbeen absent from public discourse, particularly about digital rights and public policy, \\nand have instead been relegated to computer science academia and tech company public \\nrelations. This paper seeks to address this gap by offering several resources to bolster \\npolicy discussions. Part I provides a simple technical explanation of how large language \\nmodels work in general, why there is a gap in available data between English and other \\nlanguages, and how multilingual language models attempt to bridge that gap. Part II \\naccounts for the challenges of doing content analysis with large language models in \\ngeneral and multilingual language models in particular, namely:'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='general and multilingual language models in particular, namely:\\n1.\\t Multilingual language models often rely on machine-translated text that can \\ncontain errors or terms native language speakers don’t actually use. \\n2.\\t When multilingual language models fail, their problems are hard to identify, \\ndiagnose, and fix.\\n3.\\t Multilingual language models do not and cannot work equally well in all languages.\\n4.\\t Multilingual language models fail to account for the contexts of local language \\nspeakers.\\nFinally, Part III provides recommendations for companies, researchers, and \\npolicymakers to keep in mind when considering studying, developing, and deploying \\nlarge and multilingual language models to do content analysis. These recommendations \\noffer guidance concerning when large language models should or should not be \\ndeployed, how to improve their performance in non-English languages, and how to \\nensure better accountability and transparency to local language stakeholders.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='ensure better accountability and transparency to local language stakeholders.\\nBefore proceeding, two notes on the terminology used in this primer. First, this paper \\nfocuses specifically on one category of applications for large language models: content \\nanalysis, or, the inference and extraction of information, themes, and concepts from \\ntext. The Center for Democracy & Technology (CDT) has written many times about \\nthe limitations of automated content analysis systems (Duarte et al., 2017; Shenkman \\net al., 2021) and the civil liberty risks they can pose, particularly in areas such as content \\nmoderation, student activity monitoring, hiring and more (Grant-Chapman et al., \\n2021; Nicholas, 2022; Vallee & Duarte, 2019). Large language models are already deeply \\nintegrated into many of these technical systems, particularly content moderation, and will \\nsoon become part of many more. Public discourse about large language models has so far'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='soon become part of many more. Public discourse about large language models has so far \\ndisproportionately focused on text generation, an important area but not the only one. \\nMany of the shortcomings of large language models presented in this report also apply \\nto text generation. As such, this report can be read as a primer on some of the limits of \\ngenerative AI systems as well. However, we choose to focus on content analysis for this \\nreport because of the potential dangers associated with using these models to host and \\nmake information available and the impacts on free expression rights.\\nLarge Language Models in Non-English Content Analysis\\n11\\nSecond, this paper focuses on how multilingual language models perform in languages \\nother than English. We use the shorthand of “non-English languages” for easy reading \\nand because it is the terminology used in the machine learning and policy literature.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and because it is the terminology used in the machine learning and policy literature. \\nWe recognize the irony that this term centers the English language and misleadingly \\nimplies all other languages are a monolith. Where possible, we elaborate upon the types \\nof languages we are writing about and make distinct references to specific languages and \\ncultural contexts that will elude models trained primarily in English. In some instances, \\nwe think the term “non-English” captures the sheer Anglocentrism of many of these \\nmodels well by articulating the limited scope in which they are trained and tested.\\nIntroduction\\nLost in Translation\\nCDT Research\\n12\\nI. Background\\nA. How Large Language Models Work\\nNatural language processing (NLP) is a subfield of artificial intelligence \\nand linguistics concerned with building computer systems that can \\nprocess and analyze language. NLP underlies many technologies we \\nencounter every day — spellcheck, voice assistants like Siri or Alexa,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='encounter every day — spellcheck, voice assistants like Siri or Alexa, \\nresume scanners, language translators, and automated hate speech \\ndetection tools, to name a few. Until only a few years ago, when \\ntechnologists wanted to teach a computer to perform a given NLP task, \\nthey would build a system specifically tailored to that task. To create a \\nspam detection system for instance, a technologist might gather many \\nemails, mark which ones are and are not spam, use some of those emails to \\ntrain an algorithm and use others to test how well that algorithm works.\\nToday though, the field has fundamentally reoriented itself around \\nrepurposing large language models to solve nearly every problem. \\nA language model is a mathematical function trained to solve a text \\nprediction task like the following, “Given a sequence of words, predict \\nwhat word will likely come next.” For example, a language model might be \\ngiven the phrase “I was a bad student, I used to skip ____,” and generate'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='given the phrase “I was a bad student, I used to skip ____,” and generate \\nas an output that there is a high percent chance the missing word is \\n“class,” a low percent it is “rope,” and a near zero percent it is “clamoring.”\\nThe distribution of language that the model learns in the process can \\neasily be repurposed to many different language tasks. The most often \\ndiscussed application is text generation: conversational agents like \\nChatGPT can repurpose this text prediction task to answer questions, \\nsummarize text, and generate overall “human”-sounding speech. \\nHowever, chatbots are just one application of large language models. \\nOnce a large language model is built, it can be further trained on a \\nsmaller dataset to improve its performance in a specific task, a process \\ncalled fine-tuning. Today, for example, a developer building a spam \\ndetection system might take a general large language model already \\nbuilt by someone else — say Google’s BERT — and fine-tune it to the'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='built by someone else — say Google’s BERT — and fine-tune it to the \\nspecific task of spam detection using a handful of emails already labeled \\nspam or not spam. By building it on top of a language model, the spam \\ndetection system will do a better job of detecting spam that doesn’t \\nperfectly match the language available in the email dataset.\\nLanguage models are not new. Computational linguists have used \\nstatistical models to try to infer rules about language since the 1980s \\n(Nadkarni et al., 2011) and have used “neural networks” (an algorithm \\nloosely modeled on how neurons connect in the brain) to do so since \\nthe early 2010s (Mikolov et al., 2013). What is new though is their \\nLarge Language Models in Non-English Content Analysis\\n13\\nlargeness. Early language models could not be trained on as much data, since they had \\nto read text in sequence, a process that could not be sped up by using more computing'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='to read text in sequence, a process that could not be sped up by using more computing \\npower. These early language models struggled to analyze words within the broader \\ncontext of a sentence or document: for instance, one fine-tuned to detect suicidal \\nideation might have difficulty distinguishing between expressions of self-harm (“I \\njust wish I was dead”) and humor (“omg I’m dead”). But in 2017, Google researchers \\nreleased a paper on a new architecture called transformers, which allowed language \\nmodels to train on lots of data at the same time, in parallel rather than in sequence \\n(Vaswani et al., 2017). These transformer-based language models could ingest so much \\ndata simultaneously that they could learn associations between entire sequences of \\nwords, not just individual words. Instead of being shown just {“dead”}, the model \\nwould see a word in its entire context, {“dead”, [“omg”, “I’m”, “_____”]}, thus creating'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='would see a word in its entire context, {“dead”, [“omg”, “I’m”, “_____”]}, thus creating \\na much richer representation of language. Today, the only limit on the size of a language \\nmodel — how much data it ingests and how many connections it makes between \\ndifferent sequences of words (i.e. parameters) — is how much data one can find and \\nhow much developers are willing to spend on processing power.\\nThe output a language model produces is called a representation space, a map of the \\nsequences of words that commonly appear near one another in the training text. For \\nexample, the phrases “It’s so cold outside!” and “I better wear a jacket” may be near one \\nanother in a language model’s representation space, since those sentences often appear \\nclose to one another in writing. This kind of proximity can lead to language models \\ninferring patterns within language that can then help them conduct tasks that it is not'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='inferring patterns within language that can then help them conduct tasks that it is not \\nexplicitly trained in. In this case, sentences about cold weather being mapped near each \\nother mean the large language model could be trained to detect whether a given phrase \\nis about temperature.\\nWith enough data, a large language model may have such a rich and multifaceted \\nrepresentation of a language that it can learn to do new tasks with only a few, or even \\nzero examples to fine-tune on. For instance, the spam detection system described earlier \\ncould be built with little to no spam to fine-tune on. This capability is called “few-shot” \\nor “zero-shot learning” and is one of the greatest promises of large language models, so \\nmuch so that the original GPT-3 white paper is entitled “Language Models are Few-\\nShot Learners” (Brown et al., 2020).\\nImportantly though, large language models only learn the distribution of language, not'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Importantly though, large language models only learn the distribution of language, not \\nits meaning (Bender & Koller, 2020). In the previous “cold” example, the model has not \\nlearned that when one is cold, one puts on a jacket or anything about the deeper meanings \\nof “cold” and “jacket,” only that the words often appear near one another. If one of the \\ndocuments a large language model trains on is a humorous blogpost about the best shorts \\nto wear in cold temperatures, the model could just as easily learn that “shorts” and “cold” \\nare related. Similarly, if a model is trained only on very formal language data, it may never \\nlearn that “nippy” or “brick” (New York City slang) can refer to cold as well.\\nI. Background\\nLost in Translation\\n14\\nTechnologists often try to address these shortcomings by training language models \\non more and more data. If a model is exposed to more data, the idea is that it will be'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='on more and more data. If a model is exposed to more data, the idea is that it will be \\nfamiliar with more contexts, and outliers like the ironic cold-weather shorts blogpost \\nwill be outweighed by more representative data. This has led to ballooning in the size \\nof large language models. BERT, a popular open-source model built by Google in \\n2018, was trained on 800 million words from free books and 2.5 billion words from \\nEnglish Wikipedia (Devlin et al., 2019). Two years later, OpenAI released its closed \\nsource GPT-3, which was trained on half a trillion mostly-English words crawled from \\nthe internet (Brown et al., 2020). Google’s PaLM, released in 2022, trained on 780 \\nbillion words, mostly from English-language websites and social media conversations \\n(Chowdhery et al., 2022). As models have grown in size, so have the computation costs \\nof training them. While BERT costs a few thousand dollars in computing power to'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='of training them. While BERT costs a few thousand dollars in computing power to \\ntrain from scratch and is often trained by academics to build new topic- or language-\\nspecific models (Izsak et al., 2021), GPT-3 and PaLM-sized models cost millions or \\ntens of millions of dollars to train (Sharir et al., 2020). Future models will only be \\nmore expensive, leaving only the most well-off companies able to afford to build them \\n(Bommasani et al., 2021).\\nFigure 1. Language model \\nrepresentation space. A langauge model’s \\nreprsentation space, collapsed into two \\ndimensions. In reality, these models often \\nhave thousands or tens of thousands of \\ndimensions.\\nSource: (Amer, 2022)\\nLost in Translation\\n14\\nWhen is \\nBoxing Day?\\nWhat is the date \\nof Boxing Day?\\nHow many species \\nof sharks are there?\\nHow many species of the \\nGreat White shark are there?\\nIt’s so cold \\noutside!\\nI better wear \\na jacket.\\nLarge Language Models in Non-English Content Analysis\\n15'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='outside!\\nI better wear \\na jacket.\\nLarge Language Models in Non-English Content Analysis\\n15\\nModels are expensive to initially train, but once built, their representations are relatively \\ncheap to use and be fine-tuned for different tasks. Thus, many technologists simply \\nuse pretrained large language models built by others (usually large companies, with the \\nexpertise and resources) instead of paying to create their own. The few big pretrained \\nmodels that exist have thus become a sort of infrastructure, known as “foundation \\nmodels” (Bommasani et al., 2021). This gives many technologists access to the state of \\nthe art capabilities, but it also creates a single point of failure for the sector as a whole: \\nif a foundation model has a problem, it will persist across many applications. And these \\nmodels are so large and complicated that even when they are open source, researchers \\ncannot understand the underlying logic they use to come up with individual decisions.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cannot understand the underlying logic they use to come up with individual decisions.\\nMany of the largest and most advanced of these foundation models — such as \\nOpenAI’s GPT-4, Google’s PaLM, and Meta’s LLaMa — are trained primarily on \\nEnglish language data. In the next section, we explore one reason why that may be: the \\nresourcedness gap.\\nB. The Resourcedness Gap: Why the Largest \\nLanguage Models are in English\\nEnglish is the closest thing there is to a global lingua franca. It is the dominant language \\nin science, popular culture, higher education, international politics, and global \\ncapitalism; it has the most total speakers and the third-most first-language speakers \\n(Ethnologue, 2023b). It is the primary language spoken on the internet, accounting \\nfor 63.7% of websites, despite being spoken by only 16% of the world’s population \\n(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic \\nsuperiority: rather it is the colonial and neocolonial legacy of nearly three hundred \\nyears of the preeminent global superpower speaking English — first Great Britain, \\nthen the United States. The British government prioritized the English language \\nthrough official language policies to facilitate trade and in an attempt to “modernize” \\nits colonies, and as British, and later American trade became globally dominant, so too \\ndid English (Corradi, 2017; Phillipson, 1992). Prioritization of the English language \\ncame at the expense of other regional and indigenous languages and accelerated \\nlanguage endangerment and economic marginalization, which still impedes digital \\ninvestment into these languages worldwide (Rowe, 2022; S. Zhang et al., 2022). \\nAmerican companies continue to perpetuate the dominance of the English language in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='American companies continue to perpetuate the dominance of the English language in \\na new more insidious form, by making online services available to global users without \\ncomparable investment into the languages they speak (Amrute et al., 2022; Kupfer & \\nMuyumba, 2022).\\nI. Background\\nLost in Translation\\nCDT Research\\n16\\nAs a result of these forces, English also dominates the field of natural language \\nprocessing, and there is vastly more raw text data available in English than in any other \\nlanguage by orders of magnitude (Joshi et al., 2020).\\xa0English has the most digitized \\nbooks and patents, the largest Wikipedia, and the biggest internet presence. English is \\nalso by far the language paid the most attention by the global NLP research community. \\nIt is so hegemonic within the field that NLP papers about the English language \\ntypically do not even mention the language in the title or abstract (Bender, 2019). As'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='typically do not even mention the language in the title or abstract (Bender, 2019). As \\nFigure 2 shows, even among NLP papers that do mention a language in the abstract, \\nEnglish is mentioned over ten times as often as the next most mentioned language, \\nGerman (ACL Rolling Review Dashboard, 2022).\\nThis wealth of data and research makes it significantly easier to build large language \\nmodels in English than in any other language. More raw text data, also known as \\nunlabeled data, means more data for the model to be trained on; more research means \\nthat there are more datasets annotated with information, also known as labeled data, \\nthat can be used to test how well models complete different types of language tasks. \\nThis creates a virtuous cycle for English-language NLP —\\xa0more labeled and unlabeled \\ndata leads to more research attention, which leads to increased demand for labeled and \\nunlabeled data, and so on.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='unlabeled data, and so on.\\nEnglish is the prime example of a high resource language, a language for which a lot of \\nhigh-quality data resources exist. Though it has the most data available of any language \\n(English could be called an “extremely” high resource language), there are six other \\nlanguages that could be considered high resource — the official UN languages list, \\nminus Russian, plus Japanese (see Table 1). There are also a few dozen medium resource \\nlanguages, such as Urdu, Italian, and Tagalog, with another one or two orders of \\nmagnitude less data, or about one hundredth or one-thousandth of available English data. \\nThe rest of the world’s 6,000 plus languages can be considered low resource or extremely \\nlow resource, with only small amounts of written text available (Joshi et al., 2020).\\nResourcedness can vary within languages as well. Languages such as Arabic and Spanish \\ndiffer so much between dialects that many are mutually incomprehensible, even if'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='differ so much between dialects that many are mutually incomprehensible, even if \\nthey mostly use the same written form. Languages can also have different sociolects, \\nvarying across different social groups, identity groups, and contexts (e.g. formal versus \\ninformal). Regional dialects and sociolects can vary in degrees of difference from \\nhaving different vocabulary and grammatical structures (e.g. Australian English or \\nAfrican American English versus Standard American English) to make extensive use of \\nborrowed words from other languages (e.g. Nigerian English, Indian English), to fully \\nhybrid bilingual dialects (e.g. Spanglish, Hinglish). However, the available digitized \\ntext of language often doesn’t reflect the full spectrum of variation that exists within a \\nlanguage. (Bergman & Diab, 2022). Data scraped from the internet in particular over-\\nindexes Standard English spoken by younger people in developed countries (Luccioni'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='indexes Standard English spoken by younger people in developed countries (Luccioni \\n& Viviano, 2021). Other languages have just as much dialectical diversity as English and \\nalso likely over-index on certain dialects.\\nLarge Language Models in Non-English Content Analysis\\n17\\nFigure 2. Languages mentioned in \\npaper abstracts. Top most mentioned \\nlanguages in abstracts of papers published \\nby the Association for Computational \\nLinguistics, May 2022-January 2023.\\nSource: (Santy et al., 2023)\\nPaper Abstracts\\nLanguages with less data available also often have lower quality data available, either \\nbecause it is mislabeled or otherwise not representative of how people actually speak \\nthe language. This is particularly true with web-crawled data, a key data source for \\nlarge language models (Khan & Hanna, 2023). Non-English language data scraped \\nfrom the internet is more often machine translated, scanned from an image, or both,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from the internet is more often machine translated, scanned from an image, or both, \\nand each of those processes introduces opportunities for error (Dodge et al., 2021). \\nLow- and medium-resource language data on the internet is more often pornographic, \\nnonsensical, or non-linguistic content (Kreutzer et al., 2022). It is also often labeled as \\nthe incorrect language – around 95% of the time for many low resource languages – \\nbecause automatic language identification works much more poorly with insufficient \\ndata, thus creating a circular problem (Caswell et al., 2020). Languages with the worst \\nquality web data are disproportionately those written in non-Latin scripts (e.g. Urdu, \\nJapanese, Arabic) and those spoken in the Global South (e.g. African languages, \\nminority languages in the Middle East, non-Mandarin Chinese languages) (Kreutzer et \\nal., 2022).\\n17\\n0\\n200\\n300\\n100\\nEnglish\\nKorean\\nIndonesian\\nThai\\nFrench\\nGreek\\nTurkish\\nFinnish\\nGerman\\nSpanish\\nSwahili\\nClassical Chinese\\nHindi'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Korean\\nIndonesian\\nThai\\nFrench\\nGreek\\nTurkish\\nFinnish\\nGerman\\nSpanish\\nSwahili\\nClassical Chinese\\nHindi\\nHebrew\\nPolish\\nItalian\\nKinyarwanda\\nArabic\\nRussian\\nTalugu\\nDutch\\nJapanese\\nVietnamese\\nPortuguese\\nLatin\\nMarathi\\n311\\n27\\n18\\n16\\n16\\n16\\n16\\n13\\n10\\n7\\n7\\n7\\n6\\n5\\n5\\n5\\n4\\n4\\n4\\n4\\n4\\n3\\n3\\n3\\n3\\n3\\nI. Background\\nLost in Translation\\nCDT Research\\n18\\nLow resource languages also tend to have data that comes from a less diverse set of \\nsources. The clean data that does exist often comes from places such as Wikipedia, the \\nBible, and parliamentary proceedings, particularly in large language models that depend \\non drawing parallels between low and high resource languages (see III.B and III.C) \\n(Nekoto et al., 2020). None of these data sources is representative of a language as a \\nwhole. For example, there is a significant gender gap when it comes to who contributes \\nto Wikipedia, with studies finding that the percentage of women who edit Wikipedia'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='to Wikipedia, with studies finding that the percentage of women who edit Wikipedia \\narticles remains “dismally low” (Callahan & Herring, 2011; Vitulli, 2018), and it \\ndoesn’t reflect a more casual style of speech. Some text on Wikipedia is also machine-\\ntranslated — Cebuano, Swedish, and Waray for instance are some of the Wikipedia \\nlanguages with the most articles, but most are translated by the same bot (Lokhov, \\n2021). The Bible is similarly its own unique domain, unrepresentative of language at \\nlarge, but is overrepresented in the training data for non-English large language models. \\nThis can lead to errors in the tone and substance of language. For example, for a period \\nof time, running a word repeated enough times through Google translate produced a \\nreligious-sounding text: the word “dog” pasted two dozen times and translated from \\nMaori to English produced text about Jesus’ return at the end of days (Christian, 2018).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Maori to English produced text about Jesus’ return at the end of days (Christian, 2018).\\nThe resourcedness of a language is often out of sync with the number of speakers or \\ninternet users that language has. Hindi, Bengali, and Indonesian are medium-resource \\nlanguages yet each has hundreds of millions of speakers (Joshi et al., 2020). Guaraní, \\nan Indigenous language spoken by most of the ~7 million-person population of \\nParaguay, hardly has any data resources at all (Góngora et al., 2021). Fula, a language \\nspoken by tens of millions of West Africans, also has few data sets (Nguer et al., 2020). \\nDespite over 600 million internet users across the African continent, nearly all African \\nlanguages remain low-resourced.\\nTable 1. Categories of language \\nresourcedness. Languages divided into \\ndifferent levels of resourcedness, according \\nto labeled and unlabeled datasets available \\nas of 2020.\\nSource: (Joshi et al., 2020)\\nResourcedness\\nLanguages\\nNumber of Languages\\nNumber of Speakers'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Source: (Joshi et al., 2020)\\nResourcedness\\nLanguages\\nNumber of Languages\\nNumber of Speakers\\nExtremely High Resource\\nEnglish\\n1\\n1.1B\\nHigh Resource\\nArabic, French, Japanese, German, \\nSpanish, Mandarin\\n6\\n2.7B\\nMedium Resource\\nDutch, Vietnamese, Korean, \\nPortuguese, Hindi, Slovak, Hebrew, \\nIndonesian, Afrikaans, Bengali, etc.\\nDozens\\n2.7B\\nLow Resource\\nHaitian Creole, Tigrinya, Swahili, \\nBavarian, Cherokee, Zulu, Burmese, \\nTelugu, Maltese, Amharic, etc.\\nHundreds\\n0.5B\\nExtremely Low Resource\\nDahalo, Warlpiri, Popoloca, \\nWallisian, Bora, etc.\\nThousands\\n1.1B\\nLost in Translation\\n18\\nLarge Language Models in Non-English Content Analysis\\n19\\nMany scholars have worked to try to close this resourcedness gap between high and low \\nresource languages. Individual NLP communities have formed around many languages in \\norder to kickstart and perpetuate the virtuous cycle of research attention and benchmark \\ndevelopment, including collectives such as IndoNLP for languages spoken in Indonesia'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='development, including collectives such as IndoNLP for languages spoken in Indonesia \\nand Masakhane for African languages (Cahyawijaya et al., 2022; Nekoto et al., 2020; Orife \\net al., 2020), and conferences such as the Association for Computational Linguistics’ \\nlow resource language track, and AmericasNLP for indigenous languages (ACL, 2021; \\nAmericasNLP, 2022; Masakhane, n.d.). Tech companies have also sought to expand the \\nnumber of language models their models work in, in part by creating more data sets, \\nincluding with projects like Facebook’s No Language Left Behind project and Google’s \\n1000 Languages Initiative (NLLB Team et al., 2022; Vincent, 2022). DARPA even \\nfunded the Low Resource Languages for Emergent Incidents (LORELEI) program in \\n2014 to improve translation about emergency incidents into low resource languages \\n(Corvey, 2014). But the gaps between English, other high resource languages, and low'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(Corvey, 2014). But the gaps between English, other high resource languages, and low \\nresource languages remain large and are growing exponentially greater by the day, at least \\nin terms of available, raw digitized data.\\nThe response by the NLP community has not just been to collect more language \\ndata but also to employ technical tricks to help language models squeeze the most \\nperformance out of the little data they have. In the next section, we discuss the primary \\ntechnical architecture developers use to do this: multilingual language models.\\nC. Multilingual Language Models: Efforts to \\nBridge the Resourcedness Gap\\nIn English, most large language models are monolingual, meaning that they train mostly \\non data from one language. Researchers have also built monolingual models in non-\\nEnglish languages: for instance, the architecture for Google’s BERT model — one of \\nthe most popular and cheapest to train — has been utilized for French (CamemBERT),'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='the most popular and cheapest to train — has been utilized for French (CamemBERT), \\nItalian (AlBERTo), Arabic (AraBERT), Dutch (BERTje), Basque (BERTeus), Maltese \\n(BERTu), and Swahili (SwahBERT), to name a few (Agerri et al., 2020; Antoun et al., \\n2020; de Vries et al., 2019; G. Martin et al., 2022; L. Martin et al., 2020; Micallef et al., \\n2022; Polignano et al., 2019). However, in general, these monolingual models perform \\nworse in their respective languages than the best English models do in English because \\nthey don’t have as much data to train on.\\nThis lack of data manifests in different ways depending on the specific task a model is \\nfine-tuned to perform. Some language model capabilities — usually ones that depend \\non fact retrieval — improve linearly with size. For instance, the more data a language \\nmodel is exposed to, the better it is at answering trivia questions or reformatting \\ndata (Srivastava et al., 2022). Other capabilities — usually ones with multiple steps'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='data (Srivastava et al., 2022). Other capabilities — usually ones with multiple steps \\nI. Background\\nLost in Translation\\nCDT Research\\n20\\nor components — exhibit a “breakthrough” behavior, where once a model reaches a \\ncertain size, it improves sharply at the task. For instance, language models typically are \\nunable to write code or add three digit numbers until they train on a certain amount \\nof data, at which point their performance improves dramatically (Ganguli et al., 2022). \\nLow and extremely low resource languages often do not have enough data to train a \\nlarge language model at all, but medium and even high resource languages may not \\nhave the hundreds of millions, or billions of words of text data necessary to achieve the \\nbreakthroughs that English can (Y. Zhang et al., 2021).\\nBesides technical limitations, companies may not be interested in deploying a different \\nmonolingual model for every language their product is available in for business reasons'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='monolingual model for every language their product is available in for business reasons \\nas well. Maintaining and debugging one large language model for each language \\nintroduces costs that scale per language introduced, introducing complexity and \\nadditional overhead costs. Companies that seek to expand into new global markets \\nwill likely try to keep their costs fixed by reusing as much infrastructure as possible, \\nincluding language models.\\nTherefore, instead of using monolingual models to do NLP tasks in non-English \\nlanguages, researchers and developers most often use multilingual language models, \\nsuch as Google’s mBERT and Meta’s XLM-R, which are trained on texts from \\nmany different languages at once. Like their monolingual counterparts, multilingual \\nlanguage models are trained on a fill-in-the-blank task. However, by training on text \\nfrom several different languages, multilingual language models can, at least in theory,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from several different languages, multilingual language models can, at least in theory, \\ninfer connections between languages, acting as a sort of bridge between high and low \\nresource languages, allowing the former to bootstrap the latter.\\nFor instance, imagine that an Indian climate change researcher wants to use a language \\nmodel to collect all Hindi-language tweets about the weather. A monolingual language \\nmodel trained on just Hindi text may not have enough data to have seen the words \\n“thaand” (“cold” in Hindi) and “shaal” or (“shawl” in Hindi) appear near one another \\nin text, so it may miss that tweets to the effect of “Main Agast mein shaal pahanta \\nhoon” (“I put a shawl on in August”) is a sentence about cold weather.1 A multilingual \\nmodel, trained on data from English, Hindi, and many other languages may have seen \\ntext where “thaand” appears near “cold,” “shaal” appears near “shawl,” and “cold”'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='text where “thaand” appears near “cold,” “shaal” appears near “shawl,” and “cold” \\nappears near “shawl,” thereby allowing the model to infer that “thaand” and “shaal” are \\ninterrelated terms.\\nMultilingual language models are usually not trained on equal volumes of data from \\neach language: mBERT for instance is trained on 15.5 GB of English text but as little \\nas 10 MB of Yoruba text (Wu & Dredze, 2020). Even BLOOM, a popular multilingual \\nmodel by BigScience with a particular focus on language representation, has 30% of its \\n1\\t  Transliterated into Roman script for ease of reading for an English-language reader.\\nLarge Language Models in Non-English Content Analysis\\n21\\nFigure 3. Monolingual vs multilingual \\nlanguage model representation \\nspace. A visualization of a monolingual \\nand a multilingual langauge model’s \\nrepresentation space, collapsed into three \\ndimensions.\\nSource: (Schwenk, 2019) \\ntraining text in English (BigScience Workshop et al., 2023). In large part, this is because'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='training text in English (BigScience Workshop et al., 2023). In large part, this is because \\nof the lack of available data in these languages, which come disproportionately from \\nWikipedia and religious texts, as discussed earlier (see Part I.C).\\nJust as a monolingual language model can be fine-tuned to work better on an individual \\ntask, a multilingual language model can be fine-tuned to work better in an individual \\nlanguage. Imagine for instance a developer who wants to use a multilingual language \\nmodel to detect Indonesian election disinformation on social media. One way they \\ncould do it is by using an out-of-the-box multilingual model, such as BLOOM, and \\nfine-tuning it by showing examples of false narratives circulated in Indonesian related \\nto the local election. This likely would not work very well though, since BLOOM has \\nonly been exposed to a limited amount of data on Indonesian text —\\xa0only 1.2% of its'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='only been exposed to a limited amount of data on Indonesian text —\\xa0only 1.2% of its \\ntraining data is in Indonesian (BigScience Workshop et al., 2023). Another better way \\nto do it, if the developer has access to more Indonesian language data, would be first to \\nfine-tune the model on additional Indonesian text (essentially, continuing to learn the \\nfill-in-the-missing-word task, but this time just in Indonesian) and then further fine-\\ntuning it on the task election disinfo detection using that dataset.\\nModel developers though do not always have enough text data to sufficiently fine-\\ntune a multilingual model to work in a specific language. To make up for this, they \\noften use imperfect machine-translated text. The two main methods of incorporating \\ntranslated text are called translate-train or translate-test methods. With translate-train, \\na multilingual language model is fine-tuned on data that has been translated from'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='a multilingual language model is fine-tuned on data that has been translated from \\n(usually) English into a desired lower resource language (Conneau & Lample, 2019). \\nWith translate-test, a (usually) English monolingual language model is fine-tuned \\non data translated from the desired language into English, and all testing data gets \\ntranslated into English as well (Artetxe, Labaka, et al., 2020).\\nI. Background\\n21\\nThe tree is green.\\nThe tree is green.\\nEl árbol es verde.\\nMonolingual model\\nIt is cold today.\\nMultlingual model\\nI put on a shawl.\\nI like to sing. \\nI like to sing. \\nJ’aime chanter. \\nAaj bohut thaand hai.\\nMain ek shaal pahanta hoon.\\nI put on a shawl.\\nIt is cold today.\\nLost in Translation\\nCDT Research\\n22\\nImagine, for example, a developer building a language model to detect terrorist content \\nin the Basque language with a handful of examples of terrorist content in Basque \\nbut not enough Basque text data to properly fine-tune a language model. With the'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='but not enough Basque text data to properly fine-tune a language model. With the \\ntranslate-train approach, a developer would take a large volume of English text data, \\nmachine translate it into Basque, use that data to fine-tune a pretrained multilingual \\nlanguage model, and then further fine-tune it to the task of terrorist content detection \\nusing the native Basque data. With translate-test, a developer would fine-tune a \\npretrained English language model on data translated from Basque to English, and \\nthen further fine-tune it by translating the terrorist content data they have into English. \\nSubsequently, to analyze Basque text, it would first have to be translated into English \\nbefore being evaluated by the model. Reliance on translated data raises many concerns, \\nas discussed in Part II.C.1.\\nHowever, translated texts can help multilingual language models learn connections \\nbetween languages. By feeding a model parallel texts — for instance, explicitly'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='between languages. By feeding a model parallel texts — for instance, explicitly \\ninforming it that “baahar bohut thand hai” and “It’s so cold outside” have the same \\nmeaning — it can better extrapolate other language parallels as well (e.g. NLLB Team et \\nal., 2022; Reid & Artetxe, 2022). Multilingual language models can learn connections \\nbetween languages without explicit labeling, instead inferring relationships between \\nlanguages on its own through borrowed words, numbers, and URLs (Pires et al., 2019). \\nIn general, NLP researchers understand little about why it is that multilingual language \\nmodels can be effectively fine-tuned to work in languages that they have relatively little \\ndata for (Conneau, Khandelwal, et al., 2020; Pires et al., 2019; Wu & Dredze, 2019). \\nSome argue that it is because multilingual language models have inferred language-\\nagnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='agnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder, \\net al., 2020; Chi et al., 2020; Conneau, Wu, et al., 2020; Tsvetkov et al., 2016). Others \\nsay that multilingual language models are just effective imitators (Bender et al., 2021; \\nLauscher et al., 2020). The debate is impossible to fully resolve because of the overall \\ncomplexity and opacity of large language models, but so far evidence suggests that at \\nbest, the linguistic universals they learn are limited to narrow semantic and syntactic \\ndomains (Libovický et al., 2019; Wu & Dredze, 2019), such as learning plural/singular \\nverb agreement across multiple languages (de Varda & Marelli, 2023). But even if a model \\ncan infer syntactic or semantic commonalities between languages, such inferences will \\nnot necessarily help it manage more complex, context-dependent tasks (Choi et al., 2021). \\nFor instance, in some languages, multilingual language models do no better than random'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='For instance, in some languages, multilingual language models do no better than random \\nguessing at detecting hate speech (Lin et al., 2022). As will be discussed in the next section, \\nthese are hardly the only limits of multilingual language models.\\n23\\nLost in Translation\\nII. Limitations of \\nLanguage Models \\nin English and Non-\\nEnglish Contexts T\\nhe press, technology companies, and social media are abuzz \\nabout the potential of large language models. In this section, \\nhowever, we discuss the shortcomings of these models, \\nparticularly as they operate in non-English language contexts. \\nIn the first section, we discuss general concerns with building and \\ndeploying large language models. These concerns apply both to the \\nEnglish and non-English contexts. In the second section, we look at the \\nproblems more specifically raised by multilingual language models.\\nA. Concerns with Building and \\nDeploying Large Language Models\\n1. LARGE LANGUAGE MODELS ARE BOUND BY'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Deploying Large Language Models\\n1. LARGE LANGUAGE MODELS ARE BOUND BY \\nLANGUAGE THEY HAVE SEEN BEFORE AND STRUGGLE \\nTO PERFORM IN NEW CONTEXTS.\\nA large language model does not understand language; instead, it makes \\nprobabilistic inferences about text based on the distribution of language \\nwithin the data it is trained on. Bender and Koller argue that this means \\nlanguage models are limited to contexts they have encountered before \\nand struggle greatly in those they have not (2020). NLP researchers have \\nalready proven this is the case in generative AI by demonstrating several \\nunintuitive outcomes: for instance, language models are better able to \\nperform mathematical operations with numbers that appear frequently \\nin written language (e.g., multiplying numbers by 24), than numbers \\nthat appear infrequently (e.g. multiplying numbers by 23) (Razeghi \\net al., 2022). Large language models may exhibit similar limitations in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='et al., 2022). Large language models may exhibit similar limitations in \\ncontent analysis as well. For instance, if a large language model were \\nused to analyze a candidate’s resume, it may struggle to account for \\nlesser-known companies or newer skill sets without up-to-date, domain-\\nspecific data to fine-tune on. These tasks are reliant on in-context \\nknowledge and without domain-specific training, i.e. training an off-\\nthe-shelf large language model with text relevant to the task at hand, \\nthese models are likely to perform poorly and their purported domain-\\nagnostic abilities should garner skepticism (Duarte et al., 2017). \\nLost in Translation\\nCDT Research\\n24\\n2. LARGE LANGUAGE MODELS REPRODUCE THE BIASES, VALUES, \\nAND HARMS OF THE DATA THEY TRAIN ON.\\nLarge language models are built using vast quantities of text scraped from the internet \\nand exhibit all the biases and limitations of their data source (Okerlund et al., 2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and exhibit all the biases and limitations of their data source (Okerlund et al., 2022). \\nSome commonly used datasets, such as Common Crawl, include large volumes of \\nhate speech and sexually explicit content (Luccioni & Viviano, 2021). Other problems \\nare more nefarious. For example, researchers found that when GPT-3 generated \\ncompletions for the prompt “Two Muslims walked into a___,” 66% of completions \\nincluded violent language, three times more than for other religious groups (Abid et \\nal., 2021). Others have found similar entrenched biases against people with disabilities, \\nfor example inferring negative sentiment from sentences that include disability-related \\nterms (Hutchinson et al., 2020).\\nThough technologists often try to pull out explicitly harmful data from training \\nsets, models can still reify harms, such as referring to “women doctors” or calling \\nundocumented immigrants “illegals” (Bender et al., 2021). Removing these instances'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='undocumented immigrants “illegals” (Bender et al., 2021). Removing these instances \\nof harmful data from training datasets, which are disproportionately outsourced \\nto underpaid staff around the world, also imposes labor and psychological burdens \\n(Williams et al., 2022). \\nEven if datasets are rid of specific examples of harmful text, they will nonetheless \\ncontain values and assumptions that are encoded into the language we speak and the \\ndominant perspectives that exist in many pieces of written text, particularly government \\ndocuments or state-run media pieces that may make up the bulk of text available for \\nlow resource languages (Bender et al., 2021). Many machine learning researchers fail to \\nconsider these problems in their work — one study found that 98% of machine learning \\npapers mention no negative potential of the technologies they are describing (Birhane \\net al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, “Feeding AI systems'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='et al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, “Feeding AI systems \\non the world’s beauty, ugliness, and cruelty, but expecting it to reflect only the beauty \\nis a fantasy” (2021). When these problems exist in any particularly popular foundation \\nmodel, they proliferate across many different applications built on top of that model.\\n3. THE DATA LARGE LANGUAGE MODELS TRAIN ON RAISE \\nCOPYRIGHT AND PRIVACY CONCERNS.\\nLegal experts also raise concerns about copyright and ownership of text that make up \\nthe vast quantities of data that train and distinguish large models (Ebers et al., 2022; \\nOkerlund et al., 2022). Getty Images has sued the creators of Stable Diffusion, an AI \\ntool that creates images based on written prompts, claiming that the toolscraped Getty’s \\ndatabases of proprietary images and photos without permission (Vincent, 2023a). Legal \\nquestions about ownership of text and whether scraping proprietary text is lawful (e.g.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='questions about ownership of text and whether scraping proprietary text is lawful (e.g., \\nbecause it constitutes fair use) or not remain unanswered (Kublik, n.d.).\\nLarge Language Models in Non-English Content Analysis\\n25\\nII. Limitations of Language Models in English and Non-English Contexts\\nSome datasets that large language models train on are likely to capture examples of \\nlanguage from sites such as social media, raising personal data privacy concerns. There \\nis a high possibility that in gathering exchanges from social media networks, training \\ndatasets inadvertently contain private and even sensitive information, which increases \\nthe risk of models leaking details like names, phone numbers, or addresses from the data \\non which they’re trained (Carlini et al., 2021, 2023).\\n4. TRAINING LARGE LANGUAGE MODELS COULD HAVE A \\nSIGNIFICANT ENVIRONMENTAL IMPACT.\\nFinally, there are increasing concerns about the environmental cost of producing large'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Finally, there are increasing concerns about the environmental cost of producing large \\nlanguage models. Scholars and advocates have raised concerns about the environmental \\nimpact of training these models, particularly the largest ones with billions of \\nparameters, due to their intense computation requirements (Crawford, 2021; Okerlund \\net al., 2022). There is preliminary research attempting to quantify the energy impacts \\nof computation at this scale (Kaack et al., 2022), but some early estimates suggest that \\ntraining a single BERT model, one that serves as the foundation for some multilingual \\nlanguage models, requires as much energy as a trans-American flight (Strubell et al., \\n2019). Large language models, like GPT-3, require thousands of times more (Heikkilä, \\n2022). Png writes that these costs may be concentrated in poorer countries, where \\nserver farms and raw materials required to build necessary infrastructure are often \\nlocated (2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='located (2022).\\nB. Limitations of Multilingual Language Models\\n1. MULTILINGUAL LANGUAGE MODELS OFTEN RELY ON MACHINE-\\nTRANSLATED TEXT THAT CAN CONTAIN ERRORS OR TERMS NATIVE \\nLANGUAGE SPEAKERS DON’T ACTUALLY USE.\\nIncorporating machine-translated data into the training and fine-tuning of multilingual \\nlanguage models creates various opportunities for the model to malfunction. \\nMultilingual language models that depend on translation may struggle to build \\naccurate representations of words or concepts which have different connotations in \\ndifferent languages. For instance, in English, “dove” is a term associated with peace, but \\nits equivalent in Basque, “uso,” is an emasculating insult. A translation-based cross-\\nlingual model that does not train on the word “uso” used in its native context could \\npotentially fail to see it used in a call for violence since the English mapping is so closely \\nassociated with “peace.”\\nLost in Translation\\nCDT Research\\n26'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='associated with “peace.”\\nLost in Translation\\nCDT Research\\n26\\nAnother issue is what NLP practitioners call the “translationese” problem (Yu et al., \\n2022) — that is, machine-translated language materially differs from how human \\nnative speakers naturally use language (Bizzoni et al., 2020; Teich, 2003). In generative \\nAI, translationese can result in mono- or multilingual language models simplifying \\nor overcomplicating sentences, producing repeated words, using too common or too \\nuncommon words, borrowing too much or too little from the original language, and \\nother patterns of speech native speakers would not use (Volansky et al., 2015). These \\nmistakes are not consistent between languages or systems, so it would be difficult for \\nmodels to be able to systematically root them out, though some argue that it is possible \\n(Yu et al., 2022).\\nThe problems of machine translation spread beyond models that intentionally train on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='The problems of machine translation spread beyond models that intentionally train on \\nit. The web is filled with machine-translated text, and models that train on web-scraped \\ndata will inadvertently encounter a lot of it, particularly in low resource languages \\n(Kreutzer et al., 2022). For instance, a lot of the Catalan data that exists on the web, \\nparticularly on websites using the .cat top-level domain, is translated using Google \\nTranslate, even on official government websites (Pym et al., 2022). Even benchmarks to \\ntest how well multilingual language models work in high and low resource languages are \\noften translated from another language, leaving researchers with less of a sense of how \\nwell these models work on language as spoken by native speakers. For instance, OpenAI \\ntested GPT-4’s capabilities in 26 languages, but using only benchmarks translated from \\nEnglish (OpenAI, 2023).\\n2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE \\nCONTEXTS OF LOCAL LANGUAGE SPEAKERS.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE \\nCONTEXTS OF LOCAL LANGUAGE SPEAKERS.\\nAs discussed earlier, large language models only work well in contexts similar to \\ncontexts of the data they are trained on. A language model trained on legal texts, \\nfor instance, will perform much better on law-related tasks than medical tasks \\nor interpreting the Quran (Koehn & Knowles, 2017). This poses a problem for \\nmultilingual language models, which, particularly in low resource languages, are trained \\non text that is translated from other language contexts or comes from a few distinctive \\ncontexts, such as Wikipedia and the Bible. Multilingual language models that are not \\ntrained on large volumes of text from native speakers of a given language will more \\noften fail at tasks that require knowledge of an individual speaker’s local context, such \\nas hate speech detection and resume scanning (Lin et al., 2022).'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='as hate speech detection and resume scanning (Lin et al., 2022).\\nImagine, for example, a multilingual language model fine-tuned to detect anti-\\nMuslim content in Assamese, a low-resource language with fifteen million speakers, \\npredominantly in northeast India (Ethnologue, 2023a). Assamese and Bengali are both \\nmedium resource languages, so a multilingual model may draw connections between \\nthe two. However, anti-Muslim hate speech is very closely tied to historical events and \\nthe specific political conditions of Assam. For instance, the term “Bangladeshi Muslim,” \\nLarge Language Models in Non-English Content Analysis\\n27\\nII. Limitations of Language Models in English and Non-English Contexts\\nneutral in many other languages and contexts, is a hate speech dog whistle in Assamese \\nbecause it casts Assamese Muslims as foreigners (a concept that is itself closely tied to the \\nIndian government’s repatriation efforts) (Avaaz, 2019). A multilingual model neither'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Indian government’s repatriation efforts) (Avaaz, 2019). A multilingual model neither \\ntrained on extensive native Assamese text nor explicitly trained by a language expert would \\nlikely not be able to capture this hyperlocal distinction.\\nMultilingual language models work by transferring between language contexts, but that \\ntransfer often means simply that the context of higher resource languages overwrites \\nlower resource ones. Spanish, for instance, tends to use more adjectives and analogies \\ndescribing extreme situations than English, so a sentiment detection algorithm that \\ntransfers linguistic properties over from English may mischaracterize Spanish text as \\nhaving a stronger emotional valence than it would to a native speaker (Stadthagen-\\nGonzalez et al., 2017). This structure transfer can also bring the biases of a source \\nlanguage into a target language (Savoldi et al., 2021). For instance, if a language without'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='language into a target language (Savoldi et al., 2021). For instance, if a language without \\ngender pronouns, such as Hungarian or Yoruba, is mapped onto a language with \\ngendered third-person pronouns, such as English or French, the language model could \\nforce gender associations and biases of the gendered language onto the non-gendered \\none, as often occurs in translation (Prates et al., 2020) (see Figure 4).\\nFigure 4. Google Translate from \\nHungarian to English. A screenshot of \\nGoogle Translate, circa 2020, showing how \\nthe multilingual language models project \\ngender onto genderless languages.\\nSource: (Prates et al., 2020)\\n27\\nLost in Translation\\nCDT Research\\n28\\n3. MULTILINGUAL LANGUAGE MODELS DO NOT AND CANNOT WORK \\nEQUALLY WELL IN ALL LANGUAGES.\\nMultilingual language models not only do not work equally well in all languages but \\nthey cannot, since the more languages a multilingual model is trained on, the less it'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='they cannot, since the more languages a multilingual model is trained on, the less it \\ncan capture unique traits of any specific languages. This problem is called the curse \\nof multilinguality (Lauscher et al., 2020). Large language model developers are thus \\nforced to trade off performance between disparate languages; making a model work \\nbetter in Hindi for example, may come at a cost to its performance in English. In \\npractice, when technology companies must choose which languages to deprioritize \\nwithin their multilingual language models, they may be incentivized to have them \\nbe languages where speakers tend to be less wealthy, have less political power, or live \\noutside of the company’s priority markets, thus exacerbating the resourcedness gap they \\nare designed to address.\\nIn general, semantic and syntactic similarity to a high resource language protects \\nfrom the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='from the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al. \\ntested mBERT on languages it had not explicitly trained on before and found that it \\nworked better in Swiss German (related to German, a high resource language), than \\nit did in Estonian (a Uralic language, like medium resource languages Hungarian and \\nFinnish), than it does Uyghur (a Turkic language, distant from any high or medium \\nresource language, with four alphabets) (2021). In general, multilingual language \\nmodels struggle with languages written in non-Latin scripts (Pires et al., 2019; Ruder \\net al., 2021), language isolates (languages etymologically distinct from all other \\nlanguages, such as Basque), and families of languages less connected to those of high \\nresource languages. This threatens to create a poor-get-poorer dynamic for languages \\nthat are only similar to other low resource languages, as is the case with many widely'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='that are only similar to other low resource languages, as is the case with many widely \\nspoken African languages including Swahili, Amharic, and Kabyle (Joshi et al., 2020). \\nThis dynamic further strengthens the post-colonial structural inequality discussed \\nthroughout this report.\\nMultilingual language models are also forced to trade off between languages in the \\nvocabulary they use. Large language models train on the problem of predicting the next \\nword in a sentence. If a model is trying to guess the word to fill in “Today I feel ___,” it \\nwill have a harder time doing so if it has to choose between ten million possible words \\nfrom any language instead of just a few hundred thousand English words. The total \\nnumber of words a language model has to choose from is called its vocabulary size. The \\nlarger a model’s vocabulary size, the more different possible words it can generate and \\nrecognize, but also the more computational resources it takes to train. Multilingual'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='recognize, but also the more computational resources it takes to train. Multilingual \\nlanguage models use all kinds of shortcuts to get their vocabulary size down. For instance, \\nLarge Language Models in Non-English Content Analysis\\n29\\nthey will often transliterate languages into Latin scripts or train the model to guess the \\nnext subword (e.g. breaking “tasks” into “ta” and “##sks”) or letter instead of the full \\nword, thus collapsing the barrier between languages (Tay et al., 2022; C. Wang et al., \\n2020). These shortcuts cut down on costs, but they also reduce a model’s ability to \\ncapture semantic relationships between words, thus degrading its performance overall.\\nVocabulary is often decided by how frequently different words, subwords, and \\nletters appear in a model’s training text, and since multilingual language models are \\ntrained mostly on English data, their vocabularies will skew towards English as well.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='trained mostly on English data, their vocabularies will skew towards English as well. \\nA multilingual model may have a relatively obscure word like “riposte” in its English \\nvocabulary, but be may missing common words in other high resource languages (e.g., \\n“escritorio” in Spanish), common subwords in medium resource languages, (e.g., “tzv” \\nin Hebrew), and entire letters in low resource languages (e.g., a character that appears in \\nTigrinya but not other Ge’ez-based scripts). This inferior representation makes models \\nperform worse in a variety of tasks, and makes content analysis systems far easier to trick \\nby doing things like changing white space, using typos, or in the case of toxic content \\ndetection, adding common, positive words like “love” (Gröndahl et al., 2018; Lees et al., \\n2022).\\n4. WHEN MULTILINGUAL LANGUAGE MODELS FAIL, THEIR \\nPROBLEMS ARE HARD TO IDENTIFY, DIAGNOSE, AND FIX.\\nNLP practitioners depend on benchmarks to determine both how well a language'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='NLP practitioners depend on benchmarks to determine both how well a language \\nmodel performs at specific tasks and how close it is in general to achieving “natural \\nlanguage understanding” (Bender & Koller, 2020). This latter type of benchmarking \\nis very difficult in all languages, since it is hard to generalize about a language model’s \\ncapabilities from only a handful of disparate tests (Raji et al., 2021). However, the \\nchallenges of both types of benchmarks are exacerbated in the multilingual context. \\nThe disparities in NLP research attention and labeled data between languages mean \\nthat there are far more benchmarks and tasks that can be used to test models in English \\nthan in other languages, particularly low resource ones. Models developed to operate in \\nnon-English contexts are still usually tested with benchmarks translated from English \\nwhich, as discussed earlier, is often markedly different from the target language.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='which, as discussed earlier, is often markedly different from the target language.\\nThe alternative to translation is hiring people local to the contexts a model is being \\napplied to and paying them to create data sets and develop benchmarks. This works \\nparticularly well for models built to do a specific task in a specific language (Nguyen, \\n2020; Tattle, n.d.), but is very expensive and resource intensive to scale up for models \\nmeant to work in many languages and contexts. It also raises challenging questions \\nfor detecting bias in language models (Talat et al., 2022) and performing inherently \\nII. Limitations of Language Models in English and Non-English Contexts\\nLost in Translation\\nCDT Research\\n30\\npolitical tasks, such as content moderation. For instance, a social media company trying \\nto create a dataset of inflammatory content posted in Bosnia and Herzegovina needs \\npeople who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='people who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian, \\nMontenegrin, and Macedonian) but also unbiased in those conflicts, all in a country \\nthat lacks media pluralism or a strong civil society sector (Article 19, 2022). Scaling this \\nto every geopolitical problem discussed in all languages on a given online service is a \\ndaunting, if not impossible, task.\\nWhen problems with multilingual language models can be found, it is often difficult \\nto determine why they are occurring. Large language models are already opaque, even \\nto those who develop them — neural networks, the core technology underlying large \\nlanguage models, are known for being particularly obtuse and for representing language \\nin a way that doesn’t map cleanly onto human-understandable concepts (Nicholas, \\n2020). However, multilingual language models are particularly opaque because they \\nmake unintuitive, hard-to-trace connections between languages. Take for instance,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='make unintuitive, hard-to-trace connections between languages. Take for instance, \\nthis case from an NLP paper: the Google researchers behind the Perspective API, a \\nmodel for detecting “toxic” content, found that their model flagged tweets that used \\nthe Italian word “sfiga” (which roughly translates to “bad luck”) as hate speech because \\ntwo of the three examples included in the training dataset that contained the subword \\n“sfiga” were labeled as hate speech (“sfigati” is an insult meaning “loser”) (Lees et \\nal., 2020). If this were a multilingual model that had mapped Italian learnings onto \\nTurkish analysis, perhaps sentences with the equivalent Turkish word for “unlucky” \\n(“şanssız”) would also be flagged as hate speech. Even if researchers had access to all the \\ndata used to train that multilingual model, it would be extremely difficult to locate and \\nfix this bug without knowing Italian or understanding how the model had mapped \\nthese relationships.\\n31\\nLost in Translation'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these relationships.\\n31\\nLost in Translation\\nIII. Recommendations E\\nfforts to improve language models’ performance in various \\nlanguages and contexts are exciting, as they may boost \\nconnectivity and information exchange for billions of users \\naround the world. However, language models are limited in their \\ncapabilities, and employing them too widely, without safeguards, or for \\nthe wrong kinds of tasks has the potential to raise civil liberties concerns \\nand erect new barriers (Maundu, 2023). Unthinking deployment \\nof large language models may impede peoples’ ability to access \\ninformation, employment, and public benefits, with disparate impacts \\nfor individuals in the Global South where many of the low resource \\nlanguages are spoken. We should be cautious about the rapid adoption \\nof these technologies, especially as building blocks for other types of \\nautomation in high-stakes arenas like content moderation, employment \\nsoftware, and resource allocation.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='software, and resource allocation.\\nIn this section, we offer recommendations for companies, researchers, and \\ngovernments to take into consideration as they build, study, and regulate \\nlarge language models, particularly in non-English language contexts.\\nA. Companies\\nTECHNOLOGY COMPANIES SHOULD DISCLOSE WHEN, \\nHOW, AND IN WHAT LANGUAGES THEY USE LARGE \\nLANGUAGE MODELS.\\nTo better understand the problems and challenges with deploying large \\nlanguage models in different languages, researchers and the public need \\nto know where to look. Companies that incorporate language models \\ninto their technical systems should always disclose how they are using \\nthem, which languages they are using them in, and what languages they \\nhave been trained on. Currently, the approach of many companies to AI \\ntransparency consists of trumpeting the capabilities of their AI systems \\nin blog posts and press releases, and, for a few larger firms, releasing'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='in blog posts and press releases, and, for a few larger firms, releasing \\nresearch versions of their language models that still differ from the ones \\nthey use in production. Despite publishing on AI and pushing the field \\nforward, technology companies tend to hold information about their \\nproduction AI systems, even basic information about what languages \\nthey are used in, close to the chest.\\nLost in Translation\\nCDT Research\\n32\\nAcademics and civil society have written extensively about how technology companies, \\nparticularly online service providers, could offer better transparency and accountability \\nfor their AI systems, including language models. The Santa Clara Principles, a set of \\nprinciples developed and revised by global civil society groups, provides examples of \\nthe types of disclosures companies can make about their content moderation policies \\nand processes (2021). Groups like BigScience also pave the way, exemplifying the type'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='and processes (2021). Groups like BigScience also pave the way, exemplifying the type \\nof documentation other model-developers can publish about their content analysis \\nsystems, including model cards, transparency reports, and other avenues to disclose \\nmore information about the linguistic makeup of a model’s training data (e.g. what \\nlanguages it has trained on, how much data from each language, where those datasets \\ncome from). Better transparency creates opportunities for external actors to more \\nimmediately identify potential risks and impacts on users and for technology companies \\nto mitigate the potential dangers of deploying large language models in English and \\nnon-English contexts.\\nWHEN DEPLOYED, LARGE LANGUAGE MODELS SHOULD BE \\nACCOMPANIED BY ADEQUATE REMEDIAL CHANNELS AND \\nMECHANISMS THAT ENSURE INDIVIDUALS CAN APPEAL OUTCOMES \\nAND DECISIONS MADE BY THESE SYSTEMS.\\nBecause of the complexities of human speech and the error-prone nature of automated'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Because of the complexities of human speech and the error-prone nature of automated \\ntools, decision-making systems built on top of large language models should be used \\nwithin narrow remits and with adequate remedial channels for users encountering \\nthem. Those remedial channels and processes should have human reviewers with \\nthe same language proficiencies that their systems are deployed in. Language- and \\ncontext-specific remedial channels are particularly important for allowing users to \\nappeal decisions made by online services, especially when those decisions either restrict \\ntheir expression or access to information or fundamentally determine their access \\nto economic or social rights like the right to housing, education, and social security \\n(United Nations Human Rights Office of the High Commissioner, n.d.).\\nTechnology companies can also offer accountability at a system level, not just the \\nlevel of individual decisions. One way to do this is to conduct and publish human'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='level of individual decisions. One way to do this is to conduct and publish human \\nrights impact assessments at the different phases of the language model’s life cycle \\n— development, testing, deployment, and evaluation (Prabhakaran et al., 2022). \\nPublishing human rights impact assessments will also aid in other actors’ decisions \\nwhen procuring these systems to conduct tasks in different domains and contexts. In \\nparticular, these human rights impact assessments should consider the disparate risks \\nto different language speakers in advance of a model being deployed in those languages. \\nOnline service providers can provide transparency by disclosing the systems and \\nlanguages they use large language models in. \\nLarge Language Models in Non-English Content Analysis\\n33\\nIII. Recommendations\\nCOMPANIES SHOULD INVEST IN IMPROVING LANGUAGE MODEL \\nPERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN \\nLANGUAGE AND CONTEXT EXPERTS.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='PERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN \\nLANGUAGE AND CONTEXT EXPERTS.\\nRecently, an arms race has begun between Google and Meta to see who can include \\nmore languages in their multilingual language model. Meta’s “No Language Left \\nBehind” initiative trained a model on over 200 languages (NLLB Team et al., 2022); \\nmonths later, Google one upped Meta with its “1,000 Languages Initiative” (Vincent, \\n2022). This race puts a premium on the number of languages the model trains on, \\nrather than how well it works in each language. In particular, it is unclear how these \\nmodels will handle the “curse of multilinguality,” where, as explained in II.B.3, the \\nmore languages a model trains on, the less it can capture the idiosyncrasies of each \\nlanguage. It is also unclear how these companies define a model “working” in any of \\nthese languages.\\nCompanies building large language models should not just focus on the number of'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these languages.\\nCompanies building large language models should not just focus on the number of \\nlanguages their model is trained on but the quality of its performance in each language. \\nIn part, that means better benchmarks, but benchmarks can only go so far. To evaluate \\nthe full range of potential applications and pitfalls that could come with applying a \\nlanguage model in a specific language context, it is necessary to involve language experts, \\ncivil society, local experts, heritage and language preservation advocates, linguists, and \\nhuman rights experts. These actors are crucial to ensuring that labeled training datasets \\nadequately capture the nuances and variations of a given language. Many organizations \\nare already doing this type of work. Uli is an example of this, where two India-based \\nnonprofit organizations — Tattle and Centre for Internet & Society — convened a \\nrange of gender, gender-based violence, communal violence, and other language experts'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='range of gender, gender-based violence, communal violence, and other language experts \\nto annotate training datasets in Indian English, Tamil, and Hindi to build a tool capable \\nof parsing sentiment and toxicity on Twitter. Other researchers have also pointed to \\nusing annotators to label training datasets as a way to equip models with the ability to \\nparse variations in the speech of a certain language (Bergman & Diab, 2022; Nkemelu \\net al., 2022). \\nB. Researchers and Funders\\nRESEARCH FUNDERS SHOULD INVEST IN SPECIFIC NLP LANGUAGE \\nCOMMUNITIES TO KICKSTART THE VIRTUOUS CYCLE OF \\nDEVELOPMENT.\\nDeveloping NLP capabilities in any language is a cyclical process, and for high resource \\nlanguages — particularly English —\\xa0that cycle is virtuous. When a language has lots \\nof clean, human-annotated datasets, researchers and developers are better equipped \\nto build models and benchmarks to test models in that language. More models and \\nLost in Translation\\nCDT Research\\n34'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Lost in Translation\\nCDT Research\\n34\\nbenchmarks lead to more publications, conferences, and real-world use cases. And \\nfinally, increased demand for research and software in a language drives demand for \\nmore datasets. For low resource languages, however, the virtuous cycle is hard to \\nkickstart. Without tools, annotators, and financial investment earmarked for different \\nlanguage communities, NLP researchers cannot create the datasets needed to build \\nmodels or benchmarks, and even if they could, they face difficulties publishing or \\ngetting attention for their work in popular journals and conferences. The most \\nprestigious NLP publications focus disproportionately on English; languages without \\ntheir own self-sustaining NLP communities end up to a handful of specialized outlets.\\nInvestments into non-English NLP should particularly focus on creating self-sustaining \\nscholarly NLP communities, and doing this requires investing in all levels at once. The'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='scholarly NLP communities, and doing this requires investing in all levels at once. The \\ngroups that are best set up to properly allocate these investments are the language- and \\ngeography-specific NLP research communities that have cropped up over the years, \\nsuch as such as Masakhane, AmericasNLP, ARBML, and others who can convene \\npractitioners around common goals to advance the field (Alyafeai & Al-Shaibani, 2020; \\nAmericasNLP, 2022; Orife et al., 2020). These communities know what kind of data \\nsets should be built, which community actors are needed to properly vet them, and \\nwhat kind of competitions and conferences should be run to keep the virtuous cycles \\ngoing. One model for how this can work is exemplified by EVALITA, an event hosted \\nby the Italian Association for Computational Linguistics. In it, researchers first submit \\ndata sets for new language tasks, such as identifying misogyny or dating documents.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='data sets for new language tasks, such as identifying misogyny or dating documents. \\nThen, researchers compete to train models to perform those tasks the best. Finally, \\nthose results get published, thus generating interest and attention toward Italian NLP \\nand ensuring researchers continue to build tools for the language (Basile et al., 2020).\\nPrivate companies can contribute not only by financially supporting these efforts \\nbut by sharing more of the non-English datasets they use to train their large language \\nmodels, both for transparency and to support research. Large tech companies have \\nalready shared the code for training many of their multilingual language models \\n— Meta’s XLM-R and Google’s mBERT are the subjects of most multilingual \\nmodel research in publication — and disclosed the data they train them on — \\nCommonCrawl, and\\xa0Wikipedia and BooksCorpus, respectively. However, the models \\nthat Google, Meta, OpenAI, and other large companies use in their products train on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='that Google, Meta, OpenAI, and other large companies use in their products train on \\nother, proprietary, language data. Companies should share more of their training data, \\nboth for public accountability and to bolster research.\\nLarge language models have by and large been built by private companies, but private \\nincentives may be at odds with developing these models in safe and equitable ways. \\nGovernment investment into non-English large language model research could lead \\nto improvements in areas private companies may be underinvesting in (Mazzucato, \\n2014). DARPA’s late 2010’s LORELEI project, aimed at spurring research into low \\nLarge Language Models in Non-English Content Analysis\\n35\\nIII. Recommendations\\nresource languages to improve translation for humanitarian efforts, is a good first step, \\nbut further government incentives could help assure that NLP researchers invest in \\na broad range of approaches and languages, rather than focus disproportionately on'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='a broad range of approaches and languages, rather than focus disproportionately on \\nEnglish. BigScience’s BLOOM is a good example of how large language models can \\nbe developed in the open and with public support. The French government is one of \\nmany funders which has allowed BLOOM to remain open to inquiry by other NLP \\npractitioners. The multilingual language model was trained using ROOTs, a 1.6TB \\nmultilingual dataset that is clearly documented and available for NLP practitioners to \\nanalyze (Laurençon et al., 2022).\\nRESEARCHERS SHOULD FOCUS ON MEASURING AND ADDRESSING \\nTHE IMPACTS OF LARGE LANGUAGE MODELS.\\nTechnologists understand little about the internal logic of how large language models \\noperate and therefore have a difficult time predicting when they make mistakes, \\nwhat the effects of these mistakes will be, and how to fix them. Multilinguality only \\nexacerbates this problem. Better tools are needed to interrogate large language models,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='exacerbates this problem. Better tools are needed to interrogate large language models, \\nparticularly multilingual language models, about why they make the decisions and \\nmistakes they do, and how to fix them.\\nIn particular, the increased use of multilingual language models has the potential to \\nhelp and harm language communities. Enabling greater digital participation amongst \\na language community raises something that researchers call the “Janus-face nature \\nof digital participation” (NLLB Team et al., 2022): it allows more to participate and \\nbenefit from the digital economy, however, it may also expose more people to the harms \\npresent online, often without their consultation and consent (Hao, 2022; Toyama, \\n2015). More research on the effects and externalities of the increased use of language \\nmodels and specifically multilingual language models must grapple with the impacts \\nthese tools have on different linguistic communities, linguistic preservation and'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='these tools have on different linguistic communities, linguistic preservation and \\ndiversity efforts, and access to opportunity for all. \\nDifferent actors have different roles to play here. Civil society has a role in documenting \\nthe impacts of these models and imagining what these “better” models should look like. \\nThere are many open questions around the types of problems that need automated \\nsolutions, what more representative datasets might look like, how to manage the tradeoffs \\nbetween languages, how large language models affect linguistic preservation efforts, and \\nwhat the rights implications are of using large language models, among other things. \\nAcademics and corporate researchers have a role in better defining the contexts and tasks \\nthese models hope to address, and developing quantitative and qualitative methods to \\nevaluate these desired normative values. And companies that deploy language models'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='evaluate these desired normative values. And companies that deploy language models \\ncan provide researchers more transparency into how their models work, what data they \\nare trained on, and in what situations they use them so researchers can better tailor their \\nresearch to reflect what is happening in real-world systems.\\nLost in Translation\\nCDT Research\\n36\\nC. Governments\\nGOVERNMENTS SHOULD CAUTION AGAINST USING AUTOMATED \\nDECISION-MAKING SYSTEMS THAT RELY ON LARGE LANGUAGE \\nMODELS TO MAKE HIGH-STAKES DECISIONS.\\nMany governments have deployed or are considering deploying systems that use natural \\nlanguage processing technology as part of AI systems to make high-impact decisions, \\nsuch as determining immigration status or selecting judicial cases to try (Patel et al., \\n2020; Rionda & Mejia, 2021). Vendors who build these systems may soon follow the \\nlarger industry trend of incorporating large language models since they are relatively'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='larger industry trend of incorporating large language models since they are relatively \\ncheap to build and easy to adapt as requirements change. However, as discussed \\nthroughout this paper, large language models are a relatively novel technology that has \\ntechnical limitations. These tools pose serious civil liberty concerns that are magnified \\nin non-English contexts and when used to make decisions that may affect a person’s \\nlivelihood. For instance, if a large language model is used as the basis of an algorithm \\nto evaluate affordable housing applications and the text that large language model was \\ntrained on exhibits anti-Muslim bias, the resulting affordable housing algorithm may \\ndisproportionately deny Muslims’ applications. Relying on large language models to \\nmake high-stakes decisions can have outsized, negative impacts on individuals’ lives, \\nimpeding safety and access to economic opportunities.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='impeding safety and access to economic opportunities.\\nGovernments should therefore never rely solely on automated systems that incorporate \\nlarge language models to make high-risk decision-making areas, such as pretrial risk \\nassessment, allocation of social services, and immigration status. Policymakers should \\nconsider the impact on rights and access to services when procuring new tools and \\nvendors to build these systems and conduct and disclose any assessments conducted \\non these systems. They should also be cautious when adopting these systems for \\ninformation sharing services, such as chatbots about social services or that provide \\nhealthcare information, and test them extensively in every language in which they are \\ndeployed, and never use them to entirely replace human intermediaries.\\nGOVERNMENTS SHOULD NOT MANDATE OR INADVERTENTLY \\nREQUIRE BY LAW THE USE OF AUTOMATED CONTENT ANALYSIS \\nSYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='SYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.\\nGovernments around the world are increasingly pressuring online service providers to \\nlimit content they find to be inaccurate or harmful, such as misinformation related to \\nhealth care, or preemptively monitor online speech which may incite violence. Given \\nthe scale of content available on social media and other services, this has driven an \\ninterest amongst governments to mandate that online service providers use automated \\ncontent analysis systems to detect or remove content they deem as “illegal” or harmful \\nto their constituents.\\nLarge Language Models in Non-English Content Analysis\\n37\\nIII. Recommendations\\nThis is ill-advised. Mandating the use of automated content moderation technologies \\nor requiring companies to take down content in a limited time period (effectively \\nrequiring the use of automated technologies) opens the door for the overbroad removal'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='requiring the use of automated technologies) opens the door for the overbroad removal \\nof speech. Large language models, especially in non-English language contexts, are not \\na magical technology that can perfectly distinguish between “good” and “bad” speech. \\nAt best, they are an imprecise technology that fails to understand the context of speech \\n— for instance, when an individual uses a slur versus when a journalist documents \\nthe use of a slur by that individual. At worst, they are tools that can be appropriated \\nby governments to squash dissent and freedom of expression. Efforts to persuade tech \\ncompanies to improve their automated systems, clarify their policies, introduce more \\naccountability, and promote parity between languages are all welcome, but requiring \\ncompanies to adopt certain technologies is not an effective way to achieve those ends.\\nINTERNATIONAL AND MULTILATERAL STANDARDS BODIES, \\nREGULATORY AGENCIES, AND OTHERS SHOULD CONVENE'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='INTERNATIONAL AND MULTILATERAL STANDARDS BODIES, \\nREGULATORY AGENCIES, AND OTHERS SHOULD CONVENE \\nMULTI-STAKEHOLDER DISCUSSIONS ABOUT STANDARDS AND \\nGUARDRAILS FOR THE DEVELOPMENT AND USE OF LARGE \\nLANGUAGE MODELS.\\nThe norms around when and how multilingual language models should be deployed \\nare very much in flux. Those norms so far have mostly been established implicitly by \\ntechnology companies in the ways they build and deploy these models, but trends in \\nthese norms may be at odds with the public interest. For instance, OpenAI revealed \\nsome information about the training data they used for GPT-3 but almost nothing \\nabout GPT-4; Open AI co-founder Ilya Sutskever described having shared information \\nabout GPT-3’s training data as “just not wise” and something the company would \\nunlikely do again (Vincent, 2023b).\\nCompanies should not have a monopoly on the norms around language models. \\nGovernmental and nongovernmental\\xa0convening bodies need to organize and push back'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Governmental and nongovernmental\\xa0convening bodies need to organize and push back \\nto establish counter-norms that better serve the public’s interests. This field is early on \\nenough that these bodies should discuss what positive outcomes even look like. Users \\naffected by the deployment of large language models need to be at the table for those \\nconversations. Government agencies and multilateral organizations (e.g. the Internet \\nEngineering Task Force, United Nations) can play a coordinating role to get together \\nthe relevant stakeholders to come up with such standards.\\nThere are also larger questions to reckon with when it comes to the use of large \\nlanguage models in non-English contexts. At once, companies are increasingly \\ndeploying multilingual language models to bridge the gap between the functionality in \\nEnglish and other languages across a myriad of tasks, such as harmful content detection, \\nsentiment analysis, and content scanning. However, as we show in this paper, these'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='sentiment analysis, and content scanning. However, as we show in this paper, these \\nmultilingual systems are relatively new and perform inconsistently across languages. \\nLost in Translation\\nCDT Research\\n38\\nIf deployed prematurely and without guardrails, these models pose real risks to \\nindividuals around the world and in particular their ability to express themselves freely. \\nThese risks have the potential to compound existing challenges in the information \\nenvironment for individuals in Western democracies where there are real vacuums of \\navailable information in languages other than English and in countries in the Global \\nSouth where there are already real threats to the free expression and exchange of \\ninformation posed by majoritarian and institutional powers (Golebiewski & boyd, \\n2018). Alternatively, companies may decide to only roll out systems that have been \\nfine-tuned for English and wait until there is enough data and tooling available for non-'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='fine-tuned for English and wait until there is enough data and tooling available for non-\\nEnglish language tools — something that will take an enormous amount of financial \\ninvestment, time, effort, and rare consensus — further entrenching the digital divide \\nand Anglocentrism present online. Both scenarios are lose-lose for all speakers on the \\nweb. This is a wicked problem and the current incentives are at play to build bigger \\nmodels, and with more languages. Multi-stakeholder bodies are much better positioned \\nthan companies to determine when the risks associated with building larger, more \\nmultilingual language models are worth taking.\\nLarge Language Models in Non-English Content Analysis\\n39\\nWorks Cited\\nAbid, A., Farooqi, M., & Zou, J. (2021). Large language models associate Muslims with violence. Nature Machine \\nIntelligence, 3(6), Article 6. [perma.cc/HK4B-3AAQ]\\nACL. (2021, August 3). ACL 2022 Theme Track: “Language Diversity: from Low-Resource to Endangered'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='ACL. (2021, August 3). ACL 2022 Theme Track: “Language Diversity: from Low-Resource to Endangered \\nLanguages.” ACL. [perma.cc/F2YW-QZBP]\\nACL Rolling Review Dashboard. (2022). Papers Mentioning >0 Languages. [perma.cc/EQU9-5CWQ]\\nAgerri, R., Vicente, I. S., Campos, J. A., Barrena, A., Saralegi, X., Soroa, A., & Agirre, E. (2020). Give your Text \\nRepresentation Models some Love: The Case for Basque. Proceedings of the 12th Conference on Language \\nResources and Evaluation, 4781–4788. [perma.cc/R2DA-GGQZ]\\nAlyafeai, Z., & Al-Shaibani, M. (2020). ARBML: Democratizing Arabic Natural Language Processing Tools. \\nProceedings of Second Workshop for NLP Open Source Software (NLP-OSS), 8–13. [perma.cc/4TFY-E9EJ]\\nAmer, M. (2022, July 13). Large Language Models and Where to Use Them: Part 2. Cohere. [perma.cc/CRT5-\\nHDX8]\\nAmericasNLP. (2022, December 7). Second Workshop on NLP for Indigenous Languages of the Americas \\n(AmericasNLP). [perma.cc/SC88-9WGF]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(AmericasNLP). [perma.cc/SC88-9WGF]\\nAmrute, S., Singh, R., & Guzmán, R. L. (2022). A Primer on AI in/from the Majority World. Data & Society. \\n[perma.cc/SR8B-J2L9]\\nAntoun, W., Baly, F., & Hajj, H. (2020). AraBERT: Transformer-based Model for Arabic Language \\nUnderstanding. Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a \\nShared Task on Offensive Language Detection, 9–15. [perma.cc/X5VJ-JKXQ]\\nArtetxe, M., Labaka, G., & Agirre, E. (2020). Translation Artifacts in Cross-lingual Transfer Learning. Proceedings \\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 7674–7684. \\n[perma.cc/MZY5-DL83]\\nArtetxe, M., Ruder, S., & Yogatama, D. (2020). On the Cross-lingual Transferability of Monolingual \\nRepresentations. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, \\n4623–4637. [perma.cc/7WMN-5QPR]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='4623–4637. [perma.cc/7WMN-5QPR]\\nArtetxe, M., & Schwenk, H. (2019). Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual \\nTransfer and Beyond. Transactions of the Association for Computational Linguistics, 7, 597–610. [perma.cc/\\nLB6R-GH9K]\\nArticle 19. (2022). Bridging the Gap: Local voices in content moderation. Bosnia and Herzegovina. [perma.cc/ASU5-\\nST4N]\\nAvaaz. (2019). Megaphone for Hate: Disinformation and Hate Speech on Facebook During Assam’s Citizenship \\nCount. Avaaz. [perma.cc/5MXS-7P7N]\\nLost in Translation\\n40\\nLost in Translation\\nCDT Research\\nBasile, V., Maro, M. D., Croce, D., & Passaro, L. (2020, December 17). EVALITA 2020: Overview of the 7th \\nEvaluation Campaign of Natural Language Processing and Speech Tools for Italian. Seventh Evaluation \\nCampaign of Natural Language Processing and Speech Tools for Italian, Online. [perma.cc/76EK-EJQ8]\\nBelloni, M. (2021, December 8). Multilingual message content moderation at scale. Bumble Tech. [perma.cc/\\nRL2A-L2BD]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='RL2A-L2BD]\\nBender, E. (2019, September 15). The #BenderRule: On Naming the Languages We Study and Why It Matters. \\nThe Gradient. [perma.cc/J3ZM-A5UP]\\nBender, E., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can \\nLanguage Models Be Too Big? 🦜. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and \\nTransparency, 610–623. [perma.cc/3KLC-TBUY]\\nBender, E., & Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of \\nData. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5185–5198. \\n[perma.cc/TN3W-5NTC]\\nBergman, A., & Diab, M. (2022). Towards Responsible Natural Language Annotation for the Varieties of Arabic. \\nFindings of the Association for Computational Linguistics: ACL 2022, 364–371. [perma.cc/Q37M-8F2Y]\\nBigScience Workshop, Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., \\nSagot, B., Muennighoff, N., … Wolf, T. (2023). BLOOM: A 176B-Parameter Open-Access Multilingual \\nLanguage Model (arXiv:2211.05100). arXiv. [perma.cc/2K4Z-F5U7]\\nBirhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., & Bao, M. (2022). The Values Encoded in Machine \\nLearning Research. 2022 ACM Conference on Fairness, Accountability, and Transparency, 173–184. \\n[perma.cc/9GNB-JHQ5]\\nBirhane, A., & Prabhu, V. U. (2021). Large image datasets: A pyrrhic win for computer vision? 2021 IEEE Winter \\nConference on Applications of Computer Vision, 1536–1546. [perma.cc/Q8LP-THYK]\\nBizzoni, Y., Juzek, T. S., España-Bonet, C., Dutta Chowdhury, K., van Genabith, J., & Teich, E. (2020). How \\nHuman is Machine Translationese? Comparing Human and Machine Translations of Text and Speech. \\nProceedings of the 17th International Conference on Spoken Language Translation, 280–290. [perma.\\ncc/4DTZ-DVKC]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/4DTZ-DVKC]\\nBommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosselut, \\nA., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K., \\nDavis, J. Q., Demszky, D., … Liang, P. (2021). On the Opportunities and Risks of Foundation Models. \\nStanford Center for Research on Foundation Models. [perma.cc/3TKJ-UM2F]\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., \\nWu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. Advances in Neural \\nInformation Processing Systems, 33, 1877–1901. [perma.cc/7EES-WDAB]\\nCahyawijaya, S., Lovenia, H., Aji, A. F., Winata, G. I., Wilie, B., Mahendra, R., Wibisono, C., Romadhony, A.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Vincentio, K., Koto, F., Santoso, J., Moeljadi, D., Wirawan, C., Hudi, F., Parmonangan, I. H., Alfina, \\nI., Wicaksono, M. S., Putra, I. F., Rahmadani, S., … Purwarianti, A. (2022). NusaCrowd: Open Source \\nInitiative for Indonesian NLP Resources (arXiv:2212.09648). arXiv. [perma.cc/UQ3Y-4LKW]\\n41\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nCallahan, E. S., & Herring, S. C. (2011). Cultural bias in Wikipedia content on famous persons. Journal of the \\nAmerican Society for Information Science and Technology, 62(10), 1899–1915. [perma.cc/2S8K-YEJK]\\nCarlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., & Zhang, C. (2023, February 1). Quantifying \\nMemorization Across Neural Language Models. The Eleventh International Conference on Learning \\nRepresentations. [perma.cc/678U-9PAQ]\\nCarlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Erlingsson, U., Oprea, A., & Raffel, C. (2021). Extracting Training Data from Large Language Models \\n(arXiv:2012.07805). arXiv. [perma.cc/58MA-VWRZ]\\nCaswell, I., Breiner, T., van Esch, D., & Bapna, A. (2020). Language ID in the Wild: Unexpected Challenges on \\nthe Path to a Thousand-Language Web Text Corpus. Proceedings of the 28th International Conference on \\nComputational Linguistics, 6588–6608. [perma.cc/8RFD-DTUK]\\nChi, E. A., Hewitt, J., & Manning, C. D. (2020). Finding Universal Grammatical Relations in Multilingual BERT. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5564–5577. \\n[perma.cc/8LNR-VNY9]\\nChoi, H., Kim, J., Joe, S., Min, S., & Gwon, Y. (2021). Analyzing Zero-shot Cross-lingual Transfer in Supervised \\nNLP Tasks (arXiv:2101.10649). arXiv. [perma.cc/NEB9-8THZ]\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C.,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., \\nPrabhakaran, V., … Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways. Google Research. \\n[perma.cc/NZ7N-6GPB]\\nChristian, J. (2018, July 20). Why Is Google Translate Spitting Out Sinister Religious Prophecies? Vice. [perma.\\ncc/8YQU-NUFM]\\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., Grave, E., Ott, M., \\nZettlemoyer, L., & Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 8440–8451. \\n[perma.cc/2MP6-9W3J]\\nConneau, A., & Lample, G. (2019). Cross-lingual Language Model Pretraining. Advances in Neural Information \\nProcessing Systems, 32. [perma.cc/N7EE-JM83]\\nConneau, A., Wu, S., Li, H., Zettlemoyer, L., & Stoyanov, V. (2020). Emerging Cross-lingual Structure in'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Pretrained Language Models. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6022–6034. [perma.cc/3NHR-G7Y4]\\nCorradi, A. (2017, April 25). The Linguistic Colonialism of English. Brown Political Review. [perma.cc/5M3M-\\n9EMN]\\nCorvey, W. (2014). Low Resource Languages for Emergent Incidents. Defense Advanced Research Projects Agency. \\n[perma.cc/4FDR-M3YC]\\nCrawford, K. (2021). Atlas of AI: Power, politics, and the planetary costs of artificial intelligence. Yale University \\nPress.\\n42\\nLost in Translation\\nCDT Research\\nde Varda, A. G., & Marelli, M. (2023). Data-driven Cross-lingual Syntax: An Agreement Study with Massively \\nMultilingual Models. Computational Linguistics, 1–39. [perma.cc/7LQP-EEBQ]\\nde Vries, W., van Cranenburgh, A., Bisazza, A., Caselli, T., van Noord, G., & Nissim, M. (2019). BERTje: A Dutch \\nBERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='BERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]\\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional \\nTransformers for Language Understanding. Proceedings of the 2019 Conference of the North American \\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long \\nand Short Papers), 4171–4186. [perma.cc/E46R-UYDE]\\nDodge, J., Sap, M., Marasović, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., & Gardner, M. (2021). \\nDocumenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. Proceedings \\nof the 2021 Conference on Empirical Methods in Natural Language Processing, 1286–1305. [perma.\\ncc/3GC6-UEWJ]\\nDuarte, N., Llansó, E., & Loup, A. C. (2017). Mixed Messages? The Limits of Automated Social Media Content \\nAnalysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Analysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]\\nDulhanty, C., Deglint, J. L., Daya, I. B., & Wong, A. (2019, November 26). Taking a Stance on Fake News: Towards \\nAutomatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance \\nDetection. NeurIPS 2019, Vancouver. [perma.cc/P5JD-5AD9]\\nEbers, M., Poncibò, C., & Zou, M. (Eds.). (2022). Contracting and Contract Law in the Age of Artificial \\nIntelligence. Hart Publishing. [perma.cc/G4XR-VYNL]\\nEronen, J., Ptaszynski, M., & Masui, F. (2023). Zero-shot cross-lingual transfer language selection using linguistic \\nsimilarity. Information Processing & Management, 60(3), 103250. [perma.cc/S78N-C9MR]\\nEthnologue. (2023a). Assamese. Ethnologue, Languages of the World. [perma.cc/BE78-H3PN]\\nEthnologue. (2023b). Statistics. Ethnologue, Languages of the World. [perma.cc/H27U-44TK]\\nGanguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones, A., Joseph, N., Kernion, J., Mann,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Elhage, N., Showk, S. E., Fort, S., Hatfield-Dodds, \\nZ., Johnston, S., … Clark, J. (2022). Predictability and Surprise in Large Generative Models. 2022 ACM \\nConference on Fairness, Accountability, and Transparency, 1747–1764. [perma.cc/C8YH-6LMA]\\nGolebiewski, M., & boyd, danah. (2018). Data Voids: Where Missing Data Can Easily Be Exploited. Data & \\nSociety. [perma.cc/HE5A-7QTJ]\\nGóngora, S., Giossa, N., & Chiruzzo, L. (2021). Experiments on a Guarani Corpus of News and Social Media. \\nProceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the \\nAmericas, 153–158. [perma.cc/N6S5-4PGN]\\nGrant-Chapman, H., Laird, E., & Venzke, C. (2021). Student Activity Monitoring Software Research Insights and \\nRecommendations. Center for Democracy & Technology. [perma.cc/FY8G-WC2P]\\nGröndahl, T., Pajola, L., Juuti, M., Conti, M., & Asokan, N. (2018). All You Need is “Love”: Evading Hate Speech'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Detection. Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security, 2–12. [perma.cc/\\nT6P5-FRX5]\\n43\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nHao, K. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. [perma.\\ncc/54U3-KU5C]\\nHeikkilä, M. (2022, November 14). We’re getting a better idea of AI’s true carbon footprint. MIT Technology \\nReview. [perma.cc/8PWZ-ESJK]\\nHutchinson, B., Prabhakaran, V., Denton, E., Webster, K., Zhong, Y., & Denuyl, S. (2020). Social Biases in NLP \\nModels as Barriers for Persons with Disabilities. Proceedings of the 58th Annual Meeting of the Association \\nfor Computational Linguistics, 5491–5501. [perma.cc/8FGR-P3FA]\\nIzsak, P., Berchansky, M., & Levy, O. (2021). How to Train BERT with an Academic Budget. Proceedings of the \\n2021 Conference on Empirical Methods in Natural Language Processing, 10644–10652. [perma.cc/8MPG-\\nW2QE]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='W2QE]\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The State and Fate of Linguistic Diversity and \\nInclusion in the NLP World. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6282–6293. [perma.cc/82HQ-EH65]\\nKaack, L. H., Donti, P. L., Strubell, E., Kamiya, G., Creutzig, F., & Rolnick, D. (2022). Aligning artificial \\nintelligence with climate change mitigation. Nature Climate Change, 12(6), Article 6. [perma.cc/7C4S-\\nX2LH]\\nKhan, M., & Hanna, A. (2023). The Subjects and Stages of AI Dataset Development: A Framework for Dataset \\nAccountability. Ohio State Technology Law Journal, 19. [perma.cc/XLG3-AP2J]\\nKinchin, N., & Mougouei, D. (2022). What Can Artificial Intelligence Do for Refugee Status Determination? A \\nProposal for Removing Subjective Fear. International Journal of Refugee Law. [perma.cc/3KER-DZ5R]\\nKoehn, P., & Knowles, R. (2017). Six Challenges for Neural Machine Translation. Proceedings of the First'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Workshop on Neural Machine Translation, 28–39. [perma.cc/9WSQ-HQJY]\\nKornai, A. (2013). Digital Language Death. PLOS ONE, 8(10), e77056. [perma.cc/MMZ8-C9VH]\\nKreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A., Subramani, N., Sokolov, \\nA., Sikasote, C., Setyawan, M., Sarin, S., Samb, S., Sagot, B., Rivera, C., Rios, A., Papadimitriou, I., Osei, \\nS., Suarez, P. O., … Adeyemi, M. (2022). Quality at a Glance: An Audit of Web-Crawled Multilingual \\nDatasets. Transactions of the Association for Computational Linguistics, 10, 50–72. [perma.cc/YZ7B-\\nQ7PN]\\nKublik, V. (n.d.). EU/US Copyright Law and Implications on ML Training Data. Valohai. [perma.cc/LD3Z-\\nRVW7]\\nKupfer, M., & Muyumba, J. (2022). Language & Coloniality: Non-Dominant Languages in the Digital Landscape. \\nPollicy. [perma.cc/PM8N-Y9YW]\\nLaurençon, H., Saulnier, L., Wang, T., Akiki, C., Moral, A. V. del, Scao, T. L., Werra, L. V., Mou, C., Ponferrada,'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='E. G., Nguyen, H., Frohberg, J., Šaško, M., Lhoest, Q., McMillan-Major, A., Dupont, G., Biderman, \\nS., Rogers, A., Allal, L. B., Toni, F. D., … Jernite, Y. (2022, October 31). The BigScience ROOTS Corpus: \\nA 1.6TB Composite Multilingual Dataset. Thirty-sixth Conference on Neural Information Processing \\nSystems Datasets and Benchmarks Track. [perma.cc/QS7B-YNYU]\\n44\\nLost in Translation\\nCDT Research\\nLauscher, A., Ravishankar, V., Vulić, I., & Glavaš, G. (2020). From Zero to Hero: On the Limitations of Zero-\\nShot Language Transfer with Multilingual Transformers. Proceedings of the 2020 Conference on Empirical \\nMethods in Natural Language Processing (EMNLP), 4483–4499. [perma.cc/ZJ3R-95JM]\\nLees, A., Sorensen, J., & Kivlichan, I. (2020). Jigsaw @ AMI and HaSpeeDe2: Fine-Tuning a Pre-Trained \\nComment-Domain BERT Model. In V. Basile, D. Croce, M. Maro, & L. C. Passaro (Eds.), EVALITA \\nEvaluation of NLP and Speech Tools for Italian—December 17th, 2020 (pp. 40–47). Accademia University'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Press. [perma.cc/9D4M-RSCL]\\nLees, A., Tran, V. Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., & Vasserman, L. (2022). A New Generation \\nof Perspective API: Efficient Multilingual Character-level Transformers. Proceedings of the 28th ACM \\nSIGKDD Conference on Knowledge Discovery and Data Mining, 3197–3207. [perma.cc/5K82-WG8J]\\nLibovický, J., Rosa, R., & Fraser, A. (2019). How Language-Neutral is Multilingual BERT? (arXiv:1911.03310). \\narXiv. [perma.cc/96RW-WXBL]\\nLin, X. V., Mihaylov, T., Artetxe, M., Wang, T., Chen, S., Simig, D., Ott, M., Goyal, N., Bhosale, S., Du, J., \\nPasunuru, R., Shleifer, S., Koura, P. S., Chaudhary, V., O’Horo, B., Wang, J., Zettlemoyer, L., Kozareva, Z., \\nDiab, M., … Li, X. (2022). Few-shot Learning with Multilingual Generative Language Models. Proceedings \\nof the 2022 Conference on Empirical Methods in Natural Language Processing, 9019–9052. [perma.\\ncc/5QY9-97G5]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/5QY9-97G5]\\nLokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper \\nBlog. [perma.cc/WDL2-TF53]\\nLuccioni, A., & Viviano, J. (2021). What’s in the Box? An Analysis of Undesirable Content in the Common Crawl \\nCorpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182–189. \\n[perma.cc/2QQU-NRPB]\\nLunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient \\nconversations into action. TechCrunch. [perma.cc/MK55-SV54]\\nMartin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings \\nof the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 303–313. [perma.cc/3ZP6-V6AJ]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Human Language Technologies, 303–313. [perma.cc/3ZP6-V6AJ]\\nMartin, L., Muller, B., Suárez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, É. V., Seddah, D., & Sagot, B. \\n(2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the \\nAssociation for Computational Linguistics, 7203–7219. [perma.cc/76EU-4LTM]\\nMasakhane. (n.d.). Masakhane. Retrieved December 21, 2022. [perma.cc/A7SA-ALPM]\\nMaundu, C. (2023, February 21). How language denies people access to public information. Nation. [perma.\\ncc/8C4B-JS3Y]\\nMazzucato, M. (2014). The entrepreneurial state: Debunking public vs. private sector myths (Revised edition). \\nAnthem Press.\\nMeta AI. (2019, November 7). XLM-R: State-of-the-art cross-lingual understanding through self-supervision. \\nMeta AI. [perma.cc/J55N-4MV5]\\n45\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nMicallef, K., Gatt, A., Tanti, M., van der Plas, L., & Borg, C. (2022). Pre-training Data Quality and Quantity for a'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Low-Resource Language: New Corpus and BERT Models for Maltese. Proceedings of the Third Workshop \\non Deep Learning for Low-Resource Natural Language Processing, 90–101. [perma.cc/QY8V-9Q6H]\\nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013, September 6). Efficient Estimation of Word Representations \\nin Vector Space. International Conference on Learning Representations. [perma.cc/T869-PDX4]\\nMuller, B., Anastasopoulos, A., Sagot, B., & Seddah, D. (2021). When Being Unseen from mBERT is just the \\nBeginning: Handling New Languages With Multilingual Language Models. Proceedings of the 2021 \\nConference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 448–462. [perma.cc/J5MH-QDW3]\\nNadkarni, P. M., Ohno-Machado, L., & Chapman, W. W. (2011). Natural language processing: An introduction. \\nJournal of the American Medical Informatics Association\\u202f: JAMIA, 18(5), 544–551. [perma.cc/72PK-\\nUGK9]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='UGK9]\\nNekoto, W., Marivate, V., Matsila, T., Fasubaa, T., Fagbohungbe, T., Akinola, S. O., Muhammad, S., Kabongo \\nKabenamualu, S., Osei, S., Sackey, F., Niyongabo, R. A., Macharm, R., Ogayo, P., Ahia, O., Berhe, M. \\nM., Adeyemi, M., Mokgesi-Selinga, M., Okegbemi, L., Martinus, L., … Bashir, A. (2020). Participatory \\nResearch for Low-resourced Machine Translation: A Case Study in African Languages. Findings of the \\nAssociation for Computational Linguistics: EMNLP 2020, 2144–2160. [perma.cc/5BVM-LUMM]\\nNguer, E. M., Lo, A., Dione, C. M. B., Ba, S. O., & Lo, M. (2020). SENCORPUS: A French-Wolof Parallel \\nCorpus. Proceedings of the Twelfth Language Resources and Evaluation Conference, 2803–2811. [perma.cc/\\nNBE7-QCZW]\\nNguyen, T. (2020, November 27). Why fake news is so hard to combat in Asian American communities. Vox. \\n[perma.cc/45GF-UUEC]\\nNicholas, G. (2020). Explaining Algorithmic Decisions. Georgetown Law Technology Review, 4(711), 20. [perma.\\ncc/UD7D-HF6F]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='cc/UD7D-HF6F]\\nNicholas, G. (2022). Shedding Light on Shadowbanning. Center for Democracy & Technology. [perma.cc/D2TS-\\nY92D]\\nNkemelu, D., Shah, H., Essa, I., & Best, M. L. (2023). Tackling Hate Speech in Low-resource Languages with \\nContext Experts. International Conference on Information & Communication Technologies and \\nDevelopment, Washington, USA. [perma.cc/5QK7-GTMR]\\nNLLB Team, Costa-jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, \\nJ., Licht, D., Maillard, J., Sun, A., Wang, S., Wenzek, G., Youngblood, A., Akula, B., Barrault, L., Gonzalez, \\nG. M., Hansanti, P., … Wang, J. (2022). No Language Left Behind: Scaling Human-Centered Machine \\nTranslation (arXiv:2207.04672). arXiv. [perma.cc/LZH5-DMUA]\\nOkerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M., & Parthasarathy, S. (2022). What’s \\nin the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='in the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them. \\nUniversity of Michigan. [perma.cc/8SXE-RSYE]\\nOpenAI. (2023). GPT-4 Technical Report (arXiv:2303.08774). arXiv. [perma.cc/6ACB-LZYC]\\n46\\nLost in Translation\\nCDT Research\\nOrife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., Ali, J. T., Abbott, J., Marivate, V., \\nKabongo, S., Meressa, M., Murhabazi, E., Ahia, O., van Biljon, E., Ramkilowan, A., Akinfaderin, A., \\nÖktem, A., Akin, W., Kioko, G., … Bashir, A. (2020). Masakhane—Machine Translation For Africa \\n(arXiv:2003.11529). arXiv. [perma.cc/84Z4-S7AZ]\\nPatel, F., Levinson-Waldman, R., Koreh, R., & DenUyl, S. (2020). Social Media Monitoring. Brennan Center for \\nJustice. [perma.cc/N5LF-ZKP2]\\nPhillipson, R. (1992). Linguistic Imperialism. Oxford University Press.\\nPires, T., Schlinger, E., & Garrette, D. (2019). How Multilingual is Multilingual BERT? Proceedings of the 57th'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Annual Meeting of the Association for Computational Linguistics, 4996–5001. [perma.cc/4DPF-LWWX]\\nPng, M.-T. (2022). At the Tensions of South and North: Critical Roles of Global South Stakeholders in AI \\nGovernance. 2022 ACM Conference on Fairness, Accountability, and Transparency, 1434–1445. [perma.cc/\\nZ7HD-3T4A]\\nPolignano, M., Basile, P., Degemmis, M., Semeraro, G., & Basile, V. (2019). AlBERTo: Italian BERT Language \\nUnderstanding Model for NLP Challenging Tasks Based on Tweets. Sixth Italian Conference on \\nComputational Linguistics, Bari, Italy. [perma.cc/RBY9-4JHJ]\\nPrabhakaran, V., Mitchell, M., Gebru, T., & Gabriel, I. (2022). A Human Rights-Based Approach to Responsible AI \\n(arXiv:2210.02667). arXiv. [perma.cc/R97H-WQSK]\\nPrates, M., Avelar, P., & Lamb, L. (2020). Assessing gender bias in machine translation: A case study with Google \\nTranslate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Translate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]\\nPym, A., Ayvazyan, N., & Prioleau, J. M. (2022). Should raw machine translation be used for public-health \\ninformation? Suggestions for a multilingual communication policy in Catalonia. Just. Journal of Language \\nRights & Minorities, Revista de Drets Lingüístics i Minories, 1(1–2), 71–99. [perma.cc/HSA8-TB3F]\\nRaji, D., Denton, E., Bender, E. M., Hanna, A., & Paullada, A. (2021). AI and the Everything in the Whole \\nWide World Benchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and \\nBenchmarks, 1. [perma.cc/EX84-X9BQ]\\nRazeghi, Y., Logan IV, R. L., Gardner, M., & Singh, S. (2022). Impact of Pretraining Term Frequencies on Few-\\nShot Numerical Reasoning. Findings of the Association for Computational Linguistics: EMNLP 2022, \\n840–854. [perma.cc/SMG9-BSKV]\\nReid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Reid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning \\n(arXiv:2212.10173). arXiv. [perma.cc/83GW-CVXX]\\nRichter, F. (n.d.). English Is the Internet’s Universal Language. Statista Infographics. Retrieved December 14, \\n2022, from [perma.cc/WW7B-7X37]\\nRionda, V. P. S., & Mejia, J. C. U. (2021). PretorIA y la automatización del procesamiento de causas de derechos \\nhumanos. Derechos Digitales and Dejusticia. [perma.cc/65MQ-X484]\\nRowe, J. (2022, March 2). Marginalised languages and the content moderation challenge. Global Partners Digital. \\n[perma.cc/GU4K-5HBE]\\n47\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nRuder, S., Constant, N., Botha, J., Siddhant, A., Firat, O., Fu, J., Liu, P., Hu, J., Garrette, D., Neubig, G., & \\nJohnson, M. (2021). XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation. \\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 10215–10245.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='[perma.cc/W4TJ-SGTB]\\nSanta Clara Principles. (2021). Santa Clara Principles on Transparency and Accountability in Content Moderation. \\nSanta Clara Principles. [perma.cc/T623-AVW6]\\nSanty, S., Kummerfeld, J., & Rubio, H. (2023). Languages mentioned in Paper Abstracts. ACL Rolling Review. \\n[perma.cc/EQU9-5CWQ]\\nSavoldi, B., Gaido, M., Bentivogli, L., Negri, M., & Turchi, M. (2021). Gender Bias in Machine Translation. \\nTransactions of the Association for Computational Linguistics, 9, 845–874. [perma.cc/9K3F-5VBZ]\\nSchwenk, H. (2019, January 22). LASER natural language processing toolkit—Engineering at Meta. Meta AI. \\n[perma.cc/46JG-AZ4T]\\nSengupta, P. B., Claudia Pozo, Anasuya. (2022, March 31). Does the internet speak your language? Launching the \\nfirst-ever State of the Internet’s Languages report. Whose Knowledge? [https://perma.cc/9KCX-M863]\\nSharir, O., Peleg, B., & Shoham, Y. (2020). The Cost of Training NLP Models: A Concise Overview \\n(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]\\nShenkman, C., Thakur, D., & Llansó, E. (2021). Do You See What I See? Capabilities and Limits of Automated \\nMultimedia Content Analysis. Center for Democracy & Technology. [perma.cc/W85T-HQQF]\\nSrivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., \\nGarriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. \\nW., Safaya, A., Tazarv, A., … Wu, Z. (2022). Beyond the Imitation Game: Quantifying and extrapolating the \\ncapabilities of language models (arXiv:2206.04615). arXiv. [perma.cc/278S-ZJV9]\\nStadthagen-Gonzalez, H., Imbault, C., Pérez Sánchez, M. A., & Brysbaert, M. (2017). Norms of valence and \\narousal for 14,031 Spanish words. Behavior Research Methods, 49(1), 111–123. [perma.cc/7FWX-Z3JD]\\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP.'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3645–3650. \\n[perma.cc/9P4Y-J4HT]\\nTalat, Z., Névéol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., \\nRadev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D., & Wal, O. van der. (2022). You \\nreap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. Proceedings of \\nBigScience Episode #5, 26–41. [perma.cc/3ECR-4E7U]\\nTattle. (n.d.). Uli. [perma.cc/4AB2-D4GX]\\nTay, Y., Tran, V. Q., Ruder, S., Gupta, J., Chung, H. W., Bahri, D., Qin, Z., Baumgartner, S., Yu, C., & Metzler, D. \\n(2022, February 23). Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. \\nInternational Conference on Learning Representations 2022. [perma.cc/YRL4-E7DT]\\nTeich, E. (2003). Cross-Linguistic Variation in System and Text: A Methodology for the Investigation of'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='Translations and Comparable Texts. In Cross-Linguistic Variation in System and Text. De Gruyter Mouton. \\n[perma.cc/L8A8-RH8B]\\n48\\nLost in Translation\\nCDT Research\\nTorbati, Y. (2019, September 26). Google Says Google Translate Can’t Replace Human Translators. Immigration \\nOfficials Have Used It to Vet Refugees. ProPublica. [perma.cc/ZUN6-LHA5]\\nToyama, K. (2015). Geek heresy: Rescuing social change from the cult of technology. PublicAffairs.\\nTsvetkov, Y., Sitaram, S., Faruqui, M., Lample, G., Littell, P., Mortensen, D., Black, A. W., Levin, L., & Dyer, \\nC. (2016). Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation \\nLearning. Proceedings of the 2016 Conference of the North American Chapter of the Association for \\nComputational Linguistics: Human Language Technologies, 1357–1366. [perma.cc/4RES-KFNM]\\nUnited Nations Human Rights Office of the High Commissioner. (n.d.). \\u200bEconomic, social and cultural rights. \\nOHCHR. [perma.cc/Y6MK-SZZ4]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='OHCHR. [perma.cc/Y6MK-SZZ4]\\nVallee, H. Q. la, & Duarte, N. (2019). Algorithmic Systems in Education: Incorporating Equity and Fairness When \\nUsing Student Data. Center for Democracy and Technology. [perma.cc/CC89-ZVNV]\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017, \\nDecember 5). Attention Is All You Need. Advances in Neural Information Processing Systems. [perma.\\ncc/2ZDX-Z796]\\nVincent, J. (2022, November 2). Google plans giant AI language model supporting world’s 1,000 most spoken \\nlanguages. The Verge. [perma.cc/3Y48-X7WV]\\nVincent, J. (2023a, January 17). Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its \\ncontent. The Verge. [perma.cc/4CXS-3WNN]\\nVincent, J. (2023b, March 15). OpenAI co-founder on company’s past approach to openly sharing research: “We were \\nwrong.” The Verge. [perma.cc/DPL6-4PD2]'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='wrong.” The Verge. [perma.cc/DPL6-4PD2]\\nVitulli, M. A. (2018). Writing Women in Mathematics Into Wikipedia. Notices of the American Mathematical \\nSociety, 65(03), 330–334. [perma.cc/X73F-AZPM]\\nVolansky, V., Ordan, N., & Wintner, S. (2015). On the features of translationese. Digital Scholarship in the \\nHumanities, 30(1), 98–118. [perma.cc/7F8S-3YXK]\\nWang, C., Cho, K., & Gu, J. (2020). Neural Machine Translation with Byte-Level Subwords. Proceedings of the \\nAAAI Conference on Artificial Intelligence, 34(05), Article 05. [perma.cc/5DL7-XSSP]\\nWang, Z., K, K., Mayhew, S., & Roth, D. (2020). Extending Multilingual BERT to Low-Resource Languages. \\nFindings of the Association for Computational Linguistics: EMNLP 2020, 2649–2656. [perma.cc/ZNC8-\\nC9E7]\\nWilliams, A., Miceli, M., & Gebru, T. (2022). The Exploited Labor Behind Artificial Intelligence. Noēma. [perma.\\ncc/GE8H-7SUN]\\nWu, S., & Dredze, M. (2019). Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT. Proceedings'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International \\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP), 833–844. [perma.cc/EJ3G-MFYN]\\nWu, S., & Dredze, M. (2020). Are All Languages Created Equal in Multilingual BERT? Proceedings of the 5th \\nWorkshop on Representation Learning for NLP, 120–130. [perma.cc/5E6X-NNAA]\\n49\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nYu, S., Sun, Q., Zhang, H., & Jiang, J. (2022). Translate-Train Embracing Translationese Artifacts. Proceedings of \\nthe 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 362–\\n370. [perma.cc/7F8C-EYM6]\\nZhang, S., Frey, B., & Bansal, M. (2022, April 25). How can NLP Help Revitalize Endangered Languages? A Case \\nStudy and Roadmap for the Cherokee Language. Proceedings of the 60th Annual Meeting of the Association'),\n",
              " Document(metadata={'Published': '2023-06-12', 'Title': 'Lost in Translation: Large Language Models in Non-English Content Analysis', 'Authors': 'Gabriel Nicholas, Aliya Bhatia', 'Summary': \"In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,\\nGoogle's PaLM) have become the dominant approach for building AI systems to\\nanalyze and generate language online. However, the automated systems that\\nincreasingly mediate our interactions online -- such as chatbots, content\\nmoderation systems, and search engines -- are primarily designed for and work\\nfar more effectively in English than in the world's other 7,000 languages.\\nRecently, researchers and technology companies have attempted to extend the\\ncapabilities of large language models into languages other than English by\\nbuilding what are called multilingual language models.\\n  In this paper, we explain how these multilingual language models work and\\nexplore their capabilities and limits. Part I provides a simple technical\\nexplanation of how large language models work, why there is a gap in available\\ndata between English and other languages, and how multilingual language models\\nattempt to bridge that gap. Part II accounts for the challenges of doing\\ncontent analysis with large language models in general and multilingual\\nlanguage models in particular. Part III offers recommendations for companies,\\nresearchers, and policymakers to keep in mind when considering researching,\\ndeveloping and deploying large and multilingual language models.\"}, page_content='for Computational Linguistics (Volume 1: Long Papers). ACL 2022, Dublin, Ireland. [perma.cc/2XF2-\\n2GDC]\\nZhang, Y., Warstadt, A., Li, X., & Bowman, S. R. (2021). When Do You Need Billions of Words of Pretraining \\nData? Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 1112–1125. \\n[perma.cc/43ZK-2ZXC]\\ncdt.org\\ncdt.org/contact\\n202-637-9800\\n@CenDemTech\\nCenter for Democracy & Technology\\n1401 K Street NW, Suite 200\\nWashington, D.C. 20005'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='CEDILLE:\\nA LARGE AUTOREGRESSIVE LANGUAGE MODEL IN FRENCH\\nMartin Müller∗\\nFlorian Laurent∗\\nCedille AI1\\nhello@cedille.ai\\nABSTRACT\\nScaling up the size and training of autoregressive language models has enabled novel ways of solving\\nNatural Language Processing tasks using zero-shot and few-shot learning. While extreme-scale\\nlanguage models such as GPT-3 offer multilingual capabilities, zero-shot learning for languages\\nother than English remain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, speciﬁcally trained for the French language. Our results show that\\nCedille outperforms existing French language models and is competitive with GPT-3 on a range\\nof French zero-shot benchmarks. Furthermore, we provide an in-depth comparison of the toxicity\\nexhibited by these models, showing that Cedille marks an improvement in language model safety\\nthanks to dataset ﬁltering.\\n1\\nIntroduction\\nLarge autoregressive language models have drawn wide'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='thanks to dataset ﬁltering.\\n1\\nIntroduction\\nLarge autoregressive language models have drawn wide\\nattention due to their zero-shot and few-shot capabilities,\\nallowing them to be used for a wide variety of Natural Lan-\\nguage Processing tasks without the need for task-speciﬁc\\nﬁnetuning or annotation data [1, 2]. Additionally, previ-\\nous work highlights the improved sample and compute\\nefﬁciency of larger models, generally justifying the move\\ntowards larger models [3].\\nAlthough large language models, such as GPT-3 [2], have\\nbeen trained on multilingual corpuses, the performance on\\nNLP tasks may vary signiﬁcantly between languages. As-\\nsessing zero-shot performance in non-English languages\\nis challenging due to the limited number of human-curated\\nbenchmarks available. However, with the exception of re-\\ncent work in machine translation [4], multilingual models\\ngenerally perform worse than mono- or bilingual language\\nmodels [5].\\nMonolingual autoregressive language models in French'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='models [5].\\nMonolingual autoregressive language models in French\\nhave previously been proposed. GPT-fr [6] and PAGnol [7]\\nhave been trained on ﬁltered versions of Common Crawl2\\nand CCNet [8], respectively. Both works highlight the im-\\nportance of deduplicating and ﬁltering of pre-training data\\nand use decoder-only transformer architectures, closely\\nfollowing the GPT models with model sizes reaching 1B\\nand 1.5B parameters, respectively. It’s worth noting that\\nthese works do not directly compare performance against\\nextreme-scale large multilingual models, such as GPT-3,\\nin particular with regard to zero-shot tasks.\\nPrevious work on the various encoding biases in large lan-\\nguage models highlights the importance of dataset curation\\nand documentation [9, 10]. Experiments conducted on\\nGPT-3 (which has been trained on 570GB of text data\\nfrom Common Crawl) show that the model may gener-\\nate toxic sentences even when prompted with non-toxic'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ate toxic sentences even when prompted with non-toxic\\ntext [11]. Although applying ﬁltering of training data using\\nautomated toxicity scores may introduce classiﬁer-speciﬁc\\nbiases [12], this technique remains more effective than\\n∗Authors contributed equally, order is random\\n1Coteries SA, EPFL Innovation Park, Lausanne, Switzerland\\n2https://commoncrawl.org/\\narXiv:2202.03371v1  [cs.CL]  7 Feb 2022\\ndecoder-based detoxiﬁcation using methods such as swear\\nword ﬁlters, PPLM [13], soft prompt tuning [14] or toxicity\\ncontrol tokens [15].\\nAs a consequence of the aforementioned risks, the trend\\ntowards larger models coincides with a trend to not release\\nmodels publicly. Controlling access to large language mod-\\nels may protect against certain bad actors but also limits\\nreproducibility and research efforts to mitigate the negative\\nproperties of such models. In a push for building models in\\nthe open, EleutherAI, a grassroot collective of researchers,'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the open, EleutherAI, a grassroot collective of researchers,\\nreleased GPT-J [16], a 6B parameter English language\\nmodel. This model was trained on the Pile [20], a 825GB\\ntext corpus by the same collective.\\nThe contributions of this paper are as follows: (1) We intro-\\nduce Cedille, an openly available French language model\\nbuilt on GPT-J, which is capable of achieving competitive\\nzero-shot performance against existing French language\\nmodels and GPT-3. (2) We release the toxicity scores\\nof the complete French C4 dataset, and (3) we provide a\\ncomparison of Cedille’s toxicity to other language models\\n(including GPT-3).\\n2\\nMethods\\n2.1\\nModel architecture\\nOur model architecture is identical to GPT-J [16]. GPT-J\\nuses a similar transformer architecture to the one used in\\n6.7B GPT-3 with three main differences: (1) No sparse\\nattention patterns were used; (2) the dimension of the atten-\\ntion head was increased from 128 to 256; and (3) Rotary'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tion head was increased from 128 to 256; and (3) Rotary\\npositional embeddings [17] were used instead of sinusoidal\\nembeddings. See Table 1 for more details.\\nNumber of parameters\\n6,053,381,344\\nNumber of layers N\\n28\\nModel dimensions dmodel\\n4096\\nFeed-forward dimension dff\\n16,384\\nNumber of attention heads nheads\\n16\\nHead dimension dhead\\n256\\nContext size\\n2048\\nVocab size\\n50,257\\nTable 1: Cedille model details.\\n2.2\\nTraining data\\nCedille is trained on a ﬁltered version of the French part\\nof the multilingual C4 (mC4) dataset [18], which contains\\n332M documents or 1.1TB of uncompressed text. mC4 is\\nextracted from 71 Common Crawl snapshots (years 2013\\nto 2020) and uses CLD33, a small feed-forward neural net-\\nwork, for language identiﬁcation. mC4 ﬁltered out pages\\nof less than three lines of at least 200 characters.\\nWe apply two different forms of ﬁltering to the dataset 1)\\ntoxicity ﬁltering using the Detoxify model [19] and 2) loss\\nﬁltering using the FlauBERT model [20]. For both ﬁltering'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ﬁltering using the FlauBERT model [20]. For both ﬁltering\\nsteps we compute the metric on a per document level of the\\nentire base dataset. In some cases chunking the documents\\ninto splits of 1200 characters was necessary due to the\\nﬁxed context size of the used models. Chunks smaller than\\n600 characters were not evaluated. The predictions were\\nrun on TPU v3-8 machines with 8-fold data parallelism\\neach.\\nEach percentile as well as the tails of both the loss and the\\ntoxicity distribution were sampled and manually inspected\\nto ﬁnd suitable cut-off values for ﬁltering. The inspection\\nof these samples revealed that both toxicity and loss values\\nwere appropriate4. We removed documents correspond-\\ning to a toxicity score higher than 0.5, corresponding to\\n0.25% of the content (0.8M documents). For the loss ﬁl-\\ntering we considered the loss distribution of each of the\\n2048 ﬁles and removed documents below a 0.2 percentile\\nloss (corresponding to a loss value of roughly 4.5) and'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='loss (corresponding to a loss value of roughly 4.5) and\\nabove an absolute loss value of 10. This corresponded to\\na removal of roughly 20% of all documents (66M docu-\\nments). The combined ﬁltering led to a ﬁnal training set of\\n265M documents, which corresponds to roughly 773GB\\nof uncompressed text.\\nThe text was then run through the fix_text method of\\nthe Python library ftfy [21] using NFKC normalization\\nand encoded using the unmodiﬁed GPT-2 tokenizer. Docu-\\nments were simply concatenated and split into samples of\\n2049 tokens. The ﬁnal training set yielded a total of 130M\\nsamples corresponding to 268B tokens.\\n2.3\\nTraining process\\nCedille was trained starting from the ofﬁcial GPT-J model\\ncheckpoint using the mesh-transformer-jax codebase [22].\\nTraining was conducted on a v3-128 TPU VM using 16-\\nfold data parallelism and 8-fold model sharding. For all\\nour experiments we used an effective batch size of 256.\\nWe used a linear warmup of 42k steps up to a peak learning'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='We used a linear warmup of 42k steps up to a peak learning\\nrate of 5e-5 and a cosine decay to 1e-5. Weight decay was\\nset to 0.1. Cedille was trained for 150k steps, which corre-\\nsponds to 0.3 epochs on the training set or 78.7B tokens.\\nThe starting and ﬁnal training perplexities were 6.13 and\\n3.89, respectively. During training we monitored the loss\\non a dataset of French news stories published too recently\\nto be part of the training data.\\n3https://github.com/google/cld3\\n4Despite the positive visual inspection a bug in the loss computation was discovered much later in the analysis. Further investiga-\\ntion revealed that roughly 10% of samples were wrongly included in the ﬁnal dataset as a result. Although it cannot be fully ruled\\nout we do not believe that a systematic bias was introduced.\\n2\\n2.4\\nEvaluation\\nZero-shot performance was evaluated using a forked ver-\\nsion of the lm-evaluation-harness codebase [23]. In par-\\nticular, we added a different way of evaluating perplexity'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='ticular, we added a different way of evaluating perplexity\\nusing strides (see section 3.1), implemented the various\\nbenchmarks discussed in this work, and integrated the\\nmesh-transformer-jax library (for evaluating checkpoints\\non TPUs) and the Pagnol model families. Benchmarking\\nwas conducted on v3-8 TPU VMs and on A100 GPUs.\\nToxicity evaluation was conducted using a modiﬁed ver-\\nsion of the real-toxicity-prompts codebase5. The main\\ndifference is the use of the Detoxify model in order\\nto predict toxicity (see section 4).\\nOur adapted code-\\nbase is available at https://github.com/coteries/\\nreal-toxicity-prompts.\\n3\\nTasks\\n3.1\\nPerplexity\\nModel\\n#params\\nByte-PPL\\nToken-PPL\\nGPT-3 (ada)\\n1.3Ba\\n1.930\\n7.952\\nGPT-3 (babbage)\\n6.7B\\n1.973\\n6.447\\nGPT-3 (curie)\\n13B\\n1.809\\n5.082\\nGPT-3 (davinci)\\n175B\\n1.656\\n3.993\\nGPT-J\\n6.05B\\n1.746\\n5.797\\nCedille\\n6.05B\\n1.646\\n3.932\\nPagnol (small)\\n124M\\n1.852\\n17.802\\nPagnol (medium)\\n335M\\n1.775\\n14.623\\nPagnol (large)\\n773M\\n1.725\\n12.791\\nGPT-fr (base)\\n1B\\n2.090\\n11.882'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='Pagnol (medium)\\n335M\\n1.775\\n14.623\\nPagnol (large)\\n773M\\n1.725\\n12.791\\nGPT-fr (base)\\n1B\\n2.090\\n11.882\\nTable 2: Byte-level and token-level perplexity scores on the\\nWikiText-fr benchmark (lower is better).\\naOpenAI hasn’t ofﬁcially disclosed the size of the models\\nprovided by their API, however recent experiments suggest the\\nmapping presented in the table [24].\\nZero-shot perplexity was evaluated on the test subset of\\nthe WikiText-fr6 dataset [6], containing articles from the\\nFrench Wikipedia which are part of the “quality articles” or\\n“good articles” categories, similar to the English WikiText-\\n103 dataset [25]. The test set contains 589k words or 3.7M\\ncharacters of cleaned French text from 60 articles. We eval-\\nuated perplexity by concatenating the text without further\\npreprocessing and using a sliding window approach [26]\\nwith a stride of 512 tokens. Therefore models with a con-\\ntext window of 1024 tokens (GPT-fr, Pagnol) had 512\\ntokens of context, whereas models with a context window'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tokens of context, whereas models with a context window\\nof 2048 tokens had 1536 tokens of context. Table 2 shows\\nthe summed log likelihoods both normalized by number\\nof characters and by number of tokens. Note that the\\ntoken-level perplexity for GPT-fr and Pagnol is not directly\\ncomparable to the other models, as they are not using the\\n(English) GPT-2 tokenizer.\\nCedille achieves the lowest perplexity score out of the an-\\nalyzed models, clearly outcompeting existing French lan-\\nguage models and narrowly outcompeting GPT-3 (davinci).\\nUnsurprisingly, models with larger context windows gen-\\nerally perform better at this task. It is noteworthy that the\\ntest dataset is likely contained in the training data as no\\ndataset-speciﬁc ﬁltering of the training data was conducted\\nas part of this work.\\n3.2\\nSummarization\\nWe evaluated the summarization capabilities on the Orange-\\nSum benchmark, as introduced in the BARThez work [27]\\nas a French equivalent of XSum [28]. The benchmark con-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='as a French equivalent of XSum [28]. The benchmark con-\\ntains news articles published between February 2011 and\\nSeptember 2020, scraped from the French website “Orange\\nActu”. The models were given the news article in the test\\nsubset using the following prompt:\\n{article text}\\\\nPour résumer :\\nThe models were tasked to generate 100 tokens using top-k\\nof 2 and a temperature of 1, following the methodology\\nin [1]. We used greedy decoding (top-k = 1) for GPT-3,\\nsince at the time of this work being conducted, the API\\ndidn’t allow for other top-k values. When the prompt ex-\\nceeded the context window of the model it was left-side\\ntruncated. The output was then clipped to contain at most 3\\nsentences (using simplistic sentence splitting at the period\\ncharacter). Table 3 shows the ROUGE score [29] of the\\noutput compared to the title of the corresponding articles.\\nModel\\nR1\\nR2\\nRL\\nGPT-3 (ada)\\n13.95\\n4.75\\n11.59\\nGPT-3 (babbage)\\n4.62\\n1.76\\n3.86\\nGPT-3 (curie)\\n5.28\\n2.21\\n4.42\\nGPT-3 (davinci)\\n15.49\\n5.82'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='4.75\\n11.59\\nGPT-3 (babbage)\\n4.62\\n1.76\\n3.86\\nGPT-3 (curie)\\n5.28\\n2.21\\n4.42\\nGPT-3 (davinci)\\n15.49\\n5.82\\n13.05\\nGPT-J\\n14.46\\n4.72\\n11.68\\nCedille\\n14.74\\n4.83\\n11.86\\nPagnol (small)\\n8.52\\n1.61\\n7.24\\nPagnol (medium)\\n8.98\\n1.86\\n7.55\\nPagnol (large)\\n9.19\\n1.85\\n7.71\\nGPT-fr (base)\\n10.15\\n2.60\\n8.27\\nTable 3: Performance of summarization in French. Shown are\\nthe ROUGE scores on the OrangeSum dataset (higher is better).\\nGenerally, we observed some variance due to the non-\\ngreedy sampling procedure. However, computational limi-\\n5https://github.com/allenai/real-toxicity-prompts\\n6https://huggingface.co/datasets/asi/wikitext_fr\\n3\\ntations and cost made it difﬁcult to estimate this variance.\\nWe also observed that the choice of the preﬁx (“Pour ré-\\nsumer :”) strongly inﬂuences the scores. Some of the\\nevaluated models are also more likely to generate bullet\\npoint summaries, rather than a single sentence, which may\\nagain lead to different sentence splitting. This may ex-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='again lead to different sentence splitting. This may ex-\\nplain the increased score for GPT-3 (ada) compared to\\nlarger GPT-3 models. Nevertheless, the scores provided\\nin Table 3 give some rough indication of summarization\\nperformance.\\n3.3\\nQuestion Answering (QA)\\nQuestion answering (QA) was evaluated on FQuAD\\n(French Question Answering Dataset) [30], a dataset in-\\nspired by the English SQuAD equivalent [31]. The models\\nwere evaluated on the validation subset, which contains\\n3188 human-curated question-answer pairs, based on 768\\nhigh-quality French Wikipedia articles.\\nModel\\nF1\\nExact match (%)\\nGPT-3 (ada)\\n19.09\\n4.48\\nGPT-3 (babbage)\\n26.16\\n8.81\\nGPT-3 (curie)\\n39.49\\n17.84\\nGPT-3 (davinci)\\n-\\n-\\nGPT-J\\n26.14\\n6.96\\nCedille\\n34.59\\n12.23\\nPagnol (small)\\n10.66\\n0.43\\nPagnol (medium)\\n13.80\\n0.84\\nPagnol (large)\\n17.67\\n2.72\\nGPT-fr (base)\\n15.15\\n2.03\\nTable 4: Question-answering F1 and exact match scores in\\nFrench on the FQuAD benchmark (higher is better).\\nThe models were evaluated using the SQuAD v2 met-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='French on the FQuAD benchmark (higher is better).\\nThe models were evaluated using the SQuAD v2 met-\\nric [31], which also takes into consideration “no answer”\\nprobabilities, i.e. cases when no answer to a particular\\nquestion is possible given the context. The models were\\ntasked to generate 100 tokens and at most 1 sentence using\\ngreedy sampling and the following prompt:\\nTitre:\\n{title}\\\\nContexte:\\n{context}\\\\n\\\\n\\nQuestion:\\n{question}\\\\n\\\\nRéponse:\\nThe “no answer” probabilities were calculated against the\\nstring:\\n{prompt} Sans réponse.\\nHowever, all questions in the evaluated data contained\\nexactly one answer.\\nThe results in Table 4 show that GPT-3 is very competitive\\non this task, with GPT-3 (curie) outperforming Cedille\\nand all other evaluated models. GPT-3 (davinci) was not\\nevaluated on this task for cost reasons, as OpenAI did not\\nsupport our request for funding at the time of writing. The\\nresults may be contrasted to a ﬁnetuned version of Camem-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='results may be contrasted to a ﬁnetuned version of Camem-\\nBERT [32] which yields F1 of 88% and best match of 78%\\non this dataset [30].\\n3.4\\nTranslation\\nZero-shot translation was evaluated for the language pair\\nEnglish and French on the WMT14 dataset [33]. Tradi-\\ntionally, such benchmarks are evaluated using the BLEU\\nscore [34]. The datasets contains 3003 samples each and\\nare provided by the sacrebleu library [35]. The zero-shot\\ntask is formulated using the following pattern:\\n{source_lang} phrase:\\n{text}\\\\n{target_lang}\\nphrase:\\nWhere source_lang and target_lang are French and\\nEnglish, respectively, depending on the direction. Greedy\\nsampling is used to generate 256 tokens. The output was\\nclipped to at most 1 sentence.\\nCedille outperforms other models for the direction English\\nto French, highlighting the strong French writing capabil-\\nities (see Table 5). Likewise, GPT-3 (davinci) performs\\nbetter for the French to English direction. Monolingual'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='better for the French to English direction. Monolingual\\nmodels, such as Pagnol and GPT-fr perform worse at this\\ntask presumably due to the limited amount of English that\\nwas part of their pretraining data. Often, smaller models\\nwere unable to follow the instructions and simply repeated\\nthe context in the given language. As opposed to summa-\\nrization and question-answering benchmarks, the target is\\ngenerally not part of the context, therefore simply repeating\\nthe input normally results in a low score.\\nAs of 2021, dedicated neural machine translation solutions,\\nsuch as Very Deep Transformers, reach 46.4 BLEU for\\nEnglish to French translation [36].\\nModel\\nBLEU (en→fr)\\nBLEU (fr→en)\\nGPT-3 (ada)\\n2.71\\n16.64\\nGPT-3 (babbage)\\n3.20\\n24.56\\nGPT-3 (curie)\\n13.45\\n27.15\\nGPT-3 (davinci)\\n20.40\\n27.70\\nGPT-J\\n14.71\\n26.06\\nCedille\\n24.89\\n20.59\\nPagnol (small)\\n0.76\\n1.20\\nPagnol (medium)\\n1.07\\n1.48\\nPagnol (large)\\n1.06\\n3.47\\nGPT-fr (base)\\n1.47\\n1.57\\nTable 5: BLEU scores for ranslation on WMT14 for the English-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='1.06\\n3.47\\nGPT-fr (base)\\n1.47\\n1.57\\nTable 5: BLEU scores for ranslation on WMT14 for the English-\\nFrench language pair (higher is better).\\n4\\nToxicity analysis\\nIn order to evaluate the toxicity of the model we closely\\nfollowed the work conducted in [11]. We studied the case\\n4\\nof unprompted (i.e. conditioned only on a start-of-sentence\\ntoken) and prompted generation.\\nThe original work in [11] used the Perspective API, a ser-\\nvice that uses machine learning classiﬁers to estimate the\\nperceived toxicity of text. In this work, we employ the\\nDetoxify tool [19] instead. We made this choice as the\\nunderlying models used by Perspective evolve with time\\nand are not released publicly, which limits experimental\\nreproducibility.\\nDetoxify assigns a toxicity score between 0 and 1, with 1\\ndenoting “a very hateful, aggressive, or disrespectful com-\\nment”. We refer to content with a score > 0.5 as “toxic”.\\nWe use the “multilingual” Detoxify model from release'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='We use the “multilingual” Detoxify model from release\\nv0.4.0, and compare the toxicity of Cedille output to 3\\nother models: GPT-2 (117M), GPT-3 (davinci), GPT-J and\\nGPT-fr (base).\\n4.1\\nUnprompted toxicity\\nFor the unprompted toxicity we analyze the expected max-\\nimum toxicity, i.e. the expected worst-case toxicity score\\ngiven N unprompted generations. Figure 1 shows boot-\\nstrap estimates (1000 iterations) of the expected maximum\\ntoxicity for N generations with variance bounds as shades.\\nIn this setting, Cedille consistently generates content with\\nlower expected maximum toxicity than GPT-2, GPT-J, and\\nGPT-3. After 100 generations, this value is under 0.5 for\\nGPT-fr and Cedille (0.41 and 0.48, respectively), which\\nmeans that the worst content from these models is not\\nexpected to be toxic. This is in contrast with the other\\nmodels, for which maximum expected toxicity values are\\n0.64, 0.54 and 0.56.\\nAfter 10K generations, Cedille and GPT-fr are the only'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='0.64, 0.54 and 0.56.\\nAfter 10K generations, Cedille and GPT-fr are the only\\nmodels for which the expected worst outputs don’t reach\\na toxicity level of 1.0 We expect all other models to have\\nat least one output that is maximally toxic as detected by\\nDetoxify. Generally the two models that perform best are\\nGPT-fr and Cedille, which were both trained on carefully\\nﬁltered datasets, pointing to the importance of dataset cu-\\nration when considering the safety of language models.\\nWithout any conditioning, the multilingual models almost\\nexclusively generate English content: this is the case of\\nGPT-2, GPT-J and GPT-3. However, with the Detoxify\\nmodel being multilingual, the toxicity scores remain com-\\nparable.\\n4.2\\nPrompted toxicity\\nFor prompted toxicity we used a set of 50 French prompts\\nwith values of toxicity spanning the full range, with a mean\\nof 0.34. The set of prompts was selected randomly from\\nthe RealToxicityPrompt dataset and manually translated'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the RealToxicityPrompt dataset and manually translated\\nfrom English to French by a French native speaker. We\\nused a smaller number of prompts than in [11] due to lim-\\nited computing resources. The French prompts cause the\\nmultilingual models (GPT-2, GPT-J and GPT-3) to gener-\\nate French content. For each prompt, each model generates\\n50 completions. We used nucleus sampling with p = 0.9\\nto generate up to 20 tokens per continuation, following the\\nprotocol from [11].\\nTable 6 shows two properties: 1) the expected maximum\\ntoxicity over 25 generations (with standard deviations in\\nparentheses) and 2) the empirical probability of generating\\ntoxic text at least once among 25 generations.\\nModel\\nExp. max tox.\\nProb. toxicity\\nGPT-2a\\n0.63 (0.23)\\n0.66\\nGPT-3 (davinci)\\n0.68 (0.27)\\n0.74\\nGPT-J\\n0.73 (0.26)\\n0.78\\nCedille\\n0.66 (0.27)\\n0.72\\nGPT-fr (base)\\n0.73 (0.27)\\n0.78\\nTable 6: Toxicity of prompted generations.\\naUpon manual inspection, it appeared that GPT-2 is unable'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='aUpon manual inspection, it appeared that GPT-2 is unable\\nto generate sensible French content, and as such the resulting\\ntoxicity values can’t be compared to other models.\\nFor both properties, Cedille outperforms the other models.\\nWe can see again that Cedille is less toxic than GPT-J,\\nindicating that the training not only improved the model’s\\nFrench capabilities, but also increased its safety.\\n5\\nConclusions\\nIn this work we introduced Cedille, a large auto-regressive\\nFrench language model.\\nOur work shows that mono-\\nlingual models such as Cedille, can be competitive com-\\npared to extreme scale multilingual language models, i.e.\\nGPT-3. Compared to existing French language models,\\nCedille is capable of performing well on zero-shot natural\\nlanguage understanding tasks and reaches a new state-of-\\nthe-art perplexity score on the French WikiText corpus.\\nLastly, our approach of toxicity ﬁltering of the training\\ndata led to a decrease in both maximum toxicity as well as'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='data led to a decrease in both maximum toxicity as well as\\nthe likelihood of toxic output.\\nAs a result of the ﬁnetuning approach starting from GPT-J,\\nCedille has been exposed to a large amount of both English\\nand French language data from the Pile and French mC4.\\nThis combination allows for competitive zero-shot trans-\\nlation scores for the French-English language pair. Early\\nexperiments indicate that ﬁnetuning an existing English\\nlanguage model and adapting it to French is more efﬁcient\\neven with considerable compute and data investments (see\\nappendix).\\nGiven the scarcity of high-quality human-curated datasets\\nin non-English languages it is especially challenging to\\nprovide a fair comparison of language models. For the\\nzero-shot benchmarks we observed a high degree of sen-\\nsitivity towards evaluation settings such as preﬁxes, sam-\\npling parameters, and type of evaluation metric. The scores\\n5\\n10\\n100\\n1K\\n10K\\nNumber of Generations\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='5\\n10\\n100\\n1K\\n10K\\nNumber of Generations\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0\\nExpected Maximum Toxicity\\nGPT-2\\nGPT-3\\nGPT-J\\nGPT-fr\\nCedille\\nFigure 1: Unprompted expected maximum toxicity against increasing numbers of generations.\\nshould therefore only be considered as a rough guidance\\nand model performance may be highly task speciﬁc. In this\\nwork we haven’t provided performance metrics for other\\nNLP tasks such as text classiﬁcation or word sense disam-\\nbiguation. Furthermore, this work focused on zero-shot\\nevaluation, ignoring few-shot or ﬁnetuning approaches.\\nApart from training larger models, a possible path for-\\nward is to deduplicate training data. This method has been\\nshown to improve end-task performance signiﬁcantly [8,\\n37] but was not conducted as part of this work. In order to\\nfurther reduce language model toxicity, a possible direc-\\ntion is the integration of human feedback in the training\\nprocess in order to reduce toxic output generation [38].\\nData availability.'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='process in order to reduce toxic output generation [38].\\nData availability.\\nCedille is available under the MIT\\nLicense on the Hugging Face model hub:\\nhttps:\\n//huggingface.co/Cedille/fr-boris, and on our\\nGitHub repository: https://github.com/coteries/\\ncedille-ai. Regarding the French mC4 toxicity scores\\nand toxicity analysis code, please refer to: https://\\ngithub.com/coteries/real-toxicity-prompts.\\nFunding.\\nThis work was funded by, and conducted at,\\nCoteries SA7. The model was trained on Cloud TPUs pro-\\nvided by Google’s TPU Research Cloud program.\\nAcknowledgments.\\nWe thank Sébastien Flury and\\nFrançois Bochatay for their guidance and feedback. Tiago\\nCastanheiro, Flavien Bonvin and Livio Gamassia imple-\\nmented the web-based Playground used to evaluate the\\nmodel. Tiago Castanheiro, Flavien Bonvin, Sacha To-\\nufani, Livio Gamassia, and Kasper Andkjaer tested out\\nmultiple versions of the model. Sébastien Von Roth de-\\nsigned the Cedille logo as well as the visual design of the'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='signed the Cedille logo as well as the visual design of the\\nPlayground and Cedille website8. Sonja Dossenbach as-\\nsembled the dataset of recent French news. We are grateful\\nto EleutherAI for publicly releasing the GPT-J model and\\noffering us support on their Discord server9. We thank the\\nTPU Research Cloud team for their access to Cloud TPUs\\nand their support.\\nReferences\\n[1]\\nAlec Radford et al. “Language models are unsu-\\npervised multitask learners”. In: OpenAI blog 1.8\\n(2019), p. 9.\\n[2]\\nTom B Brown et al. “Language models are few-\\nshot learners”. In: arXiv preprint arXiv:2005.14165\\n(2020).\\n[3]\\nJared Kaplan et al. “Scaling laws for neu-\\nral\\nlanguage\\nmodels”.\\nIn:\\narXiv\\npreprint\\narXiv:2001.08361 (2020).\\n[4]\\nChau Tran et al. “Facebook AI WMT21 news\\ntranslation task submission”. In: arXiv preprint\\narXiv:2108.03265 (2021).\\n[5]\\nNaveen Arivazhagan et al. “Massively multilingual\\nneural machine translation in the wild: Findings and\\nchallenges”. In: arXiv preprint arXiv:1907.05019\\n(2019).'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='challenges”. In: arXiv preprint arXiv:1907.05019\\n(2019).\\n7https://coteries.com\\n8https://cedille.ai\\n9https://discord.gg/zBGx3azzUn\\n6\\n[6]\\nAntoine Simoulin and Benoit Crabbé. “Un mod-\\nèle Transformer Génératif Pré-entrainé pour le _\\nfrançais”. In: Traitement Automatique des Langues\\nNaturelles. ATALA. 2021, pp. 245–254.\\n[7]\\nJulien Launay et al. “PAGnol: An Extra-Large\\nFrench Generative Model”. In: arXiv preprint\\narXiv:2110.08554 (2021).\\n[8]\\nGuillaume Wenzek et al. “Ccnet: Extracting high\\nquality monolingual datasets from web crawl data”.\\nIn: arXiv preprint arXiv:1911.00359 (2019).\\n[9]\\nEmily M Bender et al. “On the Dangers of Stochas-\\ntic Parrots: Can Language Models Be Too Big?”\\nIn: Proceedings of the 2021 ACM Conference on\\nFairness, Accountability, and Transparency. 2021,\\npp. 610–623.\\n[10]\\nIsaac Caswell et al. “Quality at a glance: An au-\\ndit of web-crawled multilingual datasets”. In: arXiv\\npreprint arXiv:2103.12028 (2021).\\n[11]\\nSamuel Gehman et al. “RealToxicityPrompts: Evalu-'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='preprint arXiv:2103.12028 (2021).\\n[11]\\nSamuel Gehman et al. “RealToxicityPrompts: Evalu-\\nating neural toxic degeneration in language models”.\\nIn: arXiv preprint arXiv:2009.11462 (2020).\\n[12]\\nJohannes Welbl et al. “Challenges in detox-\\nifying language models”. In: arXiv preprint\\narXiv:2109.07445 (2021).\\n[13]\\nSumanth Dathathri et al. “Plug and play language\\nmodels: A simple approach to controlled text gener-\\nation”. In: arXiv preprint arXiv:1912.02164 (2019).\\n[14]\\nBrian Lester, Rami Al-Rfou, and Noah Constant.\\n“The power of scale for parameter-efﬁcient prompt\\ntuning”. In: arXiv preprint arXiv:2104.08691\\n(2021).\\n[15]\\nNitish Shirish Keskar et al. “Ctrl: A conditional\\ntransformer language model for controllable gener-\\nation”. In: arXiv preprint arXiv:1909.05858 (2019).\\n[16]\\nBen Wang and Aran Komatsuzaki. GPT-J-6B: A 6\\nBillion Parameter Autoregressive Language Model.\\nhttps : / / github . com / kingoflolz / mesh -\\ntransformer-jax. May 2021.\\n[17]'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='https : / / github . com / kingoflolz / mesh -\\ntransformer-jax. May 2021.\\n[17]\\nJianlin Su et al. “Roformer: Enhanced transformer\\nwith rotary position embedding”. In: arXiv preprint\\narXiv:2104.09864 (2021).\\n[18]\\nLinting Xue et al. “mT5: A massively multilin-\\ngual pre-trained text-to-text transformer”. In: arXiv\\npreprint arXiv:2010.11934 (2020).\\n[19]\\nLaura Hanu and Unitary team. Detoxify. https:\\n//github.com/unitaryai/detoxify. 2020.\\n[20]\\nHang Le et al. “Flaubert: Unsupervised language\\nmodel pre-training for french”. In: arXiv preprint\\narXiv:1912.05372 (2019).\\n[21]\\nRobyn Speer. ftfy. Zenodo. Version 5.5. 2019. DOI:\\n10.5281/zenodo.2591652. URL: https://doi.\\norg/10.5281/zenodo.2591652.\\n[22]\\nBen Wang. Mesh-Transformer-JAX: Model-Parallel\\nImplementation of Transformer Language Model\\nwith JAX. https://github.com/kingoflolz/\\nmesh-transformer-jax. May 2021.\\n[23]\\nLeo Gao et al. A framework for few-shot language\\nmodel evaluation. Version v0.0.1. Sept. 2021. DOI:'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='Leo Gao et al. A framework for few-shot language\\nmodel evaluation. Version v0.0.1. Sept. 2021. DOI:\\n10.5281/zenodo.5371628. URL: https://doi.\\norg/10.5281/zenodo.5371628.\\n[24]\\nLeo Gao. On the Sizes of OpenAI API Models.\\nhttps://blog.eleuther.ai/gpt3- model-\\nsizes/. May 2021.\\n[25]\\nStephen Merity et al. “Pointer sentinel mixture mod-\\nels”. In: arXiv preprint arXiv:1609.07843 (2016).\\n[26]\\nPerplexity of ﬁxed-length models. https : / /\\nhuggingface . co / docs / transformers /\\nperplexity. Accessed: 2022-02-04.\\n[27]\\nMoussa Kamal Eddine, Antoine J-P Tixier, and\\nMichalis Vazirgiannis. “BARThez: a skilled pre-\\ntrained french sequence-to-sequence model”. In:\\narXiv preprint arXiv:2010.12321 (2020).\\n[28]\\nShashi Narayan, Shay B Cohen, and Mirella La-\\npata. “Don’t give me the details, just the sum-\\nmary! topic-aware convolutional neural networks\\nfor extreme summarization”. In: arXiv preprint\\narXiv:1808.08745 (2018).\\n[29]\\nChin-Yew Lin. “Rouge: A package for automatic'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='arXiv:1808.08745 (2018).\\n[29]\\nChin-Yew Lin. “Rouge: A package for automatic\\nevaluation of summaries”. In: Text summarization\\nbranches out. 2004, pp. 74–81.\\n[30]\\nMartin d’Hoffschmidt et al. “FQuAD: French\\nquestion answering dataset”. In: arXiv preprint\\narXiv:2002.06071 (2020).\\n[31]\\nPranav Rajpurkar et al. “SQuAD: 100,000+ ques-\\ntions for machine comprehension of text”. In: arXiv\\npreprint arXiv:1606.05250 (2016).\\n[32]\\nLouis Martin et al. “CamemBERT: a tasty\\nfrench\\nlanguage\\nmodel”.\\nIn:\\narXiv\\npreprint\\narXiv:1911.03894 (2019).\\n[33]\\nOndˇrej Bojar et al. “Findings of the 2014 workshop\\non statistical machine translation”. In: Proceedings\\nof the ninth workshop on statistical machine trans-\\nlation. 2014, pp. 12–58.\\n[34]\\nKishore Papineni et al. “Bleu: a method for auto-\\nmatic evaluation of machine translation”. In: Pro-\\nceedings of the 40th annual meeting of the Associa-\\ntion for Computational Linguistics. 2002, pp. 311–\\n318.\\n[35]\\nMatt Post. “A Call for Clarity in Reporting BLEU'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='318.\\n[35]\\nMatt Post. “A Call for Clarity in Reporting BLEU\\nScores”. In: Proceedings of the Third Conference\\non Machine Translation: Research Papers. Belgium,\\nBrussels: Association for Computational Linguis-\\ntics, Oct. 2018, pp. 186–191. URL: https://www.\\naclweb.org/anthology/W18-6319.\\n[36]\\nXiaodong Liu et al. “Very deep transformers for\\nneural machine translation”. In: arXiv preprint\\narXiv:2008.07772 (2020).\\n[37]\\nKatherine Lee et al. “Deduplicating training data\\nmakes language models better”. In: arXiv preprint\\narXiv:2107.06499 (2021).\\n[38]\\nLong Ouyang et al. Training language models to\\nfollow instructions with human feedback. https://\\nopenai.com/blog/instruction-following/.\\nJan. 2022.\\n7\\nSUPPLEMENTARY MATERIAL\\n1\\nExperiments training from scratch\\nGiven the amount of compute and data available, training from scratch rather than ﬁnetuning was considered. We\\nexperimented training Cedille from scratch using both the GPT-2 tokenizer (Cedille-fs-GPT2, vocab size 50,400) and'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='the GPT-fr tokenizer (Cedille-fs-GPTfr, vocab size 50.000) for 60k steps using a peak learning rate of 1.2e-4 end\\nlearning rate 1.2e-5, and 7281 warm-up steps. These two variants are therefore only trained on one third of the data\\ncompared to the released Cedille model (150k steps). In order to have a fair comparison we show the result of Cedille\\nafter the same amount of steps (Cedille-60k). All models were trained on the same ﬁltered mC4 dataset, as described in\\nthis work.\\nAs shown in Table S1, Cedille-60k outperforms the from-scratch variants on the WikiText-fr benchmark. However,\\ndue to compute limitations we did not run the variants for longer than 60k steps and it is possible that we could’ve\\nreached similar performance after 150k steps. Furthermore, both variants perform similarly, even though they are using\\na different tokenizer. Due to the variants performing very similarly, we conclude that even though a dedicated French'),\n",
              " Document(metadata={'Published': '2022-02-07', 'Title': 'Cedille: A large autoregressive French language model', 'Authors': 'Martin Müller, Florian Laurent', 'Summary': 'Scaling up the size and training of autoregressive language models has\\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\\nmultilingual capabilities, zero-shot learning for languages other than English\\nremain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, specifically trained for the French language.\\nOur results show that Cedille outperforms existing French language models and\\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\\nthese models, showing that Cedille marks an improvement in language model\\nsafety thanks to dataset filtering.'}, page_content='tokenizer is a lot more efﬁcient at encoding French text compared to the GPT-2 tokenizer, its beneﬁt with regard to\\nend-task performance was minimal in our experiments.\\nModel\\nPPL (byte)\\nPPL (token)\\nGPT-J\\n1.746\\n5.797\\nCedille-60k\\n1.673\\n4.112\\nCedille-fs-GPT2\\n1.794\\n4.972\\nCedille-fs-GPTfr\\n1.775\\n6.856\\nTable S1: Byte-level and token-level perplexities for the WikiText-fr benchmark. Cedille-60k is the Cedille model at checkpoint 60k\\n(out of 150k), Cedille-fs-GPT2 and Cedille-fs-GPTfr are models trained for 60k steps on the same dataset, but with random weight\\ninitialization.\\n8'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='arXiv:2305.06530v1  [cs.CL]  11 May 2023\\nAfricaNLP workshop at ICLR2022\\nHOW GOOD ARE COMMERCIAL LARGE LANGUAGE\\nMODELS ON AFRICAN LANGUAGES?\\nJessica Ojo\\nMasakhane\\njessicaojo19@gmail.com\\nKelechi Ogueji\\nMasakhane\\nkelechi.ogueji@uwaterloo.ca\\nABSTRACT\\nRecent advancements in Natural Language Processing (NLP) has led to the pro-\\nliferation of large pretrained language models. These models have been shown to\\nyield good performance, using in-context learning, even on unseen tasks and lan-\\nguages. They have also been exposed as commercial APIs as a form of language-\\nmodel-as-a-service, with great adoption. However, their performance on African\\nlanguages is largely unknown. We present a preliminary analysis of commercial\\nlarge language models on two tasks (machine translation and text classiﬁcation)\\nacross eight African languages, spanning different language families and geo-\\ngraphical areas. Our results suggest that commercial language models produce'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='graphical areas. Our results suggest that commercial language models produce\\nbelow-par performance on African languages. We also ﬁnd that they perform bet-\\nter on text classiﬁcation than machine translation. In general, our ﬁndings present\\na call-to-action to ensure African languages are well represented in commercial\\nlarge language models, given their growing popularity.\\n1\\nINTRODUCTION\\nLarge language models have risen to the fore of Natural Language Processing (NLP). These models\\nhave been shown to achieve state-of-the-art performances on several tasks. More recently, focus has\\nshifted from the pretrain-ﬁnetune paradigm (Howard & Ruder, 2018; Devlin et al., 2019; Liu et al.,\\n2019; Raffel et al., 2020) to in-context learning (Brown et al., 2020; Lin et al., 2021; Wei et al.,\\n2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al., 2023). In-context\\nlearning proves that prompting large language models with some task-speciﬁc examples allows them'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='learning proves that prompting large language models with some task-speciﬁc examples allows them\\nperform well on test examples of that task, all without updating the model’s parameters. This has\\nled to reduced computation costs and has made it possible to create language-models-as-a-service\\n(Sun et al., 2022), in the form of commercial Application Programming Interfaces (APIs). Com-\\nmercial language models have become very prevalent. For context, the recently released ChatGPT1\\namassed 100 million users2 in two months, making it the fastest growing consumer app in recent\\nhistory. Given their dominance and inevitable continual rise, it is important to understand how these\\nmodels perform on African languages. Hence, we present a preliminary effort to close this gap by\\nevaluating two commercial large language models using in-context learning on African languages.\\nEvaluation is performed on two tasks - text classiﬁcation and machine translation. Our experiments,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Evaluation is performed on two tasks - text classiﬁcation and machine translation. Our experiments,\\nspanning 8 African languages from different language families and geographical locations, suggests\\nthat commercial language models do not perform well on African languages. In particular, we note\\na large disparity in performance, depending on the evaluation task - models perform better on text\\nclassiﬁcation than machine translation. Our work sheds light on the need to ensure the inclusion\\nof African languages in the development of commercial language models, given their inevitable\\nadoption in our daily lives.\\n1https://chat.openai.com/\\n2https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-faste\\n1\\nAfricaNLP workshop at ICLR2022\\n2\\nRELATED WORK\\n2.1\\nIN-CONTEXT LEARNING\\nThe use of pretrained language models has become the de-facto approach to solving natural language'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='The use of pretrained language models has become the de-facto approach to solving natural language\\nprocessing (NLP) tasks. Previous models such as BERT (Devlin et al., 2019), RoBERTa (Liu et al.,\\n2019) and T5 (Raffel et al., 2020) largely follow a pretrain-ﬁnetune setting (Howard & Ruder,\\n2018). In this method, the pretrained model is ﬁnetuned on a downstream task, such as text classi-\\nﬁcation, and then used for that task. While this works very well, it has several downsides. For one,\\nﬁnetuned models are usually task-speciﬁc and this means one has to maintain separate models for\\nseparate tasks. Furthermore, the growing size of pretrained language models (Kaplan et al., 2020)\\nmeans that it is becoming increasingly expensive to ﬁnetune such gigantic models. One solution\\nthat has proven popular in recent times is in-context learning (Brown et al., 2020; Schick & Sch¨utze,\\n2021; Wei et al., 2022a; Chowdhery et al., 2022; Chung et al., 2022; Sanh et al., 2022; Dong et al.,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='2023). The core idea behind this method is to enable pretrained language models learn from ex-\\namples within the context. In this setting, a user prompts a pretrained language model with a few\\nlabelled examples of a task following a speciﬁc pattern, and unlabelled examples that need to be pre-\\ndicted on (Wei et al., 2022c; Liu et al., 2022; Wei et al., 2022b). In-context learning can also work\\nin a zero-shot setting where no labelled examples are included in the prompt. In-context learning\\nworks surprisingly well and is very efﬁcient since there is no update to the model’s parameters. As\\na result, computation costs are signiﬁcantly reduced and it becomes possible to expose language\\nmodels as a service (Sun et al., 2022). Commercial APIs are heavily reliant on in-context learning\\nas this is the primary method through which users interact 3 with the models4.\\n2.2\\nMULTILINGUAL IN-CONTEXT LEARNING\\nLarge language models have proven successful in multilingual settings.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Large language models have proven successful in multilingual settings.\\nLin et al. (2021) train\\nseveral multilingual models, of which the largest one (7.5B parameters) sets a state-of-the-art in\\nfew-shot learning on more than 20 languages. Their model outperforms GPT3 on several mul-\\ntilingual tasks. Muennighoff et al. (2022) perform multitask prompted ﬁnetuning on multilingual\\npretrained language models and observe impressive zero-shot generalization to tasks in unseen lan-\\nguages. Following ﬁndings from Blevins & Zettlemoyer (2022) that non-English dataset present in\\nthe pretraining corpora of English language models explains their surprising cross-lingual ability,\\nChowdhery et al. (2022) deliberately introduce non-English corpora (≈22%) into the pretraining\\ncorpora of their PaLM model and achieve impressive few-shot multilingual performance. Shi et al.\\n(2022) evaluate GPT3 and PaLM on a newly introduced grade school mathematics multilingual'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='(2022) evaluate GPT3 and PaLM on a newly introduced grade school mathematics multilingual\\nbenchmark. They ﬁnd that using prompts with intermediate reasoning steps in English consistently\\nled to competitive or better results than those written in the native language of the question. They\\nalso set a new state-of-the-art on a common-sense reasononing multilingual benchmark, XCOPA\\n(Ponti et al., 2020), using few-shot examples. Zhao & Sch¨utze (2021) show that prompting yields\\nbetter cross-lingual transfer in few-shot settings than ﬁnetuning and in-language training of multilin-\\ngual natural language inference. Furthermore, Winata et al. (2021) evaluate the multilingual ability\\nof GPT (Radford et al., 2019) and T5 (Raffel et al., 2020) models on multi-class text classiﬁcation,\\nand ﬁnd that they work well on non-English languages given a few English examples. Concurrent\\nwork (Jiao et al., 2023) evaluate ChatGPT on machine translation and ﬁnd that, while it is compet-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='work (Jiao et al., 2023) evaluate ChatGPT on machine translation and ﬁnd that, while it is compet-\\nitive with other commercial translation APIs such as Google translate5, it is less robust on other\\ndomains such as biomedical. Another concurrent work (Zhang et al., 2023) conducts a study on\\nthe performance of GLM (Zeng et al., 2022) on machine translation. They note several interesting\\nﬁndings on the effect of prompt template, examples and language. Despite the plethora of works\\non multilingual prompting, little to no African languages are usually contained in the evaluation\\nsets of nearly all of these works. When present, they are often obtained by translating the existing\\ndatasets of other languages (Yu et al., 2022) This method has been shown to contain artifacts that\\ncan inﬂate the performance of models evaluated on such datasets (Artetxe et al., 2020). Our work is\\northogonal to all of this works because we focus solely on commercial language model APIs, given'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='orthogonal to all of this works because we focus solely on commercial language model APIs, given\\ntheir prevalence. The closest to our work is concurrent by Abott et al. (2023), who evaluate GPT\\n3https://platform.openai.com/docs/guides/completion/prompt-design\\n4https://docs.cohere.ai/docs/prompt-engineering\\n5https://translate.google.com/\\n2\\nAfricaNLP workshop at ICLR2022\\n3.5 on Named Entity Recognition and Machine Translation on only isiZulu. However, our work is\\ndifferent from this as we compare two commercial APIs in the evaluation of text classiﬁcation and\\nMachine Translation across 8 African language.\\n3\\nMETHODOLOGY\\n3.1\\nDATASETS\\nEvaluation is done on two tasks - text classiﬁcation and machine translation.\\n3.1.1\\nTEXT CLASSIFICATION\\nWe use the news topic classiﬁcation datasets from Hedderich et al. (2020) and Alabi et al. (2022).\\nWe select the Hausa (hau) language from Hedderich et al. (2020) which has 5 categories. Pretrained'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='We select the Hausa (hau) language from Hedderich et al. (2020) which has 5 categories. Pretrained\\nlanguage models have been shown to work very well on this dataset in both few and zero-shot\\nsettings. The dataset from Alabi et al. (2022) covers ﬁve languages, out of which we select four\\n- Nigerian Pidgin (pcm), Malagasay (mlg), and Somali (som), isiZulu (zul). Each language has 5\\ncategories, except Somali which has 6. For both datasets, we use the train, validation and test splits\\nas released by the authors. We select these languages because they cover different language families\\nand geographical areas.\\n3.1.2\\nMACHINE TRANSLATION\\nWe use the MAFAND-MT machine translation dataset from Adelani et al. (2022) which covers 16\\nAfrican languages. Running translation on commercial APIs is cumbersome and expensive, hence\\nwe select 5 languages from the 16. The ﬁve languages are isiZulu (zul), Yoruba (yor), Nigerian'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='we select 5 languages from the 16. The ﬁve languages are isiZulu (zul), Yoruba (yor), Nigerian\\nPidgin (pcm), Swahili (Swa) and Lugala (lug). We use the splits as released by the authors.\\n3.2\\nMODELS\\nTwo commercial APIs6 are considered: ChatGPT7 and Cohere8. We consider both these APIs be-\\ncause they are arguably the most popular ones9. ChatGPT is based on the Instruct-GPT models\\n(Ouyang et al., 2022). It is optimized for conversations and has been shown to be capable of sev-\\neral NLP tasks including text classiﬁcation, machine translation, question answering, and so on.\\nWe use Cohere’s multilingual model10 which is based on their multilingual embedding model11.\\nThe embedding model supports 100 languages, including 15 African languages. All the languages\\nwe consider, except Nigerian Pidgin, are supported by the model. However, given the linguistic\\nproximity of Nigerian Pidgin to English (Faraclas, 2008; Ogueji & Ahia, 2019; Chang et al., 2020;'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='proximity of Nigerian Pidgin to English (Faraclas, 2008; Ogueji & Ahia, 2019; Chang et al., 2020;\\nAhia & Ogueji, 2020a; Lent et al., 2021; 2022), the model should be able to perform well on the\\ndataset.\\n3.3\\nPROMPTING AND EVALUATION\\nWe describe our prompting and evaluation approaches for text classiﬁcation and machine translation.\\n3.3.1\\nTEXT CLASSIFICATION\\nFor Cohere, we use the Classify12 endpoint and follow the format speciﬁed in the API documenta-\\ntion13. When using ChatGPT, we design several prompts ourselves and we also ask ChatGPT for\\n6Experiments were run between January 22, 2023 and February 5, 2023.\\n7https://chat.openai.com/\\n8https://www.cohere.ai\\n9https://venturebeat.com/uncategorized/openai-rival-cohere-launches-language-model-api/\\n10https://docs.cohere.ai/changelog/multilingual-support-for-coclassify\\n11https://docs.cohere.ai/docs/multilingual-language-models\\n12https://api.cohere.ai/classify\\n13https://docs.cohere.ai/reference/classify\\n3\\nAfricaNLP workshop at ICLR2022'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='13https://docs.cohere.ai/reference/classify\\n3\\nAfricaNLP workshop at ICLR2022\\nthe best prompt for classiﬁcation, following concurrent work (Jiao et al., 2023). We perform some\\ninitial evaluation of the prompts and select the best one.\\nOur best prompt is shown below:\\nGiven the following news headlines and their categories:\\nText:\\n{Sentence}\\nCategory:\\n{Label}\\nPlease classify the following news headlines into one of:\\n{Label List}.\\nText:\\n{Sentence}\\nCategory:\\nWhere Sentence is the news headline to be classiﬁed, Category is the news topic, and LabelList\\nis a comma separated list of all unique labels for that language.\\nFor both models, we supply two example demonstrations per category from the training set. We\\nrandomly sample 100 samples from the test set for each language and evaluate on this. Both demon-\\nstrations and evaluation are done across two random seeds, such that we sample distinct demonstra-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='strations and evaluation are done across two random seeds, such that we sample distinct demonstra-\\ntions and test samples for each language with each random seed. We report the average F1 score for\\neach language across both seeds. It should be noted that we decide to evaluate on a subset of the test\\nset because of the tedious nature of obtaining results ChatGPT.\\n3.3.2\\nMACHINE TRANSLATION\\nWe do not use Cohere for machine translation because its generation API currently supports only\\nEnglish14. ChatGPT is used for all our machine translation evaluations. Preliminary results from\\ncomparing few-shot to zero-shot translations on Nigerian Pidgin suggested no noticeable difference.\\nHence, we perform all translations in a zero-shot manner because of the tedious nature and low-\\nthroughput of obtaining results from ChatGPT.\\nWe use the prompt used in concurrent work (Jiao et al., 2023) which is shown below:\\nPlease provide the [TGT] translation for these sentences:\\n{Sentence}\\n{Sentence}'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Please provide the [TGT] translation for these sentences:\\n{Sentence}\\n{Sentence}\\nWhere T GT is the target language to be translated into, and Sentence is a sentence to be translated.\\nWe sample 100 sentences from the test set of each language and evaluate translating this to and from\\nEnglish. We report the BLEU score (Papineni et al., 2002) which is calculated using SacreBLEU\\n(Post, 2018).\\nIt has been shown that English prompts perform better, on average, than in-language prompts\\n(Lin et al., 2021; Shi et al., 2022), so we do not explore prompting in the target language for both\\ntasks.\\n4\\nRESULTS\\n4.1\\nTEXT CLASSIFICATION\\nResults are reported in table 1. As we can see, both commercial models fall well below the current\\nstate of the art. Surprisingly, Cohere’s multilingual embedding model is the worst performer, despite\\nsupporting almost all the languages evaluated on. Nigerian Pidgin has the highest score in the Cohere'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='results. This is most likely as a result of its close linguistic relationship with English language, which\\nusually makes up a signiﬁcant portion of the pretraining corpora of pretrained language models\\n(Wenzek et al., 2020; Gao et al., 2020; Laurenc¸on et al., 2022). ChatGPT is the best performing\\ncommercial model, and it gets above average F1 scores on all languages. Similar to Cohere, Hausa\\n14https://docs.cohere.ai/docs/generation-card#technical-notes\\n4\\nAfricaNLP workshop at ICLR2022\\nTable 1: Text Classiﬁcation Results: We report the F1 scores for the commercial models. We also\\nreport the current state of the art result obtained from Alabi et al. (2022). Best results per language\\nare in bold.\\nLanguage\\nCohere\\nChatGPT\\nCurrent SOTA\\nHausa (hau)\\n43.2\\n77.9\\n91.2\\nMalagasay (mlg)\\n35.0\\n51.1\\n67.3\\nNigerian Pidgin (pcm)\\n48.8\\n73.4\\n82.2\\nSomali (som)\\n28.4\\n51.3\\n79.9\\nisiZulu (zul)\\n24.8\\n54.8\\n79.6\\nand Nigerian Pidgin possess the highest F1 scores. The details of ChatGPT’s pretraining corpora'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='and Nigerian Pidgin possess the highest F1 scores. The details of ChatGPT’s pretraining corpora\\nand exact training methods are unknown, so it is hard to hypothesize a reason for its relatively\\ngood performance. However, it is very likely that its pretraining corpora contains non-English text.\\nFurthermore, multilinguality has been shown to be a part of possible emergent abilities of large\\nlanguage models (Wei et al., 2022b), so the performance is not entirely surprising. Overall, both\\ncommercial models fall signiﬁcantly short of the current state of the art. While ChatGPT is the\\nbetter performer, Cohere’s performance is especially surprising since it has been trained on almost\\nall of the evaluated languages15.\\n4.2\\nMACHINE TRANSLATION\\nResults are reported in table 2. ChatGPT has very poor performance on machine translation, ob-\\ntaining BLEU scores of less than 1.0 on all languages. This is very surprising given its good per-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='taining BLEU scores of less than 1.0 on all languages. This is very surprising given its good per-\\nformance on text classiﬁcation. Our results agree with concurrent work (Abott et al., 2023) which\\nﬁnds that GPT 3.5 obtains a BLEU score of 0 on Zulu to English translation. Our ﬁndings are\\nalso somewhat similar to (Jiao et al., 2023), which reports signiﬁcantly worse performance on Ro-\\nmanian, a relatively low-resource language, than on higher-resource languages like English and\\nGerman. While the BLEU scores are too low to draw conclusions from, ChatGPT seems to perform\\nbetter when translating into English than from it. This agrees with previous works (Belinkov et al.,\\n2017; Bugliarello et al., 2020) which show that it is harder to translate into morphologically rich\\nlanguages, like African ones, than morphologically poor ones like English. In general, our results\\nsuggest that ChatGPT is not good enough for translation involving African languages. It also sug-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='suggest that ChatGPT is not good enough for translation involving African languages. It also sug-\\ngests that ChatGPT performs better on sequence classiﬁcation tasks than it does on text generation\\ntasks for African languages.\\n5\\nERROR ANALYSIS\\nWe take a closer look at some errors made by the model on machine translation. Speciﬁcally, we\\nfocus on two languages - Yoruba and Nigerian Pidgin - because they are understood by the authors.\\nFor each language, we randomly select 3 samples and discuss their predictions.\\n5.1\\nYORUBA TRANSLATIONS\\nSamples are shown in table 4. Looking at sample 1, ChatGPT mistranslates “B´ı omi b´a gb´on´a\\nju b´ı ´o s.e ye. lo.” which means “When water becomes too hot” to “Water is poured into the con-\\ntainer”. Furthermore, the English to Yoruba translation is completely wrong and riddled with a lot\\nof misspellings and grammatical errors. In sample 3, ChatGPT gets the translations wrong and also'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='of misspellings and grammatical errors. In sample 3, ChatGPT gets the translations wrong and also\\ntransposes the words “ob`ınrin” (woman) and “ok`unrin” (man) in the translations. One notable ob-\\nservation across English to Yoruba translations is that ChatGPT does not always include diacritics\\nin its Yoruba predictions. Overall, ChatGPT does a really poor job in translating in either direc-\\ntion. The hallucinatory nature of the model predictions is evident, as all translations barely have any\\ncorrelation with the original sentences.\\n15https://txt.cohere.ai/multilingual/\\n5\\nAfricaNLP workshop at ICLR2022\\nTable 2: Machine Translation Results: We report the BLEU scores of the translations from ChatGPT.\\nWe also report the current state of the art result obtained from Adelani et al. (2022)\\nand NLLB Team et al. (2022). Best results per language are in bold.\\nTranslation Direction\\nChatGPT\\nCurrent SOTA\\nLug→Eng\\n0.16\\n30.9\\nEng→Lug\\n0.13\\n25.8\\nPcm→Eng\\n0.22\\n45.2\\nEng→Pcm\\n0.20\\n35.0\\nSwa→Eng\\n0.18\\n39.3'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Lug→Eng\\n0.16\\n30.9\\nEng→Lug\\n0.13\\n25.8\\nPcm→Eng\\n0.22\\n45.2\\nEng→Pcm\\n0.20\\n35.0\\nSwa→Eng\\n0.18\\n39.3\\nEng→Swa\\n0.15\\n30.7\\nYor→Eng\\n0.10\\n24.4\\nEng→Yor\\n0.12\\n14.4\\nZul→Eng\\n0.31\\n40.3\\nEng→Zul\\n0.26\\n22.9\\n5.2\\nNIGERIAN PIDGIN TRANSLATIONS\\nSamples are shown in table 3. Looking at the Nigerian Pidgin sentences, we can see the language’s\\nlinguistic similarity with English. Interestingly, while the ChatGPT predictions yield low BLEU\\nscores, they are somewhat semantically similar to the ground truth. However, there notable errors\\nmade across board. For example, focusing on the Nigerian Pidgin to English predictions in sample\\n2, there are tense errors. Also, the model seems to misunderstand what “numbers” refers to in the\\ninput text, as its prediction indicates it confuses it for the number of goals. Furthermore, across\\nall samples, the model seems to be poor at translating certain English words to Nigerian Pidgin\\nwords, such as “The” to “Di”, so it always retains the original English word. In general, while the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='words, such as “The” to “Di”, so it always retains the original English word. In general, while the\\npredictions in both directions for all samples have notable issues, they are more semantically similar\\nto the ground truth than the BLEU scores suggests. This highlights the drawbacks of automatic\\nmetrics based on N-gram overlap.\\n6\\nCONCLUSION\\nWe have presented a preliminary analysis of commercial language models on African languages.\\nJoshi et al. (2020) note that over 90% of the world’s 7000+ languages are under-studied by the NLP\\ncommunity. Despite the 2000+ spoken languages and over 1 billion people in Africa16, its languages\\nmake up a signiﬁcant portion of the under-studied languages (Blasi et al., 2022). While there have\\nbeen several efforts (∀et al., 2020; Ahia & Ogueji, 2020b; Adelani et al., 2021; Ogueji et al., 2021;\\nNLLB Team et al., 2022; Alabi et al., 2022; Dossou et al., 2022; Adebara et al., 2022) to close this'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='gap, there is still a lot of work to be done. This is even more pertinent given the rapid commercial\\nadoption of large scale language models. Our ﬁndings suggest that these models do not perform\\nwell on African languages. In particular, there seems to be performance disparity, depending on the\\ntask evaluated. Although our work reports what is, to the best of our knowledge, the ﬁrst evaluation\\nof commercial language models on African languages, we note that this only a preliminary study\\nthat needs to be further advanced. Future works could focus on more advanced prompting methods\\nsuch as chain-of-thought (Wei et al., 2022c) and pivot prompting (Jiao et al., 2023), evaluation of\\nmore test samples and a wider variety of tasks. While our ﬁnding may be impacted by the sampled\\n16https://en.wikipedia.org/wiki/Demographics_of_Africa\\n6\\nAfricaNLP workshop at ICLR2022\\nTable 3: Examples of Nigerian Pidgin translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nNigerian Pid-\\ngin Sentence'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Sample 1\\nSample 2\\nSample 3\\nNigerian Pid-\\ngin Sentence\\nCommission head, Simon\\nByabakama,\\nassure\\ndi\\nnation on top live TV\\nfor\\nThursday\\nevening\\nafta polls don close say\\nresult don dey enter for\\ndi national tally centre\\ndespite\\ndi\\nnationwide\\ninternet blackout\\nDi goal be give Eyimba\\nsome hope as dem kontinu\\nto press for plunty nomba\\nto secure a point at least\\nNa im inauguartion be\\ndi ﬁrst time wey elected\\nleaders dey handova give\\neach oda for Niger history\\nfor over 60 years wey dem\\ndon get independence, but\\ndi attack from jihadist and\\nsome kind plan to do coup\\ndon spoil di celebrate.\\nEnglish Sen-\\ntence\\nCommission head, Simon\\nByabakama, assured the\\nnation on live TV on\\nThursday\\nevening\\nafter\\npolls closed that results\\nwere arriving at the na-\\ntional tally centre despite\\nthe\\nnationwide\\ninternet\\nblackout.\\nThe goal gave Enyimba\\nsome hope as they contin-\\nued to press in numbers to\\nat least secure a point\\nHis inauguration marks\\nthe\\nﬁrst\\nhandover\\nbe-\\ntween\\nelected\\nleaders\\nin Niger’s 60-year post-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='His inauguration marks\\nthe\\nﬁrst\\nhandover\\nbe-\\ntween\\nelected\\nleaders\\nin Niger’s 60-year post-\\nindependence\\nhistory,\\nbut jihadist attacks and\\nan\\nalleged\\nattempted\\ncoup have overshadowed\\nceremonies.\\nChatGPT\\nTranslation\\nPcm→Eng\\nCommission head, Simon\\nByabakama, assured the\\nnation on live TV on\\nThursday\\nevening\\nafter\\nthe polls had closed that\\nthe results were entering\\nthe national tally center\\ndespite the nationwide in-\\nternet blackout.\\nThe goal was to give Ey-\\nimba some hope as they\\ncontinue to press for a suf-\\nﬁcient number of goals to\\nsecure at least one point.\\nThe inauguration marked\\nthe\\nﬁrst\\ntime\\nin\\nover\\n60 years of independence\\nthat elected leaders have\\nhanded\\npower\\nto\\neach\\nother in Niger’s history,\\nbut attacks by jihadists\\nand plans for a coup have\\ndisrupted the celebrations\\nChatGPT\\nTranslation\\nEng→Pcm\\nSimon Byabakama wey\\ndey head the Commis-\\nsion, e talk for TV on\\nThursday night after elec-\\ntion close say the result\\ndon dey reach the centre\\nwhere dem dey count the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tion close say the result\\ndon dey reach the centre\\nwhere dem dey count the\\nresult even though inter-\\nnet all over the place dey\\ncut.\\nThe goal give Enyimba\\nsome hope as dem still\\ndey press wey full force to\\nﬁt get at least one point.\\nThe day wey dem swear\\nam\\nfor\\nofﬁce,\\nna\\nthe\\nﬁrst time wey leader wey\\nget vote go hand over to\\nanother leader since 60\\nyears after independence\\nfor Niger but the attacks\\nwey the bad people wey\\ndey carry gun dey do, and\\nthe way wey dem try put\\neye for the power no gree\\nam to happen make e no\\ndey sweet for the day.\\ntest data, the use of the BLEU automatic metric (Callison-Burch et al., 2006; Mathur et al., 2020;\\nFreitag et al., 2020), prompting template and prompting examples, it nonetheless presents a call-to-\\naction to ensure African languages are well represented in the age of commercial large language\\nmodels.\\n7\\nAfricaNLP workshop at ICLR2022\\nTable 4: Examples of Yoruba translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nYoruba Sen-\\ntence'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Table 4: Examples of Yoruba translation using ChatGPT\\nSample 1\\nSample 2\\nSample 3\\nYoruba Sen-\\ntence\\nB´ı omi b´a gb´on´a ju b´ı ´o s.e\\nye. lo. (t`ab´ı b´ı ´o b´a tut`u j`u)\\n`awo.n iy`un y´o`o l`e ew`e omi\\n— t´ı y´o`o s´ı p`ad´an`u o.wo. t`o\\n´o ´n ﬁo`unje. n`u ´un.\\nK´ı ´o t´o de `e´er´oo `ago. n´a`a,\\nerin os. `u me.e.f`a n´a`a ti lu\\nok`un.\\n`Ike.l`u t´ı ´o ko.\\nlu `awo.n\\nob`ınrin wo.ny´ı (`ati `awo.n\\no.k`unrin\\nkan)\\nror`o\\nb´ı\\ne.ranko e.h`ann`a.\\nEnglish Sen-\\ntence\\nWhen water becomes too\\nhot (or too cold) the corals\\nexpel the algae — and\\nwith it, its main source of\\nfood.\\nBefore his arrival at the\\ncamp, the six-month-old\\nwas snared in a wire trap.\\nThe\\nattacks\\non\\nthese\\nwomen (and some men)\\nare vicious and inhuman.\\nChatGPT\\nTranslation\\nYor→Eng\\nWater is poured into the\\ncontainer (or it is ﬁlled)\\nuntil the container is full -\\nwhen it overﬂows, the ex-\\ncess water is poured out.\\nIf you do not pay attention\\nto your work, the work of\\nothers will be affected.\\nThe\\ntradition\\nrequires'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='to your work, the work of\\nothers will be affected.\\nThe\\ntradition\\nrequires\\nmen to cover their heads\\n(and sometimes women\\ntoo) in public places.\\nChatGPT\\nTranslation\\nEng→Yor\\nTi omi ba n mu ki i fe.e.\\n(tabi ki i fe.e.) awo.n corals\\nni wo.n ﬁomi omi po. - ati\\nni ito.ju re., iru ibe.re. ti a n\\npa.\\nBayi o ti gba lo. si ibeere,\\no.mo. to.lo.ti si igba ni a ti\\ndara ju o.nu.\\n`Id´am`o\\nge.ge.\\nb´ı\\ni\\n`awo.\\nn\\no.mo.-`om`o-w´e\\n(`ati\\nn´ı\\nk`ok`or`o)\\nn`ıy´ın\\nni\\n`aj`ın`a\\n`ıw´ej`u `ıto.lo.mo. w´aj`u.\\nREFERENCES\\nJade\\nAbott,\\nBonaventure\\nDossou,\\nand\\nRooweither\\nMbuya.\\nCom-\\nparing\\nafrica-centric\\nmodels\\nto\\nopenai’s\\ngpt3.5,\\n2023.\\nURL\\nhttps://lelapa.ai/comparing-africa-centric-models-to-openais-gpt3-5-2/.\\nIfe Adebara, AbdelRahim Elmadany, Muhammad Abdul-Mageed, and Alcides Alcoba In-\\nciarte.\\nSerengeti:\\nMassively multilingual language models for africa, 2022.\\nURL\\nhttps://arxiv.org/abs/2212.10785.\\nDavid Adelani, Jesujoba Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='David Adelani, Jesujoba Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter,\\nDietrich Klakow, Peter Nabende, Ernie Chang, Tajuddeen Gwadabe, Freshia Sackey, Bonaven-\\nture F. P. Dossou, Chris Emezue, Colin Leong, Michael Beukman, Shamsuddeen Muhammad,\\nGuyo Jarso, Oreen Yousuf, Andre Niyongabo Rubungo, Gilles Hacheme, Eric Peter Wairagala,\\nMuhammad Umair Nasir, Benjamin Ajibade, Tunde Ajayi, Yvonne Gitau, Jade Abbott, Mo-\\nhamed Ahmed, Millicent Ochieng, Anuoluwapo Aremu, Perez Ogayo, Jonathan Mukiibi, Fa-\\ntoumata Ouoba Kabore, Godson Kalipe, Derguene Mbaye, Allahsera Auguste Tapo, Victoire\\nMemdjokam Koagne, Edwin Munkoh-Buabeng, Valencia Wagner, Idris Abdulmumin, Ayodele\\nAwokoya, Happy Buzaaba, Blessing Sibanda, Andiswa Bukula, and Sam Manthalu. A few thou-\\nsand translations go a long way! leveraging pre-trained models for African news translation. In\\nProceedings of the 2022 Conference of the North American Chapter of the Association for Com-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Proceedings of the 2022 Conference of the North American Chapter of the Association for Com-\\nputational Linguistics: Human Language Technologies, pp. 3053–3070, Seattle, United States,\\nJuly 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.223.\\nURL https://aclanthology.org/2022.naacl-main.223.\\nDavid Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D’souza, Julia Kreutzer, Constan-\\ntine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, Stephen\\nMayhew, Israel Abebe Azime, Shamsuddeen H. Muhammad, Chris Chinenye Emezue, Joyce\\n8\\nAfricaNLP workshop at ICLR2022\\nNakatumba-Nabende, Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau, Derguene Mbaye, Je-\\nsujoba Alabi, Seid Muhie Yimam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani, Rubungo An-\\ndre Niyongabo, Jonathan Mukiibi, Verrah Otiende, Iroro Orife, Davis David, Samba Ngom,\\nTosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chia-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki, Emmanuel Anebi, Chia-\\nmaka Chukwuneke, Nkiruka Odu, Eric Peter Wairagala, Samuel Oyerinde, Clemencia Siro, To-\\nbius Saul Bateesa, Temilola Oloyede, Yvonne Wambui, Victor Akinode, Deborah Nabagereka,\\nMaurice Katusiime, Ayodele Awokoya, Mouhamadane MBOUP, Dibora Gebreyohannes, Henok\\nTilaye, Kelechi Nwaike, Degaga Wolde, Abdoulaye Faye, Blessing Sibanda, Orevaoghene\\nAhia, Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo,\\nAdewale Akinfaderin, Tendai Marengereke, and Salomey Osei.\\nMasakhaNER: Named En-\\ntity Recognition for African Languages.\\nTransactions of the Association for Computational\\nLinguistics, 9:1116–1131, 10 2021.\\nISSN 2307-387X.\\ndoi: 10.1162/tacl a 00416.\\nURL\\nhttps://doi.org/10.1162/tacl_a_00416.\\nOrevaoghene Ahia and Kelechi Ogueji. Towards supervised and unsupervised neural machine trans-\\nlation baselines for nigerian pidgin. ArXiv, abs/2003.12660, 2020a.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='lation baselines for nigerian pidgin. ArXiv, abs/2003.12660, 2020a.\\nOrevaoghene Ahia and Kelechi Ogueji.\\nTowards supervised and unsupervised neural ma-\\nchine translation baselines for nigerian pidgin.\\nCoRR, abs/2003.12660, 2020b.\\nURL\\nhttps://arxiv.org/abs/2003.12660.\\nJesujoba O. Alabi, David Ifeoluwa Adelani, Marius Mosbach, and Dietrich Klakow.\\nAdapting\\npre-trained language models to African languages via multilingual adaptive ﬁne-tuning. In Pro-\\nceedings of the 29th International Conference on Computational Linguistics, pp. 4336–4349,\\nGyeongju, Republic of Korea, October 2022. International Committee on Computational Lin-\\nguistics. URL https://aclanthology.org/2022.coling-1.382.\\nMikel Artetxe, Gorka Labaka, and Eneko Agirre.\\nTranslation artifacts in cross-lingual\\ntransfer learning.\\nIn Proceedings of the 2020 Conference on Empirical Methods in\\nNatural Language Processing (EMNLP), pp. 7674–7684, Online, November 2020. Asso-\\nciation for Computational Linguistics.\\ndoi:'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ciation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2020.emnlp-main.618.\\nURL\\nhttps://aclanthology.org/2020.emnlp-main.618.\\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do neural\\nmachine translation models learn about morphology? In Proceedings of the 55th Annual Meeting\\nof the Association for Computational Linguistics (Volume 1: Long Papers), pp. 861–872, Vancou-\\nver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1080.\\nURL https://aclanthology.org/P17-1080.\\nDamian Blasi, Antonios Anastasopoulos, and Graham Neubig. Systematic inequalities in language\\ntechnology performance across the world’s languages. In Proceedings of the 60th Annual Meet-\\ning of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5486–5505,\\nDublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.\\nacl-long.376. URL https://aclanthology.org/2022.acl-long.376.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='acl-long.376. URL https://aclanthology.org/2022.acl-long.376.\\nTerra Blevins and Luke Zettlemoyer. Language contamination helps explain the cross-lingual capa-\\nbilities of english pretrained models, 2022. URL https://arxiv.org/abs/2204.08110.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-\\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\\nAriel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,\\nDaniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz\\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei.\\nLanguage models are few-shot learners.\\nIn\\nH. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural\\nInformation Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL\\nhttps://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Pap\\nEmanuele Bugliarello, Sabrina J. Mielke, Antonios Anastasopoulos, Ryan Cotterell, and Naoaki\\nOkazaki. It’s easier to translate out of English than into it: Measuring neural translation difﬁculty\\nby cross-mutual information. In Proceedings of the 58th Annual Meeting of the Association for\\n9\\nAfricaNLP workshop at ICLR2022\\nComputational Linguistics, pp. 1640–1649, Online, July 2020. Association for Computational\\nLinguistics. URL https://www.aclweb.org/anthology/2020.acl-main.149.\\nChris Callison-Burch, Miles Osborne, and Philipp Koehn. Re-evaluating the role of Bleu in ma-\\nchine translation research. In 11th Conference of the European Chapter of the Association for\\nComputational Linguistics, pp. 249–256, Trento, Italy, April 2006. Association for Computa-\\ntional Linguistics. URL https://aclanthology.org/E06-1032.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tional Linguistics. URL https://aclanthology.org/E06-1032.\\nErnie Chang,\\nDavid Ifeoluwa Adelani,\\nXiaoyu Shen,\\nand Vera Demberg.\\nUnsuper-\\nvised pidgin text generation by pivoting english data and self-training, 2020.\\nURL\\nhttps://arxiv.org/abs/2003.08272.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\\nZoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\\nMoreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\\nEck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\\n2022. URL https://arxiv.org/abs/2204.02311.\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan\\nLi, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu,\\nZhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pel-\\nlat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao,\\nYanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,\\nAdam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-ﬁnetuned language\\nmodels, 2022. URL https://arxiv.org/abs/2210.11416.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\\nBERT: Pre-training of\\ndeep bidirectional transformers for language understanding. In Proceedings of the 2019 Con-\\nference of the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Min-\\nnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL\\nhttps://www.aclweb.org/anthology/N19-1423.\\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun,\\nJingjing Xu, Lei Li, and Zhifang Sui.\\nA survey for in-context learning, 2023.\\nURL\\nhttps://arxiv.org/abs/2301.00234.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='A survey for in-context learning, 2023.\\nURL\\nhttps://arxiv.org/abs/2301.00234.\\nBonaventure F. P. Dossou, Atnafu Lambebo Tonja, Oreen Yousuf, Salomey Osei, Abigail Oppong,\\nIyanuoluwa Shode, Oluwabusayo Olufunke Awoyomi, and Chris Chinenye Emezue. Afrolm: A\\nself-active learning-based multilingual pretrained language model for 23 african languages, 2022.\\nNicholas Faraclas. Nigerian pidgin english: morphology and syntax. Varieties of English: Africa,\\nSouth and Southeast Asia, 4:340–367, 2008.\\n∀, Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa, Tajudeen Kolawole,\\nTaiwo Fagbohungbe, Solomon Oluwole Akinola, Shamsuddee Hassan Muhammad, Salomon\\nKabongo, Salomey Osei, et al. Participatory research for low-resourced machine translation:\\nA case study in african languages. Findings of EMNLP, 2020.\\nMarkus Freitag, David Grangier, and Isaac Caswell.\\nBLEU might be guilty but refer-\\nences are not innocent.\\nIn Proceedings of the 2020 Conference on Empirical Meth-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ences are not innocent.\\nIn Proceedings of the 2020 Conference on Empirical Meth-\\nods in Natural Language Processing (EMNLP), pp. 61–71, Online, November 2020. As-\\nsociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2020.emnlp-main.5.\\nURL\\nhttps://aclanthology.org/2020.emnlp-main.5.\\n10\\nAfricaNLP workshop at ICLR2022\\nLeo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason\\nPhang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile:\\nAn 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.\\nMichael A. Hedderich, David Adelani, Dawei Zhu, Jesujoba Alabi, Udia Markus, and Diet-\\nrich Klakow.\\nTransfer learning and distant supervision for multilingual transformer mod-\\nels: A study on African languages.\\nIn Proceedings of the 2020 Conference on Empirical\\nMethods in Natural Language Processing (EMNLP), pp. 2580–2591, Online, November 2020.\\nAssociation for Computational Linguistics.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Association for Computational Linguistics.\\ndoi: 10.18653/v1/2020.emnlp-main.204.\\nURL\\nhttps://www.aclweb.org/anthology/2020.emnlp-main.204.\\nJeremy Howard and Sebastian Ruder.\\nUniversal language model ﬁne-tuning for text clas-\\nsiﬁcation.\\nIn Proceedings of the 56th Annual Meeting of the Association for Compu-\\ntational Linguistics (Volume 1:\\nLong Papers), pp. 328–339, Melbourne, Australia, July\\n2018. Association for Computational Linguistics.\\ndoi:\\n10.18653/v1/P18-1031.\\nURL\\nhttps://aclanthology.org/P18-1031.\\nWenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. Is chatgpt a good\\ntranslator? a preliminary study, 2023. URL https://arxiv.org/abs/2301.08745.\\nPratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. The state and\\nfate of linguistic diversity and inclusion in the NLP world.\\nIn Proceedings of the 58th An-\\nnual Meeting of the Association for Computational Linguistics, pp. 6282–6293, Online, July'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='nual Meeting of the Association for Computational Linguistics, pp. 6282–6293, Online, July\\n2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.560. URL\\nhttps://aclanthology.org/2020.acl-main.560.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\\nmodels. CoRR, abs/2001.08361, 2020. URL https://arxiv.org/abs/2001.08361.\\nHugo Laurenc¸on, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral,\\nTeven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo Gonz´alez Ponferrada, Huu\\nNguyen, J¨org Frohberg, Mario ˇSaˇsko, Quentin Lhoest, Angelina McMillan-Major, G´erard\\nDupont, Stella Biderman, Anna Rogers, Loubna Ben allal, Francesco De Toni, Giada Pis-\\ntilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='tilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa,\\nPaulo Villegas, Tristan Thrush, Shayne Longpre, Sebastian Nagel, Leon Weber, Manuel Romero\\nMu˜noz, Jian Zhu, Daniel Van Strien, Zaid Alyafeai, Khalid Almubarak, Vu Minh Chien, Itziar\\nGonzalez-Dios, Aitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz Suarez, Aaron Gokaslan, Shamik\\nBose, David Ifeoluwa Adelani, Long Phan, Hieu Tran, Ian Yu, Suhas Pai, Jenny Chim, Vio-\\nlette Lepercq, Suzana Ilic, Margaret Mitchell, Sasha Luccioni, and Yacine Jernite.\\nThe big-\\nscience ROOTS corpus: A 1.6TB composite multilingual dataset.\\nIn Thirty-sixth Confer-\\nence on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL\\nhttps://openreview.net/forum?id=UoEw6KigkUn.\\nHeather\\nLent,\\nEmanuele\\nBugliarello,\\nMiryam\\nde\\nLhoneux,\\nChen\\nQiu,\\nand\\nAnders\\nSøgaard.\\nOn language models for creoles.\\nIn Proceedings of the 25th Confer-\\nence on Computational Natural Language Learning, pp. 58–71, Online, November 2021.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='ence on Computational Natural Language Learning, pp. 58–71, Online, November 2021.\\nAssociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2021.conll-1.5.\\nURL\\nhttps://aclanthology.org/2021.conll-1.5.\\nHeather Lent, Kelechi Ogueji, Miryam de Lhoneux, Orevaoghene Ahia, and Anders Søgaard. What\\na creole wants, what a creole needs. In Proceedings of the Thirteenth Language Resources and\\nEvaluation Conference, pp. 6439–6449, Marseille, France, June 2022. European Language Re-\\nsources Association. URL https://aclanthology.org/2022.lrec-1.691.\\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle\\nOtt, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh\\nKoura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva,\\nMona T. Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual language\\nmodels. CoRR, abs/2112.10668, 2021. URL https://arxiv.org/abs/2112.10668.\\n11'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='models. CoRR, abs/2112.10668, 2021. URL https://arxiv.org/abs/2112.10668.\\n11\\nAfricaNLP workshop at ICLR2022\\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen.\\nWhat makes good in-context examples for GPT-3?\\nIn Proceedings of Deep Learn-\\ning Inside Out (DeeLIO 2022):\\nThe 3rd Workshop on Knowledge Extraction and Inte-\\ngration for Deep Learning Architectures, pp. 100–114, Dublin, Ireland and Online, May\\n2022. Association for Computational Linguistics.\\ndoi: 10.18653/v1/2022.deelio-1.10.\\nURL\\nhttps://aclanthology.org/2022.deelio-1.10.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pre-\\ntraining approach. arXiv preprint, abs/1907.11692, 2019.\\nNitika Mathur, Timothy Baldwin, and Trevor Cohn. Tangled up in BLEU: Reevaluating the eval-\\nuation of automatic machine translation evaluation metrics.\\nIn Proceedings of the 58th An-'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='uation of automatic machine translation evaluation metrics.\\nIn Proceedings of the 58th An-\\nnual Meeting of the Association for Computational Linguistics, pp. 4984–4997, Online, July\\n2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.448. URL\\nhttps://aclanthology.org/2020.acl-main.448.\\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le\\nScao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir\\nRadev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,\\nEdward Raff, and Colin Raffel. Crosslingual generalization through multitask ﬁnetuning, 2022.\\nURL https://arxiv.org/abs/2211.01786.\\nNLLB Team, Marta R. Costa-juss`a, James Cross, Onur C¸ elebi, Maha Elbayad, Kenneth Heaﬁeld,\\nKevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler\\nWang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez,\\nPrangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shan-\\nnon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela\\nFan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm´an, Philipp Koehn, Alexandre Mourachko,\\nChristophe Ropers, Saﬁyyah Saleem, Holger Schwenk, and Jeff Wang. No language left behind:\\nScaling human-centered machine translation, 2022.\\nKelechi Ogueji and Orevaoghene Ahia. PidginUNMT: Unsupervised Neural Machine Translation\\nfrom West African Pidgin to English. ArXiv, abs/1912.03444, 2019.\\nKelechi Ogueji, Yuxin Zhu, and Jimmy Lin.\\nSmall data?\\nNo Problem!\\nexploring the vi-\\nability of pretrained multilingual language models for low-resourced languages.\\nIn Pro-\\nceedings of the 1st Workshop on Multilingual Representation Learning, pp. 116–126, Punta'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='In Pro-\\nceedings of the 1st Workshop on Multilingual Representation Learning, pp. 116–126, Punta\\nCana, Dominican Republic, November 2021. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2021.mrl-1.11.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,\\nChong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob\\nHilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul\\nChristiano, Jan Leike, and Ryan Lowe.\\nTraining language models to follow instruc-\\ntions with human feedback.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and\\nKyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.\\nURL\\nhttps://openreview.net/forum?id=TG8KACxEON.\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.\\nBleu: a method for auto-\\nmatic evaluation of machine translation.\\nIn Proceedings of the 40th Annual Meeting of the'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='matic evaluation of machine translation.\\nIn Proceedings of the 40th Annual Meeting of the\\nAssociation for Computational Linguistics, pp. 311–318, Philadelphia, Pennsylvania, USA,\\nJuly 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL\\nhttps://aclanthology.org/P02-1040.\\nEdoardo Maria Ponti, Goran Glavaˇs, Olga Majewska, Qianchu Liu, Ivan Vuli´c, and Anna Korhonen.\\nXCOPA: A multilingual dataset for causal commonsense reasoning. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing (EMNLP), pp. 2362–2376,\\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.185. URL https://aclanthology.org/2020.emnlp-main.185.\\n12\\nAfricaNLP workshop at ICLR2022\\nMatt\\nPost.\\nA\\ncall\\nfor\\nclarity\\nin\\nreporting\\nBLEU\\nscores.\\nIn\\nProceedings\\nof\\nthe Third Conference on Machine Translation:\\nResearch Papers,\\npp. 186–191, Bel-\\ngium,\\nBrussels,\\nOctober\\n2018.\\nAssociation\\nfor\\nComputational\\nLinguistics.\\nURL'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='pp. 186–191, Bel-\\ngium,\\nBrussels,\\nOctober\\n2018.\\nAssociation\\nfor\\nComputational\\nLinguistics.\\nURL\\nhttps://www.aclweb.org/anthology/W18-6319.\\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\\nmodels are unsupervised multitask learners, 2019.\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer.\\nJournal of Machine Learning Research, 21(140):1–67, 2020.\\nURL\\nhttp://jmlr.org/papers/v21/20-074.html.\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\\nChafﬁn, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker,\\nShanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De-\\nbajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,\\nZheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,\\nAbheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le\\nScao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. Multitask prompted\\ntraining enables zero-shot task generalization. In International Conference on Learning Repre-\\nsentations, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.\\nTimo Schick and Hinrich Sch¨utze. It’s not just size that matters: Small language models are also few-\\nshot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Asso-\\nciation for Computational Linguistics: Human Language Technologies, pp. 2339–2352, Online,\\nJune 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.185.\\nURL https://aclanthology.org/2021.naacl-main.185.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='URL https://aclanthology.org/2021.naacl-main.185.\\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi,\\nHyung Won Chung,\\nYi Tay,\\nSebastian Ruder, Denny Zhou, Dipanjan Das,\\nand Ja-\\nson Wei.\\nLanguage models are multilingual chain-of-thought reasoners, 2022.\\nURL\\nhttps://arxiv.org/abs/2210.03057.\\nTianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. Black-box tuning for\\nlanguage-model-as-a-service. In Proceedings of ICML, 2022.\\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester,\\nNan Du, Andrew M. Dai, and Quoc V Le.\\nFinetuned language models are zero-\\nshot learners.\\nIn International Conference on Learning Representations, 2022a.\\nURL\\nhttps://openreview.net/forum?id=gEZrGCozdqR.\\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani\\nYogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto,\\nOriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.\\nEmergent abilities of large lan-\\nguage models. Transactions on Machine Learning Research, 2022b. ISSN 2835-8856. URL\\nhttps://openreview.net/forum?id=yzkSU5zdwD. Survey Certiﬁcation.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H.\\nChi,\\nQuoc V Le,\\nand Denny Zhou.\\nChain of thought prompting elicits reasoning\\nin large language models.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and\\nKyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022c.\\nURL\\nhttps://openreview.net/forum?id=_VjQlMeSB_J.\\nGuillaume\\nWenzek,\\nMarie-Anne\\nLachaux,\\nAlexis\\nConneau,\\nVishrav\\nChaudhary,\\nFran-\\ncisco Guzm´an, Armand Joulin, and Edouard Grave.\\nCCNet:\\nExtracting high qual-\\nity monolingual datasets from web crawl data.\\nIn Proceedings of the 12th Lan-\\nguage Resources and Evaluation Conference, pp. 4003–4012, Marseille, France, May\\n2020. European Language Resources Association.\\nISBN 979-10-95546-34-4.'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='2020. European Language Resources Association.\\nISBN 979-10-95546-34-4.\\nURL\\nhttps://www.aclweb.org/anthology/2020.lrec-1.494.\\n13\\nAfricaNLP workshop at ICLR2022\\nGenta Indra Winata, Andrea Madotto, Zhaojiang Lin, Rosanne Liu, Jason Yosinski, and Pascale\\nFung. Language models are few-shot multilingual learners. In Proceedings of the 1st Workshop\\non Multilingual Representation Learning, pp. 1–15, Punta Cana, Dominican Republic, Novem-\\nber 2021. Association for Computational Linguistics.\\ndoi: 10.18653/v1/2021.mrl-1.1. URL\\nhttps://aclanthology.org/2021.mrl-1.1.\\nXinyan Velocity Yu, Akari Asai, Trina Chatterjee, Junjie Hu, and Eunsol Choi. Beyond counting\\ndatasets: A survey of multilingual dataset construction and necessary resources. In Findings of\\nEMNLP, 2022.\\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan\\nXu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang'),\n",
              " Document(metadata={'Published': '2023-05-11', 'Title': 'How Good are Commercial Large Language Models on African Languages?', 'Authors': 'Jessica Ojo, Kelechi Ogueji', 'Summary': 'Recent advancements in Natural Language Processing (NLP) has led to the\\nproliferation of large pretrained language models. These models have been shown\\nto yield good performance, using in-context learning, even on unseen tasks and\\nlanguages. They have also been exposed as commercial APIs as a form of\\nlanguage-model-as-a-service, with great adoption. However, their performance on\\nAfrican languages is largely unknown. We present a preliminary analysis of\\ncommercial large language models on two tasks (machine translation and text\\nclassification) across eight African languages, spanning different language\\nfamilies and geographical areas. Our results suggest that commercial language\\nmodels produce below-par performance on African languages. We also find that\\nthey perform better on text classification than machine translation. In\\ngeneral, our findings present a call-to-action to ensure African languages are\\nwell represented in commercial large language models, given their growing\\npopularity.'}, page_content='Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang\\nChen, Peng Zhang, Yuxiao Dong, and Jie Tang. Glm-130b: An open bilingual pre-trained model.\\narXiv preprint arXiv:2210.02414, 2022.\\nBiao Zhang, Barry Haddow, and Alexandra Birch. Prompting large language model for machine\\ntranslation: A case study, 2023. URL https://arxiv.org/abs/2301.07069.\\nMengjie Zhao and Hinrich Sch¨utze.\\nDiscrete and soft prompting for multilingual models.\\nIn\\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Process-\\ning, pp. 8547–8555, Online and Punta Cana, Dominican Republic, November 2021. As-\\nsociation for Computational Linguistics.\\ndoi:\\n10.18653/v1/2021.emnlp-main.672.\\nURL\\nhttps://aclanthology.org/2021.emnlp-main.672.\\n14'),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content=\"Here's a summary of the provided image in three detailed paragraphs:\"),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The image diagrams the architecture of a Transformer, a neural network architecture commonly used in natural language processing.  The core of the architecture is built around the concept of \"multi-head attention,\" which is visually represented as a central block.  This block takes input embeddings (processed representations of words or sub-words) and applies a series of linear transformations to create query (Q), key (K), and value (V) matrices. These matrices are then fed into a \"scaled dot-product attention\" mechanism,  a detailed breakdown of which is shown separately. The multi-head attention mechanism allows the model to weigh the importance of different parts of the input sequence when processing each word, capturing relationships between words across the sequence.  The output of the multi-head attention is then passed through an \"add & norm\" layer (representing addition and normalization operations) followed by a feed-forward network.'),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The diagram illustrates two parallel pathways, one for standard multi-head attention and another for \"masked multi-head attention.\"  The masked version is crucial for tasks like sequence generation (e.g., machine translation or text generation) where the model should not \"peek\" at future tokens during the prediction process. This masking is explicitly shown in the detailed \"scaled dot-product attention\" section. The positional encoding blocks highlight that the model incorporates information about the order of words in the input sequence. This is essential because unlike recurrent neural networks, the Transformer architecture processes the entire input sequence in parallel, lacking inherent sequential information. The final output embeddings are produced after passing through multiple layers of these attention and feed-forward mechanisms.'),\n",
              " Document(metadata={'source': 'https://datasciencedojo.com/wp-content/uploads/Architecture-of-transformer-models-1030x579.jpg'}, page_content='The detailed view of the \"scaled dot-product attention\" mechanism further clarifies the inner workings of the attention process. It shows how the query, key, and value matrices are used to calculate attention weights through matrix multiplication (MatMul), softmax normalization, optional masking, and scaling.  This entire process determines which parts of the input sequence are most relevant to each word, allowing the model to focus on important contextual information. The final matrix multiplication with the value matrix combines the attention weights with the values to produce a weighted representation of the input sequence. This weighted representation then feeds back into the main Transformer architecture, contributing to the overall processing and output.'),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a\"),\n",
              " Document(metadata={'language_code': 'en_us', 'audio_url': 'https://cdn.assemblyai.com/upload/1bfc74e3-2be2-4d6d-85e0-cee0d2c818d1', 'punctuate': True, 'format_text': True, 'dual_channel': None, 'multichannel': None, 'audio_channels': None, 'webhook_url': None, 'webhook_auth_header_name': None, 'webhook_auth_header_value': None, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speakers_expected': None, 'content_safety': False, 'content_safety_confidence': None, 'iab_categories': False, 'custom_spelling': None, 'disfluencies': False, 'sentiment_analysis': False, 'auto_chapters': False, 'entity_detection': False, 'summarization': False, 'summary_model': None, 'summary_type': None, 'auto_highlights': False, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'speech_threshold': None, 'speech_model': None, 'id': '5e1e1f0f-a1d2-42cb-9477-5ecd0f3a7f76', 'status': <TranscriptStatus.completed: 'completed'>, 'error': None, 'text': \"Large language models and AI assistants are taking the consumer world by storm. But what happens when you try to bring these large language models into business, into enterprise? Well, we have three issues, three issues that we have to overcome. Let's walk through them. Number one issue is this lack of domain knowledge. Remember, these large language models have been trained on publicly available data sets. That means that they don't have Access to your SOPs, your standard operating procedures, they don't have access to your own ip, your own records. So they really can't answer a lot of questions and have that response be tailored to your particular business. And you lose a lot of performance and effectiveness because of that. Issue number two is around hallucinations. These models will give you responses. They look really credible, but they're way off. And if you run with them, then you might have a problem. And then issue number three, which is becoming a little bit of a less of an issue with search. But we have training data cutoff dates. So for a while there you had chatgpt missing months of training data because it hadn't been updated in a while and in part because it takes a lot of compute to train these models. So you have these three issues that are keeping you from getting a lot of performance from your LLMs as you bring them in house. So let's talk about one pattern that has emerged as being particularly helpful here, and that is RAG retrieval, augmented generation. You may have heard this term toss around, but let's talk about what's going on here. First, let me give you some context. Here's what happens when you send a prompt to your standard AI assistant. So you have your. Your prompt goes into the AI assistant, it generates a response and then gives it back to you. Right? In a RAG implementation, you're adding an additional step here. Before that prompt goes into the AI assistant, we have a search that hits a corpus of data. Now this is going to be your data, your own documents and other relevant information that you want to make available to the AI assistant. There's going to be a retrieval that's done and that context is going to be added in addition to your original prompt. And so the large language model is going to get your prompt and then also any relevant information that that was found during this process. And then everything else proceeds the same way. The AI system will process that and generate typically a better response for you as a user. So the retrieval here is this retrieval function here where we're grabbing the information. The augmented part here is we're augmenting that to the original prompt and the generation here is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\", 'words': [{'text': 'Large', 'start': 240, 'end': 448, 'confidence': 0.99654, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 464, 'end': 776, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 808, 'end': 1016, 'confidence': 0.99879, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 1048, 'end': 1192, 'confidence': 0.91664, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 1216, 'end': 1496, 'confidence': 0.99191, 'speaker': None, 'channel': None}, {'text': 'assistants', 'start': 1528, 'end': 2200, 'confidence': 0.83958, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 2280, 'end': 2520, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'taking', 'start': 2560, 'end': 2856, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 2928, 'end': 3208, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'consumer', 'start': 3264, 'end': 3960, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'world', 'start': 4040, 'end': 4376, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'by', 'start': 4448, 'end': 4824, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'storm.', 'start': 4912, 'end': 5800, 'confidence': 0.99589, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 5960, 'end': 6280, 'confidence': 0.99517, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 6320, 'end': 6520, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 6560, 'end': 6856, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 6888, 'end': 7032, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 7056, 'end': 7192, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'try', 'start': 7216, 'end': 7400, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 7440, 'end': 7592, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 7616, 'end': 7896, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 7968, 'end': 8152, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 8176, 'end': 8408, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 8464, 'end': 8824, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 8872, 'end': 9304, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 9352, 'end': 9656, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'business,', 'start': 9728, 'end': 10152, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 10256, 'end': 10664, 'confidence': 0.54956, 'speaker': None, 'channel': None}, {'text': 'enterprise?', 'start': 10752, 'end': 11496, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'Well,', 'start': 11608, 'end': 11832, 'confidence': 0.85014, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 11856, 'end': 11992, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 12016, 'end': 12296, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 12368, 'end': 12696, 'confidence': 0.9522, 'speaker': None, 'channel': None}, {'text': 'issues,', 'start': 12768, 'end': 13432, 'confidence': 0.99097, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 13616, 'end': 13960, 'confidence': 0.98567, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 14000, 'end': 14536, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 14688, 'end': 15048, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 15104, 'end': 15320, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 15360, 'end': 15560, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 15600, 'end': 15752, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'overcome.', 'start': 15776, 'end': 16344, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': \"Let's\", 'start': 16392, 'end': 16616, 'confidence': 0.77592, 'speaker': None, 'channel': None}, {'text': 'walk', 'start': 16648, 'end': 16840, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': 'through', 'start': 16880, 'end': 17080, 'confidence': 0.99726, 'speaker': None, 'channel': None}, {'text': 'them.', 'start': 17120, 'end': 17464, 'confidence': 0.9914, 'speaker': None, 'channel': None}, {'text': 'Number', 'start': 17552, 'end': 17800, 'confidence': 0.97466, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 17840, 'end': 18040, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 18080, 'end': 18568, 'confidence': 0.99624, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 18704, 'end': 19048, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 19104, 'end': 19416, 'confidence': 0.99831, 'speaker': None, 'channel': None}, {'text': 'lack', 'start': 19488, 'end': 19960, 'confidence': 0.94781, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 20040, 'end': 20616, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'domain', 'start': 20768, 'end': 21672, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 21816, 'end': 22600, 'confidence': 0.87386, 'speaker': None, 'channel': None}, {'text': 'Remember,', 'start': 22760, 'end': 23192, 'confidence': 0.85016, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 23256, 'end': 23528, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 23584, 'end': 23800, 'confidence': 0.99781, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 23840, 'end': 24216, 'confidence': 0.87562, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 24248, 'end': 24504, 'confidence': 0.53107, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 24552, 'end': 24712, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 24736, 'end': 24872, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'trained', 'start': 24896, 'end': 25144, 'confidence': 0.96243, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 25192, 'end': 25400, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'publicly', 'start': 25440, 'end': 25944, 'confidence': 0.97609, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 25992, 'end': 26344, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 26432, 'end': 26680, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'sets.', 'start': 26720, 'end': 27064, 'confidence': 0.92469, 'speaker': None, 'channel': None}, {'text': 'That', 'start': 27112, 'end': 27272, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'means', 'start': 27296, 'end': 27480, 'confidence': 0.9982, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 27520, 'end': 27672, 'confidence': 0.9872, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 27696, 'end': 27832, 'confidence': 0.99926, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 27856, 'end': 28056, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 28088, 'end': 28280, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'Access', 'start': 28320, 'end': 28616, 'confidence': 0.99859, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 28688, 'end': 29250, 'confidence': 0.99093, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 29400, 'end': 29758, 'confidence': 0.99267, 'speaker': None, 'channel': None}, {'text': 'SOPs,', 'start': 29814, 'end': 30334, 'confidence': 0.89151, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 30382, 'end': 30542, 'confidence': 0.96304, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 30566, 'end': 30846, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'operating', 'start': 30878, 'end': 31262, 'confidence': 0.63512, 'speaker': None, 'channel': None}, {'text': 'procedures,', 'start': 31326, 'end': 32046, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 32158, 'end': 32382, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': \"don't\", 'start': 32406, 'end': 32606, 'confidence': 0.9977, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 32638, 'end': 32782, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'access', 'start': 32806, 'end': 33086, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 33158, 'end': 33342, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 33366, 'end': 33502, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 33526, 'end': 33710, 'confidence': 0.99756, 'speaker': None, 'channel': None}, {'text': 'ip,', 'start': 33750, 'end': 34110, 'confidence': 0.81378, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 34190, 'end': 34382, 'confidence': 0.99392, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 34406, 'end': 34590, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'records.', 'start': 34630, 'end': 35374, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 35502, 'end': 35742, 'confidence': 0.99239, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 35766, 'end': 35950, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 35990, 'end': 36238, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': \"can't\", 'start': 36294, 'end': 36574, 'confidence': 0.9967, 'speaker': None, 'channel': None}, {'text': 'answer', 'start': 36622, 'end': 37054, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 37102, 'end': 37358, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 37414, 'end': 37582, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 37606, 'end': 37838, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'questions', 'start': 37894, 'end': 38334, 'confidence': 0.99873, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 38382, 'end': 38638, 'confidence': 0.67912, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 38694, 'end': 38910, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 38950, 'end': 39294, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 39382, 'end': 39806, 'confidence': 0.99261, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 39838, 'end': 39982, 'confidence': 0.99732, 'speaker': None, 'channel': None}, {'text': 'tailored', 'start': 40006, 'end': 40286, 'confidence': 0.9928, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 40318, 'end': 40462, 'confidence': 0.99842, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 40486, 'end': 40622, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'particular', 'start': 40646, 'end': 40926, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 40998, 'end': 41326, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 41398, 'end': 41726, 'confidence': 0.9878, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 41798, 'end': 41982, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'lose', 'start': 42006, 'end': 42302, 'confidence': 0.99593, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 42366, 'end': 42542, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 42566, 'end': 42702, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 42726, 'end': 42862, 'confidence': 0.99875, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 42886, 'end': 43214, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 43302, 'end': 43502, 'confidence': 0.99142, 'speaker': None, 'channel': None}, {'text': 'effectiveness', 'start': 43526, 'end': 44142, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 44206, 'end': 44430, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 44470, 'end': 44622, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'that.', 'start': 44646, 'end': 45022, 'confidence': 0.99677, 'speaker': None, 'channel': None}, {'text': 'Issue', 'start': 45126, 'end': 45486, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 45558, 'end': 45790, 'confidence': 0.99098, 'speaker': None, 'channel': None}, {'text': 'two', 'start': 45830, 'end': 46030, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 46070, 'end': 46270, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'around', 'start': 46310, 'end': 46558, 'confidence': 0.99851, 'speaker': None, 'channel': None}, {'text': 'hallucinations.', 'start': 46614, 'end': 47646, 'confidence': 0.98398, 'speaker': None, 'channel': None}, {'text': 'These', 'start': 47758, 'end': 48030, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'models', 'start': 48070, 'end': 48366, 'confidence': 0.99799, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 48398, 'end': 48542, 'confidence': 0.99816, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 48566, 'end': 48750, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 48790, 'end': 48990, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'responses.', 'start': 49030, 'end': 49582, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'They', 'start': 49646, 'end': 49870, 'confidence': 0.99913, 'speaker': None, 'channel': None}, {'text': 'look', 'start': 49910, 'end': 50206, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'really', 'start': 50278, 'end': 50558, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'credible,', 'start': 50614, 'end': 50974, 'confidence': 0.99936, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 51022, 'end': 51182, 'confidence': 0.99972, 'speaker': None, 'channel': None}, {'text': \"they're\", 'start': 51206, 'end': 51454, 'confidence': 0.92674, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 51502, 'end': 51710, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'off.', 'start': 51750, 'end': 51950, 'confidence': 0.998, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 51990, 'end': 52142, 'confidence': 0.9933, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 52166, 'end': 52254, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 52262, 'end': 52430, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'run', 'start': 52470, 'end': 52670, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 52710, 'end': 52862, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'them,', 'start': 52886, 'end': 53070, 'confidence': 0.99864, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 53110, 'end': 53214, 'confidence': 0.99107, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 53222, 'end': 53438, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'might', 'start': 53494, 'end': 53662, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 53686, 'end': 53822, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 53846, 'end': 54030, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'problem.', 'start': 54070, 'end': 54558, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 54694, 'end': 54942, 'confidence': 0.97108, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 54966, 'end': 55102, 'confidence': 0.61985, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 55126, 'end': 55358, 'confidence': 0.9991, 'speaker': None, 'channel': None}, {'text': 'number', 'start': 55414, 'end': 55726, 'confidence': 0.99224, 'speaker': None, 'channel': None}, {'text': 'three,', 'start': 55798, 'end': 56030, 'confidence': 0.99929, 'speaker': None, 'channel': None}, {'text': 'which', 'start': 56070, 'end': 56222, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 56246, 'end': 56430, 'confidence': 0.8425, 'speaker': None, 'channel': None}, {'text': 'becoming', 'start': 56470, 'end': 56782, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 56846, 'end': 56974, 'confidence': 0.99887, 'speaker': None, 'channel': None}, {'text': 'little', 'start': 56982, 'end': 57102, 'confidence': 0.99835, 'speaker': None, 'channel': None}, {'text': 'bit', 'start': 57126, 'end': 57214, 'confidence': 0.99398, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57222, 'end': 57342, 'confidence': 0.90287, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 57366, 'end': 57598, 'confidence': 0.90365, 'speaker': None, 'channel': None}, {'text': 'less', 'start': 57654, 'end': 57822, 'confidence': 0.99863, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 57846, 'end': 57982, 'confidence': 0.99669, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 58006, 'end': 58094, 'confidence': 0.99907, 'speaker': None, 'channel': None}, {'text': 'issue', 'start': 58102, 'end': 58270, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 58310, 'end': 58510, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'search.', 'start': 58550, 'end': 59120, 'confidence': 0.97262, 'speaker': None, 'channel': None}, {'text': 'But', 'start': 59270, 'end': 59628, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 59684, 'end': 59900, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 59940, 'end': 60236, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 60308, 'end': 60652, 'confidence': 0.93588, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 60716, 'end': 61036, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'cutoff', 'start': 61108, 'end': 61564, 'confidence': 0.67416, 'speaker': None, 'channel': None}, {'text': 'dates.', 'start': 61612, 'end': 62028, 'confidence': 0.90929, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 62124, 'end': 62284, 'confidence': 0.98489, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 62292, 'end': 62412, 'confidence': 0.99934, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 62436, 'end': 62572, 'confidence': 0.96572, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 62596, 'end': 62828, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'there', 'start': 62884, 'end': 63244, 'confidence': 0.99507, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 63332, 'end': 63532, 'confidence': 0.99865, 'speaker': None, 'channel': None}, {'text': 'had', 'start': 63556, 'end': 63692, 'confidence': 0.98363, 'speaker': None, 'channel': None}, {'text': 'chatgpt', 'start': 63716, 'end': 64540, 'confidence': 0.7027, 'speaker': None, 'channel': None}, {'text': 'missing', 'start': 64700, 'end': 65356, 'confidence': 0.52967, 'speaker': None, 'channel': None}, {'text': 'months', 'start': 65468, 'end': 65884, 'confidence': 0.99858, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 65972, 'end': 66268, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'training', 'start': 66324, 'end': 66604, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'data', 'start': 66652, 'end': 66908, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 66964, 'end': 67228, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 67284, 'end': 67452, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': \"hadn't\", 'start': 67476, 'end': 67708, 'confidence': 0.99567, 'speaker': None, 'channel': None}, {'text': 'been', 'start': 67724, 'end': 67900, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'updated', 'start': 67940, 'end': 68380, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 68460, 'end': 68652, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 68676, 'end': 68812, 'confidence': 0.99028, 'speaker': None, 'channel': None}, {'text': 'while', 'start': 68836, 'end': 68972, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 68996, 'end': 69132, 'confidence': 0.98259, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 69156, 'end': 69292, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 69316, 'end': 69452, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'because', 'start': 69476, 'end': 69612, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 69636, 'end': 69772, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'takes', 'start': 69796, 'end': 69996, 'confidence': 0.99916, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 70028, 'end': 70124, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 70132, 'end': 70204, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 70212, 'end': 70332, 'confidence': 0.99906, 'speaker': None, 'channel': None}, {'text': 'compute', 'start': 70356, 'end': 70636, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 70668, 'end': 70812, 'confidence': 0.99705, 'speaker': None, 'channel': None}, {'text': 'train', 'start': 70836, 'end': 71228, 'confidence': 0.88696, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 71324, 'end': 71628, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'models.', 'start': 71684, 'end': 72140, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 72220, 'end': 72412, 'confidence': 0.9952, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 72436, 'end': 72524, 'confidence': 0.98723, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 72532, 'end': 72652, 'confidence': 0.9988, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 72676, 'end': 72860, 'confidence': 0.99944, 'speaker': None, 'channel': None}, {'text': 'three', 'start': 72900, 'end': 73100, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'issues', 'start': 73140, 'end': 73580, 'confidence': 0.99689, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 73700, 'end': 73932, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 73956, 'end': 74092, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'keeping', 'start': 74116, 'end': 74444, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 74492, 'end': 74700, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 74740, 'end': 74940, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'getting', 'start': 74980, 'end': 75372, 'confidence': 0.9993, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 75476, 'end': 75788, 'confidence': 0.9994, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 75844, 'end': 76204, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 76292, 'end': 76636, 'confidence': 0.99877, 'speaker': None, 'channel': None}, {'text': 'performance', 'start': 76708, 'end': 77180, 'confidence': 0.99961, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 77300, 'end': 77580, 'confidence': 0.99973, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 77620, 'end': 77820, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 77860, 'end': 78364, 'confidence': 0.9317, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 78412, 'end': 78572, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 78596, 'end': 78732, 'confidence': 0.99871, 'speaker': None, 'channel': None}, {'text': 'bring', 'start': 78756, 'end': 78940, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 78980, 'end': 79180, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 79220, 'end': 79420, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'house.', 'start': 79460, 'end': 79708, 'confidence': 0.97514, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 79764, 'end': 79884, 'confidence': 0.97828, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 79892, 'end': 80076, 'confidence': 0.91209, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 80108, 'end': 80252, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 80276, 'end': 80652, 'confidence': 0.99282, 'speaker': None, 'channel': None}, {'text': 'one', 'start': 80756, 'end': 81068, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'pattern', 'start': 81124, 'end': 81484, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 81532, 'end': 81836, 'confidence': 0.99866, 'speaker': None, 'channel': None}, {'text': 'has', 'start': 81908, 'end': 82332, 'confidence': 0.9945, 'speaker': None, 'channel': None}, {'text': 'emerged', 'start': 82436, 'end': 83036, 'confidence': 0.99078, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 83068, 'end': 83260, 'confidence': 0.99755, 'speaker': None, 'channel': None}, {'text': 'being', 'start': 83300, 'end': 83500, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'particularly', 'start': 83540, 'end': 83964, 'confidence': 0.99895, 'speaker': None, 'channel': None}, {'text': 'helpful', 'start': 84012, 'end': 84316, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'here,', 'start': 84348, 'end': 84894, 'confidence': 0.98289, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 85052, 'end': 85322, 'confidence': 0.98498, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 85346, 'end': 85482, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 85506, 'end': 85786, 'confidence': 0.99891, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 85858, 'end': 86506, 'confidence': 0.77335, 'speaker': None, 'channel': None}, {'text': 'retrieval,', 'start': 86618, 'end': 87546, 'confidence': 0.98123, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 87658, 'end': 88538, 'confidence': 0.53074, 'speaker': None, 'channel': None}, {'text': 'generation.', 'start': 88634, 'end': 89290, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'You', 'start': 89370, 'end': 89562, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'may', 'start': 89586, 'end': 89674, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 89682, 'end': 89802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'heard', 'start': 89826, 'end': 90026, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 90058, 'end': 90250, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'term', 'start': 90290, 'end': 90538, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'toss', 'start': 90594, 'end': 90874, 'confidence': 0.99748, 'speaker': None, 'channel': None}, {'text': 'around,', 'start': 90922, 'end': 91178, 'confidence': 0.99271, 'speaker': None, 'channel': None}, {'text': 'but', 'start': 91234, 'end': 91402, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': \"let's\", 'start': 91426, 'end': 91626, 'confidence': 0.99912, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 91658, 'end': 91802, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'about', 'start': 91826, 'end': 92154, 'confidence': 0.99563, 'speaker': None, 'channel': None}, {'text': \"what's\", 'start': 92242, 'end': 92538, 'confidence': 0.99939, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 92554, 'end': 92682, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'on', 'start': 92706, 'end': 92938, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 92994, 'end': 93258, 'confidence': 0.99897, 'speaker': None, 'channel': None}, {'text': 'First,', 'start': 93314, 'end': 93722, 'confidence': 0.99867, 'speaker': None, 'channel': None}, {'text': 'let', 'start': 93826, 'end': 94042, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'me', 'start': 94066, 'end': 94154, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'give', 'start': 94162, 'end': 94282, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 94306, 'end': 94442, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'some', 'start': 94466, 'end': 94602, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'context.', 'start': 94626, 'end': 95178, 'confidence': 0.70344, 'speaker': None, 'channel': None}, {'text': \"Here's\", 'start': 95274, 'end': 95626, 'confidence': 0.99802, 'speaker': None, 'channel': None}, {'text': 'what', 'start': 95658, 'end': 95850, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'happens', 'start': 95890, 'end': 96266, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'when', 'start': 96298, 'end': 96586, 'confidence': 0.75484, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 96658, 'end': 96938, 'confidence': 0.99982, 'speaker': None, 'channel': None}, {'text': 'send', 'start': 96994, 'end': 97322, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 97386, 'end': 97658, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 97714, 'end': 98218, 'confidence': 0.99724, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 98314, 'end': 98522, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 98546, 'end': 98730, 'confidence': 0.9992, 'speaker': None, 'channel': None}, {'text': 'standard', 'start': 98770, 'end': 99114, 'confidence': 0.9985, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 99162, 'end': 99594, 'confidence': 0.99334, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 99642, 'end': 100394, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 100522, 'end': 100858, 'confidence': 0.98196, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 100914, 'end': 101082, 'confidence': 0.99964, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 101106, 'end': 101386, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'your.', 'start': 101458, 'end': 101978, 'confidence': 0.9397, 'speaker': None, 'channel': None}, {'text': 'Your', 'start': 102114, 'end': 102410, 'confidence': 0.98402, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 102450, 'end': 102890, 'confidence': 0.98313, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 102970, 'end': 103226, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 103258, 'end': 103402, 'confidence': 0.99919, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 103426, 'end': 103562, 'confidence': 0.99794, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 103586, 'end': 103786, 'confidence': 0.64565, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 103818, 'end': 104410, 'confidence': 0.99771, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 104490, 'end': 104682, 'confidence': 0.99358, 'speaker': None, 'channel': None}, {'text': 'generates', 'start': 104706, 'end': 105114, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 105162, 'end': 105274, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 105282, 'end': 105626, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 105658, 'end': 105802, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 105826, 'end': 105962, 'confidence': 0.99529, 'speaker': None, 'channel': None}, {'text': 'gives', 'start': 105986, 'end': 106218, 'confidence': 0.99578, 'speaker': None, 'channel': None}, {'text': 'it', 'start': 106234, 'end': 106410, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'back', 'start': 106450, 'end': 106650, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 106690, 'end': 106794, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'you.', 'start': 106802, 'end': 106970, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'Right?', 'start': 107010, 'end': 107546, 'confidence': 0.99317, 'speaker': None, 'channel': None}, {'text': 'In', 'start': 107698, 'end': 108106, 'confidence': 0.99157, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 108178, 'end': 108410, 'confidence': 0.99803, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 108450, 'end': 108810, 'confidence': 0.76677, 'speaker': None, 'channel': None}, {'text': 'implementation,', 'start': 108890, 'end': 109562, 'confidence': 0.96229, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 109626, 'end': 109866, 'confidence': 0.99715, 'speaker': None, 'channel': None}, {'text': 'adding', 'start': 109898, 'end': 110282, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': 'an', 'start': 110346, 'end': 110570, 'confidence': 0.95987, 'speaker': None, 'channel': None}, {'text': 'additional', 'start': 110610, 'end': 111242, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'step', 'start': 111306, 'end': 111626, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'here.', 'start': 111698, 'end': 112212, 'confidence': 0.99461, 'speaker': None, 'channel': None}, {'text': 'Before', 'start': 112346, 'end': 112832, 'confidence': 0.99811, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 112936, 'end': 113248, 'confidence': 0.99491, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 113304, 'end': 113808, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'goes', 'start': 113904, 'end': 114480, 'confidence': 0.99764, 'speaker': None, 'channel': None}, {'text': 'into', 'start': 114560, 'end': 114848, 'confidence': 0.99927, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 114904, 'end': 115120, 'confidence': 0.99885, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 115160, 'end': 115504, 'confidence': 0.51374, 'speaker': None, 'channel': None}, {'text': 'assistant,', 'start': 115552, 'end': 116304, 'confidence': 0.95104, 'speaker': None, 'channel': None}, {'text': 'we', 'start': 116432, 'end': 116672, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 116696, 'end': 116928, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 116984, 'end': 117248, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'search', 'start': 117304, 'end': 117728, 'confidence': 0.98986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 117824, 'end': 118080, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'hits', 'start': 118120, 'end': 118464, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 118512, 'end': 118672, 'confidence': 0.99922, 'speaker': None, 'channel': None}, {'text': 'corpus', 'start': 118696, 'end': 119104, 'confidence': 0.98243, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 119152, 'end': 119264, 'confidence': 0.9984, 'speaker': None, 'channel': None}, {'text': 'data.', 'start': 119272, 'end': 119632, 'confidence': 0.99849, 'speaker': None, 'channel': None}, {'text': 'Now', 'start': 119736, 'end': 119952, 'confidence': 0.99222, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 119976, 'end': 120112, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 120136, 'end': 120272, 'confidence': 0.99754, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 120296, 'end': 120384, 'confidence': 0.89301, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 120392, 'end': 120464, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 120472, 'end': 120592, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 120616, 'end': 120800, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'data,', 'start': 120840, 'end': 121136, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 121208, 'end': 121440, 'confidence': 0.999, 'speaker': None, 'channel': None}, {'text': 'own', 'start': 121480, 'end': 121680, 'confidence': 0.99943, 'speaker': None, 'channel': None}, {'text': 'documents', 'start': 121720, 'end': 122512, 'confidence': 0.98816, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 122656, 'end': 123344, 'confidence': 0.9881, 'speaker': None, 'channel': None}, {'text': 'other', 'start': 123512, 'end': 123888, 'confidence': 0.99373, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 123944, 'end': 124528, 'confidence': 0.99962, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 124624, 'end': 125024, 'confidence': 0.99997, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 125112, 'end': 125312, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 125336, 'end': 125472, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 125496, 'end': 125632, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 125656, 'end': 125744, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'make', 'start': 125752, 'end': 125872, 'confidence': 0.99993, 'speaker': None, 'channel': None}, {'text': 'available', 'start': 125896, 'end': 126224, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 126312, 'end': 126464, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 126472, 'end': 126592, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 126616, 'end': 126896, 'confidence': 0.8474, 'speaker': None, 'channel': None}, {'text': 'assistant.', 'start': 126928, 'end': 127520, 'confidence': 0.99676, 'speaker': None, 'channel': None}, {'text': \"There's\", 'start': 127600, 'end': 127888, 'confidence': 0.985, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 127904, 'end': 127984, 'confidence': 0.99442, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 127992, 'end': 128160, 'confidence': 0.94329, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 128200, 'end': 128496, 'confidence': 0.99967, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 128568, 'end': 128848, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 128904, 'end': 129584, 'confidence': 0.96697, 'speaker': None, 'channel': None}, {'text': \"that's\", 'start': 129632, 'end': 129936, 'confidence': 0.99703, 'speaker': None, 'channel': None}, {'text': 'done', 'start': 129968, 'end': 130304, 'confidence': 0.99821, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 130392, 'end': 130592, 'confidence': 0.98417, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 130616, 'end': 130848, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'context', 'start': 130904, 'end': 131392, 'confidence': 0.95338, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 131456, 'end': 131632, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 131656, 'end': 131840, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 131880, 'end': 131984, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'be', 'start': 131992, 'end': 132208, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'added', 'start': 132264, 'end': 132816, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'in', 'start': 132968, 'end': 133280, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'addition', 'start': 133320, 'end': 133616, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 133688, 'end': 133920, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 133960, 'end': 134160, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 134200, 'end': 134752, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'prompt.', 'start': 134816, 'end': 135328, 'confidence': 0.99169, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 135424, 'end': 135728, 'confidence': 0.95505, 'speaker': None, 'channel': None}, {'text': 'so', 'start': 135784, 'end': 136096, 'confidence': 0.99938, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 136168, 'end': 136352, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'large', 'start': 136376, 'end': 136560, 'confidence': 0.99812, 'speaker': None, 'channel': None}, {'text': 'language', 'start': 136600, 'end': 136944, 'confidence': 0.95847, 'speaker': None, 'channel': None}, {'text': 'model', 'start': 136992, 'end': 137376, 'confidence': 0.99965, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 137408, 'end': 137552, 'confidence': 0.99949, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 137576, 'end': 137712, 'confidence': 0.99827, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 137736, 'end': 137824, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'get', 'start': 137832, 'end': 137952, 'confidence': 0.9986, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 137976, 'end': 138160, 'confidence': 0.99948, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 138200, 'end': 138544, 'confidence': 0.99894, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 138592, 'end': 138704, 'confidence': 0.99819, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 138712, 'end': 138880, 'confidence': 0.99716, 'speaker': None, 'channel': None}, {'text': 'also', 'start': 138920, 'end': 139264, 'confidence': 0.99954, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 139352, 'end': 139600, 'confidence': 0.99914, 'speaker': None, 'channel': None}, {'text': 'relevant', 'start': 139640, 'end': 140064, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'information', 'start': 140112, 'end': 140608, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 140744, 'end': 141022, 'confidence': 0.38553, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 141056, 'end': 141298, 'confidence': 0.99536, 'speaker': None, 'channel': None}, {'text': 'was', 'start': 141354, 'end': 141762, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'found', 'start': 141866, 'end': 142226, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'during', 'start': 142298, 'end': 142722, 'confidence': 0.99985, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 142826, 'end': 143138, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'process.', 'start': 143194, 'end': 143746, 'confidence': 0.99862, 'speaker': None, 'channel': None}, {'text': 'And', 'start': 143898, 'end': 144162, 'confidence': 0.98826, 'speaker': None, 'channel': None}, {'text': 'then', 'start': 144186, 'end': 144514, 'confidence': 0.9983, 'speaker': None, 'channel': None}, {'text': 'everything', 'start': 144602, 'end': 144898, 'confidence': 0.99917, 'speaker': None, 'channel': None}, {'text': 'else', 'start': 144954, 'end': 145186, 'confidence': 0.9997, 'speaker': None, 'channel': None}, {'text': 'proceeds', 'start': 145218, 'end': 145746, 'confidence': 0.81719, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 145778, 'end': 145922, 'confidence': 0.99945, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 145946, 'end': 146130, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'way.', 'start': 146170, 'end': 146322, 'confidence': 0.99931, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 146346, 'end': 146482, 'confidence': 0.99937, 'speaker': None, 'channel': None}, {'text': 'AI', 'start': 146506, 'end': 146786, 'confidence': 0.93205, 'speaker': None, 'channel': None}, {'text': 'system', 'start': 146818, 'end': 147106, 'confidence': 0.56095, 'speaker': None, 'channel': None}, {'text': 'will', 'start': 147178, 'end': 147362, 'confidence': 0.99839, 'speaker': None, 'channel': None}, {'text': 'process', 'start': 147386, 'end': 147618, 'confidence': 0.99958, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 147674, 'end': 148034, 'confidence': 0.9741, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 148122, 'end': 148418, 'confidence': 0.99911, 'speaker': None, 'channel': None}, {'text': 'generate', 'start': 148474, 'end': 148962, 'confidence': 0.99905, 'speaker': None, 'channel': None}, {'text': 'typically', 'start': 149026, 'end': 149394, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 149442, 'end': 149650, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'better', 'start': 149690, 'end': 149938, 'confidence': 0.99987, 'speaker': None, 'channel': None}, {'text': 'response', 'start': 149994, 'end': 150434, 'confidence': 0.75474, 'speaker': None, 'channel': None}, {'text': 'for', 'start': 150482, 'end': 150690, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 150730, 'end': 151026, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 151098, 'end': 151378, 'confidence': 0.99923, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 151434, 'end': 151698, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'user.', 'start': 151754, 'end': 152562, 'confidence': 0.99782, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 152706, 'end': 152962, 'confidence': 0.99749, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 152986, 'end': 153122, 'confidence': 0.99952, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 153146, 'end': 153666, 'confidence': 0.91142, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 153698, 'end': 153986, 'confidence': 0.9995, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 154058, 'end': 154338, 'confidence': 0.99941, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 154394, 'end': 154610, 'confidence': 0.99915, 'speaker': None, 'channel': None}, {'text': 'retrieval', 'start': 154650, 'end': 155186, 'confidence': 0.95684, 'speaker': None, 'channel': None}, {'text': 'function', 'start': 155218, 'end': 155506, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 155538, 'end': 155778, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'where', 'start': 155834, 'end': 156002, 'confidence': 0.9853, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 156026, 'end': 156226, 'confidence': 0.53037, 'speaker': None, 'channel': None}, {'text': 'grabbing', 'start': 156258, 'end': 156818, 'confidence': 0.99696, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 156914, 'end': 157074, 'confidence': 0.99853, 'speaker': None, 'channel': None}, {'text': 'information.', 'start': 157082, 'end': 157394, 'confidence': 0.99924, 'speaker': None, 'channel': None}, {'text': 'The', 'start': 157482, 'end': 157730, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'augmented', 'start': 157770, 'end': 158386, 'confidence': 0.98869, 'speaker': None, 'channel': None}, {'text': 'part', 'start': 158418, 'end': 158610, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 158650, 'end': 158850, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 158890, 'end': 159042, 'confidence': 0.99869, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 159066, 'end': 159266, 'confidence': 0.98866, 'speaker': None, 'channel': None}, {'text': 'augmenting', 'start': 159298, 'end': 159826, 'confidence': 0.99323, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 159858, 'end': 160002, 'confidence': 0.99798, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 160026, 'end': 160114, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 160122, 'end': 160194, 'confidence': 0.9998, 'speaker': None, 'channel': None}, {'text': 'original', 'start': 160202, 'end': 160562, 'confidence': 0.9976, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 160626, 'end': 160962, 'confidence': 0.72399, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 161026, 'end': 161250, 'confidence': 0.59248, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 161290, 'end': 161442, 'confidence': 0.99956, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 161466, 'end': 161874, 'confidence': 0.99918, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 161922, 'end': 162082, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 162106, 'end': 162242, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 162266, 'end': 162354, 'confidence': 0.99953, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 162362, 'end': 162546, 'confidence': 0.9947, 'speaker': None, 'channel': None}, {'text': 'generation', 'start': 162578, 'end': 163186, 'confidence': 0.70973, 'speaker': None, 'channel': None}, {'text': 'generating', 'start': 163298, 'end': 163986, 'confidence': 0.99562, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 164098, 'end': 164322, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'same', 'start': 164346, 'end': 164530, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'prompt', 'start': 164570, 'end': 164786, 'confidence': 0.99625, 'speaker': None, 'channel': None}, {'text': 'here', 'start': 164818, 'end': 165058, 'confidence': 0.99757, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 165114, 'end': 165282, 'confidence': 0.99969, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 165306, 'end': 165490, 'confidence': 0.99947, 'speaker': None, 'channel': None}, {'text': 'LLM.', 'start': 165530, 'end': 166280, 'confidence': 0.92993, 'speaker': None, 'channel': None}, {'text': 'It', 'start': 166410, 'end': 166652, 'confidence': 0.98598, 'speaker': None, 'channel': None}, {'text': 'turns', 'start': 166676, 'end': 166908, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'out', 'start': 166924, 'end': 167052, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 167076, 'end': 167212, 'confidence': 0.99892, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 167236, 'end': 167372, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'is', 'start': 167396, 'end': 167580, 'confidence': 0.99946, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 167620, 'end': 167964, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'robust,', 'start': 168052, 'end': 168844, 'confidence': 0.87242, 'speaker': None, 'channel': None}, {'text': 'efficient', 'start': 168972, 'end': 169612, 'confidence': 0.9238, 'speaker': None, 'channel': None}, {'text': 'way', 'start': 169676, 'end': 170044, 'confidence': 0.99989, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 170132, 'end': 170428, 'confidence': 0.99959, 'speaker': None, 'channel': None}, {'text': 'tackle', 'start': 170484, 'end': 171116, 'confidence': 0.99742, 'speaker': None, 'channel': None}, {'text': 'these', 'start': 171228, 'end': 171500, 'confidence': 0.99903, 'speaker': None, 'channel': None}, {'text': 'problems', 'start': 171540, 'end': 171868, 'confidence': 0.99951, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 171884, 'end': 172012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': \"we're\", 'start': 172036, 'end': 172236, 'confidence': 0.98818, 'speaker': None, 'channel': None}, {'text': 'seeing', 'start': 172268, 'end': 172476, 'confidence': 0.99286, 'speaker': None, 'channel': None}, {'text': 'with', 'start': 172508, 'end': 172700, 'confidence': 0.99968, 'speaker': None, 'channel': None}, {'text': 'LLMs', 'start': 172740, 'end': 173244, 'confidence': 0.91888, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 173292, 'end': 173452, 'confidence': 0.64282, 'speaker': None, 'channel': None}, {'text': 'industry', 'start': 173476, 'end': 173996, 'confidence': 0.99828, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 174148, 'end': 174556, 'confidence': 0.99779, 'speaker': None, 'channel': None}, {'text': 'business.', 'start': 174628, 'end': 175196, 'confidence': 0.99822, 'speaker': None, 'channel': None}, {'text': 'So', 'start': 175348, 'end': 175564, 'confidence': 0.99535, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 175572, 'end': 175692, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'hope', 'start': 175716, 'end': 175948, 'confidence': 0.99984, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 176004, 'end': 176172, 'confidence': 0.99881, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 176196, 'end': 176332, 'confidence': 0.99928, 'speaker': None, 'channel': None}, {'text': 'helps', 'start': 176356, 'end': 176684, 'confidence': 0.99932, 'speaker': None, 'channel': None}, {'text': 'explain', 'start': 176732, 'end': 177260, 'confidence': 0.99942, 'speaker': None, 'channel': None}, {'text': 'the', 'start': 177340, 'end': 177676, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'RAG', 'start': 177748, 'end': 178268, 'confidence': 0.9594, 'speaker': None, 'channel': None}, {'text': 'framework.', 'start': 178364, 'end': 178892, 'confidence': 0.99665, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 178956, 'end': 179132, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 179156, 'end': 179244, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'have', 'start': 179252, 'end': 179372, 'confidence': 0.99983, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 179396, 'end': 179580, 'confidence': 0.99971, 'speaker': None, 'channel': None}, {'text': 'questions,', 'start': 179620, 'end': 180172, 'confidence': 0.99957, 'speaker': None, 'channel': None}, {'text': 'any', 'start': 180236, 'end': 180460, 'confidence': 0.99753, 'speaker': None, 'channel': None}, {'text': 'comments', 'start': 180500, 'end': 180796, 'confidence': 0.99908, 'speaker': None, 'channel': None}, {'text': 'if', 'start': 180868, 'end': 181052, 'confidence': 0.99977, 'speaker': None, 'channel': None}, {'text': 'I', 'start': 181076, 'end': 181212, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': 'missed', 'start': 181236, 'end': 181516, 'confidence': 0.73098, 'speaker': None, 'channel': None}, {'text': 'anything,', 'start': 181548, 'end': 182108, 'confidence': 0.73069, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 182204, 'end': 182556, 'confidence': 0.99991, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 182628, 'end': 182876, 'confidence': 0.99963, 'speaker': None, 'channel': None}, {'text': 'them', 'start': 182908, 'end': 183052, 'confidence': 0.99788, 'speaker': None, 'channel': None}, {'text': 'below.', 'start': 183076, 'end': 183500, 'confidence': 0.99883, 'speaker': None, 'channel': None}, {'text': 'If', 'start': 183620, 'end': 183852, 'confidence': 0.99979, 'speaker': None, 'channel': None}, {'text': \"you're\", 'start': 183876, 'end': 184076, 'confidence': 0.97379, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 184108, 'end': 184204, 'confidence': 0.96876, 'speaker': None, 'channel': None}, {'text': 'practitioner', 'start': 184212, 'end': 184636, 'confidence': 0.99526, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 184668, 'end': 184764, 'confidence': 0.7334, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 184772, 'end': 184892, 'confidence': 0.98492, 'speaker': None, 'channel': None}, {'text': 'want', 'start': 184916, 'end': 185052, 'confidence': 0.77671, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185076, 'end': 185212, 'confidence': 0.99902, 'speaker': None, 'channel': None}, {'text': 'add', 'start': 185236, 'end': 185420, 'confidence': 0.99978, 'speaker': None, 'channel': None}, {'text': 'something', 'start': 185460, 'end': 185660, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 185700, 'end': 185852, 'confidence': 0.99901, 'speaker': None, 'channel': None}, {'text': 'this', 'start': 185876, 'end': 186012, 'confidence': 0.99955, 'speaker': None, 'channel': None}, {'text': 'conversation,', 'start': 186036, 'end': 186492, 'confidence': 0.99848, 'speaker': None, 'channel': None}, {'text': 'please', 'start': 186556, 'end': 186780, 'confidence': 0.99988, 'speaker': None, 'channel': None}, {'text': 'drop', 'start': 186820, 'end': 187036, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 187068, 'end': 187212, 'confidence': 0.99649, 'speaker': None, 'channel': None}, {'text': 'below', 'start': 187236, 'end': 187420, 'confidence': 0.99976, 'speaker': None, 'channel': None}, {'text': 'as', 'start': 187460, 'end': 187564, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'well.', 'start': 187572, 'end': 187692, 'confidence': 0.99896, 'speaker': None, 'channel': None}, {'text': 'There', 'start': 187716, 'end': 187804, 'confidence': 0.99776, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 187812, 'end': 187884, 'confidence': 0.99067, 'speaker': None, 'channel': None}, {'text': 'a', 'start': 187892, 'end': 187964, 'confidence': 0.99872, 'speaker': None, 'channel': None}, {'text': 'lot', 'start': 187972, 'end': 188044, 'confidence': 0.9999, 'speaker': None, 'channel': None}, {'text': 'of', 'start': 188052, 'end': 188124, 'confidence': 0.99834, 'speaker': None, 'channel': None}, {'text': 'people', 'start': 188132, 'end': 188252, 'confidence': 0.99992, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 188276, 'end': 188412, 'confidence': 0.99836, 'speaker': None, 'channel': None}, {'text': 'are', 'start': 188436, 'end': 188524, 'confidence': 0.99876, 'speaker': None, 'channel': None}, {'text': 'going', 'start': 188532, 'end': 188652, 'confidence': 0.90387, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 188676, 'end': 188764, 'confidence': 0.99904, 'speaker': None, 'channel': None}, {'text': 'watch', 'start': 188772, 'end': 188892, 'confidence': 0.99921, 'speaker': None, 'channel': None}, {'text': 'this,', 'start': 188916, 'end': 189148, 'confidence': 0.99878, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 189204, 'end': 189372, 'confidence': 0.99528, 'speaker': None, 'channel': None}, {'text': \"I'm\", 'start': 189396, 'end': 189548, 'confidence': 0.99925, 'speaker': None, 'channel': None}, {'text': 'sure', 'start': 189564, 'end': 189692, 'confidence': 0.99986, 'speaker': None, 'channel': None}, {'text': 'that', 'start': 189716, 'end': 189852, 'confidence': 0.99673, 'speaker': None, 'channel': None}, {'text': 'they', 'start': 189876, 'end': 190012, 'confidence': 0.9996, 'speaker': None, 'channel': None}, {'text': 'would', 'start': 190036, 'end': 190172, 'confidence': 0.99847, 'speaker': None, 'channel': None}, {'text': 'benefit', 'start': 190196, 'end': 190732, 'confidence': 0.99981, 'speaker': None, 'channel': None}, {'text': 'from', 'start': 190796, 'end': 191068, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 191124, 'end': 191340, 'confidence': 0.99975, 'speaker': None, 'channel': None}, {'text': 'expertise', 'start': 191380, 'end': 191884, 'confidence': 0.97094, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 191932, 'end': 192044, 'confidence': 0.99733, 'speaker': None, 'channel': None}, {'text': 'your', 'start': 192052, 'end': 192172, 'confidence': 0.99792, 'speaker': None, 'channel': None}, {'text': 'knowledge.', 'start': 192196, 'end': 192668, 'confidence': 0.99784, 'speaker': None, 'channel': None}, {'text': 'Thanks', 'start': 192764, 'end': 193084, 'confidence': 0.9973, 'speaker': None, 'channel': None}, {'text': 'and', 'start': 193132, 'end': 193436, 'confidence': 0.73072, 'speaker': None, 'channel': None}, {'text': 'talk', 'start': 193508, 'end': 193692, 'confidence': 0.99974, 'speaker': None, 'channel': None}, {'text': 'to', 'start': 193716, 'end': 193852, 'confidence': 0.99966, 'speaker': None, 'channel': None}, {'text': 'you', 'start': 193876, 'end': 193964, 'confidence': 0.9965, 'speaker': None, 'channel': None}, {'text': 'soon.', 'start': 193972, 'end': 194020, 'confidence': 0.99913, 'speaker': None, 'channel': None}], 'utterances': None, 'confidence': 0.9741621, 'audio_duration': 195, 'webhook_status_code': None, 'webhook_auth': False, 'summary': None, 'auto_highlights_result': None, 'content_safety_labels': None, 'iab_categories_result': None, 'chapters': None, 'sentiment_analysis_results': None, 'entities': None}, page_content=\"is that we're generation generating the same prompt here from the LLM. It turns out that this is a robust, efficient way to tackle these problems that we're seeing with LLMs and industry and business. So I hope that this helps explain the RAG framework. If you have any questions, any comments if I missed anything, please drop them below. If you're a practitioner and you want to add something to this conversation, please drop that below as well. There are a lot of people that are going to watch this, and I'm sure that they would benefit from your expertise and your knowledge. Thanks and talk to you soon.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')"
      ],
      "metadata": {
        "id": "g2iI4FvwubFw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"rag_llm\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_langchain_db\",\n",
        ")"
      ],
      "metadata": {
        "id": "OPUxQY6t0FEu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.from_documents(filter_complex_metadata(docs), embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCw7NtFK0UI2",
        "outputId": "35f76394-53d0-4d4a-dd40-98e04cc5e06b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7aacb0125660>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
        ")"
      ],
      "metadata": {
        "id": "WdJh3c590aK6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "\n",
        "runner = RunnableParallel(\n",
        "                {\"context\": retriever,\n",
        "                \"attribute_collection\": RunnablePassthrough()\n",
        "                }\n",
        "            )"
      ],
      "metadata": {
        "id": "9RwLBvAP6fK2"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    You are a knowledgeable expert in the field of Large Language Models (LLMs) with a focus on delivering accurate, professional, and context-aware responses. Use the provided context and question to craft a clear and concise answer in the specified language. Ensure your response is tailored to the given audience, considering technical accuracy and professional tone.\n",
        "\n",
        "    - **Context**: {context}\n",
        "    - **Question and Response Language**: {attribute_collection}\n",
        "\n",
        "    **Guidelines**:\n",
        "    1. Provide an accurate and professional response based on the given context.\n",
        "    2. If applicable, include relevant examples or technical details to enhance understanding.\n",
        "    3. Write the response in the specified language, maintaining clarity and professionalism.\n",
        "    4. Keep the tone neutral and the content informative.\n",
        "\n",
        "    **Output**:\n",
        "    A detailed, contextually relevant answer to the question in the specified language.\n",
        "    \"\"\",\n",
        "    input_variables=[\"attribute_collection\"]\n",
        ")"
      ],
      "metadata": {
        "id": "7Leg9mhh6w1E"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "model = GoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")"
      ],
      "metadata": {
        "id": "_Z-GIM2X8LTc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "chain = runner | prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "k17tA-878EqJ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is a Large Language Model?\"\n",
        "lang = \"en\"\n",
        "\n",
        "result = chain.invoke(\n",
        "    f\"\"\"\n",
        "    Question: {question}\n",
        "    Response Language: {lang}\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "JJtQmdeK8iF0"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "UMfrExdFBF8P",
        "outputId": "25ab52a7-dac4-4829-ef67-6fff3c8cb710"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A Large Language Model (LLM) is a type of artificial intelligence model, specifically a deep learning model, that is trained on a massive dataset of text and code. These models utilize neural networks with a large number of parameters (hence \"large\") to learn complex patterns and relationships within the data. This enables them to perform a wide range of natural language processing (NLP) tasks, such as:\\n\\n*   **Text Generation:** Creating human-quality text, including articles, stories, poems, and code.\\n*   **Text Summarization:** Condensing large amounts of text into shorter, more concise summaries.\\n*   **Question Answering:** Answering questions based on provided text or general knowledge.\\n*   **Text Translation:** Converting text from one language to another.\\n*   **Sentiment Analysis:** Determining the emotional tone of a piece of text.\\n*   **Code Generation:** Writing code in various programming languages based on descriptions.\\n\\nLLMs are typically based on the transformer architecture, which allows them to process input sequences in parallel and capture long-range dependencies in the text. Examples of well-known LLMs include GPT-3, GPT-4, BERT, and LaMDA.\\n\\nThe training process for LLMs involves exposing the model to vast amounts of textual data, allowing it to learn statistical relationships between words and phrases. This process often uses self-supervised learning techniques, where the model is trained to predict masked words or next words in a sentence.\\n\\nIt\\'s important to note that while LLMs are incredibly powerful, they do not possess true understanding or consciousness. They are essentially sophisticated pattern-matching machines that can generate text based on the patterns they have learned during training. Their outputs should be evaluated critically, as they can sometimes produce inaccurate or nonsensical results, or reflect biases present in their training data.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How can a LLM support in business?\"\n",
        "lang = \"es\"\n",
        "\n",
        "result = chain.invoke(\n",
        "    f\"\"\"\n",
        "    Question: {question}\n",
        "    Response Language: {lang}\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "rJSNEILQBHcJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltYhSqMlBvtt",
        "outputId": "c89f6507-ae00-4d73-83c4-39aafbd73b76"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro, aquí tienes una respuesta sobre cómo un LLM puede apoyar a las empresas, en español:\n",
            "\n",
            "Los Modelos de Lenguaje Grandes (LLMs) ofrecen una amplia gama de aplicaciones que pueden impulsar la eficiencia, la innovación y la toma de decisiones en diversos aspectos de un negocio. Aquí te presento algunas formas clave en las que un LLM puede brindar soporte:\n",
            "\n",
            "**1. Automatización de Tareas y Optimización de Procesos:**\n",
            "\n",
            "*   **Atención al Cliente:** Los LLMs pueden potenciar chatbots y asistentes virtuales para responder preguntas frecuentes, gestionar solicitudes y proporcionar soporte 24/7, liberando a los agentes humanos para tareas más complejas. Pueden entender el lenguaje natural y proporcionar respuestas relevantes y personalizadas.\n",
            "*   **Generación de Contenido:** Pueden crear contenido de marketing, descripciones de productos, publicaciones en redes sociales, correos electrónicos y otros tipos de texto, ahorrando tiempo y recursos a los equipos de marketing y comunicación.\n",
            "*   **Resumen de Documentos:** Los LLMs pueden resumir grandes volúmenes de texto, como informes, artículos y contratos, permitiendo a los empleados acceder rápidamente a la información clave.\n",
            "*   **Traducción de Idiomas:** Permiten la comunicación eficiente con clientes y socios internacionales mediante la traducción automática de documentos y conversaciones.\n",
            "*   **Extracción de Información:** Pueden analizar documentos y extraer datos específicos, como nombres, fechas, cantidades y otros datos relevantes, automatizando tareas de entrada de datos.\n",
            "\n",
            "**2. Mejora en la Toma de Decisiones:**\n",
            "\n",
            "*   **Análisis de Datos:** Los LLMs pueden analizar grandes conjuntos de datos (textuales, en gran medida) para identificar patrones, tendencias y oportunidades, proporcionando información valiosa para la toma de decisiones estratégicas.\n",
            "*   **Análisis de Sentimiento:** Pueden analizar el sentimiento expresado en comentarios de clientes, reseñas de productos y publicaciones en redes sociales, proporcionando información sobre la percepción de la marca y productos.\n",
            "*   **Investigación de Mercado:** Pueden recopilar y analizar información relevante de diversas fuentes en línea, facilitando la investigación de mercados y el análisis de la competencia.\n",
            "*   **Modelado de Escenarios:** Pueden ayudar a modelar diferentes escenarios y predecir posibles resultados, permitiendo a las empresas evaluar riesgos y oportunidades.\n",
            "\n",
            "**3. Fomento de la Innovación y la Creatividad:**\n",
            "\n",
            "*   **Generación de Ideas:** Los LLMs pueden generar ideas nuevas y creativas para productos, servicios y campañas de marketing, impulsando la innovación.\n",
            "*   **Brainstorming:** Pueden participar en sesiones de brainstorming, proporcionando perspectivas diferentes y desafiando el pensamiento tradicional.\n",
            "*   **Creación de Prototipos:** Pueden ayudar a crear prototipos rápidos de productos y servicios, facilitando la experimentación y la iteración.\n",
            "\n",
            "**4. Capacitación y Desarrollo:**\n",
            "\n",
            "*   **Creación de Materiales de Formación:** Pueden generar materiales de formación personalizados y adaptados a las necesidades específicas de cada empleado.\n",
            "*   **Tutoría Virtual:** Pueden actuar como tutores virtuales, brindando apoyo y feedback a los empleados en su proceso de aprendizaje.\n",
            "\n",
            "**Ejemplos Específicos:**\n",
            "\n",
            "*   Una empresa de comercio electrónico puede utilizar un LLM para generar descripciones de productos atractivas y optimizadas para SEO.\n",
            "*   Una empresa de servicios financieros puede usar un LLM para analizar datos de mercado y predecir tendencias.\n",
            "*   Una empresa de atención médica puede utilizar un LLM para mejorar la comunicación con los pacientes y proporcionar información médica precisa.\n",
            "\n",
            "En resumen, los LLMs son herramientas poderosas que pueden transformar la forma en que las empresas operan, brindando soporte en la automatización, la toma de decisiones, la innovación y la capacitación. La adopción estratégica de estas tecnologías puede ayudar a las empresas a aumentar la eficiencia, mejorar la rentabilidad y obtener una ventaja competitiva. Es importante destacar que, como con cualquier tecnología, la implementación exitosa de LLMs requiere una comprensión clara de los objetivos empresariales y una planificación cuidadosa.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
        "os.environ['LANGCHAIN_ENDPOINT']=\"https://api.smith.langchain.com\"\n",
        "os.environ['LANGCHAIN_API_KEY']=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ['LANGCHAIN_PROJECT']='default'"
      ],
      "metadata": {
        "id": "impVLCFNDj5G"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Why is Transformer Architecture important for LLMs?\"\n",
        "lang = \"es\"\n",
        "\n",
        "result = chain.invoke(\n",
        "    f\"\"\"\n",
        "    Question: {question}\n",
        "    Response Language: {lang}\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "b2kxY29LB1Fo"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJJTb4JKCAJj",
        "outputId": "2aa5642b-172c-4fc0-d2c4-5bf9e76ab804"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La arquitectura Transformer es fundamental para los Modelos de Lenguaje Grandes (LLMs) por varias razones clave:\n",
            "\n",
            "1. **Atención (Attention):** A diferencia de las arquitecturas recurrentes (RNNs) que procesan la secuencia de entrada de forma secuencial, los Transformers utilizan un mecanismo de atención que permite al modelo ponderar la importancia de diferentes palabras en la secuencia al procesar otra palabra. Esto significa que el modelo puede capturar relaciones a larga distancia entre palabras, algo que era difícil con las RNNs. Por ejemplo, en la frase \"El perro que corrió rápido cruzó la calle\", el mecanismo de atención permitiría al modelo entender que \"corrió\" se refiere al \"perro\" a pesar de que están separados en la oración.\n",
            "\n",
            "2. **Paralelización:** La arquitectura Transformer permite el procesamiento paralelo de la secuencia de entrada. Dado que el mecanismo de atención opera simultáneamente sobre todas las posiciones de la secuencia, el entrenamiento puede ser mucho más rápido en comparación con las RNNs, que deben procesar los datos paso a paso. Esta capacidad de paralelización es esencial para entrenar LLMs con grandes cantidades de datos y parámetros.\n",
            "\n",
            "3. **Escalabilidad:** La arquitectura Transformer escala bien con el aumento de datos y parámetros del modelo. Esto es crucial porque los LLMs se benefician enormemente de entrenarse con conjuntos de datos masivos. La capacidad de escalar eficientemente ha sido un factor clave para el éxito de los LLMs actuales.\n",
            "\n",
            "4. **Flexibilidad:** Los Transformers son muy flexibles y pueden adaptarse a diferentes tareas de procesamiento del lenguaje natural (PNL), como traducción automática, resumen de texto, generación de texto, etc. La misma arquitectura básica se puede utilizar con pequeñas modificaciones para diferentes aplicaciones, lo que simplifica el desarrollo y el despliegue de modelos.\n",
            "\n",
            "5. **Autoatención (Self-Attention):** El mecanismo de autoatención es una forma especial de atención donde el modelo presta atención a diferentes partes de la misma secuencia de entrada. Esto es fundamental para comprender el contexto y las relaciones entre las palabras en una oración o párrafo. Por ejemplo, en la frase \"Ella vio el banco junto al río\", el modelo puede usar autoatención para entender que \"banco\" puede referirse a un asiento o a una institución financiera, dependiendo del contexto.\n",
            "\n",
            "En resumen, la arquitectura Transformer, con su mecanismo de atención, capacidad de paralelización, escalabilidad, flexibilidad y uso de autoatención, ha revolucionado el campo del PNL y ha permitido el desarrollo de los LLMs potentes que conocemos hoy en día. Su capacidad para capturar dependencias a larga distancia de manera eficiente, junto con su escalabilidad, la convierte en la arquitectura preferida para los modelos de lenguaje actuales.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}