{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYHTUVd2YwjnTlv+ori7R3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ektE-RM_jqy0","executionInfo":{"status":"ok","timestamp":1726926355369,"user_tz":300,"elapsed":10911,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"64cfdca0-de58-44d9-97cd-30d62e0926a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n","Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.5)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.47.0)\n","Requirement already satisfied: langchain_chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.7)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.125)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.115.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2)\n","Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n","Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.6.6)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.19.2)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n","Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48b0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n","Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.0)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.8.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.38.5)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n","Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.7)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n","Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n","Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n","Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n","Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n","Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n","Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"]}],"source":["!pip install langchain langchain_core langchain_community langchain-openai openai langchain_chroma tiktoken chromadb"]},{"cell_type":"code","source":["from typing import List, Dict, Optional\n","from pydantic import BaseModel, Field, conlist\n","\n","class InputData(BaseModel):\n","    topic: str = Field(..., description=\"The main topic\")\n","    file_url: str = Field(..., description=\"URL of the file to be processed\")\n","    file_type: str = Field(..., description=\"Type of the file (e.g., csv, json, xls, xlsx, xml)\")\n","    lang: str = Field(..., description=\"Language of the document\")\n","\n","class Topic(BaseModel):\n","    topic_id: str = Field(..., description=\"Unique identifier for the topic\")\n","    topic_name: str = Field(..., description=\"Human-readable name of the topic\")\n","    keywords: List[str] = Field(..., description=\"List of keywords that define the topic\")\n","    importance_score: float = Field(..., description=\"Score representing the importance of this topic in the clustering\")\n","    description: Optional[str] = Field(None, description=\"Optional description of the topic\")\n","\n","\n","class ClusterMetadata(BaseModel):\n","    num_clusters: int = Field(..., description=\"Total number of clusters generated\")\n","    method: str = Field(..., description=\"Method used for clustering (e.g., K-means, LDA, etc.)\")\n","    timestamp: Optional[str] = Field(None, description=\"Timestamp when the clustering process was completed\")\n","\n","\n","class TopicCluster(BaseModel):\n","    cluster_id: str = Field(..., description=\"Unique identifier for the topic cluster\")\n","    topics: List[Topic] = Field(..., description=\"List of topics within this cluster\")\n","    central_topic: Optional[str] = Field(None, description=\"The central topic or most important topic within the cluster, if applicable\")\n","\n","\n","class TopicClusteringOutput(BaseModel):\n","    clustering_algorithm: str = Field(..., description=\"Algorithm used to generate the clusters\")\n","    clusters: conlist(TopicCluster) = Field(..., description=\"List of all topic clusters\")\n","    metadata: ClusterMetadata = Field(..., description=\"Metadata regarding the clustering process\")\n"],"metadata":{"id":"aFOykW6Ul2Fz","executionInfo":{"status":"ok","timestamp":1726926355369,"user_tz":300,"elapsed":10,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"GLemniX9m4e1","executionInfo":{"status":"ok","timestamp":1726926357738,"user_tz":300,"elapsed":2378,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_google_genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dg4ojE1Lm6xj","executionInfo":{"status":"ok","timestamp":1726926363075,"user_tz":300,"elapsed":5347,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"82bc74e2-c12c-4664-ed5f-684c422766e6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.10/dist-packages (2.0.0)\n","Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.7.2)\n","Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.3.5)\n","Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (2.9.2)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.6)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.19.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.137.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.1.125)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (24.1)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (8.5.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.23.4)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.10.7)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.14.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.0.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.2.2)\n"]}]},{"cell_type":"code","source":["os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"],"metadata":{"id":"hM2tnjMQm9C1","executionInfo":{"status":"ok","timestamp":1726926364461,"user_tz":300,"elapsed":1393,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from enum import Enum\n","\n","class FileType(Enum):\n","    PDF = 'pdf'\n","    CSV = 'csv'\n","    TXT = 'txt'\n","    MD = 'md'\n","    URL = \"url\"\n","    PPTX = 'pptx'\n","    DOCX = \"docx\"\n","    XLS = \"xls\"\n","    XLSX = \"xlsx\"\n","    XML = 'xml'\n","\n","    GDOC = 'gdoc'\n","    GSHEET = \"gsheet\"\n","    GSLIDE = \"gslide\"\n","    GPDF = 'gpdf'\n","\n","    YOUTUBE_URL = 'youtube_url'\n","    IMG = 'img'"],"metadata":{"id":"DAiWTYl9m-9r","executionInfo":{"status":"ok","timestamp":1726926364463,"user_tz":300,"elapsed":12,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class FileHandlerError(Exception):\n","    \"\"\"Raised when a file content cannot be loaded. Used for tools which require file handling.\"\"\"\n","    def __init__(self, message, url=None):\n","        self.message = message\n","        self.url = url\n","        super().__init__(self.message)\n","\n","    def __str__(self):\n","        return f\"{self.message}\"\n","\n","class ImageHandlerError(Exception):\n","    \"\"\"Raised when an image cannot be loaded. Used for tools which require image handling.\"\"\"\n","    def __init__(self, message, url):\n","        self.message = message\n","        self.url = url\n","        super().__init__(self.message)\n","\n","    def __str__(self):\n","        return f\"{self.message}\"\n","\n","class VideoTranscriptError(Exception):\n","    \"\"\"Raised when a video transcript cannot be loaded. Used for tools which require video transcripts.\"\"\"\n","    def __init__(self, message, url):\n","        self.message = message\n","        self.url = url\n","        super().__init__(self.message)\n","\n","    def __str__(self):\n","        return f\"{self.message}\""],"metadata":{"id":"wV2zcHPEnYkX","executionInfo":{"status":"ok","timestamp":1726926364463,"user_tz":300,"elapsed":11,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["%%writefile document_loaders.py\n","from langchain_community.document_loaders import YoutubeLoader, PyPDFLoader, TextLoader, UnstructuredURLLoader, UnstructuredPowerPointLoader, Docx2txtLoader, UnstructuredExcelLoader, UnstructuredXMLLoader\n","from langchain_community.document_loaders.csv_loader import CSVLoader\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.messages import HumanMessage\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_core.documents import Document\n","import os\n","import tempfile\n","import uuid\n","import requests\n","import gdown\n","from enum import Enum\n","\n","class FileType(Enum):\n","    PDF = 'pdf'\n","    CSV = 'csv'\n","    TXT = 'txt'\n","    MD = 'md'\n","    URL = 'url'\n","    PPTX = 'pptx'\n","    DOCX = 'docx'\n","    XLS = 'xls'\n","    XLSX = 'xlsx'\n","    XML = 'xml'\n","    GDOC = 'gdoc'\n","    GSHEET = 'gsheet'\n","    GSLIDE = 'gslide'\n","    GPDF = 'gpdf'\n","    YOUTUBE_URL = 'youtube_url'\n","    IMG = 'img'\n","\n","STRUCTURED_TABULAR_FILE_EXTENSIONS = {\"csv\", \"xls\", \"xlsx\", \"gsheet\", \"xml\"}\n","\n","splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 1000,\n","    chunk_overlap = 100\n",")\n","\n","def read_text_file(file_path):\n","    # Get the directory containing the script file\n","    script_dir = os.path.dirname(os.path.abspath(__file__))\n","\n","    # Combine the script directory with the relative file path\n","    absolute_file_path = os.path.join(script_dir, file_path)\n","\n","    with open(absolute_file_path, 'r') as file:\n","        return file.read()\n","\n","def get_docs(file_url: str, file_type: str, verbose=True):\n","    file_type = file_type.lower()\n","    try:\n","        file_loader = file_loader_map[FileType(file_type)]\n","        docs = file_loader(file_url, verbose)\n","\n","        return docs\n","\n","    except Exception as e:\n","        print(e)\n","        print(f\"Unsupported file type: {file_type}\")\n","        raise FileHandlerError(f\"Unsupported file type\", file_url) from e\n","\n","class FileHandler:\n","    def __init__(self, file_loader, file_extension):\n","        self.file_loader = file_loader\n","        self.file_extension = file_extension\n","\n","    def load(self, url):\n","        # Generate a unique filename with a UUID prefix\n","        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n","\n","        # Download the file from the URL and save it to a temporary file\n","        response = requests.get(url)\n","        response.raise_for_status()  # Ensure the request was successful\n","\n","        with tempfile.NamedTemporaryFile(delete=False, prefix=unique_filename) as temp_file:\n","            temp_file.write(response.content)\n","            temp_file_path = temp_file.name\n","\n","        # Use the file_loader to load the documents\n","        try:\n","            loader = self.file_loader(file_path=temp_file_path)\n","        except Exception as e:\n","            print(f\"No such file found at {temp_file_path}\")\n","            raise FileHandlerError(f\"No file found\", temp_file_path) from e\n","\n","        try:\n","            documents = loader.load()\n","        except Exception as e:\n","            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n","            raise FileHandlerError(f\"No file content available\", temp_file_path) from e\n","\n","        # Remove the temporary file\n","        os.remove(temp_file_path)\n","\n","        return documents\n","\n","def load_pdf_documents(pdf_url: str, verbose=False):\n","    pdf_loader = FileHandler(PyPDFLoader, \"pdf\")\n","    docs = pdf_loader.load(pdf_url)\n","\n","    if docs:\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found PDF file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_csv_documents(csv_url: str, verbose=False):\n","    csv_loader = FileHandler(CSVLoader, \"csv\")\n","    docs = csv_loader.load(csv_url)\n","\n","    if docs:\n","        if verbose:\n","            print(f\"Found CSV file\")\n","            print(f\"Splitting documents into {len(docs)} chunks\")\n","\n","        return docs\n","\n","def load_txt_documents(notes_url: str, verbose=False):\n","    notes_loader = FileHandler(TextLoader, \"txt\")\n","    docs = notes_loader.load(notes_url)\n","\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found TXT file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_md_documents(notes_url: str, verbose=False):\n","    notes_loader = FileHandler(TextLoader, \"md\")\n","    docs = notes_loader.load(notes_url)\n","\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found MD file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_url_documents(url: str, verbose=False):\n","    url_loader = UnstructuredURLLoader(urls=[url])\n","    docs = url_loader.load()\n","\n","    if docs:\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found URL\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_pptx_documents(pptx_url: str, verbose=False):\n","    pptx_handler = FileHandler(UnstructuredPowerPointLoader, 'pptx')\n","\n","    docs = pptx_handler.load(pptx_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found PPTX file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_docx_documents(docx_url: str, verbose=False):\n","    docx_handler = FileHandler(Docx2txtLoader, 'docx')\n","    docs = docx_handler.load(docx_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found DOCX file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_xls_documents(xls_url: str, verbose=False):\n","    xls_handler = FileHandler(UnstructuredExcelLoader, 'xls')\n","    docs = xls_handler.load(xls_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found XLS file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_xlsx_documents(xlsx_url: str, verbose=False):\n","    xlsx_handler = FileHandler(UnstructuredExcelLoader, 'xlsx')\n","    docs = xlsx_handler.load(xlsx_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found XLSX file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_xml_documents(xml_url: str, verbose=False):\n","    xml_handler = FileHandler(UnstructuredXMLLoader, 'xml')\n","    docs = xml_handler.load(xml_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found XML file\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","class FileHandlerForGoogleDrive:\n","    def __init__(self, file_loader, file_extension='docx'):\n","        self.file_loader = file_loader\n","        self.file_extension = file_extension\n","\n","    def load(self, url):\n","\n","        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n","\n","        try:\n","            gdown.download(url=url, output=unique_filename, fuzzy=True)\n","        except Exception as e:\n","            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n","            raise FileHandlerError(f\"No file content available\") from e\n","\n","        try:\n","            loader = self.file_loader(file_path=unique_filename)\n","        except Exception as e:\n","            print(f\"No such file found at {unique_filename}\")\n","            raise FileHandlerError(f\"No file found\", unique_filename) from e\n","\n","        try:\n","            documents = loader.load()\n","        except Exception as e:\n","            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n","            raise FileHandlerError(f\"No file content available\") from e\n","\n","        os.remove(unique_filename)\n","\n","        return documents\n","\n","def load_gdocs_documents(drive_folder_url: str, verbose=False):\n","\n","    gdocs_loader = FileHandlerForGoogleDrive(Docx2txtLoader)\n","\n","    docs = gdocs_loader.load(drive_folder_url)\n","\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found Google Docs files\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_gsheets_documents(drive_folder_url: str, verbose=False):\n","    gsheets_loader = FileHandlerForGoogleDrive(UnstructuredExcelLoader, 'xlsx')\n","    docs = gsheets_loader.load(drive_folder_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found Google Sheets files\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_gslides_documents(drive_folder_url: str, verbose=False):\n","    gslides_loader = FileHandlerForGoogleDrive(UnstructuredPowerPointLoader, 'pptx')\n","    docs = gslides_loader.load(drive_folder_url)\n","    if docs:\n","\n","        split_docs = splitter.split_documents(docs)\n","\n","        if verbose:\n","            print(f\"Found Google Slides files\")\n","            print(f\"Splitting documents into {len(split_docs)} chunks\")\n","\n","        return split_docs\n","\n","def load_gpdf_documents(drive_folder_url: str, verbose=False):\n","\n","    gpdf_loader = FileHandlerForGoogleDrive(PyPDFLoader,'pdf')\n","\n","    docs = gpdf_loader.load(drive_folder_url)\n","    if docs:\n","\n","        if verbose:\n","            print(f\"Found Google PDF files\")\n","            print(f\"Splitting documents into {len(docs)} chunks\")\n","\n","        return docs\n","\n","def load_docs_youtube_url(youtube_url: str, verbose=True) -> str:\n","    try:\n","        loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=True)\n","    except Exception as e:\n","        print(f\"No such video found at {youtube_url}\")\n","        raise VideoTranscriptError(f\"No video found\", youtube_url) from e\n","\n","    try:\n","        docs = loader.load()\n","        length = docs[0].metadata[\"length\"]\n","        title = docs[0].metadata[\"title\"]\n","\n","    except Exception as e:\n","        print(f\"Video transcript might be private or unavailable in 'en' or the URL is incorrect.\")\n","        raise VideoTranscriptError(f\"No video transcripts available\", youtube_url) from e\n","\n","    if verbose:\n","        print(f\"Found video with title: {title} and length: {length}\")\n","        print(f\"Combined documents into a single string.\")\n","        print(f\"Beginning to process transcript...\")\n","\n","    split_docs = splitter.split_documents(docs)\n","\n","    return split_docs\n","\n","llm_for_img = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n","\n","def generate_docs_from_img(img_url, verbose: bool=False):\n","    message = HumanMessage(\n","    content=[\n","            {\n","                \"type\": \"text\",\n","                \"text\": \"Give me a summary of what you see in the image. It must be 3 detailed paragraphs.\",\n","            },\n","            {\"type\": \"image_url\", \"image_url\": img_url},\n","        ]\n","    )\n","\n","    try:\n","        response = llm_for_img.invoke([message]).content\n","        print(f\"Generated summary: {response}\")\n","        docs = Document(page_content=response, metadata={\"source\": img_url})\n","        split_docs = splitter.split_documents([docs])\n","    except Exception as e:\n","        print(f\"Error processing the request due to Invalid Content or Invalid Image URL\")\n","        raise ImageHandlerError(f\"Error processing the request\", img_url) from e\n","\n","    return split_docs\n","\n","file_loader_map = {\n","    FileType.PDF: load_pdf_documents,\n","    FileType.CSV: load_csv_documents,\n","    FileType.TXT: load_txt_documents,\n","    FileType.MD: load_md_documents,\n","    FileType.URL: load_url_documents,\n","    FileType.PPTX: load_pptx_documents,\n","    FileType.DOCX: load_docx_documents,\n","    FileType.XLS: load_xls_documents,\n","    FileType.XLSX: load_xlsx_documents,\n","    FileType.XML: load_xml_documents,\n","    FileType.GDOC: load_gdocs_documents,\n","    FileType.GSHEET: load_gsheets_documents,\n","    FileType.GSLIDE: load_gslides_documents,\n","    FileType.GPDF: load_gpdf_documents,\n","    FileType.YOUTUBE_URL: load_docs_youtube_url,\n","    FileType.IMG: generate_docs_from_img\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JBGO1_QnbRi","executionInfo":{"status":"ok","timestamp":1726926364463,"user_tz":300,"elapsed":10,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"490e915a-3b02-4afe-bda4-f46519b23db4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting document_loaders.py\n"]}]},{"cell_type":"code","source":["!pip install pypdf fpdf youtube-transcript-api pytube unstructured python-pptx docx2txt networkx pandas xlrd openpyxl gdown pytest PyPDF2 psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOYc8kyHne6k","executionInfo":{"status":"ok","timestamp":1726926374094,"user_tz":300,"elapsed":9638,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"d615633d-839a-43c3-8063-af2e4c93ba71"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.0.0)\n","Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n","Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n","Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.15.13)\n","Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (1.0.2)\n","Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n","Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.13.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n","Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.7)\n","Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n","Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.25.9)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n","Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.0.1)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (10.4.0)\n","Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.1)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.2)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured) (0.47)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n","Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (8.0.1)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.2)\n","Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n","Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n","Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n","Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (5.2.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n"]}]},{"cell_type":"code","source":["!pip uninstall -y nltk\n","!pip install nltk\n","import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXrV-3tDoGFj","executionInfo":{"status":"ok","timestamp":1726926378607,"user_tz":300,"elapsed":4526,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"01ccee68-5d83-4f0d-98de-72f95de0798f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: nltk 3.9.1\n","Uninstalling nltk-3.9.1:\n","  Successfully uninstalled nltk-3.9.1\n","Collecting nltk\n","  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","Installing collected packages: nltk\n","Successfully installed nltk-3.9.1\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def read_text_file(file_path):\n","    # Get the current working directory\n","    script_dir = os.getcwd()\n","\n","    # Combine the script directory with the relative file path\n","    absolute_file_path = os.path.join(script_dir, file_path)\n","\n","    try:\n","        with open(absolute_file_path, 'r') as file:\n","            content = file.read()\n","        return content\n","    except FileNotFoundError:\n","        # Handle the case where the file is not found\n","        print(f\"File not found: {absolute_file_path}\")\n","        return None"],"metadata":{"id":"10otU-aVoGB-","executionInfo":{"status":"ok","timestamp":1726926378608,"user_tz":300,"elapsed":7,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from langchain_openai.embeddings import OpenAIEmbeddings\n","embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"],"metadata":{"id":"XYelxYf1p9j3","executionInfo":{"status":"ok","timestamp":1726926386041,"user_tz":300,"elapsed":7439,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm_chat_openai = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"],"metadata":{"id":"0ucGq3zbp_DC","executionInfo":{"status":"ok","timestamp":1726926386042,"user_tz":300,"elapsed":16,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import GoogleGenerativeAI\n","\n","llm_google_genai = GoogleGenerativeAI(model=\"gemini-1.5-pro\")"],"metadata":{"id":"m_DdeEfM03MK","executionInfo":{"status":"ok","timestamp":1726926386042,"user_tz":300,"elapsed":15,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","hyde_prompt_template = \"\"\"\n","Generate a hypothetical answer to the user's query.\n","Query: {query}\n","Hypothetical Answer:\n","\"\"\"\n","\n","hyde_prompt = PromptTemplate(input_variables=[\"query\"], template=hyde_prompt_template)\n","\n","hyde_chain = hyde_prompt | llm_google_genai"],"metadata":{"id":"JhiJwKsJvwxj","executionInfo":{"status":"ok","timestamp":1726926386042,"user_tz":300,"elapsed":14,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from langchain.schema import Document\n","from langchain.chains import  HypotheticalDocumentEmbedder\n","from langchain.vectorstores import Chroma\n","\n","def build_docsearch(documents: List[Document], embedding_model):\n","  embeddings = HypotheticalDocumentEmbedder(\n","    llm_chain=hyde_chain,\n","    base_embeddings=embedding_model\n","  )\n","\n","  docsearch = Chroma.from_documents(documents, embeddings)\n","\n","  return docsearch"],"metadata":{"id":"BytSlH9BsnVO","executionInfo":{"status":"ok","timestamp":1726926386043,"user_tz":300,"elapsed":14,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from langchain_core.output_parsers import JsonOutputParser\n","\n","parser = JsonOutputParser(pydantic_object=TopicClusteringOutput)\n","format_instructions = parser.get_format_instructions()"],"metadata":{"id":"CEmIXa3TwnMY","executionInfo":{"status":"ok","timestamp":1726926386043,"user_tz":300,"elapsed":14,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["prompt_template = \"\"\"\n","Analyze the following document and perform topic clustering. Based on the document's content, select the most appropriate clustering algorithm, identify relevant topics, group them into clusters, and determine the importance of each topic within its cluster.\n","\n","Main Topic:\n","-----------------------------\n","{topic}\n","\n","Context:\n","-----------------------------\n","{context}\n","\n","Formatting:\n","-----------------------------\n","{format_instructions}\n","\n","Ensure the following:\n","- Automatically select the clustering algorithm based on the document.\n","- Provide metadata about the number of clusters and the method used.\n","- Identify and cluster topics, including their importance score and relevant keywords.\n","- Highlight any central topic within each cluster if applicable.\n","\"\"\""],"metadata":{"id":"Tz0NHTcRx7q2","executionInfo":{"status":"ok","timestamp":1726926386043,"user_tz":300,"elapsed":14,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt = PromptTemplate(\n","    template=prompt_template,\n","    input_variables=[\"topic\", \"context\"],\n","    partial_variables={\"format_instructions\": format_instructions}\n",")"],"metadata":{"id":"XSdwWC7DyAcF","executionInfo":{"status":"ok","timestamp":1726926386043,"user_tz":300,"elapsed":13,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["chain = prompt | llm_chat_openai | parser"],"metadata":{"id":"OR95H2NMyJKm","executionInfo":{"status":"ok","timestamp":1726926386043,"user_tz":300,"elapsed":13,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"],"metadata":{"id":"3X6I2SS_yKqd","executionInfo":{"status":"ok","timestamp":1726926386044,"user_tz":300,"elapsed":13,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from document_loaders import get_docs\n","\n","def run_chain(input_data: InputData):\n","    documents = get_docs(input_data.file_url, input_data.file_type, verbose=True)\n","    if not documents:\n","        print(\"No documents loaded.\")\n","        return\n","\n","    split_docs = splitter.split_documents(documents)\n","\n","    docstore = build_docsearch(split_docs, embedding_model)\n","\n","    user_query = \"Develop a topic clustering based in this main topic: \"+input_data.topic\n","\n","    relevant_docs = docstore.similarity_search(user_query)\n","\n","    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n","\n","    output = chain.invoke({'topic': input_data.topic, 'context': context})\n","\n","    print(output)\n","\n","    del docstore\n","\n","    return output"],"metadata":{"id":"SFm7c1gXyXKJ","executionInfo":{"status":"ok","timestamp":1726926386044,"user_tz":300,"elapsed":13,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    input_data = InputData(\n","        topic=\"LLM\",\n","        file_url=\"https://raw.github.com/AaronSosaRamos/mission-flights/main/files-for-test/text.pdf\",\n","        file_type=\"pdf\",\n","        lang=\"en\"\n","    )\n","\n","    result = run_chain(input_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Pqa7suczEMM","executionInfo":{"status":"ok","timestamp":1726926408416,"user_tz":300,"elapsed":22384,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"e99b7e33-6ee3-435a-bc13-2bbd7abd959e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Found PDF file\n","Splitting documents into 2 chunks\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"]},{"output_type":"stream","name":"stdout","text":["{'clustering_algorithm': 'K-means', 'clusters': [{'cluster_id': 'cluster_1', 'central_topic': 'Applications of LLMs', 'topics': [{'topic_id': 'topic_1', 'topic_name': 'Healthcare Applications', 'keywords': ['healthcare', 'medical documentation', 'research'], 'importance_score': 0.9, 'description': 'Use of LLMs in healthcare for documentation and research.'}, {'topic_id': 'topic_2', 'topic_name': 'Education Applications', 'keywords': ['education', 'intelligent tutoring systems'], 'importance_score': 0.8, 'description': 'Implementation of LLMs in educational tools and systems.'}, {'topic_id': 'topic_3', 'topic_name': 'Business Applications', 'keywords': ['business', 'customer service', 'chatbots', 'virtual assistants'], 'importance_score': 0.85, 'description': 'Leveraging LLMs for improving customer service in businesses.'}]}, {'cluster_id': 'cluster_2', 'central_topic': 'Challenges of LLMs', 'topics': [{'topic_id': 'topic_4', 'topic_name': 'Bias in LLMs', 'keywords': ['bias', 'societal prejudices', 'data'], 'importance_score': 0.95, 'description': 'Concerns regarding biases in LLMs due to training data.'}, {'topic_id': 'topic_5', 'topic_name': 'Computational Resources', 'keywords': ['computational resources', 'training', 'deployment'], 'importance_score': 0.85, 'description': 'High resource requirements for training and deploying LLMs.'}, {'topic_id': 'topic_6', 'topic_name': 'Interpretability', 'keywords': ['interpretability', 'trust', 'transparency'], 'importance_score': 0.9, 'description': 'Challenges in understanding LLM outputs and ensuring transparency.'}]}, {'cluster_id': 'cluster_3', 'central_topic': 'Future of LLMs', 'topics': [{'topic_id': 'topic_7', 'topic_name': 'Advancements in LLMs', 'keywords': ['advancements', 'reducing biases', 'improving efficiency'], 'importance_score': 0.8, 'description': 'Future research directions aimed at enhancing LLM capabilities.'}, {'topic_id': 'topic_8', 'topic_name': 'AI-driven Innovation', 'keywords': ['AI', 'innovation', 'applications'], 'importance_score': 0.75, 'description': 'The role of LLMs in driving future innovations in AI.'}]}], 'metadata': {'num_clusters': 3, 'method': 'K-means', 'timestamp': None}}\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"id":"ko38DPqk1lMD","executionInfo":{"status":"ok","timestamp":1726926445080,"user_tz":300,"elapsed":373,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"3252e510-c9e1-4737-a07c-f1d564e4dfde","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clustering_algorithm': 'K-means',\n"," 'clusters': [{'cluster_id': 'cluster_1',\n","   'central_topic': 'Applications of LLMs',\n","   'topics': [{'topic_id': 'topic_1',\n","     'topic_name': 'Healthcare Applications',\n","     'keywords': ['healthcare', 'medical documentation', 'research'],\n","     'importance_score': 0.9,\n","     'description': 'Use of LLMs in healthcare for documentation and research.'},\n","    {'topic_id': 'topic_2',\n","     'topic_name': 'Education Applications',\n","     'keywords': ['education', 'intelligent tutoring systems'],\n","     'importance_score': 0.8,\n","     'description': 'Implementation of LLMs in educational tools and systems.'},\n","    {'topic_id': 'topic_3',\n","     'topic_name': 'Business Applications',\n","     'keywords': ['business',\n","      'customer service',\n","      'chatbots',\n","      'virtual assistants'],\n","     'importance_score': 0.85,\n","     'description': 'Leveraging LLMs for improving customer service in businesses.'}]},\n","  {'cluster_id': 'cluster_2',\n","   'central_topic': 'Challenges of LLMs',\n","   'topics': [{'topic_id': 'topic_4',\n","     'topic_name': 'Bias in LLMs',\n","     'keywords': ['bias', 'societal prejudices', 'data'],\n","     'importance_score': 0.95,\n","     'description': 'Concerns regarding biases in LLMs due to training data.'},\n","    {'topic_id': 'topic_5',\n","     'topic_name': 'Computational Resources',\n","     'keywords': ['computational resources', 'training', 'deployment'],\n","     'importance_score': 0.85,\n","     'description': 'High resource requirements for training and deploying LLMs.'},\n","    {'topic_id': 'topic_6',\n","     'topic_name': 'Interpretability',\n","     'keywords': ['interpretability', 'trust', 'transparency'],\n","     'importance_score': 0.9,\n","     'description': 'Challenges in understanding LLM outputs and ensuring transparency.'}]},\n","  {'cluster_id': 'cluster_3',\n","   'central_topic': 'Future of LLMs',\n","   'topics': [{'topic_id': 'topic_7',\n","     'topic_name': 'Advancements in LLMs',\n","     'keywords': ['advancements', 'reducing biases', 'improving efficiency'],\n","     'importance_score': 0.8,\n","     'description': 'Future research directions aimed at enhancing LLM capabilities.'},\n","    {'topic_id': 'topic_8',\n","     'topic_name': 'AI-driven Innovation',\n","     'keywords': ['AI', 'innovation', 'applications'],\n","     'importance_score': 0.75,\n","     'description': 'The role of LLMs in driving future innovations in AI.'}]}],\n"," 'metadata': {'num_clusters': 3, 'method': 'K-means', 'timestamp': None}}"]},"metadata":{},"execution_count":24}]}]}