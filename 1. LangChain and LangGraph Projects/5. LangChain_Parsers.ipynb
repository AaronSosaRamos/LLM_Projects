{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfU3/SwSQH2ZSB6hZr1zU7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#LangChain Parsers"],"metadata":{"id":"QLm2Z_-eP5tm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JUHsJ65M7LbG","executionInfo":{"status":"ok","timestamp":1717952270852,"user_tz":300,"elapsed":26877,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"2d92531c-6808-427d-ca89-9cb2fd27305e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.52.0)\n","Collecting google-cloud-aiplatform\n","  Downloading google_cloud_aiplatform-1.54.1-py2.py3-none-any.whl (5.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain\n","  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-google-genai\n","  Downloading langchain_google_genai-1.0.6-py3-none-any.whl (35 kB)\n","Collecting langchain_core\n","  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n","Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.0)\n","Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n","Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.21.0)\n","Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n","Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.4)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.7.3)\n","Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n","Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.5.4)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain_core)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging>=14.3 (from google-cloud-aiplatform)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n","Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n","Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n","Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n","Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.4)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.84.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.66.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.12.1)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain_core)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.18.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.1.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.1.2)\n","Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain_core, langchain-text-splitters, langchain, google-cloud-aiplatform, langchain-google-genai\n","\u001b[33m  WARNING: The script langsmith is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed google-cloud-aiplatform-1.54.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.3 langchain-google-genai-1.0.6 langchain-text-splitters-0.2.1 langchain_core-0.2.5 langsmith-0.1.75 orjson-3.10.3 packaging-23.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"114ff5180cfc47e0ae81de52d488146c"}},"metadata":{}}],"source":["!pip install --upgrade --user google-cloud-aiplatform langchain langchain-google-genai langchain_core"]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n","os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n","os.environ['LANGCHAIN_API_KEY'] = userdata.get(\"LANGCHAIN_API_KEY\")\n","os.environ['LANGCHAIN_PROJECT'] = \"test-for-kai-v2\"\n","\n","if \"GOOGLE_API_KEY\" not in os.environ:\n","  os.environ['GOOGLE_API_KEY'] = userdata.get(\"GOOGLE_API_KEY\")"],"metadata":{"id":"caB7Rgg98A0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import GoogleGenerativeAI\n","from google.colab import userdata\n","\n","llm = GoogleGenerativeAI(\n","    model = \"gemini-1.0-pro\",\n","    temperate=1,\n","    location = \"us-central1\"\n",")"],"metadata":{"id":"RHCiQgap8-E9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#String Parser"],"metadata":{"id":"UX0UONAZRmdA"}},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","# And a query intented to prompt a language model to populate the data structure.\n","joke_query = \"Tell me a joke.\"\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{query}\\n\",\n","    input_variables=[\"query\"],\n",")\n","\n","chain = prompt | llm | StrOutputParser()\n","\n","chain.invoke({\"query\": joke_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"QU0EOY8CRoN4","executionInfo":{"status":"ok","timestamp":1717958135114,"user_tz":300,"elapsed":1367,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"15f3f141-f349-410b-a8be-98195da578f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Why did the golfer wear two pairs of pants?\\n\\nIn case he got a hole-in-one!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["#JSON Parser"],"metadata":{"id":"f6on2wlY9YT5"}},{"cell_type":"code","source":["from langchain_core.output_parsers import JsonOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field"],"metadata":{"id":"YfEd_3Iu9Uu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your desired data structure.\n","class Joke(BaseModel):\n","    setup: str = Field(description=\"question to set up a joke\")\n","    punchline: str = Field(description=\"answer to resolve the joke\")"],"metadata":{"id":"-5NGLEo39Z7u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# And a query intented to prompt a language model to populate the data structure.\n","joke_query = \"Tell me a joke.\"\n","\n","# Set up a parser + inject instructions into the prompt template.\n","parser = JsonOutputParser(pydantic_object=Joke)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": joke_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0GvgJAA9eXa","executionInfo":{"status":"ok","timestamp":1717952762754,"user_tz":300,"elapsed":1238,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"be0a954a-0457-457f-b797-83a4d95641ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'setup': \"What do you call a bee that can't make up its mind?\",\n"," 'punchline': 'A maybe'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from langchain_core.pydantic_v1 import BaseModel, Field, validator\n","from typing import List\n","import re\n","\n","class Quiz(BaseModel):\n","    question: str = Field(...)\n","    choices: List[str] = Field(..., min_items=3, max_items=3)\n","    answer: str = Field(...)\n","    explanation: str = Field(...)\n","\n","    @validator('choices', each_item=True)\n","    def check_choices_format(cls, v):\n","        pattern = re.compile(r'^[A-C]: .+$')\n","        if not pattern.match(v):\n","            raise ValueError('Each choice must be in the format \"A: ...\", \"B: ...\", \"C: ...\"')\n","        return v\n","\n","    @validator('answer')\n","    def check_answer_format(cls, v, values):\n","        pattern = re.compile(r'^[A-C]: .+$')\n","        if not pattern.match(v):\n","            raise ValueError('Answer must be in the format \"A: ...\", \"B: ...\", \"C: ...\"')\n","\n","        # Ensure the answer matches one of the choices\n","        if 'choices' in values and v not in values['choices']:\n","            raise ValueError('Answer must match one of the provided choices')\n","\n","        return v\n","\n","# Example usage\n","try:\n","    quiz = Quiz(\n","        question=\"What is the capital of France?\",\n","        choices=[\"A: Berlin\", \"B: Madrid\", \"C: Paris\"],\n","        answer=\"C: Paris\",\n","        explanation=\"Paris is the capital city of France.\"\n","    )\n","    print(quiz)\n","except ValueError as e:\n","    print(e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqgEXeDy-RQe","executionInfo":{"status":"ok","timestamp":1717952938073,"user_tz":300,"elapsed":338,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"91b63be1-d2c7-44e9-d2b5-aebaf4188f6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["question='What is the capital of France?' choices=['A: Berlin', 'B: Madrid', 'C: Paris'] answer='C: Paris' explanation='Paris is the capital city of France.'\n"]}]},{"cell_type":"code","source":["parser2 = JsonOutputParser(pydantic_object=Quiz)"],"metadata":{"id":"S4IDs8FF-laa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question_query = \"What is the physic Domain of Knowledge used for Quantum Computing? (Divide each choice with A, B, C and D)\"\n","\n","prompt2 = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser2.get_format_instructions()},\n",")\n","\n","chain2 = prompt2 | llm | parser2\n","chain2.invoke({\"query\": question_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHfAwJ_f-pU8","executionInfo":{"status":"ok","timestamp":1717953188107,"user_tz":300,"elapsed":2784,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"30b6c865-caf8-4b4a-bfe4-67e9ead1088e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'question': 'What is the physic Domain of Knowledge used for Quantum Computing?',\n"," 'choices': ['A. Classical Mechanics',\n","  'B. Quantum Mechanics',\n","  'C. Electromagnetism',\n","  'D. Special Relativity'],\n"," 'answer': 'B. Quantum Mechanics',\n"," 'explanation': 'Quantum Mechanics is the physic Domain of Knowledge used for Quantum Computing because it provides the mathematical framework to describe and predict the behavior of quantum systems, which are the fundamental building blocks of quantum computers.'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["###Streaming:"],"metadata":{"id":"Q6zePxHe-pK1"}},{"cell_type":"code","source":["for s in chain.stream({\"query\": joke_query}):\n","    print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOF5H_M__f46","executionInfo":{"status":"ok","timestamp":1717953235793,"user_tz":300,"elapsed":1330,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"0a1afa1a-9348-4c12-8018-208a1011df2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'setup': 'Why did the golfer wear two pairs of pants?'}\n","{'setup': 'Why did the golfer wear two pairs of pants?', 'punchline': 'In case he got a hole-in-one!'}\n"]}]},{"cell_type":"markdown","source":["#XML Parser"],"metadata":{"id":"3lR0YzDuJib8"}},{"cell_type":"code","source":["from langchain.output_parsers import XMLOutputParser\n","from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"DgEaqLXYJjgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["actor_query = \"Generate the shortened filmography for Leonardo Di Caprio.\"\n","output = llm.invoke(\n","    f\"\"\"{actor_query}\n","Please enclose the movies in <movie></movie> tags\"\"\"\n",")\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdkJFgiAJ3Vp","executionInfo":{"status":"ok","timestamp":1717955980349,"user_tz":300,"elapsed":1419,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"d099745a-0a5a-4b14-d4a3-49713969ba89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<movie>Titanic</movie>\n","<movie>The Wolf of Wall Street</movie>\n","<movie>Inception</movie>\n","<movie>The Revenant</movie>\n","<movie>Once Upon a Time in Hollywood</movie>\n"]}]},{"cell_type":"code","source":["parser = XMLOutputParser()\n","\n","prompt = PromptTemplate(\n","    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","output = chain.invoke({\"query\": actor_query})\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOIFGYc5KCEM","executionInfo":{"status":"ok","timestamp":1717956016040,"user_tz":300,"elapsed":7006,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"7cfcccbe-bccd-4b1e-fdda-b1a03062da6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'filmography': [{'film': [{'title': 'Titanic'}, {'year': '1997'}]}, {'film': [{'title': 'The Beach'}, {'year': '2000'}]}, {'film': [{'title': 'Catch Me If You Can'}, {'year': '2002'}]}, {'film': [{'title': 'The Aviator'}, {'year': '2004'}]}, {'film': [{'title': 'The Departed'}, {'year': '2006'}]}, {'film': [{'title': 'Blood Diamond'}, {'year': '2006'}]}, {'film': [{'title': 'Inception'}, {'year': '2010'}]}, {'film': [{'title': 'Django Unchained'}, {'year': '2012'}]}, {'film': [{'title': 'The Wolf of Wall Street'}, {'year': '2013'}]}, {'film': [{'title': 'The Revenant'}, {'year': '2015'}]}, {'film': [{'title': 'Once Upon a Time in Hollywood'}, {'year': '2019'}]}, {'film': [{'title': \"Don't Look Up\"}, {'year': '2021'}]}]}\n"]}]},{"cell_type":"code","source":["parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n","prompt = PromptTemplate(\n","    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","\n","chain = prompt | llm | parser\n","\n","output = chain.invoke({\"query\": actor_query})\n","\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoERbMxPKLSf","executionInfo":{"status":"ok","timestamp":1717956042204,"user_tz":300,"elapsed":3288,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"3775d163-f24a-442e-c876-817092c164da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'movies': [{'actor': [{'film': [{'name': 'Titanic'}, {'genre': 'Romance/Disaster'}]}, {'film': [{'name': 'The Wolf of Wall Street'}, {'genre': 'Comedy/Crime'}]}, {'film': [{'name': 'Inception'}, {'genre': 'Science Fiction/Action'}]}, {'film': [{'name': 'The Revenant'}, {'genre': 'Adventure/Drama'}]}, {'film': [{'name': 'Once Upon a Time in Hollywood'}, {'genre': 'Comedy/Drama'}]}]}]}\n"]}]},{"cell_type":"code","source":["for s in chain.stream({\"query\": actor_query}):\n","    print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVthzbVtKT9Y","executionInfo":{"status":"ok","timestamp":1717956071437,"user_tz":300,"elapsed":2943,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"f892ab3c-6647-4aa4-f110-1c5acce0830b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'movies': [{'actor': 'Leonardo DiCaprio'}]}\n","{'movies': [{'film': [{'name': 'Titanic'}]}]}\n","{'movies': [{'film': [{'genre': 'Drama/Romance'}]}]}\n","{'movies': [{'film': [{'name': 'The Wolf of Wall Street'}]}]}\n","{'movies': [{'film': [{'genre': 'Drama/Comedy'}]}]}\n","{'movies': [{'film': [{'name': 'The Revenant'}]}]}\n","{'movies': [{'film': [{'genre': 'Adventure/Drama'}]}]}\n","{'movies': [{'film': [{'name': 'Once Upon a Time in Hollywood'}]}]}\n","{'movies': [{'film': [{'genre': 'Comedy/Drama'}]}]}\n"]}]},{"cell_type":"markdown","source":["# CSV Parser"],"metadata":{"id":"e1ovcqjXKbEr"}},{"cell_type":"code","source":["from langchain.output_parsers import CommaSeparatedListOutputParser\n","from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"kfmno8J-LKcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_parser = CommaSeparatedListOutputParser()\n","\n","format_instructions = output_parser.get_format_instructions()\n","prompt = PromptTemplate(\n","    template=\"List five {subject}.\\n{format_instructions}\",\n","    input_variables=[\"subject\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","chain = prompt | llm | output_parser"],"metadata":{"id":"hFeprZ3JLLnF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"subject\": \"LLM\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t39gb7cnLSLn","executionInfo":{"status":"ok","timestamp":1717956328443,"user_tz":300,"elapsed":1141,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"1bf56809-0704-48ac-e535-16f92f820079"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['GPT-3', 'BLOOM', 'T5', 'Codex', 'ELECTRA']"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["for s in chain.stream({\"subject\": \"AI Systems\"}):\n","    print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNLhyjsELW_x","executionInfo":{"status":"ok","timestamp":1717956349644,"user_tz":300,"elapsed":1251,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"163bccd2-cc02-4a9f-8bba-8b3605e4258b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['- ChatGPT\\n- DALL-E 2\\n- Stable Diffusion\\n- AlphaFold\\n- GPT-3']\n"]}]},{"cell_type":"markdown","source":["#Output-fixing parser\n"],"metadata":{"id":"Nhrl-0RhLjqL"}},{"cell_type":"code","source":["from typing import List\n","\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain_core.pydantic_v1 import BaseModel, Field"],"metadata":{"id":"5mHEBgitLoAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Actor(BaseModel):\n","    name: str = Field(description=\"name of an actor\")\n","    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n","\n","actor_query = \"Generate the filmography for a random actor.\"\n","\n","parser = PydanticOutputParser(pydantic_object=Actor)"],"metadata":{"id":"oomvb9jlL1LB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n","#parser.parse(misformatted)"],"metadata":{"id":"Lo_eSJTLL9DD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.output_parsers import OutputFixingParser\n","\n","new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)"],"metadata":{"id":"lWOOvzfkL61N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_parser.parse(misformatted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyEcWDpKMDOE","executionInfo":{"status":"ok","timestamp":1717956530548,"user_tz":300,"elapsed":889,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"2f2135e9-43d7-4877-8b43-756ecdd8d6c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Cast Away', 'Saving Private Ryan'])"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["#Retry parser\n"],"metadata":{"id":"-MUp_WlpMGy2"}},{"cell_type":"code","source":["from langchain.output_parsers import (\n","    OutputFixingParser,\n","    PydanticOutputParser,\n",")\n","from langchain_core.prompts import (\n","    PromptTemplate,\n",")\n","from langchain_core.pydantic_v1 import BaseModel, Field"],"metadata":{"id":"UKpEvhPuMGf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template = \"\"\"Based on the user question, provide an Action and Action Input for what step should be taken.\n","{format_instructions}\n","Question: {query}\n","Response:\"\"\"\n","\n","\n","class Action(BaseModel):\n","    action: str = Field(description=\"action to take\")\n","    action_input: str = Field(description=\"input to the action\")\n","\n","\n","parser = PydanticOutputParser(pydantic_object=Action)"],"metadata":{"id":"5rwyRunmMfUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")"],"metadata":{"id":"pV9Ynx0eMgM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_value = prompt.format_prompt(query=\"who is leo di caprios gf?\")"],"metadata":{"id":"TrfQFOwxMnF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.output_parsers import RetryOutputParser"],"metadata":{"id":"lyE2-5N_MxPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["retry_parser = RetryOutputParser.from_llm(parser=parser, llm=llm)"],"metadata":{"id":"Rm08iIxnMz5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bad_response = '{\"action\": \"search\"}'\n","retry_parser.parse_with_prompt(bad_response, prompt_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXJgZQ90M4ax","executionInfo":{"status":"ok","timestamp":1717956770213,"user_tz":300,"elapsed":1537,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"bf16e6ab-8b77-4c3f-a1b2-fccd64d03d6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Action(action='entity_search', action_input='leo di caprios gf')"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["from langchain_core.runnables import RunnableLambda, RunnableParallel\n","\n","completion_chain = prompt | llm\n","\n","main_chain = RunnableParallel(\n","    completion=completion_chain, prompt_value=prompt\n",") | RunnableLambda(lambda x: retry_parser.parse_with_prompt(**x))\n","\n","\n","main_chain.invoke({\"query\": \"who is leo di caprios gf?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJJUdSNCNMz2","executionInfo":{"status":"ok","timestamp":1717956840579,"user_tz":300,"elapsed":1457,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"1b7d6d66-b7ec-4b3f-81bd-40eb1e55ae7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Action(action='get_celebrity_info', action_input=\"leo di caprio's gf\")"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["#Pydantic parser"],"metadata":{"id":"ufXJvrvDNULI"}},{"cell_type":"code","source":["from typing import List\n","\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field, validator"],"metadata":{"id":"_SPFn23JNW7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your desired data structure.\n","class Joke(BaseModel):\n","    setup: str = Field(description=\"question to set up a joke\")\n","    punchline: str = Field(description=\"answer to resolve the joke\")\n","\n","    # You can add custom validation logic easily with Pydantic.\n","    @validator(\"setup\")\n","    def question_ends_with_question_mark(cls, field):\n","        if field[-1] != \"?\":\n","            raise ValueError(\"Badly formed question!\")\n","        return field\n","\n","# And a query intented to prompt a language model to populate the data structure.\n","joke_query = \"Tell me a joke.\"\n","\n","# Set up a parser + inject instructions into the prompt template.\n","parser = PydanticOutputParser(pydantic_object=Joke)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": joke_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrvE8JlzNito","executionInfo":{"status":"ok","timestamp":1717956929342,"user_tz":300,"elapsed":897,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"d336a60a-e6cc-4f6f-d316-620d17ac3e67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Joke(setup='What do you call a deer with no eyes?', punchline='No idea')"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# Here's another example, but with a compound typed field.\n","class Actor(BaseModel):\n","    name: str = Field(description=\"name of an actor\")\n","    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n","\n","\n","actor_query = \"Generate the filmography for a random actor.\"\n","\n","parser = PydanticOutputParser(pydantic_object=Actor)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": actor_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1hvXr5oNtBX","executionInfo":{"status":"ok","timestamp":1717956974927,"user_tz":300,"elapsed":6843,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"09de2992-ba7d-4df0-9d5c-be219560c0ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Actor(name='Michael Gambon', film_names=['Harry Potter and the Deathly Hallows – Part 2', 'Harry Potter and the Deathly Hallows – Part 1', 'Harry Potter and the Half-Blood Prince', 'Harry Potter and the Order of the Phoenix', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Prisoner of Azkaban', 'Harry Potter and the Chamber of Secrets', \"Harry Potter and the Sorcerer's Stone\", 'Gosford Park', 'Sleepy Hollow', 'The Insider', 'The Singing Detective', 'Mary Reilly', 'A Fish Called Wanda', 'The Cook, the Thief, His Wife & Her Lover', 'The Dead', 'Paris by Night', 'Brideshead Revisited', 'Turtle Diary', 'Langrishe, Go Down', 'The Good Father', 'Another Time, Another Place', 'Heat and Dust', 'The Last September', 'The Honorary Consul', 'The Sea Wolves', 'Conduct Unbecoming', 'Soldier of Orange', 'O Lucky Man!', 'The Ruling Class', 'Loot', 'The Boyfriend', 'The Wrong Box', 'Oh! What a Lovely War', 'The Quiller Memorandum', 'Alfie', 'The Whisperers', 'The Wrong Arm of the Law', 'The Leather Boys', 'Room at the Top', 'The Angry Silence'])"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["#YAML parser\n"],"metadata":{"id":"nq2B8oolOffm"}},{"cell_type":"code","source":["from typing import List\n","\n","from langchain.output_parsers import YamlOutputParser\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field"],"metadata":{"id":"BWMe15e2Oh3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your desired data structure.\n","class Joke(BaseModel):\n","    setup: str = Field(description=\"question to set up a joke\")\n","    punchline: str = Field(description=\"answer to resolve the joke\")"],"metadata":{"id":"ATd7OOQyOkT1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# And a query intented to prompt a language model to populate the data structure.\n","joke_query = \"Tell me a joke.\"\n","\n","# Set up a parser + inject instructions into the prompt template.\n","parser = YamlOutputParser(pydantic_object=Joke)\n","\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","\n","chain.invoke({\"query\": joke_query})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w55C0rnCOtzr","executionInfo":{"status":"ok","timestamp":1717957328737,"user_tz":300,"elapsed":1755,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"c41d53e2-18b0-472c-c220-df174da61177"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Joke(setup='Why did the golfer wear two pairs of pants?', punchline='In case he got a hole-in-one!')"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["#Pandas DataFrame Parser"],"metadata":{"id":"zt80qJBxPMKO"}},{"cell_type":"code","source":["import pprint\n","from typing import Any, Dict\n","\n","import pandas as pd\n","from langchain.output_parsers import PandasDataFrameOutputParser\n","from langchain_core.prompts import PromptTemplate"],"metadata":{"id":"oP11bXHxPO8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Solely for documentation purposes.\n","def format_parser_output(parser_output: Dict[str, Any]) -> None:\n","    for key in parser_output.keys():\n","        parser_output[key] = parser_output[key].to_dict()\n","    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output)"],"metadata":{"id":"9ua9MH1FPS34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your desired Pandas DataFrame.\n","df = pd.DataFrame(\n","    {\n","        \"num_legs\": [2, 4, 8, 0],\n","        \"num_wings\": [2, 0, 0, 0],\n","        \"num_specimen_seen\": [10, 2, 1, 8],\n","    }\n",")\n","\n","# Set up a parser + inject instructions into the prompt template.\n","parser = PandasDataFrameOutputParser(dataframe=df)"],"metadata":{"id":"fEHcrvjMPWGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here's an example of a column operation being performed.\n","df_query = \"Retrieve the num_wings column.\"\n","\n","# Set up the prompt.\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","parser_output = chain.invoke({\"query\": df_query})\n","\n","format_parser_output(parser_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmJbu4OxPZB-","executionInfo":{"status":"ok","timestamp":1717957414023,"user_tz":300,"elapsed":1641,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"25142f06-4513-4a61-95aa-ae11f6747243"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'num_wings': {0: 2,\n","               1: 0,\n","               2: 0,\n","               3: 0}}\n"]}]},{"cell_type":"code","source":["# Here's an example of a row operation being performed.\n","df_query = \"Retrieve the first row.\"\n","\n","# Set up the prompt.\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","parser_output = chain.invoke({\"query\": df_query})\n","\n","format_parser_output(parser_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkATcB8gPfAF","executionInfo":{"status":"ok","timestamp":1717957430537,"user_tz":300,"elapsed":1361,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"c75f1012-6788-497c-eeb2-aefd6aa5368a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'1': {'num_legs': 4,\n","       'num_specimen_seen': 2,\n","       'num_wings': 0}}\n"]}]},{"cell_type":"code","source":["# Here's an example of a random Pandas DataFrame operation limiting the number of rows\n","df_query = \"Retrieve the average of the num_legs column from rows 1 to 3.\"\n","\n","# Set up the prompt.\n","prompt = PromptTemplate(\n","    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n","    input_variables=[\"query\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",")\n","\n","chain = prompt | llm | parser\n","parser_output = chain.invoke({\"query\": df_query})\n","\n","print(parser_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zMMf2K_Prut","executionInfo":{"status":"ok","timestamp":1717957495177,"user_tz":300,"elapsed":1331,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"05bc1711-1860-4a9b-bd19-58f21cbaf670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'mean': 4.0}\n"]}]},{"cell_type":"markdown","source":["#Enum parser"],"metadata":{"id":"DsWaM1QKP2zi"}},{"cell_type":"code","source":["from langchain.output_parsers.enum import EnumOutputParser\n","from enum import Enum\n","\n","class Colors(Enum):\n","    RED = \"red\"\n","    GREEN = \"green\"\n","    BLUE = \"blue\"\n","\n","parser = EnumOutputParser(enum=Colors)"],"metadata":{"id":"XFEdfNt6P3uD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","prompt = PromptTemplate.from_template(\n","    \"\"\"What color eyes does this person have?\n","\n","> Person: {person}\n","\n","Instructions: {instructions}\"\"\"\n",").partial(instructions=parser.get_format_instructions())\n","chain = prompt | llm | parser"],"metadata":{"id":"rsxtfc5oQPWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"person\": \"Frank Sinatra\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T10RvXmEQVrX","executionInfo":{"status":"ok","timestamp":1717957658181,"user_tz":300,"elapsed":945,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"e4f8bc0b-4f7f-4748-f464-6be0c1204e7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Colors.BLUE: 'blue'>"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["#Datetime Parser"],"metadata":{"id":"v5y5AQ-mQciu"}},{"cell_type":"code","source":["from langchain.output_parsers import DatetimeOutputParser\n","from langchain_core.prompts import PromptTemplate\n","\n","output_parser = DatetimeOutputParser()\n","template = \"\"\"Answer the users question:\n","\n","{question}\n","\n","{format_instructions}\"\"\"\n","prompt = PromptTemplate.from_template(\n","    template,\n","    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",")"],"metadata":{"id":"NcsUL0n0QfeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wo25fx1-Qmjg","executionInfo":{"status":"ok","timestamp":1717957719295,"user_tz":300,"elapsed":8,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"f1fec430-e8d1-4cbc-d418-764895341abd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 339-11-29T12:26:50.185690Z, 184-01-27T12:00:45.532358Z, 94-10-31T11:42:31.193366Z\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}')"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["chain = prompt | llm | output_parser\n","output = chain.invoke({\"question\": \"when was OpenAI founded?\"})\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFESHVA6QojB","executionInfo":{"status":"ok","timestamp":1717957749026,"user_tz":300,"elapsed":1370,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"d89083f8-1dc4-4e27-a160-933a4f6ee911"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2015-12-11 00:00:00\n"]}]},{"cell_type":"markdown","source":["#Structured output parser"],"metadata":{"id":"PAHtWYCmQx0Q"}},{"cell_type":"code","source":["from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n","from langchain_core.prompts import PromptTemplate\n","\n","response_schemas = [\n","    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n","    ResponseSchema(\n","        name=\"source\",\n","        description=\"source used to answer the user's question, should be a website.\",\n","    ),\n","]\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n","prompt = PromptTemplate(\n","    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n","    input_variables=[\"question\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n",")\n","\n","chain = prompt | llm | output_parser\n","\n","chain.invoke({\"question\": \"what's the capital of france?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXh2-nNBQ0Fh","executionInfo":{"status":"ok","timestamp":1717957920732,"user_tz":300,"elapsed":1645,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"be0d3e1e-7870-47c9-c803-f09be08b9e9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'Paris is the capital of France.',\n"," 'source': 'https://en.wikipedia.org/wiki/Paris'}"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["chain.invoke({\"question\": \"who's OpenAI founder?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpS28ZtXRact","executionInfo":{"status":"ok","timestamp":1717957941824,"user_tz":300,"elapsed":1329,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"726e51e4-7274-48cc-f5d7-c9536ad597ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'Sam Altman', 'source': 'https://en.wikipedia.org/wiki/OpenAI'}"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["for s in chain.stream({\"question\": \"who's MIT founder?\"}):\n","    print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DT-Wuu7Rfwq","executionInfo":{"status":"ok","timestamp":1717957961314,"user_tz":300,"elapsed":1573,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"07d9a90d-8667-4b52-dc33-fc67dde814f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'answer': 'William Barton Rogers', 'source': 'https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology'}\n"]}]}]}