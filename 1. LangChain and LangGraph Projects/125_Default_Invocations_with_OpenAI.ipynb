{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Default Invocations with OpenAI and LangChain\n",
        "Made by: Wilfredo Aaron Sosa Ramos (AI Lab Manager at RealityAI Labs)"
      ],
      "metadata": {
        "id": "x1OV7ddck3s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://python.langchain.com/docs/how_to/binding/"
      ],
      "metadata": {
        "id": "umCa0-iWk8_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##!. Binding stop sequences"
      ],
      "metadata": {
        "id": "pMUo6DEInWbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GOubauBzjb2M"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain_core langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "fAavo_I1l8mW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Analyse the Software Architecture. Use the format\\n\\nNAME:...\\nDESCRIPTION:...\\nTECH STACK:...\\nQUALITY ATTRIBUTES:...\\nCONSTRAINTS:...\\n\\n\",\n",
        "        ),\n",
        "        (\"human\", \"{desc}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)\n",
        "\n",
        "runnable = (\n",
        "    {\"desc\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(runnable.invoke(\"Microservices for Commercial LLMs\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQmRro2ClTzo",
        "outputId": "a18e9e1f-f16b-4082-c825-ef4120c6acdd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME: Microservices Architecture for Commercial Large Language Models (LLMs)\n",
            "\n",
            "DESCRIPTION: This architecture is designed to support the deployment and management of commercial large language models (LLMs) as microservices. Each microservice encapsulates a specific functionality related to the LLM, such as text generation, sentiment analysis, summarization, and user management. The architecture promotes scalability, maintainability, and independent deployment of services, allowing organizations to efficiently manage and utilize LLMs in various applications.\n",
            "\n",
            "TECH STACK:\n",
            "- **Programming Languages**: Python, JavaScript (Node.js), Go\n",
            "- **Frameworks**: Flask or FastAPI (for Python), Express.js (for Node.js)\n",
            "- **Containerization**: Docker\n",
            "- **Orchestration**: Kubernetes\n",
            "- **API Management**: Istio or Kong\n",
            "- **Data Storage**: PostgreSQL (for structured data), MongoDB (for unstructured data), Redis (for caching)\n",
            "- **Message Broker**: RabbitMQ or Apache Kafka\n",
            "- **Monitoring and Logging**: Prometheus, Grafana, ELK Stack (Elasticsearch, Logstash, Kibana)\n",
            "- **Authentication**: OAuth 2.0, JWT (JSON Web Tokens)\n",
            "\n",
            "QUALITY ATTRIBUTES:\n",
            "- **Scalability**: The architecture can scale horizontally by adding more instances of microservices as demand increases.\n",
            "- **Resilience**: Each microservice can fail independently without affecting the entire system, and mechanisms like circuit breakers can be implemented to enhance fault tolerance.\n",
            "- **Performance**: Optimized for low-latency responses, especially for real-time applications, with caching strategies in place.\n",
            "- **Maintainability**: Code is organized into small, manageable services, making it easier to update and maintain.\n",
            "- **Security**: Implements robust authentication and authorization mechanisms to protect sensitive data and ensure secure access to services.\n",
            "\n",
            "CONSTRAINTS:\n",
            "- **Latency**: Network latency between microservices can impact overall performance, necessitating careful design of service interactions.\n",
            "- **Data Consistency**: Managing data consistency across distributed services can be challenging, requiring strategies like eventual consistency or distributed transactions.\n",
            "- **Complexity**: The microservices architecture introduces additional complexity in terms of deployment, monitoring, and inter-service communication.\n",
            "- **Resource Management**: Each microservice may require significant computational resources, especially for LLMs, leading to potential resource contention.\n",
            "- **Compliance**: Adherence to data protection regulations (e.g., GDPR, CCPA) must be ensured, particularly when handling user data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = (\n",
        "    {\"desc\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model.bind(stop=\"CONSTRAINTS\")\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(runnable.invoke(\"Microservices for Commercial LLMs\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Zwtl0smW3B",
        "outputId": "bd14bf5e-61b6-44c0-ae3f-71b3c6a183cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME: Microservices Architecture for Commercial Large Language Models (LLMs)\n",
            "\n",
            "DESCRIPTION: This architecture leverages a microservices approach to build, deploy, and manage commercial large language models. Each microservice is responsible for a specific functionality, such as model training, inference, data preprocessing, user management, and analytics. This modular design allows for independent scaling, deployment, and maintenance of each service, facilitating rapid development and iteration of LLM capabilities. The architecture supports integration with various data sources and external APIs, enabling a comprehensive ecosystem for language model applications.\n",
            "\n",
            "TECH STACK:\n",
            "- **Programming Languages**: Python (for model development), JavaScript/TypeScript (for frontend services), Go or Java (for backend services)\n",
            "- **Frameworks**: Flask or FastAPI (for Python microservices), Spring Boot (for Java services), Node.js (for JavaScript services)\n",
            "- **Containerization**: Docker (for packaging microservices)\n",
            "- **Orchestration**: Kubernetes (for managing containerized applications)\n",
            "- **Data Storage**: PostgreSQL or MongoDB (for structured and unstructured data), Redis (for caching)\n",
            "- **Message Broker**: RabbitMQ or Apache Kafka (for inter-service communication)\n",
            "- **API Management**: Kong or Istio (for API gateway and service mesh)\n",
            "- **Monitoring and Logging**: Prometheus and Grafana (for monitoring), ELK Stack (for logging)\n",
            "\n",
            "QUALITY ATTRIBUTES:\n",
            "- **Scalability**: Each microservice can be scaled independently based on demand, allowing for efficient resource utilization.\n",
            "- **Resilience**: The architecture is designed to handle failures gracefully, with fallback mechanisms and circuit breakers in place.\n",
            "- **Maintainability**: Modular design promotes easier updates and maintenance, enabling teams to work on different services without affecting others.\n",
            "- **Performance**: Optimized for low-latency responses, especially for inference services, ensuring quick user interactions.\n",
            "- **Security**: Implementing OAuth2 and JWT for secure API access, along with data encryption and secure communication protocols.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Attaching OpenAI tools\n"
      ],
      "metadata": {
        "id": "1Ug0BNTbnbhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "LvDiHIjQnfEp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o-mini\").bind(tools=tools)\n",
        "model.invoke(\"What's the weather in SF, NYC and LA?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh4uUEyFnije",
        "outputId": "0e342683-3837-47b4-f70e-545871de6b7b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IdOzytbBAXKe497XzIIRST5c', 'function': {'arguments': '{\"location\": \"San Francisco, CA\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_P5D3Ho65Z3lFRHVZ2DoVx7DM', 'function': {'arguments': '{\"location\": \"New York City, NY\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_XNKbNnC0ss6KwyQLJKdCVbeG', 'function': {'arguments': '{\"location\": \"Los Angeles, CA\"}', 'name': 'get_current_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 82, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91342142-f795-4525-b772-7c578a563fa7-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_IdOzytbBAXKe497XzIIRST5c', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'New York City, NY'}, 'id': 'call_P5D3Ho65Z3lFRHVZ2DoVx7DM', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles, CA'}, 'id': 'call_XNKbNnC0ss6KwyQLJKdCVbeG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 82, 'output_tokens': 72, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}