{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jcVw7bDeoa-s"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "from typing import Literal\n",
        "\n",
        "class FileType(Enum):\n",
        "    PDF = 'pdf'\n",
        "    CSV = 'csv'\n",
        "    TXT = 'txt'\n",
        "    MD = 'md'\n",
        "    URL = 'url'\n",
        "    PPTX = 'pptx'\n",
        "    DOCX = 'docx'\n",
        "    XLS = 'xls'\n",
        "    XLSX = 'xlsx'\n",
        "    XML = 'xml'\n",
        "    GDOC = 'gdoc'\n",
        "    GSHEET = 'gsheet'\n",
        "    GSLIDE = 'gslide'\n",
        "    GPDF = 'gpdf'\n",
        "    YOUTUBE_URL = 'youtube_url'\n",
        "    IMG = 'img'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Any\n",
        "\n",
        "class RubricGeneratorArgs(BaseModel):\n",
        "    grade_level: Literal[\"elementary\", \"middle\", \"high\", \"college\", \"professional\"] = Field(..., description=\"Educational level to which the content is directed\")\n",
        "    point_scale: str = Field(..., description=\"Point scale used for the assignment (e.g., 100-point scale, 4.0 GPA scale)\")\n",
        "    standard: str = Field(..., description=\"Educational standard or guideline being followed\")\n",
        "    file_type: str = Field(..., description=\"Type of file being handled, according to the defined enumeration\")\n",
        "    file_url: str = Field(..., description=\"URL or path of the file to be processed\")\n",
        "    lang: str = Field(..., description=\"Language in which the file or content is written\")"
      ],
      "metadata": {
        "id": "TeyrFF14pjK4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScoreRange(BaseModel):\n",
        "    label: str = Field(..., description=\"Label for the score range (e.g., 'Excellent', 'Good')\")\n",
        "    min_score: int = Field(..., description=\"Minimum score for this label\")\n",
        "    max_score: int = Field(..., description=\"Maximum score for this label\")\n",
        "    description: str = Field(..., description=\"Description for this score range\")\n",
        "\n",
        "class RubricCriterion(BaseModel):\n",
        "    criterion_name: str = Field(..., description=\"Name of the criterion (e.g., 'Model Implementation')\")\n",
        "    score: Any = Field(..., description=\"Score for the criterion, can be a number, grade, or any value depending on rubric definition\")\n",
        "    score_range: List[ScoreRange] = Field(..., description=\"List of possible score ranges with their respective labels and descriptions\")\n",
        "    description: str = Field(..., description=\"Description of performance at the given score\")\n",
        "\n",
        "class Rubric(BaseModel):\n",
        "    criteria: List[RubricCriterion] = Field(..., description=\"List of all criteria evaluated in the rubric\")\n",
        "    total_score: Any = Field(..., description=\"Total score achieved across all criteria, flexible for different scoring systems\")\n",
        "    max_total_score: Any = Field(..., description=\"Maximum possible total score across all criteria, flexible for different scoring systems\")"
      ],
      "metadata": {
        "id": "v_YMFq7YpqnY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FileHandlerError(Exception):\n",
        "    \"\"\"Raised when a file content cannot be loaded. Used for tools which require file handling.\"\"\"\n",
        "    def __init__(self, message, url=None):\n",
        "        self.message = message\n",
        "        self.url = url\n",
        "        super().__init__(self.message)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.message}\"\n",
        "\n",
        "class ImageHandlerError(Exception):\n",
        "    \"\"\"Raised when an image cannot be loaded. Used for tools which require image handling.\"\"\"\n",
        "    def __init__(self, message, url):\n",
        "        self.message = message\n",
        "        self.url = url\n",
        "        super().__init__(self.message)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.message}\"\n",
        "\n",
        "class VideoTranscriptError(Exception):\n",
        "    \"\"\"Raised when a video transcript cannot be loaded. Used for tools which require video transcripts.\"\"\"\n",
        "    def __init__(self, message, url):\n",
        "        self.message = message\n",
        "        self.url = url\n",
        "        super().__init__(self.message)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.message}\""
      ],
      "metadata": {
        "id": "0HTIBcurrx9h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile document_loaders.py\n",
        "from langchain_community.document_loaders import YoutubeLoader, PyPDFLoader, TextLoader, UnstructuredURLLoader, UnstructuredPowerPointLoader, Docx2txtLoader, UnstructuredExcelLoader, UnstructuredXMLLoader\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "import tempfile\n",
        "import uuid\n",
        "import requests\n",
        "import gdown\n",
        "from enum import Enum\n",
        "\n",
        "class FileType(Enum):\n",
        "    PDF = 'pdf'\n",
        "    CSV = 'csv'\n",
        "    TXT = 'txt'\n",
        "    MD = 'md'\n",
        "    URL = 'url'\n",
        "    PPTX = 'pptx'\n",
        "    DOCX = 'docx'\n",
        "    XLS = 'xls'\n",
        "    XLSX = 'xlsx'\n",
        "    XML = 'xml'\n",
        "    GDOC = 'gdoc'\n",
        "    GSHEET = 'gsheet'\n",
        "    GSLIDE = 'gslide'\n",
        "    GPDF = 'gpdf'\n",
        "    YOUTUBE_URL = 'youtube_url'\n",
        "    IMG = 'img'\n",
        "\n",
        "STRUCTURED_TABULAR_FILE_EXTENSIONS = {\"csv\", \"xls\", \"xlsx\", \"gsheet\", \"xml\"}\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    # Get the directory containing the script file\n",
        "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "    # Combine the script directory with the relative file path\n",
        "    absolute_file_path = os.path.join(script_dir, file_path)\n",
        "\n",
        "    with open(absolute_file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "def get_docs(file_url: str, file_type: str, verbose=True):\n",
        "    file_type = file_type.lower()\n",
        "    try:\n",
        "        file_loader = file_loader_map[FileType(file_type)]\n",
        "        docs = file_loader(file_url, verbose)\n",
        "\n",
        "        return docs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Unsupported file type: {file_type}\")\n",
        "        raise FileHandlerError(f\"Unsupported file type\", file_url) from e\n",
        "\n",
        "class FileHandler:\n",
        "    def __init__(self, file_loader, file_extension):\n",
        "        self.file_loader = file_loader\n",
        "        self.file_extension = file_extension\n",
        "\n",
        "    def load(self, url):\n",
        "        # Generate a unique filename with a UUID prefix\n",
        "        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n",
        "\n",
        "        # Download the file from the URL and save it to a temporary file\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, prefix=unique_filename) as temp_file:\n",
        "            temp_file.write(response.content)\n",
        "            temp_file_path = temp_file.name\n",
        "\n",
        "        # Use the file_loader to load the documents\n",
        "        try:\n",
        "            loader = self.file_loader(file_path=temp_file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"No such file found at {temp_file_path}\")\n",
        "            raise FileHandlerError(f\"No file found\", temp_file_path) from e\n",
        "\n",
        "        try:\n",
        "            documents = loader.load()\n",
        "        except Exception as e:\n",
        "            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n",
        "            raise FileHandlerError(f\"No file content available\", temp_file_path) from e\n",
        "\n",
        "        # Remove the temporary file\n",
        "        os.remove(temp_file_path)\n",
        "\n",
        "        return documents\n",
        "\n",
        "def load_pdf_documents(pdf_url: str, verbose=False):\n",
        "    pdf_loader = FileHandler(PyPDFLoader, \"pdf\")\n",
        "    docs = pdf_loader.load(pdf_url)\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found PDF file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_csv_documents(csv_url: str, verbose=False):\n",
        "    csv_loader = FileHandler(CSVLoader, \"csv\")\n",
        "    docs = csv_loader.load(csv_url)\n",
        "\n",
        "    if docs:\n",
        "        if verbose:\n",
        "            print(f\"Found CSV file\")\n",
        "            print(f\"Splitting documents into {len(docs)} chunks\")\n",
        "\n",
        "        return docs\n",
        "\n",
        "def load_txt_documents(notes_url: str, verbose=False):\n",
        "    notes_loader = FileHandler(TextLoader, \"txt\")\n",
        "    docs = notes_loader.load(notes_url)\n",
        "\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found TXT file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_md_documents(notes_url: str, verbose=False):\n",
        "    notes_loader = FileHandler(TextLoader, \"md\")\n",
        "    docs = notes_loader.load(notes_url)\n",
        "\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found MD file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_url_documents(url: str, verbose=False):\n",
        "    url_loader = UnstructuredURLLoader(urls=[url])\n",
        "    docs = url_loader.load()\n",
        "\n",
        "    if docs:\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found URL\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_pptx_documents(pptx_url: str, verbose=False):\n",
        "    pptx_handler = FileHandler(UnstructuredPowerPointLoader, 'pptx')\n",
        "\n",
        "    docs = pptx_handler.load(pptx_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found PPTX file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_docx_documents(docx_url: str, verbose=False):\n",
        "    docx_handler = FileHandler(Docx2txtLoader, 'docx')\n",
        "    docs = docx_handler.load(docx_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found DOCX file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_xls_documents(xls_url: str, verbose=False):\n",
        "    xls_handler = FileHandler(UnstructuredExcelLoader, 'xls')\n",
        "    docs = xls_handler.load(xls_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found XLS file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_xlsx_documents(xlsx_url: str, verbose=False):\n",
        "    xlsx_handler = FileHandler(UnstructuredExcelLoader, 'xlsx')\n",
        "    docs = xlsx_handler.load(xlsx_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found XLSX file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_xml_documents(xml_url: str, verbose=False):\n",
        "    xml_handler = FileHandler(UnstructuredXMLLoader, 'xml')\n",
        "    docs = xml_handler.load(xml_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found XML file\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "class FileHandlerForGoogleDrive:\n",
        "    def __init__(self, file_loader, file_extension='docx'):\n",
        "        self.file_loader = file_loader\n",
        "        self.file_extension = file_extension\n",
        "\n",
        "    def load(self, url):\n",
        "\n",
        "        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n",
        "\n",
        "        try:\n",
        "            gdown.download(url=url, output=unique_filename, fuzzy=True)\n",
        "        except Exception as e:\n",
        "            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n",
        "            raise FileHandlerError(f\"No file content available\") from e\n",
        "\n",
        "        try:\n",
        "            loader = self.file_loader(file_path=unique_filename)\n",
        "        except Exception as e:\n",
        "            print(f\"No such file found at {unique_filename}\")\n",
        "            raise FileHandlerError(f\"No file found\", unique_filename) from e\n",
        "\n",
        "        try:\n",
        "            documents = loader.load()\n",
        "        except Exception as e:\n",
        "            print(f\"File content might be private or unavailable or the URL is incorrect.\")\n",
        "            raise FileHandlerError(f\"No file content available\") from e\n",
        "\n",
        "        os.remove(unique_filename)\n",
        "\n",
        "        return documents\n",
        "\n",
        "def load_gdocs_documents(drive_folder_url: str, verbose=False):\n",
        "\n",
        "    gdocs_loader = FileHandlerForGoogleDrive(Docx2txtLoader)\n",
        "\n",
        "    docs = gdocs_loader.load(drive_folder_url)\n",
        "\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found Google Docs files\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_gsheets_documents(drive_folder_url: str, verbose=False):\n",
        "    gsheets_loader = FileHandlerForGoogleDrive(UnstructuredExcelLoader, 'xlsx')\n",
        "    docs = gsheets_loader.load(drive_folder_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found Google Sheets files\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_gslides_documents(drive_folder_url: str, verbose=False):\n",
        "    gslides_loader = FileHandlerForGoogleDrive(UnstructuredPowerPointLoader, 'pptx')\n",
        "    docs = gslides_loader.load(drive_folder_url)\n",
        "    if docs:\n",
        "\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found Google Slides files\")\n",
        "            print(f\"Splitting documents into {len(split_docs)} chunks\")\n",
        "\n",
        "        return split_docs\n",
        "\n",
        "def load_gpdf_documents(drive_folder_url: str, verbose=False):\n",
        "\n",
        "    gpdf_loader = FileHandlerForGoogleDrive(PyPDFLoader,'pdf')\n",
        "\n",
        "    docs = gpdf_loader.load(drive_folder_url)\n",
        "    if docs:\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Found Google PDF files\")\n",
        "            print(f\"Splitting documents into {len(docs)} chunks\")\n",
        "\n",
        "        return docs\n",
        "\n",
        "def load_docs_youtube_url(youtube_url: str, verbose=True) -> str:\n",
        "    try:\n",
        "        loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=True)\n",
        "    except Exception as e:\n",
        "        print(f\"No such video found at {youtube_url}\")\n",
        "        raise VideoTranscriptError(f\"No video found\", youtube_url) from e\n",
        "\n",
        "    try:\n",
        "        docs = loader.load()\n",
        "        length = docs[0].metadata[\"length\"]\n",
        "        title = docs[0].metadata[\"title\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Video transcript might be private or unavailable in 'en' or the URL is incorrect.\")\n",
        "        raise VideoTranscriptError(f\"No video transcripts available\", youtube_url) from e\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Found video with title: {title} and length: {length}\")\n",
        "        print(f\"Combined documents into a single string.\")\n",
        "        print(f\"Beginning to process transcript...\")\n",
        "\n",
        "    split_docs = splitter.split_documents(docs)\n",
        "\n",
        "    return split_docs\n",
        "\n",
        "llm_for_img = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "def generate_docs_from_img(img_url, verbose: bool=False):\n",
        "    message = HumanMessage(\n",
        "    content=[\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Give me a summary of what you see in the image. It must be 3 detailed paragraphs.\",\n",
        "            },\n",
        "            {\"type\": \"image_url\", \"image_url\": img_url},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = llm_for_img.invoke([message]).content\n",
        "        print(f\"Generated summary: {response}\")\n",
        "        docs = Document(page_content=response, metadata={\"source\": img_url})\n",
        "        split_docs = splitter.split_documents([docs])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing the request due to Invalid Content or Invalid Image URL\")\n",
        "        raise ImageHandlerError(f\"Error processing the request\", img_url) from e\n",
        "\n",
        "    return split_docs\n",
        "\n",
        "file_loader_map = {\n",
        "    FileType.PDF: load_pdf_documents,\n",
        "    FileType.CSV: load_csv_documents,\n",
        "    FileType.TXT: load_txt_documents,\n",
        "    FileType.MD: load_md_documents,\n",
        "    FileType.URL: load_url_documents,\n",
        "    FileType.PPTX: load_pptx_documents,\n",
        "    FileType.DOCX: load_docx_documents,\n",
        "    FileType.XLS: load_xls_documents,\n",
        "    FileType.XLSX: load_xlsx_documents,\n",
        "    FileType.XML: load_xml_documents,\n",
        "    FileType.GDOC: load_gdocs_documents,\n",
        "    FileType.GSHEET: load_gsheets_documents,\n",
        "    FileType.GSLIDE: load_gslides_documents,\n",
        "    FileType.GPDF: load_gpdf_documents,\n",
        "    FileType.YOUTUBE_URL: load_docs_youtube_url,\n",
        "    FileType.IMG: generate_docs_from_img\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDwEAoAkr-Zb",
        "outputId": "e278853a-f5b5-4b7a-9fab-a98e56a4daf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting document_loaders.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-google-genai langchain_community langchain-chroma chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Vzej1XsAC7",
        "outputId": "afac072c-612e-4230-f6a7-e4cd10a11189"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: chroma in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.128)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.9)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.30.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.6.6)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.8.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.38.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.4.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf fpdf youtube-transcript-api pytube unstructured python-pptx docx2txt networkx pandas xlrd openpyxl gdown pytest PyPDF2 psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAQRfDGgsCwr",
        "outputId": "e06e6d4d-687f-43d7-9bf4-ddb45124eb6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.15.13)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.13.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.10.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.25.9)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.0.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (10.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (8.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.2)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (5.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y nltk\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjOOSfn4sE4j",
        "outputId": "c12556f2-a3f3-4301-a7ae-b53dd267713e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nltk 3.9.1\n",
            "Uninstalling nltk-3.9.1:\n",
            "  Successfully uninstalled nltk-3.9.1\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Installing collected packages: nltk\n",
            "Successfully installed nltk-3.9.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "import os\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "rLouPRjAsSSG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(file_path):\n",
        "    # Get the current working directory\n",
        "    script_dir = os.getcwd()\n",
        "\n",
        "    # Combine the script directory with the relative file path\n",
        "    absolute_file_path = os.path.join(script_dir, file_path)\n",
        "\n",
        "    try:\n",
        "        with open(absolute_file_path, 'r') as file:\n",
        "            content = file.read()\n",
        "        return content\n",
        "    except FileNotFoundError:\n",
        "        # Handle the case where the file is not found\n",
        "        print(f\"File not found: {absolute_file_path}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "LCghtpsdsTXO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RubricGenerator:\n",
        "    def __init__(self, args=None, vectorstore_class=Chroma, prompt=None, embedding_model=None, model=None, parser=None, verbose=False):\n",
        "        default_config = {\n",
        "            \"model\": GoogleGenerativeAI(model=\"gemini-1.5-flash\"),\n",
        "            \"embedding_model\": GoogleGenerativeAIEmbeddings(model='models/embedding-001'),\n",
        "            \"parser\": JsonOutputParser(pydantic_object=Rubric),\n",
        "            \"prompt\": read_text_file(\"prompt/rubric-generator-cot-prompt.txt\"),\n",
        "            \"vectorstore_class\": Chroma\n",
        "        }\n",
        "\n",
        "        self.prompt = prompt or default_config[\"prompt\"]\n",
        "        self.model = model or default_config[\"model\"]\n",
        "        self.parser = parser or default_config[\"parser\"]\n",
        "        self.embedding_model = embedding_model or default_config[\"embedding_model\"]\n",
        "\n",
        "        self.vectorstore_class = vectorstore_class or default_config[\"vectorstore_class\"]\n",
        "        self.vectorstore, self.retriever, self.runner = None, None, None\n",
        "        self.args = args\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if vectorstore_class is None: raise ValueError(\"Vectorstore must be provided\")\n",
        "        if args.grade_level is None: raise ValueError(\"Grade Level must be provided\")\n",
        "        if args.point_scale is None: raise ValueError(\"Point Scale must be provided\")\n",
        "        if args.standard is None: raise ValueError(\"Standard must be provided\")\n",
        "        if args.lang is None: raise ValueError(\"Language must be provided\")\n",
        "\n",
        "\n",
        "    def compile(self, documents: List[Document]):\n",
        "        # Return the chain\n",
        "        prompt = PromptTemplate(\n",
        "            template=self.prompt,\n",
        "            input_variables=[\"attribute_collection\"],\n",
        "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
        "        )\n",
        "\n",
        "        if self.runner is None:\n",
        "            print(f\"Creating vectorstore from {len(documents)} documents\") if self.verbose else None\n",
        "            self.vectorstore = self.vectorstore_class.from_documents(documents, self.embedding_model)\n",
        "            print(f\"Vectorstore created\") if self.verbose else None\n",
        "\n",
        "            self.retriever = self.vectorstore.as_retriever()\n",
        "            print(f\"Retriever created successfully\") if self.verbose else None\n",
        "\n",
        "            self.runner = RunnableParallel(\n",
        "                {\"context\": self.retriever,\n",
        "                \"attribute_collection\": RunnablePassthrough()\n",
        "                }\n",
        "            )\n",
        "\n",
        "        chain = self.runner | prompt | self.model | self.parser\n",
        "\n",
        "        if self.verbose: print(f\"Chain compilation complete\")\n",
        "\n",
        "        return chain\n",
        "\n",
        "    def generate_rubric(self, documents: List[Document]):\n",
        "        if self.verbose: print(f\"Creating the Rubric\")\n",
        "\n",
        "        chain = self.compile(documents)\n",
        "\n",
        "        response = chain.invoke(f\"Grade Level: {self.args.grade_level}, Point Scale: {self.args.point_scale}, Standard: {self.args.standard}, Language (YOU MUST RESPOND IN THIS LANGUAGE): {self.args.lang}\")\n",
        "\n",
        "        if self.verbose: print(f\"Deleting vectorstore\")\n",
        "        self.vectorstore.delete_collection()\n",
        "\n",
        "        return response"
      ],
      "metadata": {
        "id": "TyMXZOSDsZpf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "GCEser_etrzq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from document_loaders import get_docs\n",
        "\n",
        "input_data = RubricGeneratorArgs(\n",
        "    grade_level=\"professional\",\n",
        "    point_scale=\"100-point scale\",\n",
        "    standard=\"To make an ensemble Machine Learning model\",\n",
        "    file_url=\"https://raw.github.com/AaronSosaRamos/mission-flights/main/files-for-test/sample_input.pdf\",\n",
        "    file_type=\"pdf\",\n",
        "    lang=\"en\"\n",
        ")\n",
        "\n",
        "\n",
        "docs = get_docs(input_data.file_url, input_data.file_type, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cta9ksKXtwzh",
        "outputId": "a7cefe48-ea64-4ffc-c0ae-c4f1837bac9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found PDF file\n",
            "Splitting documents into 5 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEU5RZ52vThW",
        "outputId": "b6a2c25b-e820-4f83-8ae2-a7d2eb956075"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/tmp/5334ff74-cbb7-414a-94eb-a9d14515ce27.pdflknwpthf', 'page': 0}, page_content='Objectiv e:\\nStudentsaretaskedwithbuildinganensemblelearningmodeltopredictflightdelaytimesbasedonflightdata.Theensemblewillconsistofmodelsbuiltfromscratch,includingSupportVectorMachine(SVM),DecisionTrees,andLogisticRegression,usingonlypandasandnumpy.\\nDatasetOverview:\\nYouwillbeprovidedwithadatasetofoutboundflightsfrom2023-2024forLahore(LHE),Karachi(KHI),andIslamabad(ISB)airports.Thedatasetincludesthefollowingfields:\\n●Departuretime\\n●Estimateddeparturetime\\n●Delaytime(inminutes)\\n●Arrivaldetails(destination,time,etc.)\\n●AirlineandflightinformationTask:\\n1.TargetVariable:\\n○Thetargetvariableisdelay_time,whichrepresentsthedelayindeparturetimeinminutes.\\n○Binning:Youwillbinthedelay_timeintoatotalof8bins.2.EnsembleModel:\\n○Youarerequiredtobuildanensemblelearningmodelfromscratch.\\n○Useatleastthreemodelsaslearners:SupportVectorMachine(SVM),DecisionTrees,andLogisticRegression.\\n○ImplementSVMthatsupportsmultiplekernelsonly(e.g.,linear,polynomial,RBF).Single-kernelSVMsarenottobeused.'),\n",
              " Document(metadata={'source': '/tmp/5334ff74-cbb7-414a-94eb-a9d14515ce27.pdflknwpthf', 'page': 0}, page_content='○Youarefreetochoosethenumberandsequenceofmodelsintheensemble.Youcanexperimentwithbaggingorboostingtechniques.\\n○Thereshouldbeatleast3differenttypesofmodelsinyoursequence.3.ModelImplementation:'),\n",
              " Document(metadata={'source': '/tmp/5334ff74-cbb7-414a-94eb-a9d14515ce27.pdflknwpthf', 'page': 1}, page_content=\"○Buildmodelsfromscratchonlyusingpandasandnumpy.Youarenotallowedtouselibrarieslikescikit-learnforthemodelsthemselves.\\n○Implementthefollowingmodelsfromscratch:\\n■Multi-KernelSupportVectorMachine(SVM)\\n■DecisionTreeClassifier\\n■LogisticRegression4.DataPreprocessing:\\n○FeatureSelection:Youarefreetochoosethefeatures(columns)tobeusedforthemodel.Youcanmixandmatchdifferentcolumnsandcreatenewfeatures(e.g.,timeofday,destination).\\n○Handleanymissingorincorrectdatainthedatasetappropriately.\\n○Filterout“active”flightsonlytotrainyourmodel(flightstatus==active).Therestofthedatacleaningisuptoyourselection.5.EvaluationMetrics:\\n○Youwillevaluatetheensemblemodel'sperformanceusingaccuracyandF1-score.\\n○Performcross-validationtoevaluatetherobustnessofyourmodel.6.Deliverables:\\n○SubmitaJupyterNotebookorPythonscriptthat: \\n■Preprocessesthedata\\n■Implementseachofthemodels\\n■Combinesthemodelsintoanensemble\\n■Evaluatestheperformanceoftheensemblemodel\\n○Includeareportdiscussing:\\n■Featureselectionchoices\"),\n",
              " Document(metadata={'source': '/tmp/5334ff74-cbb7-414a-94eb-a9d14515ce27.pdflknwpthf', 'page': 1}, page_content='■Evaluatestheperformanceoftheensemblemodel\\n○Includeareportdiscussing:\\n■Featureselectionchoices\\n■Theensemblemethodused(e.g.,stacking,bagging,boosting)\\n■Evaluationmetricsandmodelperformance\\nBonus:\\n●Implementingmorethan3differenttypesofmodelsinyourensemble.\\n●Achievingaccuracyofmorethan93%'),\n",
              " Document(metadata={'source': '/tmp/5334ff74-cbb7-414a-94eb-a9d14515ce27.pdflknwpthf', 'page': 2}, page_content='Notes:\\n●Focusonbuildingthemodelsfromscratchandexplainingyourapproach.\\n●BuildtheMulti-KernelSVMandexperimentwithdifferentkernelcombinations.\\n●Thestudentsareencouragedtoexperimentwithdifferentcombinationsofmodelsandensemblemethods.\\n●Deadline:Thedeadlinetosubmittheassignmentis\\n14th\\nSeptember\\n2024.Nolatesubmissionwillbeaccepted.Correctandtimelysubmissionoftheassignmentistheresponsibilityofeverystudent;hencenorelaxationwillbegiventoanyone.\\n●HonorPolicy:Thisassignmentisalearningopportunitythatwillbeevaluatedbasedonyourability.Plagiarismcaseswillbedealtwithstrictly.Iffoundplagiarized,boththeinvolvedpartieswillbeawardedzeromarksinthisassignment,alltheremainingassignments,orevenanFgradeinthecourse.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rubric-generator-cot-prompt.txt\n",
        "You are an expert in generating educational assignments resistant to AI tools. Generate three AI-resistant versions of the uploaded assignment while maintaining core educational objectives. Each version should challenge AI tools by incorporating nuanced questions, promoting original thought, or solving complex problems. Explain briefly how each version increases AI resistance using **Chain-of-Thought (CoT)** reasoning.\n",
        "\n",
        "Here are the grade level, point scale, standard, and language of the assignment:\n",
        "{attribute_collection}\n",
        "\n",
        "Next, generate a rubric based on the provided inputs:\n",
        "- Align the rubric with the grade level, point scale, and standard.\n",
        "- Provide clear grading criteria for each aspect of the assignment with point allocations matching the provided scale.\n",
        "\n",
        "**Follow this steps**:\n",
        "- **Step 1**: Analyze the topic, grade level, and standard.\n",
        "- **Step 2**: Identify how AI tools could solve the original assignment easily.\n",
        "- **Step 3**: Introduce modifications that require higher-order thinking, ambiguity, or real-world application to resist AI-generated responses.\n",
        "- **Step 4**: Explain how each modification adds complexity for AI.\n",
        "\n",
        "Your response should follow this format:\n",
        "{format_instructions}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JvyIXMqvbP_",
        "outputId": "c7bf3b5e-443a-43d7-ccdf-9a3c3bd4b206"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rubric-generator-cot-prompt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = RubricGenerator(args=input_data, verbose=True).generate_rubric(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE6Dc4hy1lP5",
        "outputId": "675c75e2-b539-45dd-a52e-cab42b506d34"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the Rubric\n",
            "Creating vectorstore from 5 documents\n",
            "Vectorstore created\n",
            "Retriever created successfully\n",
            "Chain compilation complete\n",
            "Deleting vectorstore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKJ7Oem_4C5O",
        "outputId": "11d4f08f-5bef-433c-8ba9-3e975253c999"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criteria': [{'criterion_name': 'Ensemble Model Design',\n",
              "   'score': None,\n",
              "   'score_range': [{'label': 'Excellent',\n",
              "     'min_score': 80,\n",
              "     'max_score': 100,\n",
              "     'description': 'Demonstrates a thorough understanding of ensemble techniques and selects appropriate models for the task, considering the strengths and weaknesses of each model. The design is well-justified and addresses the specific challenges of the dataset.'},\n",
              "    {'label': 'Good',\n",
              "     'min_score': 60,\n",
              "     'max_score': 79,\n",
              "     'description': \"Demonstrates a good understanding of ensemble techniques and selects suitable models. The design could be strengthened by further justification and consideration of the dataset's characteristics.\"},\n",
              "    {'label': 'Needs Improvement',\n",
              "     'min_score': 40,\n",
              "     'max_score': 59,\n",
              "     'description': 'Demonstrates a basic understanding of ensemble techniques but the model selection and design lack clarity and justification. The design may not be well-suited for the task.'},\n",
              "    {'label': 'Insufficient',\n",
              "     'min_score': 0,\n",
              "     'max_score': 39,\n",
              "     'description': 'Demonstrates a limited understanding of ensemble techniques and the model design is inadequate. The design does not address the task effectively.'}],\n",
              "   'description': \"Evaluate the student's ability to design an effective ensemble model for the given task. This includes the choice of base models, the ensemble method, and the rationale behind these choices.\"},\n",
              "  {'criterion_name': 'Model Implementation and Evaluation',\n",
              "   'score': None,\n",
              "   'score_range': [{'label': 'Excellent',\n",
              "     'min_score': 80,\n",
              "     'max_score': 100,\n",
              "     'description': 'The student demonstrates a strong understanding of model implementation and evaluation techniques. The ensemble model is implemented correctly, and the evaluation is comprehensive and insightful. The student uses appropriate metrics and visualizations to interpret the results and draw meaningful conclusions.'},\n",
              "    {'label': 'Good',\n",
              "     'min_score': 60,\n",
              "     'max_score': 79,\n",
              "     'description': 'The student demonstrates a good understanding of model implementation and evaluation techniques. The ensemble model is implemented correctly, and the evaluation is adequate. The student uses appropriate metrics and visualizations to interpret the results, but some aspects of the analysis could be strengthened.'},\n",
              "    {'label': 'Needs Improvement',\n",
              "     'min_score': 40,\n",
              "     'max_score': 59,\n",
              "     'description': 'The student demonstrates a basic understanding of model implementation and evaluation techniques. The ensemble model may have some implementation issues or the evaluation is incomplete. The student may not use the most appropriate metrics or visualizations to interpret the results.'},\n",
              "    {'label': 'Insufficient',\n",
              "     'min_score': 0,\n",
              "     'max_score': 39,\n",
              "     'description': 'The student demonstrates a limited understanding of model implementation and evaluation techniques. The ensemble model has significant implementation issues or the evaluation is inadequate. The student does not use appropriate metrics or visualizations to interpret the results.'}],\n",
              "   'description': \"Evaluate the student's ability to implement and evaluate their chosen ensemble model. This includes the code quality, the correctness of the implementation, the choice of evaluation metrics, and the interpretation of the results.\"},\n",
              "  {'criterion_name': 'Critical Analysis and Justification',\n",
              "   'score': None,\n",
              "   'score_range': [{'label': 'Excellent',\n",
              "     'min_score': 80,\n",
              "     'max_score': 100,\n",
              "     'description': \"The student provides a detailed and insightful analysis of the ensemble model's performance. They identify the strengths and weaknesses of the model, discuss potential improvements, and justify their choices throughout the entire process. The analysis is well-supported by evidence and demonstrates a deep understanding of the subject matter.\"},\n",
              "    {'label': 'Good',\n",
              "     'min_score': 60,\n",
              "     'max_score': 79,\n",
              "     'description': \"The student provides a good analysis of the ensemble model's performance. They identify some strengths and weaknesses, discuss potential improvements, and offer reasonable justification for their choices. The analysis is supported by evidence, but could be more detailed and insightful.\"},\n",
              "    {'label': 'Needs Improvement',\n",
              "     'min_score': 40,\n",
              "     'max_score': 59,\n",
              "     'description': \"The student provides a basic analysis of the ensemble model's performance. They may identify some strengths and weaknesses, but the analysis lacks depth and justification. The analysis may not be well-supported by evidence or may not demonstrate a clear understanding of the subject matter.\"},\n",
              "    {'label': 'Insufficient',\n",
              "     'min_score': 0,\n",
              "     'max_score': 39,\n",
              "     'description': \"The student provides a limited analysis of the ensemble model's performance. They may not identify any strengths or weaknesses, and the analysis lacks depth and justification. The analysis is not supported by evidence and does not demonstrate an understanding of the subject matter.\"}],\n",
              "   'description': \"Evaluate the student's ability to critically analyze the performance of their ensemble model and justify their choices. This includes identifying the model's strengths and weaknesses, discussing limitations, and proposing potential improvements.\"}],\n",
              " 'total_score': None,\n",
              " 'max_total_score': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}